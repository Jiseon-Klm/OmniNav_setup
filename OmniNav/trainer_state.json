{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.730995242981065,
  "eval_steps": 2000,
  "global_step": 40000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 9.327488107452663e-05,
      "grad_norm": 210.7359161376953,
      "learning_rate": 3.729951510630362e-09,
      "loss": 3.5608737468719482,
      "memory(GiB)": 39.4,
      "step": 1,
      "train_speed(iter/s)": 0.011432
    },
    {
      "epoch": 0.00046637440537263317,
      "grad_norm": 201.20352172851562,
      "learning_rate": 1.864975755315181e-08,
      "loss": 3.52504301071167,
      "memory(GiB)": 46.43,
      "step": 5,
      "train_speed(iter/s)": 0.047491
    },
    {
      "epoch": 0.0009327488107452663,
      "grad_norm": 210.47483825683594,
      "learning_rate": 3.729951510630362e-08,
      "loss": 3.6650711059570313,
      "memory(GiB)": 51.67,
      "step": 10,
      "token_acc": 0.5212765957446809,
      "train_speed(iter/s)": 0.078319
    },
    {
      "epoch": 0.0013991232161178993,
      "grad_norm": 182.34080505371094,
      "learning_rate": 5.594927265945543e-08,
      "loss": 3.483073043823242,
      "memory(GiB)": 51.67,
      "step": 15,
      "train_speed(iter/s)": 0.101858
    },
    {
      "epoch": 0.0018654976214905327,
      "grad_norm": 188.2194061279297,
      "learning_rate": 7.459903021260724e-08,
      "loss": 3.640935516357422,
      "memory(GiB)": 51.67,
      "step": 20,
      "train_speed(iter/s)": 0.119501
    },
    {
      "epoch": 0.002331872026863166,
      "grad_norm": 341.71466064453125,
      "learning_rate": 9.324878776575905e-08,
      "loss": 3.4519882202148438,
      "memory(GiB)": 51.67,
      "step": 25,
      "train_speed(iter/s)": 0.133411
    },
    {
      "epoch": 0.0027982464322357987,
      "grad_norm": 175.6334991455078,
      "learning_rate": 1.1189854531891086e-07,
      "loss": 3.5988460540771485,
      "memory(GiB)": 51.67,
      "step": 30,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.144044
    },
    {
      "epoch": 0.003264620837608432,
      "grad_norm": 175.93565368652344,
      "learning_rate": 1.3054830287206266e-07,
      "loss": 3.4577064514160156,
      "memory(GiB)": 51.67,
      "step": 35,
      "train_speed(iter/s)": 0.153631
    },
    {
      "epoch": 0.0037309952429810654,
      "grad_norm": 148.1960906982422,
      "learning_rate": 1.4919806042521447e-07,
      "loss": 3.4704872131347657,
      "memory(GiB)": 51.67,
      "step": 40,
      "train_speed(iter/s)": 0.160852
    },
    {
      "epoch": 0.004197369648353698,
      "grad_norm": 152.47666931152344,
      "learning_rate": 1.678478179783663e-07,
      "loss": 3.6149559020996094,
      "memory(GiB)": 51.67,
      "step": 45,
      "token_acc": 0.22580645161290322,
      "train_speed(iter/s)": 0.166926
    },
    {
      "epoch": 0.004663744053726332,
      "grad_norm": 176.0937957763672,
      "learning_rate": 1.864975755315181e-07,
      "loss": 3.38651123046875,
      "memory(GiB)": 51.67,
      "step": 50,
      "train_speed(iter/s)": 0.171874
    },
    {
      "epoch": 0.005130118459098965,
      "grad_norm": 161.67031860351562,
      "learning_rate": 2.051473330846699e-07,
      "loss": 3.2667144775390624,
      "memory(GiB)": 51.68,
      "step": 55,
      "token_acc": 0.3333333333333333,
      "train_speed(iter/s)": 0.177547
    },
    {
      "epoch": 0.005596492864471597,
      "grad_norm": 227.98257446289062,
      "learning_rate": 2.2379709063782172e-07,
      "loss": 3.191252899169922,
      "memory(GiB)": 51.68,
      "step": 60,
      "token_acc": 0.2619047619047619,
      "train_speed(iter/s)": 0.181828
    },
    {
      "epoch": 0.006062867269844231,
      "grad_norm": 123.15029907226562,
      "learning_rate": 2.4244684819097354e-07,
      "loss": 3.1821100234985353,
      "memory(GiB)": 51.68,
      "step": 65,
      "train_speed(iter/s)": 0.186656
    },
    {
      "epoch": 0.006529241675216864,
      "grad_norm": 134.78659057617188,
      "learning_rate": 2.610966057441253e-07,
      "loss": 2.8823137283325195,
      "memory(GiB)": 51.68,
      "step": 70,
      "token_acc": 0.3732394366197183,
      "train_speed(iter/s)": 0.190085
    },
    {
      "epoch": 0.006995616080589497,
      "grad_norm": 111.66292572021484,
      "learning_rate": 2.7974636329727716e-07,
      "loss": 2.5897836685180664,
      "memory(GiB)": 51.68,
      "step": 75,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.19356
    },
    {
      "epoch": 0.007461990485962131,
      "grad_norm": 142.65464782714844,
      "learning_rate": 2.9839612085042895e-07,
      "loss": 2.695927047729492,
      "memory(GiB)": 51.68,
      "step": 80,
      "train_speed(iter/s)": 0.195985
    },
    {
      "epoch": 0.007928364891334763,
      "grad_norm": 92.13248443603516,
      "learning_rate": 3.170458784035808e-07,
      "loss": 2.5649955749511717,
      "memory(GiB)": 51.68,
      "step": 85,
      "train_speed(iter/s)": 0.198455
    },
    {
      "epoch": 0.008394739296707397,
      "grad_norm": 149.289306640625,
      "learning_rate": 3.356956359567326e-07,
      "loss": 2.4705089569091796,
      "memory(GiB)": 51.68,
      "step": 90,
      "train_speed(iter/s)": 0.201021
    },
    {
      "epoch": 0.00886111370208003,
      "grad_norm": 114.48311614990234,
      "learning_rate": 3.5434539350988436e-07,
      "loss": 2.452234077453613,
      "memory(GiB)": 51.68,
      "step": 95,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.20329
    },
    {
      "epoch": 0.009327488107452663,
      "grad_norm": 116.6396713256836,
      "learning_rate": 3.729951510630362e-07,
      "loss": 2.2240358352661134,
      "memory(GiB)": 51.68,
      "step": 100,
      "train_speed(iter/s)": 0.20507
    },
    {
      "epoch": 0.009793862512825297,
      "grad_norm": 195.6654510498047,
      "learning_rate": 3.9164490861618804e-07,
      "loss": 2.021519088745117,
      "memory(GiB)": 51.68,
      "step": 105,
      "train_speed(iter/s)": 0.20714
    },
    {
      "epoch": 0.01026023691819793,
      "grad_norm": 89.37862396240234,
      "learning_rate": 4.102946661693398e-07,
      "loss": 1.9094127655029296,
      "memory(GiB)": 51.68,
      "step": 110,
      "train_speed(iter/s)": 0.209321
    },
    {
      "epoch": 0.010726611323570563,
      "grad_norm": 111.26470947265625,
      "learning_rate": 4.2894442372249166e-07,
      "loss": 1.814550018310547,
      "memory(GiB)": 51.68,
      "step": 115,
      "train_speed(iter/s)": 0.210618
    },
    {
      "epoch": 0.011192985728943195,
      "grad_norm": 69.63286590576172,
      "learning_rate": 4.4759418127564345e-07,
      "loss": 1.7438953399658204,
      "memory(GiB)": 51.68,
      "step": 120,
      "token_acc": 0.5416666666666666,
      "train_speed(iter/s)": 0.211961
    },
    {
      "epoch": 0.011659360134315828,
      "grad_norm": 76.23223114013672,
      "learning_rate": 4.6624393882879523e-07,
      "loss": 1.6627290725708008,
      "memory(GiB)": 51.68,
      "step": 125,
      "token_acc": 0.4807692307692308,
      "train_speed(iter/s)": 0.213487
    },
    {
      "epoch": 0.012125734539688461,
      "grad_norm": 74.68894958496094,
      "learning_rate": 4.848936963819471e-07,
      "loss": 1.5910014152526855,
      "memory(GiB)": 51.68,
      "step": 130,
      "train_speed(iter/s)": 0.214502
    },
    {
      "epoch": 0.012592108945061095,
      "grad_norm": 57.71084213256836,
      "learning_rate": 5.035434539350989e-07,
      "loss": 1.5260910034179687,
      "memory(GiB)": 51.68,
      "step": 135,
      "train_speed(iter/s)": 0.215893
    },
    {
      "epoch": 0.013058483350433728,
      "grad_norm": 102.28475952148438,
      "learning_rate": 5.221932114882506e-07,
      "loss": 1.4832871437072754,
      "memory(GiB)": 51.68,
      "step": 140,
      "train_speed(iter/s)": 0.217221
    },
    {
      "epoch": 0.013524857755806361,
      "grad_norm": 114.25234985351562,
      "learning_rate": 5.408429690414025e-07,
      "loss": 1.4183839797973632,
      "memory(GiB)": 51.68,
      "step": 145,
      "train_speed(iter/s)": 0.218448
    },
    {
      "epoch": 0.013991232161178995,
      "grad_norm": 68.54161071777344,
      "learning_rate": 5.594927265945543e-07,
      "loss": 1.3724235534667968,
      "memory(GiB)": 51.68,
      "step": 150,
      "train_speed(iter/s)": 0.219414
    },
    {
      "epoch": 0.014457606566551628,
      "grad_norm": 89.3626708984375,
      "learning_rate": 5.781424841477061e-07,
      "loss": 1.4508925437927247,
      "memory(GiB)": 51.68,
      "step": 155,
      "token_acc": 0.39080459770114945,
      "train_speed(iter/s)": 0.220259
    },
    {
      "epoch": 0.014923980971924261,
      "grad_norm": 61.39042663574219,
      "learning_rate": 5.967922417008579e-07,
      "loss": 1.3574045181274415,
      "memory(GiB)": 51.68,
      "step": 160,
      "train_speed(iter/s)": 0.220815
    },
    {
      "epoch": 0.015390355377296895,
      "grad_norm": 67.08682250976562,
      "learning_rate": 6.154419992540098e-07,
      "loss": 1.299306297302246,
      "memory(GiB)": 51.68,
      "step": 165,
      "token_acc": 0.3541666666666667,
      "train_speed(iter/s)": 0.221746
    },
    {
      "epoch": 0.015856729782669526,
      "grad_norm": 74.51654052734375,
      "learning_rate": 6.340917568071616e-07,
      "loss": 1.2998555183410645,
      "memory(GiB)": 51.68,
      "step": 170,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.22245
    },
    {
      "epoch": 0.01632310418804216,
      "grad_norm": 107.90562438964844,
      "learning_rate": 6.527415143603135e-07,
      "loss": 1.2337539672851563,
      "memory(GiB)": 51.68,
      "step": 175,
      "token_acc": 0.6907216494845361,
      "train_speed(iter/s)": 0.223089
    },
    {
      "epoch": 0.016789478593414793,
      "grad_norm": 150.3370361328125,
      "learning_rate": 6.713912719134652e-07,
      "loss": 1.250284767150879,
      "memory(GiB)": 51.68,
      "step": 180,
      "train_speed(iter/s)": 0.223904
    },
    {
      "epoch": 0.017255852998787426,
      "grad_norm": 112.08918762207031,
      "learning_rate": 6.900410294666169e-07,
      "loss": 1.2726531982421876,
      "memory(GiB)": 51.68,
      "step": 185,
      "train_speed(iter/s)": 0.224761
    },
    {
      "epoch": 0.01772222740416006,
      "grad_norm": 125.36062622070312,
      "learning_rate": 7.086907870197687e-07,
      "loss": 1.2660661697387696,
      "memory(GiB)": 51.68,
      "step": 190,
      "train_speed(iter/s)": 0.225553
    },
    {
      "epoch": 0.018188601809532693,
      "grad_norm": 80.46731567382812,
      "learning_rate": 7.273405445729206e-07,
      "loss": 1.263247585296631,
      "memory(GiB)": 51.68,
      "step": 195,
      "token_acc": 0.575,
      "train_speed(iter/s)": 0.226166
    },
    {
      "epoch": 0.018654976214905326,
      "grad_norm": 67.6028060913086,
      "learning_rate": 7.459903021260724e-07,
      "loss": 1.2200023651123046,
      "memory(GiB)": 51.68,
      "step": 200,
      "token_acc": 0.5588235294117647,
      "train_speed(iter/s)": 0.226688
    },
    {
      "epoch": 0.01912135062027796,
      "grad_norm": 76.31006622314453,
      "learning_rate": 7.646400596792242e-07,
      "loss": 1.2543262481689452,
      "memory(GiB)": 51.68,
      "step": 205,
      "token_acc": 0.313953488372093,
      "train_speed(iter/s)": 0.227406
    },
    {
      "epoch": 0.019587725025650593,
      "grad_norm": 1399.07080078125,
      "learning_rate": 7.832898172323761e-07,
      "loss": 1.273414421081543,
      "memory(GiB)": 51.68,
      "step": 210,
      "token_acc": 0.43548387096774194,
      "train_speed(iter/s)": 0.227937
    },
    {
      "epoch": 0.020054099431023226,
      "grad_norm": 150.62527465820312,
      "learning_rate": 8.019395747855279e-07,
      "loss": 1.293412971496582,
      "memory(GiB)": 51.68,
      "step": 215,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.228432
    },
    {
      "epoch": 0.02052047383639586,
      "grad_norm": 157.24029541015625,
      "learning_rate": 8.205893323386796e-07,
      "loss": 1.192599391937256,
      "memory(GiB)": 51.68,
      "step": 220,
      "token_acc": 0.5578231292517006,
      "train_speed(iter/s)": 0.229032
    },
    {
      "epoch": 0.020986848241768493,
      "grad_norm": 93.05335235595703,
      "learning_rate": 8.392390898918315e-07,
      "loss": 1.2990072250366211,
      "memory(GiB)": 51.68,
      "step": 225,
      "token_acc": 0.7111111111111111,
      "train_speed(iter/s)": 0.229811
    },
    {
      "epoch": 0.021453222647141126,
      "grad_norm": 102.88851165771484,
      "learning_rate": 8.578888474449833e-07,
      "loss": 1.2819766998291016,
      "memory(GiB)": 51.68,
      "step": 230,
      "train_speed(iter/s)": 0.230325
    },
    {
      "epoch": 0.02191959705251376,
      "grad_norm": 80.25981140136719,
      "learning_rate": 8.76538604998135e-07,
      "loss": 1.2190681457519532,
      "memory(GiB)": 51.68,
      "step": 235,
      "train_speed(iter/s)": 0.230714
    },
    {
      "epoch": 0.02238597145788639,
      "grad_norm": 124.5072021484375,
      "learning_rate": 8.951883625512869e-07,
      "loss": 1.2481488227844237,
      "memory(GiB)": 51.68,
      "step": 240,
      "token_acc": 0.5490196078431373,
      "train_speed(iter/s)": 0.231188
    },
    {
      "epoch": 0.022852345863259023,
      "grad_norm": 113.876708984375,
      "learning_rate": 9.138381201044387e-07,
      "loss": 1.2072007179260253,
      "memory(GiB)": 51.68,
      "step": 245,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.231477
    },
    {
      "epoch": 0.023318720268631656,
      "grad_norm": 133.31532287597656,
      "learning_rate": 9.324878776575905e-07,
      "loss": 1.2188531875610351,
      "memory(GiB)": 51.68,
      "step": 250,
      "train_speed(iter/s)": 0.231845
    },
    {
      "epoch": 0.02378509467400429,
      "grad_norm": 111.1266098022461,
      "learning_rate": 9.511376352107424e-07,
      "loss": 1.2578835487365723,
      "memory(GiB)": 51.68,
      "step": 255,
      "token_acc": 0.35714285714285715,
      "train_speed(iter/s)": 0.232453
    },
    {
      "epoch": 0.024251469079376923,
      "grad_norm": 148.4925994873047,
      "learning_rate": 9.697873927638941e-07,
      "loss": 1.199843978881836,
      "memory(GiB)": 51.68,
      "step": 260,
      "train_speed(iter/s)": 0.232832
    },
    {
      "epoch": 0.024717843484749556,
      "grad_norm": 185.51925659179688,
      "learning_rate": 9.88437150317046e-07,
      "loss": 1.1955169677734374,
      "memory(GiB)": 51.68,
      "step": 265,
      "token_acc": 0.6680327868852459,
      "train_speed(iter/s)": 0.2334
    },
    {
      "epoch": 0.02518421789012219,
      "grad_norm": 139.64584350585938,
      "learning_rate": 1.0070869078701977e-06,
      "loss": 1.1900362014770507,
      "memory(GiB)": 51.68,
      "step": 270,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.233727
    },
    {
      "epoch": 0.025650592295494823,
      "grad_norm": 384.14691162109375,
      "learning_rate": 1.0257366654233495e-06,
      "loss": 1.2797383308410644,
      "memory(GiB)": 51.68,
      "step": 275,
      "train_speed(iter/s)": 0.233972
    },
    {
      "epoch": 0.026116966700867456,
      "grad_norm": 86.4690170288086,
      "learning_rate": 1.0443864229765013e-06,
      "loss": 1.249506950378418,
      "memory(GiB)": 51.68,
      "step": 280,
      "train_speed(iter/s)": 0.234425
    },
    {
      "epoch": 0.02658334110624009,
      "grad_norm": 112.65374755859375,
      "learning_rate": 1.0630361805296533e-06,
      "loss": 1.1974543571472167,
      "memory(GiB)": 51.68,
      "step": 285,
      "train_speed(iter/s)": 0.234855
    },
    {
      "epoch": 0.027049715511612723,
      "grad_norm": 110.80262756347656,
      "learning_rate": 1.081685938082805e-06,
      "loss": 1.1846012115478515,
      "memory(GiB)": 51.68,
      "step": 290,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.234899
    },
    {
      "epoch": 0.027516089916985356,
      "grad_norm": 102.3472671508789,
      "learning_rate": 1.1003356956359569e-06,
      "loss": 1.1726844787597657,
      "memory(GiB)": 51.68,
      "step": 295,
      "train_speed(iter/s)": 0.23499
    },
    {
      "epoch": 0.02798246432235799,
      "grad_norm": 103.48278045654297,
      "learning_rate": 1.1189854531891086e-06,
      "loss": 1.1526954650878907,
      "memory(GiB)": 51.68,
      "step": 300,
      "token_acc": 0.74,
      "train_speed(iter/s)": 0.235278
    },
    {
      "epoch": 0.028448838727730623,
      "grad_norm": 192.25535583496094,
      "learning_rate": 1.1376352107422604e-06,
      "loss": 1.2056344032287598,
      "memory(GiB)": 51.68,
      "step": 305,
      "train_speed(iter/s)": 0.235767
    },
    {
      "epoch": 0.028915213133103256,
      "grad_norm": 212.5478973388672,
      "learning_rate": 1.1562849682954122e-06,
      "loss": 1.2273107528686524,
      "memory(GiB)": 51.68,
      "step": 310,
      "token_acc": 0.39622641509433965,
      "train_speed(iter/s)": 0.23614
    },
    {
      "epoch": 0.02938158753847589,
      "grad_norm": 137.14895629882812,
      "learning_rate": 1.1749347258485642e-06,
      "loss": 1.156326961517334,
      "memory(GiB)": 51.68,
      "step": 315,
      "train_speed(iter/s)": 0.236492
    },
    {
      "epoch": 0.029847961943848523,
      "grad_norm": 148.94752502441406,
      "learning_rate": 1.1935844834017158e-06,
      "loss": 1.2038366317749023,
      "memory(GiB)": 51.68,
      "step": 320,
      "token_acc": 0.5362318840579711,
      "train_speed(iter/s)": 0.236733
    },
    {
      "epoch": 0.030314336349221156,
      "grad_norm": 165.81094360351562,
      "learning_rate": 1.2122342409548676e-06,
      "loss": 1.1679052352905273,
      "memory(GiB)": 51.68,
      "step": 325,
      "train_speed(iter/s)": 0.236944
    },
    {
      "epoch": 0.03078071075459379,
      "grad_norm": 103.7788314819336,
      "learning_rate": 1.2308839985080196e-06,
      "loss": 1.2054795265197753,
      "memory(GiB)": 51.68,
      "step": 330,
      "token_acc": 0.41025641025641024,
      "train_speed(iter/s)": 0.237254
    },
    {
      "epoch": 0.03124708515996642,
      "grad_norm": 87.13988494873047,
      "learning_rate": 1.2495337560611714e-06,
      "loss": 1.135018253326416,
      "memory(GiB)": 51.68,
      "step": 335,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.237604
    },
    {
      "epoch": 0.03171345956533905,
      "grad_norm": 61.4462776184082,
      "learning_rate": 1.2681835136143231e-06,
      "loss": 1.1769727706909179,
      "memory(GiB)": 56.92,
      "step": 340,
      "token_acc": 0.7764705882352941,
      "train_speed(iter/s)": 0.237698
    },
    {
      "epoch": 0.03217983397071169,
      "grad_norm": 179.36961364746094,
      "learning_rate": 1.286833271167475e-06,
      "loss": 1.2030448913574219,
      "memory(GiB)": 56.92,
      "step": 345,
      "token_acc": 0.7285067873303167,
      "train_speed(iter/s)": 0.238156
    },
    {
      "epoch": 0.03264620837608432,
      "grad_norm": 182.7387237548828,
      "learning_rate": 1.305483028720627e-06,
      "loss": 1.1630145072937013,
      "memory(GiB)": 56.92,
      "step": 350,
      "train_speed(iter/s)": 0.238667
    },
    {
      "epoch": 0.033112582781456956,
      "grad_norm": 175.17930603027344,
      "learning_rate": 1.3241327862737785e-06,
      "loss": 1.1525994300842286,
      "memory(GiB)": 56.92,
      "step": 355,
      "token_acc": 0.45217391304347826,
      "train_speed(iter/s)": 0.238906
    },
    {
      "epoch": 0.033578957186829586,
      "grad_norm": 141.5044403076172,
      "learning_rate": 1.3427825438269305e-06,
      "loss": 1.1819128036499023,
      "memory(GiB)": 56.92,
      "step": 360,
      "token_acc": 0.4659090909090909,
      "train_speed(iter/s)": 0.239061
    },
    {
      "epoch": 0.03404533159220222,
      "grad_norm": 91.90411376953125,
      "learning_rate": 1.361432301380082e-06,
      "loss": 1.1113059997558594,
      "memory(GiB)": 56.92,
      "step": 365,
      "token_acc": 0.3469387755102041,
      "train_speed(iter/s)": 0.239266
    },
    {
      "epoch": 0.03451170599757485,
      "grad_norm": 103.47621154785156,
      "learning_rate": 1.3800820589332339e-06,
      "loss": 1.1275400161743163,
      "memory(GiB)": 56.92,
      "step": 370,
      "token_acc": 0.7476635514018691,
      "train_speed(iter/s)": 0.239444
    },
    {
      "epoch": 0.03497808040294749,
      "grad_norm": 180.14695739746094,
      "learning_rate": 1.3987318164863859e-06,
      "loss": 1.1424833297729493,
      "memory(GiB)": 56.92,
      "step": 375,
      "train_speed(iter/s)": 0.239625
    },
    {
      "epoch": 0.03544445480832012,
      "grad_norm": 134.74134826660156,
      "learning_rate": 1.4173815740395374e-06,
      "loss": 1.123141098022461,
      "memory(GiB)": 56.92,
      "step": 380,
      "token_acc": 0.43478260869565216,
      "train_speed(iter/s)": 0.239913
    },
    {
      "epoch": 0.03591082921369275,
      "grad_norm": 144.2066192626953,
      "learning_rate": 1.4360313315926894e-06,
      "loss": 1.1246890068054198,
      "memory(GiB)": 56.92,
      "step": 385,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.240103
    },
    {
      "epoch": 0.036377203619065386,
      "grad_norm": 156.12254333496094,
      "learning_rate": 1.4546810891458412e-06,
      "loss": 1.1587231636047364,
      "memory(GiB)": 56.92,
      "step": 390,
      "token_acc": 0.4307692307692308,
      "train_speed(iter/s)": 0.240346
    },
    {
      "epoch": 0.036843578024438016,
      "grad_norm": 155.9315948486328,
      "learning_rate": 1.473330846698993e-06,
      "loss": 1.0709194183349608,
      "memory(GiB)": 56.92,
      "step": 395,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.240408
    },
    {
      "epoch": 0.03730995242981065,
      "grad_norm": 203.04525756835938,
      "learning_rate": 1.4919806042521448e-06,
      "loss": 1.0948177337646485,
      "memory(GiB)": 56.92,
      "step": 400,
      "token_acc": 0.4722222222222222,
      "train_speed(iter/s)": 0.240691
    },
    {
      "epoch": 0.03777632683518328,
      "grad_norm": 171.58670043945312,
      "learning_rate": 1.5106303618052968e-06,
      "loss": 1.0847496032714843,
      "memory(GiB)": 56.92,
      "step": 405,
      "token_acc": 0.3111111111111111,
      "train_speed(iter/s)": 0.240686
    },
    {
      "epoch": 0.03824270124055592,
      "grad_norm": 106.88188171386719,
      "learning_rate": 1.5292801193584484e-06,
      "loss": 1.1469314575195313,
      "memory(GiB)": 56.92,
      "step": 410,
      "token_acc": 0.43478260869565216,
      "train_speed(iter/s)": 0.240821
    },
    {
      "epoch": 0.03870907564592855,
      "grad_norm": 82.03898620605469,
      "learning_rate": 1.5479298769116001e-06,
      "loss": 1.0884272575378418,
      "memory(GiB)": 56.92,
      "step": 415,
      "token_acc": 0.4383561643835616,
      "train_speed(iter/s)": 0.241006
    },
    {
      "epoch": 0.039175450051301186,
      "grad_norm": 174.97683715820312,
      "learning_rate": 1.5665796344647521e-06,
      "loss": 1.0475749015808105,
      "memory(GiB)": 56.92,
      "step": 420,
      "train_speed(iter/s)": 0.241159
    },
    {
      "epoch": 0.039641824456673816,
      "grad_norm": 131.93353271484375,
      "learning_rate": 1.5852293920179037e-06,
      "loss": 1.0774265289306642,
      "memory(GiB)": 56.92,
      "step": 425,
      "train_speed(iter/s)": 0.241286
    },
    {
      "epoch": 0.04010819886204645,
      "grad_norm": 94.30377197265625,
      "learning_rate": 1.6038791495710557e-06,
      "loss": 1.0840703964233398,
      "memory(GiB)": 56.92,
      "step": 430,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.241292
    },
    {
      "epoch": 0.04057457326741908,
      "grad_norm": 141.02316284179688,
      "learning_rate": 1.6225289071242075e-06,
      "loss": 1.0833208084106445,
      "memory(GiB)": 56.92,
      "step": 435,
      "token_acc": 0.358974358974359,
      "train_speed(iter/s)": 0.241523
    },
    {
      "epoch": 0.04104094767279172,
      "grad_norm": 106.53472137451172,
      "learning_rate": 1.6411786646773593e-06,
      "loss": 1.094611930847168,
      "memory(GiB)": 56.92,
      "step": 440,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.241686
    },
    {
      "epoch": 0.04150732207816435,
      "grad_norm": 148.5647735595703,
      "learning_rate": 1.659828422230511e-06,
      "loss": 1.0967317581176759,
      "memory(GiB)": 56.92,
      "step": 445,
      "train_speed(iter/s)": 0.241887
    },
    {
      "epoch": 0.041973696483536986,
      "grad_norm": 127.91356658935547,
      "learning_rate": 1.678478179783663e-06,
      "loss": 1.0735472679138183,
      "memory(GiB)": 56.92,
      "step": 450,
      "token_acc": 0.41836734693877553,
      "train_speed(iter/s)": 0.242141
    },
    {
      "epoch": 0.042440070888909616,
      "grad_norm": 127.56016540527344,
      "learning_rate": 1.6971279373368146e-06,
      "loss": 1.0981764793395996,
      "memory(GiB)": 56.92,
      "step": 455,
      "train_speed(iter/s)": 0.242217
    },
    {
      "epoch": 0.04290644529428225,
      "grad_norm": 117.95071411132812,
      "learning_rate": 1.7157776948899666e-06,
      "loss": 1.1021392822265625,
      "memory(GiB)": 56.92,
      "step": 460,
      "train_speed(iter/s)": 0.24252
    },
    {
      "epoch": 0.04337281969965488,
      "grad_norm": 85.95834350585938,
      "learning_rate": 1.7344274524431184e-06,
      "loss": 1.1101486206054687,
      "memory(GiB)": 56.92,
      "step": 465,
      "train_speed(iter/s)": 0.24256
    },
    {
      "epoch": 0.04383919410502752,
      "grad_norm": 116.49089050292969,
      "learning_rate": 1.75307720999627e-06,
      "loss": 1.0283349990844726,
      "memory(GiB)": 56.92,
      "step": 470,
      "train_speed(iter/s)": 0.242582
    },
    {
      "epoch": 0.04430556851040015,
      "grad_norm": 93.7326889038086,
      "learning_rate": 1.771726967549422e-06,
      "loss": 1.0636106491088868,
      "memory(GiB)": 56.92,
      "step": 475,
      "token_acc": 0.40350877192982454,
      "train_speed(iter/s)": 0.242723
    },
    {
      "epoch": 0.04477194291577278,
      "grad_norm": 114.8109359741211,
      "learning_rate": 1.7903767251025738e-06,
      "loss": 1.0555529594421387,
      "memory(GiB)": 56.92,
      "step": 480,
      "train_speed(iter/s)": 0.242768
    },
    {
      "epoch": 0.045238317321145416,
      "grad_norm": 498.512451171875,
      "learning_rate": 1.8090264826557256e-06,
      "loss": 1.0429851531982421,
      "memory(GiB)": 56.92,
      "step": 485,
      "train_speed(iter/s)": 0.242798
    },
    {
      "epoch": 0.045704691726518046,
      "grad_norm": 91.03755950927734,
      "learning_rate": 1.8276762402088774e-06,
      "loss": 1.0865204811096192,
      "memory(GiB)": 56.92,
      "step": 490,
      "train_speed(iter/s)": 0.242817
    },
    {
      "epoch": 0.04617106613189068,
      "grad_norm": 521.4534301757812,
      "learning_rate": 1.8463259977620294e-06,
      "loss": 1.0602994918823243,
      "memory(GiB)": 56.92,
      "step": 495,
      "token_acc": 0.35555555555555557,
      "train_speed(iter/s)": 0.243067
    },
    {
      "epoch": 0.04663744053726331,
      "grad_norm": 71.80174255371094,
      "learning_rate": 1.864975755315181e-06,
      "loss": 1.0643844604492188,
      "memory(GiB)": 56.92,
      "step": 500,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.243115
    },
    {
      "epoch": 0.04710381494263595,
      "grad_norm": 88.75274658203125,
      "learning_rate": 1.883625512868333e-06,
      "loss": 1.0583040237426757,
      "memory(GiB)": 56.92,
      "step": 505,
      "token_acc": 0.46774193548387094,
      "train_speed(iter/s)": 0.243173
    },
    {
      "epoch": 0.04757018934800858,
      "grad_norm": 76.51905822753906,
      "learning_rate": 1.9022752704214847e-06,
      "loss": 1.018509864807129,
      "memory(GiB)": 56.92,
      "step": 510,
      "train_speed(iter/s)": 0.243212
    },
    {
      "epoch": 0.048036563753381216,
      "grad_norm": 41.53583526611328,
      "learning_rate": 1.9209250279746363e-06,
      "loss": 1.0279058456420898,
      "memory(GiB)": 56.92,
      "step": 515,
      "train_speed(iter/s)": 0.243474
    },
    {
      "epoch": 0.048502938158753846,
      "grad_norm": 73.38632202148438,
      "learning_rate": 1.9395747855277883e-06,
      "loss": 1.0020262718200683,
      "memory(GiB)": 56.92,
      "step": 520,
      "train_speed(iter/s)": 0.243701
    },
    {
      "epoch": 0.04896931256412648,
      "grad_norm": 128.5280303955078,
      "learning_rate": 1.9582245430809403e-06,
      "loss": 1.0799644470214844,
      "memory(GiB)": 56.92,
      "step": 525,
      "token_acc": 0.8235294117647058,
      "train_speed(iter/s)": 0.243914
    },
    {
      "epoch": 0.04943568696949911,
      "grad_norm": 81.8082046508789,
      "learning_rate": 1.976874300634092e-06,
      "loss": 1.0105111122131347,
      "memory(GiB)": 56.92,
      "step": 530,
      "train_speed(iter/s)": 0.243888
    },
    {
      "epoch": 0.04990206137487175,
      "grad_norm": 92.31826782226562,
      "learning_rate": 1.995524058187244e-06,
      "loss": 1.0521810531616211,
      "memory(GiB)": 56.92,
      "step": 535,
      "train_speed(iter/s)": 0.244001
    },
    {
      "epoch": 0.05036843578024438,
      "grad_norm": 73.99530029296875,
      "learning_rate": 2.0141738157403954e-06,
      "loss": 1.010152244567871,
      "memory(GiB)": 56.92,
      "step": 540,
      "token_acc": 0.3879310344827586,
      "train_speed(iter/s)": 0.244178
    },
    {
      "epoch": 0.050834810185617016,
      "grad_norm": 57.692237854003906,
      "learning_rate": 2.0328235732935474e-06,
      "loss": 1.0482149124145508,
      "memory(GiB)": 56.92,
      "step": 545,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.244282
    },
    {
      "epoch": 0.051301184590989646,
      "grad_norm": 96.9607162475586,
      "learning_rate": 2.051473330846699e-06,
      "loss": 0.9811620712280273,
      "memory(GiB)": 56.92,
      "step": 550,
      "token_acc": 0.2702702702702703,
      "train_speed(iter/s)": 0.24433
    },
    {
      "epoch": 0.05176755899636228,
      "grad_norm": 104.21894073486328,
      "learning_rate": 2.070123088399851e-06,
      "loss": 1.019332504272461,
      "memory(GiB)": 56.92,
      "step": 555,
      "train_speed(iter/s)": 0.244418
    },
    {
      "epoch": 0.05223393340173491,
      "grad_norm": 53.971923828125,
      "learning_rate": 2.0887728459530026e-06,
      "loss": 1.0044968605041504,
      "memory(GiB)": 56.92,
      "step": 560,
      "token_acc": 0.7472527472527473,
      "train_speed(iter/s)": 0.244537
    },
    {
      "epoch": 0.05270030780710755,
      "grad_norm": 68.23368072509766,
      "learning_rate": 2.1074226035061546e-06,
      "loss": 0.9892511367797852,
      "memory(GiB)": 56.92,
      "step": 565,
      "train_speed(iter/s)": 0.244419
    },
    {
      "epoch": 0.05316668221248018,
      "grad_norm": 63.57202911376953,
      "learning_rate": 2.1260723610593066e-06,
      "loss": 1.0373714447021485,
      "memory(GiB)": 56.92,
      "step": 570,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.244412
    },
    {
      "epoch": 0.05363305661785281,
      "grad_norm": 35.66268539428711,
      "learning_rate": 2.144722118612458e-06,
      "loss": 1.0379831314086914,
      "memory(GiB)": 56.92,
      "step": 575,
      "train_speed(iter/s)": 0.244506
    },
    {
      "epoch": 0.054099431023225446,
      "grad_norm": 62.37202072143555,
      "learning_rate": 2.16337187616561e-06,
      "loss": 1.0185842514038086,
      "memory(GiB)": 56.92,
      "step": 580,
      "train_speed(iter/s)": 0.244501
    },
    {
      "epoch": 0.054565805428598076,
      "grad_norm": 43.91986846923828,
      "learning_rate": 2.1820216337187617e-06,
      "loss": 1.0087709426879883,
      "memory(GiB)": 56.92,
      "step": 585,
      "token_acc": 0.39473684210526316,
      "train_speed(iter/s)": 0.244658
    },
    {
      "epoch": 0.05503217983397071,
      "grad_norm": 65.81028747558594,
      "learning_rate": 2.2006713912719137e-06,
      "loss": 0.9694048881530761,
      "memory(GiB)": 56.92,
      "step": 590,
      "train_speed(iter/s)": 0.244677
    },
    {
      "epoch": 0.05549855423934334,
      "grad_norm": 79.18061065673828,
      "learning_rate": 2.2193211488250653e-06,
      "loss": 1.0416038513183594,
      "memory(GiB)": 56.92,
      "step": 595,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.244789
    },
    {
      "epoch": 0.05596492864471598,
      "grad_norm": 82.03192901611328,
      "learning_rate": 2.2379709063782173e-06,
      "loss": 1.0430004119873046,
      "memory(GiB)": 56.92,
      "step": 600,
      "train_speed(iter/s)": 0.244914
    },
    {
      "epoch": 0.05643130305008861,
      "grad_norm": 45.32832336425781,
      "learning_rate": 2.256620663931369e-06,
      "loss": 1.0029691696166991,
      "memory(GiB)": 56.92,
      "step": 605,
      "token_acc": 0.6516129032258065,
      "train_speed(iter/s)": 0.245115
    },
    {
      "epoch": 0.056897677455461246,
      "grad_norm": 44.99311828613281,
      "learning_rate": 2.275270421484521e-06,
      "loss": 1.0490228652954101,
      "memory(GiB)": 56.92,
      "step": 610,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.245315
    },
    {
      "epoch": 0.057364051860833876,
      "grad_norm": 62.60329055786133,
      "learning_rate": 2.293920179037673e-06,
      "loss": 0.9786605834960938,
      "memory(GiB)": 56.92,
      "step": 615,
      "token_acc": 0.36363636363636365,
      "train_speed(iter/s)": 0.245405
    },
    {
      "epoch": 0.05783042626620651,
      "grad_norm": 79.39697265625,
      "learning_rate": 2.3125699365908244e-06,
      "loss": 0.9400054931640625,
      "memory(GiB)": 56.92,
      "step": 620,
      "train_speed(iter/s)": 0.245429
    },
    {
      "epoch": 0.05829680067157914,
      "grad_norm": 49.345340728759766,
      "learning_rate": 2.3312196941439764e-06,
      "loss": 1.0086334228515625,
      "memory(GiB)": 56.92,
      "step": 625,
      "train_speed(iter/s)": 0.245554
    },
    {
      "epoch": 0.05876317507695178,
      "grad_norm": 77.1698226928711,
      "learning_rate": 2.3498694516971284e-06,
      "loss": 0.9653972625732422,
      "memory(GiB)": 56.92,
      "step": 630,
      "token_acc": 0.6804733727810651,
      "train_speed(iter/s)": 0.245679
    },
    {
      "epoch": 0.05922954948232441,
      "grad_norm": 45.21063232421875,
      "learning_rate": 2.36851920925028e-06,
      "loss": 0.9838217735290528,
      "memory(GiB)": 56.92,
      "step": 635,
      "train_speed(iter/s)": 0.245723
    },
    {
      "epoch": 0.059695923887697046,
      "grad_norm": 191.46690368652344,
      "learning_rate": 2.3871689668034316e-06,
      "loss": 0.976252555847168,
      "memory(GiB)": 56.92,
      "step": 640,
      "train_speed(iter/s)": 0.245939
    },
    {
      "epoch": 0.060162298293069676,
      "grad_norm": 91.95693969726562,
      "learning_rate": 2.4058187243565836e-06,
      "loss": 1.0117841720581056,
      "memory(GiB)": 56.92,
      "step": 645,
      "train_speed(iter/s)": 0.245934
    },
    {
      "epoch": 0.06062867269844231,
      "grad_norm": 128.8331298828125,
      "learning_rate": 2.424468481909735e-06,
      "loss": 0.9960404396057129,
      "memory(GiB)": 56.92,
      "step": 650,
      "train_speed(iter/s)": 0.246131
    },
    {
      "epoch": 0.06109504710381494,
      "grad_norm": 55.62227249145508,
      "learning_rate": 2.443118239462887e-06,
      "loss": 1.0111349105834961,
      "memory(GiB)": 56.92,
      "step": 655,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.246136
    },
    {
      "epoch": 0.06156142150918758,
      "grad_norm": 59.28915023803711,
      "learning_rate": 2.461767997016039e-06,
      "loss": 0.96292142868042,
      "memory(GiB)": 56.92,
      "step": 660,
      "train_speed(iter/s)": 0.246269
    },
    {
      "epoch": 0.06202779591456021,
      "grad_norm": 64.02263641357422,
      "learning_rate": 2.4804177545691907e-06,
      "loss": 0.9803004264831543,
      "memory(GiB)": 56.92,
      "step": 665,
      "token_acc": 0.5636363636363636,
      "train_speed(iter/s)": 0.246359
    },
    {
      "epoch": 0.06249417031993284,
      "grad_norm": 183.30209350585938,
      "learning_rate": 2.4990675121223427e-06,
      "loss": 0.9737379074096679,
      "memory(GiB)": 56.92,
      "step": 670,
      "train_speed(iter/s)": 0.246482
    },
    {
      "epoch": 0.06296054472530548,
      "grad_norm": 70.3785629272461,
      "learning_rate": 2.5177172696754943e-06,
      "loss": 0.97615966796875,
      "memory(GiB)": 56.92,
      "step": 675,
      "train_speed(iter/s)": 0.24643
    },
    {
      "epoch": 0.0634269191306781,
      "grad_norm": 66.59649658203125,
      "learning_rate": 2.5363670272286463e-06,
      "loss": 1.0187755584716798,
      "memory(GiB)": 56.92,
      "step": 680,
      "token_acc": 0.6041666666666666,
      "train_speed(iter/s)": 0.246425
    },
    {
      "epoch": 0.06389329353605074,
      "grad_norm": 47.84138107299805,
      "learning_rate": 2.555016784781798e-06,
      "loss": 0.9718610763549804,
      "memory(GiB)": 56.92,
      "step": 685,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.246536
    },
    {
      "epoch": 0.06435966794142338,
      "grad_norm": 170.311279296875,
      "learning_rate": 2.57366654233495e-06,
      "loss": 0.9166287422180176,
      "memory(GiB)": 56.92,
      "step": 690,
      "token_acc": 0.1774193548387097,
      "train_speed(iter/s)": 0.246586
    },
    {
      "epoch": 0.06482604234679601,
      "grad_norm": 45.997562408447266,
      "learning_rate": 2.592316299888102e-06,
      "loss": 0.9443096160888672,
      "memory(GiB)": 56.92,
      "step": 695,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.246661
    },
    {
      "epoch": 0.06529241675216864,
      "grad_norm": 47.56489181518555,
      "learning_rate": 2.610966057441254e-06,
      "loss": 0.9019981384277344,
      "memory(GiB)": 56.92,
      "step": 700,
      "token_acc": 0.7549019607843137,
      "train_speed(iter/s)": 0.246748
    },
    {
      "epoch": 0.06575879115754127,
      "grad_norm": 63.60211944580078,
      "learning_rate": 2.629615814994405e-06,
      "loss": 0.9042244911193847,
      "memory(GiB)": 56.92,
      "step": 705,
      "train_speed(iter/s)": 0.246874
    },
    {
      "epoch": 0.06622516556291391,
      "grad_norm": 65.88733673095703,
      "learning_rate": 2.648265572547557e-06,
      "loss": 0.9882720947265625,
      "memory(GiB)": 56.92,
      "step": 710,
      "token_acc": 0.7610619469026548,
      "train_speed(iter/s)": 0.246984
    },
    {
      "epoch": 0.06669153996828654,
      "grad_norm": 28.369422912597656,
      "learning_rate": 2.666915330100709e-06,
      "loss": 0.9595963478088378,
      "memory(GiB)": 56.92,
      "step": 715,
      "token_acc": 0.4318181818181818,
      "train_speed(iter/s)": 0.247167
    },
    {
      "epoch": 0.06715791437365917,
      "grad_norm": 44.293155670166016,
      "learning_rate": 2.685565087653861e-06,
      "loss": 0.8763935089111328,
      "memory(GiB)": 62.17,
      "step": 720,
      "token_acc": 0.8037383177570093,
      "train_speed(iter/s)": 0.247064
    },
    {
      "epoch": 0.0676242887790318,
      "grad_norm": 46.49625015258789,
      "learning_rate": 2.7042148452070126e-06,
      "loss": 0.886558723449707,
      "memory(GiB)": 62.17,
      "step": 725,
      "train_speed(iter/s)": 0.246874
    },
    {
      "epoch": 0.06809066318440445,
      "grad_norm": 41.89897155761719,
      "learning_rate": 2.722864602760164e-06,
      "loss": 0.9025955200195312,
      "memory(GiB)": 62.17,
      "step": 730,
      "train_speed(iter/s)": 0.246872
    },
    {
      "epoch": 0.06855703758977708,
      "grad_norm": 162.6482391357422,
      "learning_rate": 2.741514360313316e-06,
      "loss": 0.9044649124145507,
      "memory(GiB)": 62.17,
      "step": 735,
      "token_acc": 0.43243243243243246,
      "train_speed(iter/s)": 0.246961
    },
    {
      "epoch": 0.0690234119951497,
      "grad_norm": 32.24056625366211,
      "learning_rate": 2.7601641178664677e-06,
      "loss": 0.9047101974487305,
      "memory(GiB)": 62.17,
      "step": 740,
      "train_speed(iter/s)": 0.247019
    },
    {
      "epoch": 0.06948978640052234,
      "grad_norm": 50.303253173828125,
      "learning_rate": 2.7788138754196197e-06,
      "loss": 0.9380280494689941,
      "memory(GiB)": 62.17,
      "step": 745,
      "token_acc": 0.45714285714285713,
      "train_speed(iter/s)": 0.247112
    },
    {
      "epoch": 0.06995616080589498,
      "grad_norm": 37.47578430175781,
      "learning_rate": 2.7974636329727717e-06,
      "loss": 0.8758926391601562,
      "memory(GiB)": 62.17,
      "step": 750,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.247169
    },
    {
      "epoch": 0.07042253521126761,
      "grad_norm": 68.61675262451172,
      "learning_rate": 2.8161133905259237e-06,
      "loss": 0.8346501350402832,
      "memory(GiB)": 62.17,
      "step": 755,
      "token_acc": 0.8333333333333334,
      "train_speed(iter/s)": 0.24718
    },
    {
      "epoch": 0.07088890961664024,
      "grad_norm": 43.170169830322266,
      "learning_rate": 2.834763148079075e-06,
      "loss": 0.8839046478271484,
      "memory(GiB)": 62.17,
      "step": 760,
      "token_acc": 0.4675324675324675,
      "train_speed(iter/s)": 0.24722
    },
    {
      "epoch": 0.07135528402201287,
      "grad_norm": 32.04035186767578,
      "learning_rate": 2.853412905632227e-06,
      "loss": 0.8565256118774414,
      "memory(GiB)": 62.17,
      "step": 765,
      "train_speed(iter/s)": 0.247266
    },
    {
      "epoch": 0.0718216584273855,
      "grad_norm": 28.417659759521484,
      "learning_rate": 2.872062663185379e-06,
      "loss": 0.8898221969604492,
      "memory(GiB)": 62.17,
      "step": 770,
      "train_speed(iter/s)": 0.247276
    },
    {
      "epoch": 0.07228803283275814,
      "grad_norm": 87.79322814941406,
      "learning_rate": 2.890712420738531e-06,
      "loss": 0.9224433898925781,
      "memory(GiB)": 62.17,
      "step": 775,
      "token_acc": 0.7980769230769231,
      "train_speed(iter/s)": 0.24733
    },
    {
      "epoch": 0.07275440723813077,
      "grad_norm": 57.077327728271484,
      "learning_rate": 2.9093621782916824e-06,
      "loss": 0.8435991287231446,
      "memory(GiB)": 62.17,
      "step": 780,
      "token_acc": 0.4649122807017544,
      "train_speed(iter/s)": 0.247344
    },
    {
      "epoch": 0.0732207816435034,
      "grad_norm": 65.7740249633789,
      "learning_rate": 2.9280119358448344e-06,
      "loss": 0.9026214599609375,
      "memory(GiB)": 62.17,
      "step": 785,
      "train_speed(iter/s)": 0.247419
    },
    {
      "epoch": 0.07368715604887603,
      "grad_norm": 84.4347915649414,
      "learning_rate": 2.946661693397986e-06,
      "loss": 0.8458301544189453,
      "memory(GiB)": 62.17,
      "step": 790,
      "train_speed(iter/s)": 0.247556
    },
    {
      "epoch": 0.07415353045424868,
      "grad_norm": 45.103946685791016,
      "learning_rate": 2.9653114509511376e-06,
      "loss": 0.8635431289672851,
      "memory(GiB)": 62.17,
      "step": 795,
      "token_acc": 0.673469387755102,
      "train_speed(iter/s)": 0.247656
    },
    {
      "epoch": 0.0746199048596213,
      "grad_norm": 88.14518737792969,
      "learning_rate": 2.9839612085042896e-06,
      "loss": 0.892559814453125,
      "memory(GiB)": 62.17,
      "step": 800,
      "train_speed(iter/s)": 0.247767
    },
    {
      "epoch": 0.07508627926499394,
      "grad_norm": 60.14273452758789,
      "learning_rate": 3.0026109660574416e-06,
      "loss": 0.889920425415039,
      "memory(GiB)": 62.17,
      "step": 805,
      "train_speed(iter/s)": 0.247945
    },
    {
      "epoch": 0.07555265367036657,
      "grad_norm": 71.8445816040039,
      "learning_rate": 3.0212607236105936e-06,
      "loss": 0.8631753921508789,
      "memory(GiB)": 62.17,
      "step": 810,
      "train_speed(iter/s)": 0.248082
    },
    {
      "epoch": 0.07601902807573921,
      "grad_norm": 80.77440643310547,
      "learning_rate": 3.039910481163745e-06,
      "loss": 0.8837404251098633,
      "memory(GiB)": 62.17,
      "step": 815,
      "token_acc": 0.4375,
      "train_speed(iter/s)": 0.248064
    },
    {
      "epoch": 0.07648540248111184,
      "grad_norm": 58.26473617553711,
      "learning_rate": 3.0585602387168967e-06,
      "loss": 0.874051284790039,
      "memory(GiB)": 62.17,
      "step": 820,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.248033
    },
    {
      "epoch": 0.07695177688648447,
      "grad_norm": 45.204952239990234,
      "learning_rate": 3.0772099962700487e-06,
      "loss": 0.9217041015625,
      "memory(GiB)": 62.17,
      "step": 825,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.248034
    },
    {
      "epoch": 0.0774181512918571,
      "grad_norm": 47.198734283447266,
      "learning_rate": 3.0958597538232003e-06,
      "loss": 0.8941088676452636,
      "memory(GiB)": 62.17,
      "step": 830,
      "train_speed(iter/s)": 0.248113
    },
    {
      "epoch": 0.07788452569722974,
      "grad_norm": 81.9317398071289,
      "learning_rate": 3.1145095113763523e-06,
      "loss": 0.9028976440429688,
      "memory(GiB)": 62.17,
      "step": 835,
      "train_speed(iter/s)": 0.248266
    },
    {
      "epoch": 0.07835090010260237,
      "grad_norm": 68.92155456542969,
      "learning_rate": 3.1331592689295043e-06,
      "loss": 0.9288089752197266,
      "memory(GiB)": 62.17,
      "step": 840,
      "train_speed(iter/s)": 0.248228
    },
    {
      "epoch": 0.078817274507975,
      "grad_norm": 80.10574340820312,
      "learning_rate": 3.1518090264826563e-06,
      "loss": 0.8940280914306641,
      "memory(GiB)": 62.17,
      "step": 845,
      "train_speed(iter/s)": 0.248242
    },
    {
      "epoch": 0.07928364891334763,
      "grad_norm": 38.67215347290039,
      "learning_rate": 3.1704587840358074e-06,
      "loss": 0.866909408569336,
      "memory(GiB)": 62.17,
      "step": 850,
      "token_acc": 0.8144329896907216,
      "train_speed(iter/s)": 0.248319
    },
    {
      "epoch": 0.07975002331872026,
      "grad_norm": 65.65704345703125,
      "learning_rate": 3.1891085415889594e-06,
      "loss": 0.877146053314209,
      "memory(GiB)": 62.17,
      "step": 855,
      "train_speed(iter/s)": 0.248425
    },
    {
      "epoch": 0.0802163977240929,
      "grad_norm": 42.20389175415039,
      "learning_rate": 3.2077582991421114e-06,
      "loss": 0.9131694793701172,
      "memory(GiB)": 62.17,
      "step": 860,
      "train_speed(iter/s)": 0.248533
    },
    {
      "epoch": 0.08068277212946554,
      "grad_norm": 32.56430435180664,
      "learning_rate": 3.2264080566952634e-06,
      "loss": 0.9031623840332031,
      "memory(GiB)": 62.17,
      "step": 865,
      "train_speed(iter/s)": 0.248574
    },
    {
      "epoch": 0.08114914653483817,
      "grad_norm": 46.6109504699707,
      "learning_rate": 3.245057814248415e-06,
      "loss": 0.8604546546936035,
      "memory(GiB)": 62.17,
      "step": 870,
      "train_speed(iter/s)": 0.248703
    },
    {
      "epoch": 0.0816155209402108,
      "grad_norm": 88.75372314453125,
      "learning_rate": 3.263707571801567e-06,
      "loss": 0.8979324340820313,
      "memory(GiB)": 62.17,
      "step": 875,
      "train_speed(iter/s)": 0.248697
    },
    {
      "epoch": 0.08208189534558344,
      "grad_norm": 83.0352554321289,
      "learning_rate": 3.2823573293547186e-06,
      "loss": 0.8718661308288574,
      "memory(GiB)": 62.17,
      "step": 880,
      "train_speed(iter/s)": 0.24871
    },
    {
      "epoch": 0.08254826975095607,
      "grad_norm": 54.830562591552734,
      "learning_rate": 3.30100708690787e-06,
      "loss": 0.8579471588134766,
      "memory(GiB)": 62.17,
      "step": 885,
      "train_speed(iter/s)": 0.248754
    },
    {
      "epoch": 0.0830146441563287,
      "grad_norm": 38.15312957763672,
      "learning_rate": 3.319656844461022e-06,
      "loss": 0.8822777748107911,
      "memory(GiB)": 62.17,
      "step": 890,
      "train_speed(iter/s)": 0.24881
    },
    {
      "epoch": 0.08348101856170133,
      "grad_norm": 52.352806091308594,
      "learning_rate": 3.338306602014174e-06,
      "loss": 0.82724609375,
      "memory(GiB)": 62.17,
      "step": 895,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.248822
    },
    {
      "epoch": 0.08394739296707397,
      "grad_norm": 58.758758544921875,
      "learning_rate": 3.356956359567326e-06,
      "loss": 0.8104536056518554,
      "memory(GiB)": 62.17,
      "step": 900,
      "train_speed(iter/s)": 0.248873
    },
    {
      "epoch": 0.0844137673724466,
      "grad_norm": 50.39650344848633,
      "learning_rate": 3.3756061171204777e-06,
      "loss": 0.8746109962463379,
      "memory(GiB)": 62.17,
      "step": 905,
      "train_speed(iter/s)": 0.248984
    },
    {
      "epoch": 0.08488014177781923,
      "grad_norm": 39.95426940917969,
      "learning_rate": 3.3942558746736293e-06,
      "loss": 0.8616966247558594,
      "memory(GiB)": 62.17,
      "step": 910,
      "token_acc": 0.4307692307692308,
      "train_speed(iter/s)": 0.249025
    },
    {
      "epoch": 0.08534651618319186,
      "grad_norm": 40.459598541259766,
      "learning_rate": 3.4129056322267813e-06,
      "loss": 0.8535297393798829,
      "memory(GiB)": 62.17,
      "step": 915,
      "train_speed(iter/s)": 0.249112
    },
    {
      "epoch": 0.0858128905885645,
      "grad_norm": 38.54075241088867,
      "learning_rate": 3.4315553897799333e-06,
      "loss": 0.8400049209594727,
      "memory(GiB)": 62.17,
      "step": 920,
      "token_acc": 0.391304347826087,
      "train_speed(iter/s)": 0.249134
    },
    {
      "epoch": 0.08627926499393714,
      "grad_norm": 35.875022888183594,
      "learning_rate": 3.450205147333085e-06,
      "loss": 0.7966182708740235,
      "memory(GiB)": 62.17,
      "step": 925,
      "train_speed(iter/s)": 0.24913
    },
    {
      "epoch": 0.08674563939930977,
      "grad_norm": 146.2338104248047,
      "learning_rate": 3.468854904886237e-06,
      "loss": 0.8334622383117676,
      "memory(GiB)": 62.17,
      "step": 930,
      "token_acc": 0.4852941176470588,
      "train_speed(iter/s)": 0.24912
    },
    {
      "epoch": 0.0872120138046824,
      "grad_norm": 31.438188552856445,
      "learning_rate": 3.487504662439389e-06,
      "loss": 0.8431421279907226,
      "memory(GiB)": 62.17,
      "step": 935,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.249132
    },
    {
      "epoch": 0.08767838821005504,
      "grad_norm": 45.414005279541016,
      "learning_rate": 3.50615441999254e-06,
      "loss": 0.8891298294067382,
      "memory(GiB)": 62.17,
      "step": 940,
      "train_speed(iter/s)": 0.249185
    },
    {
      "epoch": 0.08814476261542767,
      "grad_norm": 65.53409576416016,
      "learning_rate": 3.524804177545692e-06,
      "loss": 0.8255045890808106,
      "memory(GiB)": 62.17,
      "step": 945,
      "train_speed(iter/s)": 0.249262
    },
    {
      "epoch": 0.0886111370208003,
      "grad_norm": 30.92664909362793,
      "learning_rate": 3.543453935098844e-06,
      "loss": 0.8267636299133301,
      "memory(GiB)": 62.17,
      "step": 950,
      "token_acc": 0.41379310344827586,
      "train_speed(iter/s)": 0.249354
    },
    {
      "epoch": 0.08907751142617293,
      "grad_norm": 33.1882438659668,
      "learning_rate": 3.562103692651996e-06,
      "loss": 0.8560462951660156,
      "memory(GiB)": 62.17,
      "step": 955,
      "train_speed(iter/s)": 0.249492
    },
    {
      "epoch": 0.08954388583154556,
      "grad_norm": 45.252113342285156,
      "learning_rate": 3.5807534502051476e-06,
      "loss": 0.8164637565612793,
      "memory(GiB)": 62.17,
      "step": 960,
      "token_acc": 0.37777777777777777,
      "train_speed(iter/s)": 0.249399
    },
    {
      "epoch": 0.0900102602369182,
      "grad_norm": 22.886228561401367,
      "learning_rate": 3.5994032077582996e-06,
      "loss": 0.7953548431396484,
      "memory(GiB)": 62.17,
      "step": 965,
      "train_speed(iter/s)": 0.249377
    },
    {
      "epoch": 0.09047663464229083,
      "grad_norm": 82.62226104736328,
      "learning_rate": 3.618052965311451e-06,
      "loss": 0.860323429107666,
      "memory(GiB)": 62.17,
      "step": 970,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.249439
    },
    {
      "epoch": 0.09094300904766346,
      "grad_norm": 65.23011779785156,
      "learning_rate": 3.6367027228646027e-06,
      "loss": 0.9742920875549317,
      "memory(GiB)": 62.17,
      "step": 975,
      "train_speed(iter/s)": 0.249503
    },
    {
      "epoch": 0.09140938345303609,
      "grad_norm": 73.93451690673828,
      "learning_rate": 3.6553524804177547e-06,
      "loss": 0.8878367424011231,
      "memory(GiB)": 62.17,
      "step": 980,
      "train_speed(iter/s)": 0.24952
    },
    {
      "epoch": 0.09187575785840874,
      "grad_norm": 60.6198844909668,
      "learning_rate": 3.6740022379709067e-06,
      "loss": 0.8932342529296875,
      "memory(GiB)": 62.17,
      "step": 985,
      "train_speed(iter/s)": 0.249568
    },
    {
      "epoch": 0.09234213226378137,
      "grad_norm": 34.24418640136719,
      "learning_rate": 3.6926519955240587e-06,
      "loss": 0.8599510192871094,
      "memory(GiB)": 62.17,
      "step": 990,
      "train_speed(iter/s)": 0.249591
    },
    {
      "epoch": 0.092808506669154,
      "grad_norm": 64.906982421875,
      "learning_rate": 3.7113017530772107e-06,
      "loss": 0.8581548690795898,
      "memory(GiB)": 62.17,
      "step": 995,
      "token_acc": 0.4810126582278481,
      "train_speed(iter/s)": 0.249586
    },
    {
      "epoch": 0.09327488107452662,
      "grad_norm": 31.490144729614258,
      "learning_rate": 3.729951510630362e-06,
      "loss": 0.8581523895263672,
      "memory(GiB)": 62.17,
      "step": 1000,
      "train_speed(iter/s)": 0.249631
    },
    {
      "epoch": 0.09374125547989927,
      "grad_norm": 33.8231315612793,
      "learning_rate": 3.748601268183514e-06,
      "loss": 0.8735894203186035,
      "memory(GiB)": 62.17,
      "step": 1005,
      "train_speed(iter/s)": 0.249691
    },
    {
      "epoch": 0.0942076298852719,
      "grad_norm": 56.42540740966797,
      "learning_rate": 3.767251025736666e-06,
      "loss": 0.892755126953125,
      "memory(GiB)": 62.17,
      "step": 1010,
      "train_speed(iter/s)": 0.249759
    },
    {
      "epoch": 0.09467400429064453,
      "grad_norm": 39.27616500854492,
      "learning_rate": 3.7859007832898174e-06,
      "loss": 0.8781208992004395,
      "memory(GiB)": 62.17,
      "step": 1015,
      "train_speed(iter/s)": 0.249876
    },
    {
      "epoch": 0.09514037869601716,
      "grad_norm": 30.442712783813477,
      "learning_rate": 3.8045505408429694e-06,
      "loss": 0.8533031463623046,
      "memory(GiB)": 62.17,
      "step": 1020,
      "token_acc": 0.36363636363636365,
      "train_speed(iter/s)": 0.249867
    },
    {
      "epoch": 0.0956067531013898,
      "grad_norm": 24.995634078979492,
      "learning_rate": 3.823200298396121e-06,
      "loss": 0.8516355514526367,
      "memory(GiB)": 62.17,
      "step": 1025,
      "token_acc": 0.5697674418604651,
      "train_speed(iter/s)": 0.249841
    },
    {
      "epoch": 0.09607312750676243,
      "grad_norm": 25.289121627807617,
      "learning_rate": 3.8418500559492726e-06,
      "loss": 0.7705880165100097,
      "memory(GiB)": 62.17,
      "step": 1030,
      "train_speed(iter/s)": 0.249879
    },
    {
      "epoch": 0.09653950191213506,
      "grad_norm": 31.224912643432617,
      "learning_rate": 3.860499813502425e-06,
      "loss": 0.7992671966552735,
      "memory(GiB)": 62.17,
      "step": 1035,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.249917
    },
    {
      "epoch": 0.09700587631750769,
      "grad_norm": 48.16119384765625,
      "learning_rate": 3.8791495710555766e-06,
      "loss": 0.8609092712402344,
      "memory(GiB)": 62.17,
      "step": 1040,
      "token_acc": 0.5111111111111111,
      "train_speed(iter/s)": 0.249926
    },
    {
      "epoch": 0.09747225072288032,
      "grad_norm": 36.4152946472168,
      "learning_rate": 3.897799328608728e-06,
      "loss": 0.8046360015869141,
      "memory(GiB)": 62.17,
      "step": 1045,
      "token_acc": 0.5405405405405406,
      "train_speed(iter/s)": 0.250032
    },
    {
      "epoch": 0.09793862512825297,
      "grad_norm": 49.73455810546875,
      "learning_rate": 3.9164490861618806e-06,
      "loss": 0.790306568145752,
      "memory(GiB)": 62.17,
      "step": 1050,
      "token_acc": 0.8791208791208791,
      "train_speed(iter/s)": 0.25003
    },
    {
      "epoch": 0.0984049995336256,
      "grad_norm": 16.658164978027344,
      "learning_rate": 3.935098843715032e-06,
      "loss": 0.7749712944030762,
      "memory(GiB)": 62.17,
      "step": 1055,
      "train_speed(iter/s)": 0.249984
    },
    {
      "epoch": 0.09887137393899822,
      "grad_norm": 27.49326515197754,
      "learning_rate": 3.953748601268184e-06,
      "loss": 0.7607787132263184,
      "memory(GiB)": 62.17,
      "step": 1060,
      "train_speed(iter/s)": 0.250001
    },
    {
      "epoch": 0.09933774834437085,
      "grad_norm": 46.359947204589844,
      "learning_rate": 3.972398358821335e-06,
      "loss": 0.7926037788391114,
      "memory(GiB)": 62.17,
      "step": 1065,
      "train_speed(iter/s)": 0.25005
    },
    {
      "epoch": 0.0998041227497435,
      "grad_norm": 31.516902923583984,
      "learning_rate": 3.991048116374488e-06,
      "loss": 0.8624303817749024,
      "memory(GiB)": 62.17,
      "step": 1070,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.250114
    },
    {
      "epoch": 0.10027049715511613,
      "grad_norm": 70.9835433959961,
      "learning_rate": 4.009697873927639e-06,
      "loss": 0.8859539985656738,
      "memory(GiB)": 62.17,
      "step": 1075,
      "token_acc": 0.4411764705882353,
      "train_speed(iter/s)": 0.250101
    },
    {
      "epoch": 0.10073687156048876,
      "grad_norm": 75.90476989746094,
      "learning_rate": 4.028347631480791e-06,
      "loss": 0.8380186080932617,
      "memory(GiB)": 62.17,
      "step": 1080,
      "train_speed(iter/s)": 0.250062
    },
    {
      "epoch": 0.10120324596586139,
      "grad_norm": 51.60812759399414,
      "learning_rate": 4.046997389033943e-06,
      "loss": 0.8677249908447265,
      "memory(GiB)": 62.17,
      "step": 1085,
      "token_acc": 0.7419354838709677,
      "train_speed(iter/s)": 0.250129
    },
    {
      "epoch": 0.10166962037123403,
      "grad_norm": 57.41059112548828,
      "learning_rate": 4.065647146587095e-06,
      "loss": 0.8255645751953125,
      "memory(GiB)": 62.17,
      "step": 1090,
      "token_acc": 0.4074074074074074,
      "train_speed(iter/s)": 0.250133
    },
    {
      "epoch": 0.10213599477660666,
      "grad_norm": 46.71388244628906,
      "learning_rate": 4.0842969041402464e-06,
      "loss": 0.8192414283752442,
      "memory(GiB)": 62.17,
      "step": 1095,
      "train_speed(iter/s)": 0.250239
    },
    {
      "epoch": 0.10260236918197929,
      "grad_norm": 34.95074462890625,
      "learning_rate": 4.102946661693398e-06,
      "loss": 0.7687406539916992,
      "memory(GiB)": 62.17,
      "step": 1100,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.250182
    },
    {
      "epoch": 0.10306874358735192,
      "grad_norm": 66.86382293701172,
      "learning_rate": 4.12159641924655e-06,
      "loss": 0.7763915538787842,
      "memory(GiB)": 62.17,
      "step": 1105,
      "token_acc": 0.4473684210526316,
      "train_speed(iter/s)": 0.250225
    },
    {
      "epoch": 0.10353511799272457,
      "grad_norm": 28.24251937866211,
      "learning_rate": 4.140246176799702e-06,
      "loss": 0.8253178596496582,
      "memory(GiB)": 62.17,
      "step": 1110,
      "token_acc": 0.7333333333333333,
      "train_speed(iter/s)": 0.250285
    },
    {
      "epoch": 0.1040014923980972,
      "grad_norm": 31.062374114990234,
      "learning_rate": 4.1588959343528536e-06,
      "loss": 0.8507474899291992,
      "memory(GiB)": 62.17,
      "step": 1115,
      "token_acc": 0.5641025641025641,
      "train_speed(iter/s)": 0.250299
    },
    {
      "epoch": 0.10446786680346982,
      "grad_norm": 33.457763671875,
      "learning_rate": 4.177545691906005e-06,
      "loss": 0.7997292518615723,
      "memory(GiB)": 62.17,
      "step": 1120,
      "token_acc": 0.5416666666666666,
      "train_speed(iter/s)": 0.250236
    },
    {
      "epoch": 0.10493424120884245,
      "grad_norm": 78.98963928222656,
      "learning_rate": 4.1961954494591576e-06,
      "loss": 0.8148063659667969,
      "memory(GiB)": 62.17,
      "step": 1125,
      "train_speed(iter/s)": 0.250303
    },
    {
      "epoch": 0.1054006156142151,
      "grad_norm": 60.973026275634766,
      "learning_rate": 4.214845207012309e-06,
      "loss": 0.8670957565307618,
      "memory(GiB)": 62.17,
      "step": 1130,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.250314
    },
    {
      "epoch": 0.10586699001958773,
      "grad_norm": 27.82534408569336,
      "learning_rate": 4.233494964565461e-06,
      "loss": 0.8551342010498046,
      "memory(GiB)": 62.17,
      "step": 1135,
      "token_acc": 0.475,
      "train_speed(iter/s)": 0.250354
    },
    {
      "epoch": 0.10633336442496036,
      "grad_norm": 55.13668441772461,
      "learning_rate": 4.252144722118613e-06,
      "loss": 0.868889331817627,
      "memory(GiB)": 62.17,
      "step": 1140,
      "token_acc": 0.8383838383838383,
      "train_speed(iter/s)": 0.250376
    },
    {
      "epoch": 0.10679973883033299,
      "grad_norm": 20.903505325317383,
      "learning_rate": 4.270794479671765e-06,
      "loss": 0.8027471542358399,
      "memory(GiB)": 62.17,
      "step": 1145,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.250447
    },
    {
      "epoch": 0.10726611323570562,
      "grad_norm": 28.89475440979004,
      "learning_rate": 4.289444237224916e-06,
      "loss": 0.8072380065917969,
      "memory(GiB)": 62.17,
      "step": 1150,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.25048
    },
    {
      "epoch": 0.10773248764107826,
      "grad_norm": 43.66046142578125,
      "learning_rate": 4.308093994778068e-06,
      "loss": 0.8234442710876465,
      "memory(GiB)": 62.17,
      "step": 1155,
      "train_speed(iter/s)": 0.250529
    },
    {
      "epoch": 0.10819886204645089,
      "grad_norm": 61.77642059326172,
      "learning_rate": 4.32674375233122e-06,
      "loss": 0.873018455505371,
      "memory(GiB)": 62.17,
      "step": 1160,
      "train_speed(iter/s)": 0.250569
    },
    {
      "epoch": 0.10866523645182352,
      "grad_norm": 73.13306427001953,
      "learning_rate": 4.345393509884372e-06,
      "loss": 0.8595160484313965,
      "memory(GiB)": 62.17,
      "step": 1165,
      "train_speed(iter/s)": 0.250598
    },
    {
      "epoch": 0.10913161085719615,
      "grad_norm": 32.24338912963867,
      "learning_rate": 4.3640432674375234e-06,
      "loss": 0.8071739196777343,
      "memory(GiB)": 62.17,
      "step": 1170,
      "token_acc": 0.3793103448275862,
      "train_speed(iter/s)": 0.250621
    },
    {
      "epoch": 0.1095979852625688,
      "grad_norm": 20.78465461730957,
      "learning_rate": 4.382693024990676e-06,
      "loss": 0.7866502285003663,
      "memory(GiB)": 62.17,
      "step": 1175,
      "train_speed(iter/s)": 0.25062
    },
    {
      "epoch": 0.11006435966794142,
      "grad_norm": 31.014070510864258,
      "learning_rate": 4.401342782543827e-06,
      "loss": 0.8087422370910644,
      "memory(GiB)": 62.17,
      "step": 1180,
      "token_acc": 0.8260869565217391,
      "train_speed(iter/s)": 0.250711
    },
    {
      "epoch": 0.11053073407331405,
      "grad_norm": 23.528057098388672,
      "learning_rate": 4.419992540096979e-06,
      "loss": 0.7950056552886963,
      "memory(GiB)": 62.17,
      "step": 1185,
      "train_speed(iter/s)": 0.250575
    },
    {
      "epoch": 0.11099710847868668,
      "grad_norm": 33.48573684692383,
      "learning_rate": 4.4386422976501306e-06,
      "loss": 0.7705387115478516,
      "memory(GiB)": 62.17,
      "step": 1190,
      "token_acc": 0.475,
      "train_speed(iter/s)": 0.250585
    },
    {
      "epoch": 0.11146348288405933,
      "grad_norm": 60.377689361572266,
      "learning_rate": 4.457292055203283e-06,
      "loss": 0.8044136047363282,
      "memory(GiB)": 62.17,
      "step": 1195,
      "train_speed(iter/s)": 0.250532
    },
    {
      "epoch": 0.11192985728943196,
      "grad_norm": 22.121789932250977,
      "learning_rate": 4.4759418127564346e-06,
      "loss": 0.7674168586730957,
      "memory(GiB)": 62.17,
      "step": 1200,
      "token_acc": 0.3870967741935484,
      "train_speed(iter/s)": 0.250543
    },
    {
      "epoch": 0.11239623169480459,
      "grad_norm": 21.098834991455078,
      "learning_rate": 4.494591570309587e-06,
      "loss": 0.7825687885284424,
      "memory(GiB)": 62.17,
      "step": 1205,
      "train_speed(iter/s)": 0.250462
    },
    {
      "epoch": 0.11286260610017722,
      "grad_norm": 45.016605377197266,
      "learning_rate": 4.513241327862738e-06,
      "loss": 0.7255446434020996,
      "memory(GiB)": 62.17,
      "step": 1210,
      "token_acc": 0.9041095890410958,
      "train_speed(iter/s)": 0.250496
    },
    {
      "epoch": 0.11332898050554986,
      "grad_norm": 20.10393524169922,
      "learning_rate": 4.53189108541589e-06,
      "loss": 0.8333911895751953,
      "memory(GiB)": 62.17,
      "step": 1215,
      "token_acc": 0.6052631578947368,
      "train_speed(iter/s)": 0.250522
    },
    {
      "epoch": 0.11379535491092249,
      "grad_norm": 47.241085052490234,
      "learning_rate": 4.550540842969042e-06,
      "loss": 0.7570590019226074,
      "memory(GiB)": 62.17,
      "step": 1220,
      "token_acc": 0.8717948717948718,
      "train_speed(iter/s)": 0.250477
    },
    {
      "epoch": 0.11426172931629512,
      "grad_norm": 23.801406860351562,
      "learning_rate": 4.569190600522193e-06,
      "loss": 0.7361990928649902,
      "memory(GiB)": 62.17,
      "step": 1225,
      "token_acc": 0.3382352941176471,
      "train_speed(iter/s)": 0.250465
    },
    {
      "epoch": 0.11472810372166775,
      "grad_norm": 41.2420654296875,
      "learning_rate": 4.587840358075346e-06,
      "loss": 0.7138922691345215,
      "memory(GiB)": 62.17,
      "step": 1230,
      "train_speed(iter/s)": 0.250517
    },
    {
      "epoch": 0.11519447812704038,
      "grad_norm": 26.52727508544922,
      "learning_rate": 4.606490115628497e-06,
      "loss": 0.7901299476623536,
      "memory(GiB)": 62.17,
      "step": 1235,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.25052
    },
    {
      "epoch": 0.11566085253241302,
      "grad_norm": 29.86453628540039,
      "learning_rate": 4.625139873181649e-06,
      "loss": 0.7402325630187988,
      "memory(GiB)": 62.17,
      "step": 1240,
      "token_acc": 0.8681318681318682,
      "train_speed(iter/s)": 0.250542
    },
    {
      "epoch": 0.11612722693778565,
      "grad_norm": 22.87559700012207,
      "learning_rate": 4.6437896307348004e-06,
      "loss": 0.7381308555603028,
      "memory(GiB)": 62.17,
      "step": 1245,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.250533
    },
    {
      "epoch": 0.11659360134315828,
      "grad_norm": 39.644065856933594,
      "learning_rate": 4.662439388287953e-06,
      "loss": 0.847083568572998,
      "memory(GiB)": 62.17,
      "step": 1250,
      "train_speed(iter/s)": 0.250577
    },
    {
      "epoch": 0.11705997574853091,
      "grad_norm": 59.0269660949707,
      "learning_rate": 4.6810891458411044e-06,
      "loss": 0.8938294410705566,
      "memory(GiB)": 62.17,
      "step": 1255,
      "token_acc": 0.7821782178217822,
      "train_speed(iter/s)": 0.250598
    },
    {
      "epoch": 0.11752635015390356,
      "grad_norm": 30.881793975830078,
      "learning_rate": 4.699738903394257e-06,
      "loss": 0.817608642578125,
      "memory(GiB)": 62.17,
      "step": 1260,
      "token_acc": 0.37254901960784315,
      "train_speed(iter/s)": 0.250585
    },
    {
      "epoch": 0.11799272455927619,
      "grad_norm": 33.390262603759766,
      "learning_rate": 4.718388660947408e-06,
      "loss": 0.8029396057128906,
      "memory(GiB)": 62.17,
      "step": 1265,
      "token_acc": 0.7849462365591398,
      "train_speed(iter/s)": 0.250619
    },
    {
      "epoch": 0.11845909896464882,
      "grad_norm": 40.56038284301758,
      "learning_rate": 4.73703841850056e-06,
      "loss": 0.793531847000122,
      "memory(GiB)": 62.17,
      "step": 1270,
      "train_speed(iter/s)": 0.25067
    },
    {
      "epoch": 0.11892547337002145,
      "grad_norm": 28.159940719604492,
      "learning_rate": 4.7556881760537116e-06,
      "loss": 0.7536251068115234,
      "memory(GiB)": 62.17,
      "step": 1275,
      "train_speed(iter/s)": 0.250687
    },
    {
      "epoch": 0.11939184777539409,
      "grad_norm": 31.135665893554688,
      "learning_rate": 4.774337933606863e-06,
      "loss": 0.764673376083374,
      "memory(GiB)": 62.17,
      "step": 1280,
      "train_speed(iter/s)": 0.250734
    },
    {
      "epoch": 0.11985822218076672,
      "grad_norm": 40.557987213134766,
      "learning_rate": 4.7929876911600156e-06,
      "loss": 0.7460342407226562,
      "memory(GiB)": 62.17,
      "step": 1285,
      "train_speed(iter/s)": 0.250708
    },
    {
      "epoch": 0.12032459658613935,
      "grad_norm": 42.018096923828125,
      "learning_rate": 4.811637448713167e-06,
      "loss": 0.6822833061218262,
      "memory(GiB)": 62.17,
      "step": 1290,
      "token_acc": 0.5277777777777778,
      "train_speed(iter/s)": 0.250707
    },
    {
      "epoch": 0.12079097099151198,
      "grad_norm": 33.3181266784668,
      "learning_rate": 4.8302872062663196e-06,
      "loss": 0.7471044540405274,
      "memory(GiB)": 62.17,
      "step": 1295,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.25072
    },
    {
      "epoch": 0.12125734539688462,
      "grad_norm": 25.53984832763672,
      "learning_rate": 4.84893696381947e-06,
      "loss": 0.7854133605957031,
      "memory(GiB)": 62.17,
      "step": 1300,
      "train_speed(iter/s)": 0.250738
    },
    {
      "epoch": 0.12172371980225725,
      "grad_norm": 29.95568084716797,
      "learning_rate": 4.867586721372623e-06,
      "loss": 0.7500211715698242,
      "memory(GiB)": 62.17,
      "step": 1305,
      "train_speed(iter/s)": 0.25075
    },
    {
      "epoch": 0.12219009420762988,
      "grad_norm": 48.995513916015625,
      "learning_rate": 4.886236478925774e-06,
      "loss": 0.8558794021606445,
      "memory(GiB)": 62.17,
      "step": 1310,
      "train_speed(iter/s)": 0.250781
    },
    {
      "epoch": 0.12265646861300251,
      "grad_norm": 39.44974136352539,
      "learning_rate": 4.904886236478926e-06,
      "loss": 0.7534863471984863,
      "memory(GiB)": 62.17,
      "step": 1315,
      "train_speed(iter/s)": 0.250771
    },
    {
      "epoch": 0.12312284301837516,
      "grad_norm": 35.42099380493164,
      "learning_rate": 4.923535994032078e-06,
      "loss": 0.8230669021606445,
      "memory(GiB)": 62.17,
      "step": 1320,
      "train_speed(iter/s)": 0.250764
    },
    {
      "epoch": 0.12358921742374779,
      "grad_norm": 33.78822326660156,
      "learning_rate": 4.94218575158523e-06,
      "loss": 0.7456190586090088,
      "memory(GiB)": 62.17,
      "step": 1325,
      "token_acc": 0.6756756756756757,
      "train_speed(iter/s)": 0.250817
    },
    {
      "epoch": 0.12405559182912042,
      "grad_norm": 38.157249450683594,
      "learning_rate": 4.9608355091383814e-06,
      "loss": 0.8190649032592774,
      "memory(GiB)": 62.17,
      "step": 1330,
      "train_speed(iter/s)": 0.250774
    },
    {
      "epoch": 0.12452196623449305,
      "grad_norm": 39.06794738769531,
      "learning_rate": 4.979485266691533e-06,
      "loss": 0.7724421501159668,
      "memory(GiB)": 62.17,
      "step": 1335,
      "token_acc": 0.647887323943662,
      "train_speed(iter/s)": 0.250755
    },
    {
      "epoch": 0.12498834063986568,
      "grad_norm": 31.77745819091797,
      "learning_rate": 4.998135024244685e-06,
      "loss": 0.7976459503173828,
      "memory(GiB)": 62.17,
      "step": 1340,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.250769
    },
    {
      "epoch": 0.1254547150452383,
      "grad_norm": 43.74226379394531,
      "learning_rate": 5.016784781797836e-06,
      "loss": 0.8264366149902344,
      "memory(GiB)": 62.17,
      "step": 1345,
      "train_speed(iter/s)": 0.250813
    },
    {
      "epoch": 0.12592108945061095,
      "grad_norm": 40.43268585205078,
      "learning_rate": 5.0354345393509886e-06,
      "loss": 0.7738256454467773,
      "memory(GiB)": 62.17,
      "step": 1350,
      "token_acc": 0.39622641509433965,
      "train_speed(iter/s)": 0.250856
    },
    {
      "epoch": 0.1263874638559836,
      "grad_norm": 38.315799713134766,
      "learning_rate": 5.05408429690414e-06,
      "loss": 0.7341506958007813,
      "memory(GiB)": 62.17,
      "step": 1355,
      "train_speed(iter/s)": 0.250837
    },
    {
      "epoch": 0.1268538382613562,
      "grad_norm": 42.61269760131836,
      "learning_rate": 5.0727340544572926e-06,
      "loss": 0.770235824584961,
      "memory(GiB)": 62.17,
      "step": 1360,
      "token_acc": 0.432258064516129,
      "train_speed(iter/s)": 0.250845
    },
    {
      "epoch": 0.12732021266672885,
      "grad_norm": 32.429466247558594,
      "learning_rate": 5.091383812010444e-06,
      "loss": 0.7154937744140625,
      "memory(GiB)": 62.17,
      "step": 1365,
      "token_acc": 0.6808510638297872,
      "train_speed(iter/s)": 0.250857
    },
    {
      "epoch": 0.12778658707210147,
      "grad_norm": 33.79011917114258,
      "learning_rate": 5.110033569563596e-06,
      "loss": 0.7323516845703125,
      "memory(GiB)": 62.17,
      "step": 1370,
      "train_speed(iter/s)": 0.250856
    },
    {
      "epoch": 0.12825296147747411,
      "grad_norm": 27.427072525024414,
      "learning_rate": 5.128683327116748e-06,
      "loss": 0.7136223793029786,
      "memory(GiB)": 62.17,
      "step": 1375,
      "train_speed(iter/s)": 0.250818
    },
    {
      "epoch": 0.12871933588284676,
      "grad_norm": 30.832427978515625,
      "learning_rate": 5.1473330846699e-06,
      "loss": 0.7404566287994385,
      "memory(GiB)": 62.17,
      "step": 1380,
      "token_acc": 0.5892857142857143,
      "train_speed(iter/s)": 0.250803
    },
    {
      "epoch": 0.12918571028821937,
      "grad_norm": 33.10883331298828,
      "learning_rate": 5.165982842223052e-06,
      "loss": 0.7159193992614746,
      "memory(GiB)": 62.17,
      "step": 1385,
      "token_acc": 0.44,
      "train_speed(iter/s)": 0.250837
    },
    {
      "epoch": 0.12965208469359202,
      "grad_norm": 29.898984909057617,
      "learning_rate": 5.184632599776204e-06,
      "loss": 0.72931809425354,
      "memory(GiB)": 62.17,
      "step": 1390,
      "train_speed(iter/s)": 0.250893
    },
    {
      "epoch": 0.13011845909896466,
      "grad_norm": 19.261493682861328,
      "learning_rate": 5.203282357329355e-06,
      "loss": 0.7241591930389404,
      "memory(GiB)": 62.17,
      "step": 1395,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.250911
    },
    {
      "epoch": 0.13058483350433728,
      "grad_norm": 21.773799896240234,
      "learning_rate": 5.221932114882508e-06,
      "loss": 0.7419791221618652,
      "memory(GiB)": 62.17,
      "step": 1400,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.250952
    },
    {
      "epoch": 0.13105120790970992,
      "grad_norm": 15.022384643554688,
      "learning_rate": 5.2405818724356584e-06,
      "loss": 0.6813348770141602,
      "memory(GiB)": 62.17,
      "step": 1405,
      "token_acc": 0.85,
      "train_speed(iter/s)": 0.251003
    },
    {
      "epoch": 0.13151758231508254,
      "grad_norm": 24.553497314453125,
      "learning_rate": 5.25923162998881e-06,
      "loss": 0.6889014720916748,
      "memory(GiB)": 62.17,
      "step": 1410,
      "train_speed(iter/s)": 0.250994
    },
    {
      "epoch": 0.13198395672045518,
      "grad_norm": 19.56242561340332,
      "learning_rate": 5.277881387541962e-06,
      "loss": 0.6735507011413574,
      "memory(GiB)": 62.17,
      "step": 1415,
      "train_speed(iter/s)": 0.251007
    },
    {
      "epoch": 0.13245033112582782,
      "grad_norm": 31.38086700439453,
      "learning_rate": 5.296531145095114e-06,
      "loss": 0.7550340175628663,
      "memory(GiB)": 62.17,
      "step": 1420,
      "train_speed(iter/s)": 0.251003
    },
    {
      "epoch": 0.13291670553120044,
      "grad_norm": 38.03486251831055,
      "learning_rate": 5.3151809026482656e-06,
      "loss": 0.7341979026794434,
      "memory(GiB)": 62.17,
      "step": 1425,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251074
    },
    {
      "epoch": 0.13338307993657308,
      "grad_norm": 33.17816162109375,
      "learning_rate": 5.333830660201418e-06,
      "loss": 0.7207400798797607,
      "memory(GiB)": 62.17,
      "step": 1430,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.251079
    },
    {
      "epoch": 0.1338494543419457,
      "grad_norm": 32.18882751464844,
      "learning_rate": 5.3524804177545696e-06,
      "loss": 0.6878833293914794,
      "memory(GiB)": 62.17,
      "step": 1435,
      "train_speed(iter/s)": 0.251069
    },
    {
      "epoch": 0.13431582874731834,
      "grad_norm": 49.231510162353516,
      "learning_rate": 5.371130175307722e-06,
      "loss": 0.7509490013122558,
      "memory(GiB)": 62.17,
      "step": 1440,
      "token_acc": 0.2222222222222222,
      "train_speed(iter/s)": 0.251074
    },
    {
      "epoch": 0.134782203152691,
      "grad_norm": 17.56727409362793,
      "learning_rate": 5.3897799328608736e-06,
      "loss": 0.7769502639770508,
      "memory(GiB)": 62.17,
      "step": 1445,
      "train_speed(iter/s)": 0.251135
    },
    {
      "epoch": 0.1352485775580636,
      "grad_norm": 25.377256393432617,
      "learning_rate": 5.408429690414025e-06,
      "loss": 0.7281536102294922,
      "memory(GiB)": 62.17,
      "step": 1450,
      "train_speed(iter/s)": 0.251143
    },
    {
      "epoch": 0.13571495196343625,
      "grad_norm": 59.92877197265625,
      "learning_rate": 5.4270794479671776e-06,
      "loss": 0.7317614555358887,
      "memory(GiB)": 62.17,
      "step": 1455,
      "train_speed(iter/s)": 0.25121
    },
    {
      "epoch": 0.1361813263688089,
      "grad_norm": 38.49058532714844,
      "learning_rate": 5.445729205520328e-06,
      "loss": 0.7527507781982422,
      "memory(GiB)": 62.17,
      "step": 1460,
      "train_speed(iter/s)": 0.251201
    },
    {
      "epoch": 0.1366477007741815,
      "grad_norm": 21.672807693481445,
      "learning_rate": 5.46437896307348e-06,
      "loss": 0.7969707489013672,
      "memory(GiB)": 62.17,
      "step": 1465,
      "token_acc": 0.6372549019607843,
      "train_speed(iter/s)": 0.25119
    },
    {
      "epoch": 0.13711407517955415,
      "grad_norm": 38.814247131347656,
      "learning_rate": 5.483028720626632e-06,
      "loss": 0.6907387733459472,
      "memory(GiB)": 62.17,
      "step": 1470,
      "train_speed(iter/s)": 0.251196
    },
    {
      "epoch": 0.13758044958492677,
      "grad_norm": 26.389795303344727,
      "learning_rate": 5.501678478179784e-06,
      "loss": 0.7272842407226563,
      "memory(GiB)": 62.17,
      "step": 1475,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 0.1380468239902994,
      "grad_norm": 20.32640266418457,
      "learning_rate": 5.5203282357329354e-06,
      "loss": 0.7151848793029785,
      "memory(GiB)": 62.17,
      "step": 1480,
      "train_speed(iter/s)": 0.251239
    },
    {
      "epoch": 0.13851319839567205,
      "grad_norm": 24.645002365112305,
      "learning_rate": 5.538977993286088e-06,
      "loss": 0.7107001781463623,
      "memory(GiB)": 62.17,
      "step": 1485,
      "token_acc": 0.4205607476635514,
      "train_speed(iter/s)": 0.251079
    },
    {
      "epoch": 0.13897957280104467,
      "grad_norm": 24.946922302246094,
      "learning_rate": 5.5576277508392394e-06,
      "loss": 0.7462367057800293,
      "memory(GiB)": 62.17,
      "step": 1490,
      "token_acc": 0.5641025641025641,
      "train_speed(iter/s)": 0.251086
    },
    {
      "epoch": 0.13944594720641731,
      "grad_norm": 16.780227661132812,
      "learning_rate": 5.576277508392392e-06,
      "loss": 0.7464546203613281,
      "memory(GiB)": 62.17,
      "step": 1495,
      "token_acc": 0.4230769230769231,
      "train_speed(iter/s)": 0.251106
    },
    {
      "epoch": 0.13991232161178996,
      "grad_norm": 26.614355087280273,
      "learning_rate": 5.594927265945543e-06,
      "loss": 0.680145263671875,
      "memory(GiB)": 62.17,
      "step": 1500,
      "train_speed(iter/s)": 0.25108
    },
    {
      "epoch": 0.14037869601716257,
      "grad_norm": 182.17674255371094,
      "learning_rate": 5.613577023498695e-06,
      "loss": 0.7195748329162598,
      "memory(GiB)": 62.17,
      "step": 1505,
      "train_speed(iter/s)": 0.251081
    },
    {
      "epoch": 0.14084507042253522,
      "grad_norm": 28.06296730041504,
      "learning_rate": 5.632226781051847e-06,
      "loss": 0.7012014389038086,
      "memory(GiB)": 62.17,
      "step": 1510,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25109
    },
    {
      "epoch": 0.14131144482790783,
      "grad_norm": 42.086891174316406,
      "learning_rate": 5.650876538604999e-06,
      "loss": 0.7353513240814209,
      "memory(GiB)": 62.17,
      "step": 1515,
      "token_acc": 0.8,
      "train_speed(iter/s)": 0.251073
    },
    {
      "epoch": 0.14177781923328048,
      "grad_norm": 22.70674705505371,
      "learning_rate": 5.66952629615815e-06,
      "loss": 0.7143251419067382,
      "memory(GiB)": 62.17,
      "step": 1520,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.251129
    },
    {
      "epoch": 0.14224419363865312,
      "grad_norm": 25.103172302246094,
      "learning_rate": 5.688176053711302e-06,
      "loss": 0.7181349277496338,
      "memory(GiB)": 62.17,
      "step": 1525,
      "token_acc": 0.5689655172413793,
      "train_speed(iter/s)": 0.251143
    },
    {
      "epoch": 0.14271056804402574,
      "grad_norm": 20.292417526245117,
      "learning_rate": 5.706825811264454e-06,
      "loss": 0.7296171188354492,
      "memory(GiB)": 62.17,
      "step": 1530,
      "token_acc": 0.35294117647058826,
      "train_speed(iter/s)": 0.251156
    },
    {
      "epoch": 0.14317694244939838,
      "grad_norm": 18.86408805847168,
      "learning_rate": 5.725475568817605e-06,
      "loss": 0.737028980255127,
      "memory(GiB)": 62.17,
      "step": 1535,
      "train_speed(iter/s)": 0.251177
    },
    {
      "epoch": 0.143643316854771,
      "grad_norm": 22.697402954101562,
      "learning_rate": 5.744125326370758e-06,
      "loss": 0.7198893547058105,
      "memory(GiB)": 62.17,
      "step": 1540,
      "token_acc": 0.7934782608695652,
      "train_speed(iter/s)": 0.25121
    },
    {
      "epoch": 0.14410969126014364,
      "grad_norm": 17.470762252807617,
      "learning_rate": 5.762775083923909e-06,
      "loss": 0.6857327461242676,
      "memory(GiB)": 62.17,
      "step": 1545,
      "token_acc": 0.29545454545454547,
      "train_speed(iter/s)": 0.251217
    },
    {
      "epoch": 0.14457606566551628,
      "grad_norm": 29.655635833740234,
      "learning_rate": 5.781424841477062e-06,
      "loss": 0.715398120880127,
      "memory(GiB)": 62.17,
      "step": 1550,
      "train_speed(iter/s)": 0.251275
    },
    {
      "epoch": 0.1450424400708889,
      "grad_norm": 36.41429138183594,
      "learning_rate": 5.800074599030213e-06,
      "loss": 0.7150166511535645,
      "memory(GiB)": 62.17,
      "step": 1555,
      "train_speed(iter/s)": 0.251298
    },
    {
      "epoch": 0.14550881447626154,
      "grad_norm": 32.836647033691406,
      "learning_rate": 5.818724356583365e-06,
      "loss": 0.7359040737152099,
      "memory(GiB)": 62.17,
      "step": 1560,
      "token_acc": 0.8607594936708861,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 0.1459751888816342,
      "grad_norm": 31.206497192382812,
      "learning_rate": 5.837374114136517e-06,
      "loss": 0.7174106121063233,
      "memory(GiB)": 62.17,
      "step": 1565,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 0.1464415632870068,
      "grad_norm": 29.93080711364746,
      "learning_rate": 5.856023871689669e-06,
      "loss": 0.6755335807800293,
      "memory(GiB)": 62.17,
      "step": 1570,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 0.14690793769237945,
      "grad_norm": 30.63231086730957,
      "learning_rate": 5.87467362924282e-06,
      "loss": 0.6444782257080078,
      "memory(GiB)": 62.17,
      "step": 1575,
      "token_acc": 0.736,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 0.14737431209775206,
      "grad_norm": 16.639928817749023,
      "learning_rate": 5.893323386795972e-06,
      "loss": 0.6806515693664551,
      "memory(GiB)": 62.17,
      "step": 1580,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 0.1478406865031247,
      "grad_norm": 29.728185653686523,
      "learning_rate": 5.9119731443491236e-06,
      "loss": 0.7141528606414795,
      "memory(GiB)": 62.17,
      "step": 1585,
      "train_speed(iter/s)": 0.251297
    },
    {
      "epoch": 0.14830706090849735,
      "grad_norm": 23.64690399169922,
      "learning_rate": 5.930622901902275e-06,
      "loss": 0.7617981910705567,
      "memory(GiB)": 62.17,
      "step": 1590,
      "token_acc": 0.8018867924528302,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 0.14877343531386997,
      "grad_norm": 18.437915802001953,
      "learning_rate": 5.9492726594554276e-06,
      "loss": 0.7679856300354004,
      "memory(GiB)": 62.17,
      "step": 1595,
      "token_acc": 0.4791666666666667,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 0.1492398097192426,
      "grad_norm": 47.76600646972656,
      "learning_rate": 5.967922417008579e-06,
      "loss": 0.6816699504852295,
      "memory(GiB)": 62.17,
      "step": 1600,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 0.14970618412461525,
      "grad_norm": 37.06012725830078,
      "learning_rate": 5.986572174561731e-06,
      "loss": 0.6802376747131348,
      "memory(GiB)": 62.17,
      "step": 1605,
      "train_speed(iter/s)": 0.251481
    },
    {
      "epoch": 0.15017255852998787,
      "grad_norm": 19.01993751525879,
      "learning_rate": 6.005221932114883e-06,
      "loss": 0.751960277557373,
      "memory(GiB)": 62.17,
      "step": 1610,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.25153
    },
    {
      "epoch": 0.15063893293536051,
      "grad_norm": 19.67988395690918,
      "learning_rate": 6.023871689668035e-06,
      "loss": 0.6846273422241211,
      "memory(GiB)": 62.17,
      "step": 1615,
      "train_speed(iter/s)": 0.251559
    },
    {
      "epoch": 0.15110530734073313,
      "grad_norm": 17.888072967529297,
      "learning_rate": 6.042521447221187e-06,
      "loss": 0.7318036079406738,
      "memory(GiB)": 62.17,
      "step": 1620,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251585
    },
    {
      "epoch": 0.15157168174610577,
      "grad_norm": 42.44026565551758,
      "learning_rate": 6.061171204774339e-06,
      "loss": 0.7313447952270508,
      "memory(GiB)": 62.17,
      "step": 1625,
      "token_acc": 0.6176470588235294,
      "train_speed(iter/s)": 0.25156
    },
    {
      "epoch": 0.15203805615147842,
      "grad_norm": 28.41170883178711,
      "learning_rate": 6.07982096232749e-06,
      "loss": 0.739561653137207,
      "memory(GiB)": 62.17,
      "step": 1630,
      "train_speed(iter/s)": 0.251615
    },
    {
      "epoch": 0.15250443055685103,
      "grad_norm": 21.378311157226562,
      "learning_rate": 6.098470719880643e-06,
      "loss": 0.6624508380889893,
      "memory(GiB)": 62.17,
      "step": 1635,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 0.15297080496222368,
      "grad_norm": 19.22395133972168,
      "learning_rate": 6.1171204774337934e-06,
      "loss": 0.7216727256774902,
      "memory(GiB)": 62.17,
      "step": 1640,
      "token_acc": 0.7804878048780488,
      "train_speed(iter/s)": 0.25163
    },
    {
      "epoch": 0.1534371793675963,
      "grad_norm": 27.074527740478516,
      "learning_rate": 6.135770234986945e-06,
      "loss": 0.7002131462097168,
      "memory(GiB)": 62.17,
      "step": 1645,
      "train_speed(iter/s)": 0.251592
    },
    {
      "epoch": 0.15390355377296894,
      "grad_norm": 32.82748794555664,
      "learning_rate": 6.154419992540097e-06,
      "loss": 0.7080451011657715,
      "memory(GiB)": 62.17,
      "step": 1650,
      "train_speed(iter/s)": 0.251631
    },
    {
      "epoch": 0.15436992817834158,
      "grad_norm": 26.811922073364258,
      "learning_rate": 6.173069750093249e-06,
      "loss": 0.6787557601928711,
      "memory(GiB)": 62.17,
      "step": 1655,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.251615
    },
    {
      "epoch": 0.1548363025837142,
      "grad_norm": 21.121784210205078,
      "learning_rate": 6.1917195076464006e-06,
      "loss": 0.7402821540832519,
      "memory(GiB)": 62.17,
      "step": 1660,
      "train_speed(iter/s)": 0.251616
    },
    {
      "epoch": 0.15530267698908684,
      "grad_norm": 13.382747650146484,
      "learning_rate": 6.210369265199553e-06,
      "loss": 0.6984625816345215,
      "memory(GiB)": 62.17,
      "step": 1665,
      "token_acc": 0.68,
      "train_speed(iter/s)": 0.251622
    },
    {
      "epoch": 0.15576905139445948,
      "grad_norm": 19.317930221557617,
      "learning_rate": 6.2290190227527046e-06,
      "loss": 0.7349600791931152,
      "memory(GiB)": 62.17,
      "step": 1670,
      "train_speed(iter/s)": 0.251625
    },
    {
      "epoch": 0.1562354257998321,
      "grad_norm": 30.692359924316406,
      "learning_rate": 6.247668780305857e-06,
      "loss": 0.7380085945129394,
      "memory(GiB)": 62.17,
      "step": 1675,
      "token_acc": 0.4125,
      "train_speed(iter/s)": 0.251651
    },
    {
      "epoch": 0.15670180020520474,
      "grad_norm": 14.406522750854492,
      "learning_rate": 6.2663185378590086e-06,
      "loss": 0.685313606262207,
      "memory(GiB)": 62.17,
      "step": 1680,
      "train_speed(iter/s)": 0.251637
    },
    {
      "epoch": 0.15716817461057736,
      "grad_norm": 14.938100814819336,
      "learning_rate": 6.28496829541216e-06,
      "loss": 0.6922816276550293,
      "memory(GiB)": 62.17,
      "step": 1685,
      "train_speed(iter/s)": 0.251654
    },
    {
      "epoch": 0.15763454901595,
      "grad_norm": 9.965221405029297,
      "learning_rate": 6.3036180529653126e-06,
      "loss": 0.6587113857269287,
      "memory(GiB)": 62.17,
      "step": 1690,
      "token_acc": 0.7241379310344828,
      "train_speed(iter/s)": 0.251642
    },
    {
      "epoch": 0.15810092342132265,
      "grad_norm": 16.556787490844727,
      "learning_rate": 6.322267810518464e-06,
      "loss": 0.672331428527832,
      "memory(GiB)": 62.17,
      "step": 1695,
      "token_acc": 0.7792207792207793,
      "train_speed(iter/s)": 0.251644
    },
    {
      "epoch": 0.15856729782669526,
      "grad_norm": 29.194040298461914,
      "learning_rate": 6.340917568071615e-06,
      "loss": 0.6943126678466797,
      "memory(GiB)": 62.17,
      "step": 1700,
      "train_speed(iter/s)": 0.251586
    },
    {
      "epoch": 0.1590336722320679,
      "grad_norm": 33.572669982910156,
      "learning_rate": 6.359567325624767e-06,
      "loss": 0.7207040309906005,
      "memory(GiB)": 62.17,
      "step": 1705,
      "token_acc": 0.7171052631578947,
      "train_speed(iter/s)": 0.251618
    },
    {
      "epoch": 0.15950004663744052,
      "grad_norm": 31.203948974609375,
      "learning_rate": 6.378217083177919e-06,
      "loss": 0.6999865531921386,
      "memory(GiB)": 62.17,
      "step": 1710,
      "train_speed(iter/s)": 0.251703
    },
    {
      "epoch": 0.15996642104281317,
      "grad_norm": 17.878416061401367,
      "learning_rate": 6.3968668407310704e-06,
      "loss": 0.7273510932922364,
      "memory(GiB)": 62.17,
      "step": 1715,
      "train_speed(iter/s)": 0.251707
    },
    {
      "epoch": 0.1604327954481858,
      "grad_norm": 35.04709243774414,
      "learning_rate": 6.415516598284223e-06,
      "loss": 0.73350830078125,
      "memory(GiB)": 62.17,
      "step": 1720,
      "train_speed(iter/s)": 0.251734
    },
    {
      "epoch": 0.16089916985355843,
      "grad_norm": 33.60038757324219,
      "learning_rate": 6.4341663558373744e-06,
      "loss": 0.707309341430664,
      "memory(GiB)": 62.17,
      "step": 1725,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.2518
    },
    {
      "epoch": 0.16136554425893107,
      "grad_norm": 35.768775939941406,
      "learning_rate": 6.452816113390527e-06,
      "loss": 0.7672608375549317,
      "memory(GiB)": 62.17,
      "step": 1730,
      "token_acc": 0.4017094017094017,
      "train_speed(iter/s)": 0.25178
    },
    {
      "epoch": 0.16183191866430371,
      "grad_norm": 40.732032775878906,
      "learning_rate": 6.471465870943678e-06,
      "loss": 0.6821251392364502,
      "memory(GiB)": 62.17,
      "step": 1735,
      "train_speed(iter/s)": 0.251833
    },
    {
      "epoch": 0.16229829306967633,
      "grad_norm": 15.391794204711914,
      "learning_rate": 6.49011562849683e-06,
      "loss": 0.6996511459350586,
      "memory(GiB)": 62.17,
      "step": 1740,
      "token_acc": 0.8125,
      "train_speed(iter/s)": 0.251813
    },
    {
      "epoch": 0.16276466747504897,
      "grad_norm": 21.085905075073242,
      "learning_rate": 6.508765386049982e-06,
      "loss": 0.6342850685119629,
      "memory(GiB)": 62.17,
      "step": 1745,
      "token_acc": 0.4166666666666667,
      "train_speed(iter/s)": 0.251891
    },
    {
      "epoch": 0.1632310418804216,
      "grad_norm": 17.795623779296875,
      "learning_rate": 6.527415143603134e-06,
      "loss": 0.7034914493560791,
      "memory(GiB)": 62.17,
      "step": 1750,
      "train_speed(iter/s)": 0.251926
    },
    {
      "epoch": 0.16369741628579423,
      "grad_norm": 11.811948776245117,
      "learning_rate": 6.546064901156286e-06,
      "loss": 0.6901198863983155,
      "memory(GiB)": 62.17,
      "step": 1755,
      "train_speed(iter/s)": 0.251983
    },
    {
      "epoch": 0.16416379069116688,
      "grad_norm": 12.137704849243164,
      "learning_rate": 6.564714658709437e-06,
      "loss": 0.6835857391357422,
      "memory(GiB)": 62.17,
      "step": 1760,
      "train_speed(iter/s)": 0.252021
    },
    {
      "epoch": 0.1646301650965395,
      "grad_norm": 14.9642915725708,
      "learning_rate": 6.583364416262589e-06,
      "loss": 0.6726917266845703,
      "memory(GiB)": 62.17,
      "step": 1765,
      "train_speed(iter/s)": 0.252023
    },
    {
      "epoch": 0.16509653950191214,
      "grad_norm": 14.942808151245117,
      "learning_rate": 6.60201417381574e-06,
      "loss": 0.7149478912353515,
      "memory(GiB)": 62.17,
      "step": 1770,
      "train_speed(iter/s)": 0.252044
    },
    {
      "epoch": 0.16556291390728478,
      "grad_norm": 15.727932929992676,
      "learning_rate": 6.620663931368893e-06,
      "loss": 0.6789281368255615,
      "memory(GiB)": 62.17,
      "step": 1775,
      "token_acc": 0.40476190476190477,
      "train_speed(iter/s)": 0.252071
    },
    {
      "epoch": 0.1660292883126574,
      "grad_norm": 13.882144927978516,
      "learning_rate": 6.639313688922044e-06,
      "loss": 0.6519111633300781,
      "memory(GiB)": 62.17,
      "step": 1780,
      "train_speed(iter/s)": 0.252044
    },
    {
      "epoch": 0.16649566271803004,
      "grad_norm": 13.407504081726074,
      "learning_rate": 6.657963446475197e-06,
      "loss": 0.6813093185424804,
      "memory(GiB)": 62.17,
      "step": 1785,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 0.16696203712340266,
      "grad_norm": 17.09420394897461,
      "learning_rate": 6.676613204028348e-06,
      "loss": 0.691402530670166,
      "memory(GiB)": 62.17,
      "step": 1790,
      "token_acc": 0.49038461538461536,
      "train_speed(iter/s)": 0.252036
    },
    {
      "epoch": 0.1674284115287753,
      "grad_norm": 25.265478134155273,
      "learning_rate": 6.6952629615815e-06,
      "loss": 0.6848285675048829,
      "memory(GiB)": 62.17,
      "step": 1795,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 0.16789478593414794,
      "grad_norm": 13.489717483520508,
      "learning_rate": 6.713912719134652e-06,
      "loss": 0.6941601753234863,
      "memory(GiB)": 62.17,
      "step": 1800,
      "train_speed(iter/s)": 0.252033
    },
    {
      "epoch": 0.16836116033952056,
      "grad_norm": 16.630416870117188,
      "learning_rate": 6.732562476687804e-06,
      "loss": 0.7032321929931641,
      "memory(GiB)": 62.17,
      "step": 1805,
      "train_speed(iter/s)": 0.252088
    },
    {
      "epoch": 0.1688275347448932,
      "grad_norm": 13.796021461486816,
      "learning_rate": 6.751212234240955e-06,
      "loss": 0.635976505279541,
      "memory(GiB)": 62.17,
      "step": 1810,
      "train_speed(iter/s)": 0.252133
    },
    {
      "epoch": 0.16929390915026582,
      "grad_norm": 19.68157386779785,
      "learning_rate": 6.769861991794108e-06,
      "loss": 0.6936980247497558,
      "memory(GiB)": 62.17,
      "step": 1815,
      "train_speed(iter/s)": 0.252138
    },
    {
      "epoch": 0.16976028355563846,
      "grad_norm": 41.20659255981445,
      "learning_rate": 6.7885117493472586e-06,
      "loss": 0.6614112854003906,
      "memory(GiB)": 62.17,
      "step": 1820,
      "train_speed(iter/s)": 0.252136
    },
    {
      "epoch": 0.1702266579610111,
      "grad_norm": 16.088966369628906,
      "learning_rate": 6.80716150690041e-06,
      "loss": 0.6925766468048096,
      "memory(GiB)": 62.17,
      "step": 1825,
      "token_acc": 0.6521739130434783,
      "train_speed(iter/s)": 0.252119
    },
    {
      "epoch": 0.17069303236638372,
      "grad_norm": 26.971481323242188,
      "learning_rate": 6.8258112644535626e-06,
      "loss": 0.6789783477783203,
      "memory(GiB)": 62.17,
      "step": 1830,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 0.17115940677175637,
      "grad_norm": 49.296051025390625,
      "learning_rate": 6.844461022006714e-06,
      "loss": 0.7230084896087646,
      "memory(GiB)": 62.17,
      "step": 1835,
      "token_acc": 0.39344262295081966,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 0.171625781177129,
      "grad_norm": 26.82034683227539,
      "learning_rate": 6.8631107795598666e-06,
      "loss": 0.7255057334899903,
      "memory(GiB)": 62.17,
      "step": 1840,
      "train_speed(iter/s)": 0.252178
    },
    {
      "epoch": 0.17209215558250163,
      "grad_norm": 21.550838470458984,
      "learning_rate": 6.881760537113018e-06,
      "loss": 0.6670663356781006,
      "memory(GiB)": 62.17,
      "step": 1845,
      "token_acc": 0.8953488372093024,
      "train_speed(iter/s)": 0.252223
    },
    {
      "epoch": 0.17255852998787427,
      "grad_norm": 16.56453514099121,
      "learning_rate": 6.90041029466617e-06,
      "loss": 0.6761985778808594,
      "memory(GiB)": 62.17,
      "step": 1850,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.252217
    },
    {
      "epoch": 0.1730249043932469,
      "grad_norm": 26.548730850219727,
      "learning_rate": 6.919060052219322e-06,
      "loss": 0.7168414115905761,
      "memory(GiB)": 62.17,
      "step": 1855,
      "token_acc": 0.4696969696969697,
      "train_speed(iter/s)": 0.252239
    },
    {
      "epoch": 0.17349127879861953,
      "grad_norm": 34.315982818603516,
      "learning_rate": 6.937709809772474e-06,
      "loss": 0.6911808013916015,
      "memory(GiB)": 62.17,
      "step": 1860,
      "train_speed(iter/s)": 0.252279
    },
    {
      "epoch": 0.17395765320399217,
      "grad_norm": 14.64493179321289,
      "learning_rate": 6.956359567325625e-06,
      "loss": 0.7481697082519532,
      "memory(GiB)": 62.17,
      "step": 1865,
      "train_speed(iter/s)": 0.25226
    },
    {
      "epoch": 0.1744240276093648,
      "grad_norm": 22.527191162109375,
      "learning_rate": 6.975009324878778e-06,
      "loss": 0.6664412498474122,
      "memory(GiB)": 62.17,
      "step": 1870,
      "token_acc": 0.6136363636363636,
      "train_speed(iter/s)": 0.252265
    },
    {
      "epoch": 0.17489040201473743,
      "grad_norm": 25.74637222290039,
      "learning_rate": 6.993659082431929e-06,
      "loss": 0.7083615303039551,
      "memory(GiB)": 62.17,
      "step": 1875,
      "token_acc": 0.38461538461538464,
      "train_speed(iter/s)": 0.252318
    },
    {
      "epoch": 0.17535677642011008,
      "grad_norm": 35.733394622802734,
      "learning_rate": 7.01230883998508e-06,
      "loss": 0.7514951229095459,
      "memory(GiB)": 62.17,
      "step": 1880,
      "token_acc": 0.49707602339181284,
      "train_speed(iter/s)": 0.252382
    },
    {
      "epoch": 0.1758231508254827,
      "grad_norm": 15.7872314453125,
      "learning_rate": 7.030958597538232e-06,
      "loss": 0.678194236755371,
      "memory(GiB)": 62.17,
      "step": 1885,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.252396
    },
    {
      "epoch": 0.17628952523085534,
      "grad_norm": 20.148698806762695,
      "learning_rate": 7.049608355091384e-06,
      "loss": 0.6467745304107666,
      "memory(GiB)": 62.17,
      "step": 1890,
      "token_acc": 0.35106382978723405,
      "train_speed(iter/s)": 0.25242
    },
    {
      "epoch": 0.17675589963622795,
      "grad_norm": 27.891294479370117,
      "learning_rate": 7.0682581126445356e-06,
      "loss": 0.6987371444702148,
      "memory(GiB)": 62.17,
      "step": 1895,
      "token_acc": 0.5227272727272727,
      "train_speed(iter/s)": 0.252394
    },
    {
      "epoch": 0.1772222740416006,
      "grad_norm": 9.623148918151855,
      "learning_rate": 7.086907870197688e-06,
      "loss": 0.6841658592224121,
      "memory(GiB)": 62.17,
      "step": 1900,
      "token_acc": 0.463768115942029,
      "train_speed(iter/s)": 0.2524
    },
    {
      "epoch": 0.17768864844697324,
      "grad_norm": 11.75369644165039,
      "learning_rate": 7.1055576277508396e-06,
      "loss": 0.6898670196533203,
      "memory(GiB)": 62.17,
      "step": 1905,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.252407
    },
    {
      "epoch": 0.17815502285234586,
      "grad_norm": 12.886293411254883,
      "learning_rate": 7.124207385303992e-06,
      "loss": 0.6762559890747071,
      "memory(GiB)": 62.17,
      "step": 1910,
      "train_speed(iter/s)": 0.252431
    },
    {
      "epoch": 0.1786213972577185,
      "grad_norm": 21.317140579223633,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 0.6746134757995605,
      "memory(GiB)": 62.17,
      "step": 1915,
      "train_speed(iter/s)": 0.252487
    },
    {
      "epoch": 0.17908777166309112,
      "grad_norm": 11.539788246154785,
      "learning_rate": 7.161506900410295e-06,
      "loss": 0.6250720500946045,
      "memory(GiB)": 62.17,
      "step": 1920,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.2525
    },
    {
      "epoch": 0.17955414606846376,
      "grad_norm": 19.977048873901367,
      "learning_rate": 7.1801566579634476e-06,
      "loss": 0.6680868148803711,
      "memory(GiB)": 62.17,
      "step": 1925,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.252503
    },
    {
      "epoch": 0.1800205204738364,
      "grad_norm": 25.84778594970703,
      "learning_rate": 7.198806415516599e-06,
      "loss": 0.6792243957519531,
      "memory(GiB)": 62.17,
      "step": 1930,
      "train_speed(iter/s)": 0.252532
    },
    {
      "epoch": 0.18048689487920902,
      "grad_norm": 18.2759952545166,
      "learning_rate": 7.2174561730697516e-06,
      "loss": 0.6440337181091309,
      "memory(GiB)": 62.17,
      "step": 1935,
      "token_acc": 0.62,
      "train_speed(iter/s)": 0.252547
    },
    {
      "epoch": 0.18095326928458166,
      "grad_norm": 10.497574806213379,
      "learning_rate": 7.236105930622902e-06,
      "loss": 0.6716220378875732,
      "memory(GiB)": 62.17,
      "step": 1940,
      "train_speed(iter/s)": 0.252568
    },
    {
      "epoch": 0.1814196436899543,
      "grad_norm": 15.340128898620605,
      "learning_rate": 7.254755688176054e-06,
      "loss": 0.6668761730194092,
      "memory(GiB)": 62.17,
      "step": 1945,
      "token_acc": 0.45901639344262296,
      "train_speed(iter/s)": 0.252595
    },
    {
      "epoch": 0.18188601809532692,
      "grad_norm": 12.647482872009277,
      "learning_rate": 7.2734054457292054e-06,
      "loss": 0.6541544914245605,
      "memory(GiB)": 62.17,
      "step": 1950,
      "train_speed(iter/s)": 0.2526
    },
    {
      "epoch": 0.18235239250069957,
      "grad_norm": 14.001193046569824,
      "learning_rate": 7.292055203282358e-06,
      "loss": 0.7118899345397949,
      "memory(GiB)": 62.17,
      "step": 1955,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.252604
    },
    {
      "epoch": 0.18281876690607218,
      "grad_norm": 26.251697540283203,
      "learning_rate": 7.3107049608355094e-06,
      "loss": 0.7022637367248535,
      "memory(GiB)": 62.17,
      "step": 1960,
      "token_acc": 0.5517241379310345,
      "train_speed(iter/s)": 0.252607
    },
    {
      "epoch": 0.18328514131144483,
      "grad_norm": 13.10018253326416,
      "learning_rate": 7.329354718388662e-06,
      "loss": 0.6787337303161621,
      "memory(GiB)": 62.17,
      "step": 1965,
      "train_speed(iter/s)": 0.252603
    },
    {
      "epoch": 0.18375151571681747,
      "grad_norm": 18.004873275756836,
      "learning_rate": 7.348004475941813e-06,
      "loss": 0.6279837608337402,
      "memory(GiB)": 62.17,
      "step": 1970,
      "token_acc": 0.5301204819277109,
      "train_speed(iter/s)": 0.252667
    },
    {
      "epoch": 0.1842178901221901,
      "grad_norm": 8.991841316223145,
      "learning_rate": 7.366654233494965e-06,
      "loss": 0.6779107093811035,
      "memory(GiB)": 62.17,
      "step": 1975,
      "token_acc": 0.4215686274509804,
      "train_speed(iter/s)": 0.252655
    },
    {
      "epoch": 0.18468426452756273,
      "grad_norm": 17.482601165771484,
      "learning_rate": 7.385303991048117e-06,
      "loss": 0.6933659553527832,
      "memory(GiB)": 62.17,
      "step": 1980,
      "train_speed(iter/s)": 0.252641
    },
    {
      "epoch": 0.18515063893293537,
      "grad_norm": 16.631437301635742,
      "learning_rate": 7.403953748601269e-06,
      "loss": 0.6673551559448242,
      "memory(GiB)": 62.17,
      "step": 1985,
      "train_speed(iter/s)": 0.252655
    },
    {
      "epoch": 0.185617013338308,
      "grad_norm": 14.824403762817383,
      "learning_rate": 7.422603506154421e-06,
      "loss": 0.6932362079620361,
      "memory(GiB)": 62.17,
      "step": 1990,
      "train_speed(iter/s)": 0.252662
    },
    {
      "epoch": 0.18608338774368063,
      "grad_norm": 11.758213996887207,
      "learning_rate": 7.441253263707573e-06,
      "loss": 0.6574287414550781,
      "memory(GiB)": 62.17,
      "step": 1995,
      "token_acc": 0.3508771929824561,
      "train_speed(iter/s)": 0.252681
    },
    {
      "epoch": 0.18654976214905325,
      "grad_norm": 17.52506446838379,
      "learning_rate": 7.459903021260724e-06,
      "loss": 0.7044204235076904,
      "memory(GiB)": 62.17,
      "step": 2000,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.252682
    },
    {
      "epoch": 0.1870161365544259,
      "grad_norm": 22.061073303222656,
      "learning_rate": 7.478552778813875e-06,
      "loss": 0.7480438709259033,
      "memory(GiB)": 62.17,
      "step": 2005,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.25184
    },
    {
      "epoch": 0.18748251095979854,
      "grad_norm": 18.240612030029297,
      "learning_rate": 7.497202536367028e-06,
      "loss": 0.7774371147155762,
      "memory(GiB)": 62.17,
      "step": 2010,
      "token_acc": 0.5079365079365079,
      "train_speed(iter/s)": 0.251861
    },
    {
      "epoch": 0.18794888536517115,
      "grad_norm": 42.25651168823242,
      "learning_rate": 7.515852293920179e-06,
      "loss": 0.7676219940185547,
      "memory(GiB)": 62.17,
      "step": 2015,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.25187
    },
    {
      "epoch": 0.1884152597705438,
      "grad_norm": 15.018125534057617,
      "learning_rate": 7.534502051473332e-06,
      "loss": 0.7653908252716064,
      "memory(GiB)": 62.17,
      "step": 2020,
      "token_acc": 0.42028985507246375,
      "train_speed(iter/s)": 0.251892
    },
    {
      "epoch": 0.1888816341759164,
      "grad_norm": 21.80329132080078,
      "learning_rate": 7.553151809026483e-06,
      "loss": 0.7267949104309082,
      "memory(GiB)": 62.17,
      "step": 2025,
      "train_speed(iter/s)": 0.251893
    },
    {
      "epoch": 0.18934800858128906,
      "grad_norm": 21.567577362060547,
      "learning_rate": 7.571801566579635e-06,
      "loss": 0.753933048248291,
      "memory(GiB)": 62.17,
      "step": 2030,
      "train_speed(iter/s)": 0.251882
    },
    {
      "epoch": 0.1898143829866617,
      "grad_norm": 25.175989151000977,
      "learning_rate": 7.590451324132787e-06,
      "loss": 0.6867819786071777,
      "memory(GiB)": 62.17,
      "step": 2035,
      "token_acc": 0.45098039215686275,
      "train_speed(iter/s)": 0.251866
    },
    {
      "epoch": 0.19028075739203432,
      "grad_norm": 27.552658081054688,
      "learning_rate": 7.609101081685939e-06,
      "loss": 0.6355721473693847,
      "memory(GiB)": 62.17,
      "step": 2040,
      "train_speed(iter/s)": 0.251886
    },
    {
      "epoch": 0.19074713179740696,
      "grad_norm": 12.240174293518066,
      "learning_rate": 7.627750839239091e-06,
      "loss": 0.6571968555450439,
      "memory(GiB)": 62.17,
      "step": 2045,
      "train_speed(iter/s)": 0.251914
    },
    {
      "epoch": 0.1912135062027796,
      "grad_norm": 15.264710426330566,
      "learning_rate": 7.646400596792242e-06,
      "loss": 0.6494068145751953,
      "memory(GiB)": 62.17,
      "step": 2050,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 0.19167988060815222,
      "grad_norm": 12.28565788269043,
      "learning_rate": 7.665050354345395e-06,
      "loss": 0.6990233421325683,
      "memory(GiB)": 62.17,
      "step": 2055,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.251988
    },
    {
      "epoch": 0.19214625501352486,
      "grad_norm": 24.342798233032227,
      "learning_rate": 7.683700111898545e-06,
      "loss": 0.7034859180450439,
      "memory(GiB)": 62.17,
      "step": 2060,
      "train_speed(iter/s)": 0.251986
    },
    {
      "epoch": 0.19261262941889748,
      "grad_norm": 17.81696319580078,
      "learning_rate": 7.702349869451697e-06,
      "loss": 0.6656582832336426,
      "memory(GiB)": 62.17,
      "step": 2065,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 0.19307900382427012,
      "grad_norm": 26.177478790283203,
      "learning_rate": 7.72099962700485e-06,
      "loss": 0.6971930027008056,
      "memory(GiB)": 62.17,
      "step": 2070,
      "token_acc": 0.6829268292682927,
      "train_speed(iter/s)": 0.25199
    },
    {
      "epoch": 0.19354537822964277,
      "grad_norm": 40.27085494995117,
      "learning_rate": 7.739649384558002e-06,
      "loss": 0.7110612392425537,
      "memory(GiB)": 62.17,
      "step": 2075,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.252064
    },
    {
      "epoch": 0.19401175263501538,
      "grad_norm": 12.644107818603516,
      "learning_rate": 7.758299142111153e-06,
      "loss": 0.6262356758117675,
      "memory(GiB)": 62.17,
      "step": 2080,
      "train_speed(iter/s)": 0.252094
    },
    {
      "epoch": 0.19447812704038803,
      "grad_norm": 14.409573554992676,
      "learning_rate": 7.776948899664305e-06,
      "loss": 0.7261139869689941,
      "memory(GiB)": 62.17,
      "step": 2085,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.252088
    },
    {
      "epoch": 0.19494450144576064,
      "grad_norm": 40.93643569946289,
      "learning_rate": 7.795598657217456e-06,
      "loss": 0.6871171951293945,
      "memory(GiB)": 62.17,
      "step": 2090,
      "token_acc": 0.4473684210526316,
      "train_speed(iter/s)": 0.252091
    },
    {
      "epoch": 0.1954108758511333,
      "grad_norm": 18.750438690185547,
      "learning_rate": 7.81424841477061e-06,
      "loss": 0.7626288414001465,
      "memory(GiB)": 62.17,
      "step": 2095,
      "token_acc": 0.8539325842696629,
      "train_speed(iter/s)": 0.252125
    },
    {
      "epoch": 0.19587725025650593,
      "grad_norm": 14.219561576843262,
      "learning_rate": 7.832898172323761e-06,
      "loss": 0.710690689086914,
      "memory(GiB)": 62.17,
      "step": 2100,
      "train_speed(iter/s)": 0.252169
    },
    {
      "epoch": 0.19634362466187855,
      "grad_norm": 19.578962326049805,
      "learning_rate": 7.851547929876913e-06,
      "loss": 0.6602753639221192,
      "memory(GiB)": 62.17,
      "step": 2105,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.252155
    },
    {
      "epoch": 0.1968099990672512,
      "grad_norm": 27.79885482788086,
      "learning_rate": 7.870197687430064e-06,
      "loss": 0.6902121543884278,
      "memory(GiB)": 62.17,
      "step": 2110,
      "train_speed(iter/s)": 0.252125
    },
    {
      "epoch": 0.19727637347262383,
      "grad_norm": 15.086997032165527,
      "learning_rate": 7.888847444983216e-06,
      "loss": 0.7090510368347168,
      "memory(GiB)": 62.17,
      "step": 2115,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.252131
    },
    {
      "epoch": 0.19774274787799645,
      "grad_norm": 20.206918716430664,
      "learning_rate": 7.907497202536367e-06,
      "loss": 0.6756390571594239,
      "memory(GiB)": 62.17,
      "step": 2120,
      "train_speed(iter/s)": 0.252141
    },
    {
      "epoch": 0.1982091222833691,
      "grad_norm": 17.09441375732422,
      "learning_rate": 7.926146960089519e-06,
      "loss": 0.664760684967041,
      "memory(GiB)": 62.17,
      "step": 2125,
      "token_acc": 0.39215686274509803,
      "train_speed(iter/s)": 0.252133
    },
    {
      "epoch": 0.1986754966887417,
      "grad_norm": 22.467702865600586,
      "learning_rate": 7.94479671764267e-06,
      "loss": 0.6735358238220215,
      "memory(GiB)": 62.17,
      "step": 2130,
      "train_speed(iter/s)": 0.252156
    },
    {
      "epoch": 0.19914187109411435,
      "grad_norm": 25.18967056274414,
      "learning_rate": 7.963446475195822e-06,
      "loss": 0.6526817321777344,
      "memory(GiB)": 62.17,
      "step": 2135,
      "train_speed(iter/s)": 0.252178
    },
    {
      "epoch": 0.199608245499487,
      "grad_norm": 23.46197509765625,
      "learning_rate": 7.982096232748975e-06,
      "loss": 0.6710953712463379,
      "memory(GiB)": 62.17,
      "step": 2140,
      "train_speed(iter/s)": 0.252167
    },
    {
      "epoch": 0.2000746199048596,
      "grad_norm": 14.12015438079834,
      "learning_rate": 8.000745990302127e-06,
      "loss": 0.6725931167602539,
      "memory(GiB)": 62.17,
      "step": 2145,
      "train_speed(iter/s)": 0.252184
    },
    {
      "epoch": 0.20054099431023226,
      "grad_norm": 16.15689468383789,
      "learning_rate": 8.019395747855279e-06,
      "loss": 0.6543282508850098,
      "memory(GiB)": 62.17,
      "step": 2150,
      "train_speed(iter/s)": 0.252212
    },
    {
      "epoch": 0.2010073687156049,
      "grad_norm": 19.5562686920166,
      "learning_rate": 8.03804550540843e-06,
      "loss": 0.6816583633422851,
      "memory(GiB)": 62.17,
      "step": 2155,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.252208
    },
    {
      "epoch": 0.20147374312097752,
      "grad_norm": 14.232253074645996,
      "learning_rate": 8.056695262961582e-06,
      "loss": 0.6275742530822754,
      "memory(GiB)": 62.17,
      "step": 2160,
      "token_acc": 0.8588235294117647,
      "train_speed(iter/s)": 0.252242
    },
    {
      "epoch": 0.20194011752635016,
      "grad_norm": 24.41075897216797,
      "learning_rate": 8.075345020514735e-06,
      "loss": 0.6819291114807129,
      "memory(GiB)": 62.17,
      "step": 2165,
      "train_speed(iter/s)": 0.252262
    },
    {
      "epoch": 0.20240649193172278,
      "grad_norm": 34.10822296142578,
      "learning_rate": 8.093994778067887e-06,
      "loss": 0.7186797142028809,
      "memory(GiB)": 62.17,
      "step": 2170,
      "train_speed(iter/s)": 0.2523
    },
    {
      "epoch": 0.20287286633709542,
      "grad_norm": 24.06275177001953,
      "learning_rate": 8.112644535621036e-06,
      "loss": 0.7285603523254395,
      "memory(GiB)": 62.17,
      "step": 2175,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.252277
    },
    {
      "epoch": 0.20333924074246806,
      "grad_norm": 31.708215713500977,
      "learning_rate": 8.13129429317419e-06,
      "loss": 0.639248275756836,
      "memory(GiB)": 62.17,
      "step": 2180,
      "train_speed(iter/s)": 0.252271
    },
    {
      "epoch": 0.20380561514784068,
      "grad_norm": 25.151878356933594,
      "learning_rate": 8.149944050727341e-06,
      "loss": 0.6999976158142089,
      "memory(GiB)": 62.17,
      "step": 2185,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.252304
    },
    {
      "epoch": 0.20427198955321332,
      "grad_norm": 26.793521881103516,
      "learning_rate": 8.168593808280493e-06,
      "loss": 0.737174129486084,
      "memory(GiB)": 62.17,
      "step": 2190,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.252301
    },
    {
      "epoch": 0.20473836395858594,
      "grad_norm": 21.587316513061523,
      "learning_rate": 8.187243565833644e-06,
      "loss": 0.6490747928619385,
      "memory(GiB)": 62.17,
      "step": 2195,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.252298
    },
    {
      "epoch": 0.20520473836395858,
      "grad_norm": 30.726022720336914,
      "learning_rate": 8.205893323386796e-06,
      "loss": 0.6980786323547363,
      "memory(GiB)": 62.17,
      "step": 2200,
      "token_acc": 0.7,
      "train_speed(iter/s)": 0.252279
    },
    {
      "epoch": 0.20567111276933123,
      "grad_norm": 17.767547607421875,
      "learning_rate": 8.22454308093995e-06,
      "loss": 0.7314588069915772,
      "memory(GiB)": 62.17,
      "step": 2205,
      "train_speed(iter/s)": 0.252269
    },
    {
      "epoch": 0.20613748717470384,
      "grad_norm": 15.250903129577637,
      "learning_rate": 8.2431928384931e-06,
      "loss": 0.6489331245422363,
      "memory(GiB)": 62.17,
      "step": 2210,
      "train_speed(iter/s)": 0.252243
    },
    {
      "epoch": 0.2066038615800765,
      "grad_norm": 13.835695266723633,
      "learning_rate": 8.261842596046252e-06,
      "loss": 0.710031270980835,
      "memory(GiB)": 62.17,
      "step": 2215,
      "token_acc": 0.45098039215686275,
      "train_speed(iter/s)": 0.252262
    },
    {
      "epoch": 0.20707023598544913,
      "grad_norm": 15.703109741210938,
      "learning_rate": 8.280492353599404e-06,
      "loss": 0.6508700847625732,
      "memory(GiB)": 62.17,
      "step": 2220,
      "train_speed(iter/s)": 0.252243
    },
    {
      "epoch": 0.20753661039082175,
      "grad_norm": 17.926063537597656,
      "learning_rate": 8.299142111152556e-06,
      "loss": 0.654489278793335,
      "memory(GiB)": 62.17,
      "step": 2225,
      "token_acc": 0.4745762711864407,
      "train_speed(iter/s)": 0.25223
    },
    {
      "epoch": 0.2080029847961944,
      "grad_norm": 28.416818618774414,
      "learning_rate": 8.317791868705707e-06,
      "loss": 0.6235842704772949,
      "memory(GiB)": 62.17,
      "step": 2230,
      "train_speed(iter/s)": 0.252235
    },
    {
      "epoch": 0.208469359201567,
      "grad_norm": 32.56223678588867,
      "learning_rate": 8.336441626258859e-06,
      "loss": 0.7559554100036621,
      "memory(GiB)": 62.17,
      "step": 2235,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252216
    },
    {
      "epoch": 0.20893573360693965,
      "grad_norm": 44.85545349121094,
      "learning_rate": 8.35509138381201e-06,
      "loss": 0.6834707736968995,
      "memory(GiB)": 62.17,
      "step": 2240,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.252001
    },
    {
      "epoch": 0.2094021080123123,
      "grad_norm": 26.28223419189453,
      "learning_rate": 8.373741141365162e-06,
      "loss": 0.7000800132751465,
      "memory(GiB)": 62.17,
      "step": 2245,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 0.2098684824176849,
      "grad_norm": 19.900287628173828,
      "learning_rate": 8.392390898918315e-06,
      "loss": 0.6976551532745361,
      "memory(GiB)": 62.17,
      "step": 2250,
      "token_acc": 0.425531914893617,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 0.21033485682305755,
      "grad_norm": 25.3148136138916,
      "learning_rate": 8.411040656471467e-06,
      "loss": 0.6972195625305175,
      "memory(GiB)": 62.17,
      "step": 2255,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 0.2108012312284302,
      "grad_norm": 51.27496337890625,
      "learning_rate": 8.429690414024618e-06,
      "loss": 0.7174149036407471,
      "memory(GiB)": 62.17,
      "step": 2260,
      "token_acc": 0.6916666666666667,
      "train_speed(iter/s)": 0.251993
    },
    {
      "epoch": 0.2112676056338028,
      "grad_norm": 46.89681625366211,
      "learning_rate": 8.44834017157777e-06,
      "loss": 0.655942726135254,
      "memory(GiB)": 62.17,
      "step": 2265,
      "token_acc": 0.5875,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 0.21173398003917546,
      "grad_norm": 24.374235153198242,
      "learning_rate": 8.466989929130921e-06,
      "loss": 0.7171505928039551,
      "memory(GiB)": 62.17,
      "step": 2270,
      "train_speed(iter/s)": 0.252036
    },
    {
      "epoch": 0.21220035444454807,
      "grad_norm": 22.7891902923584,
      "learning_rate": 8.485639686684075e-06,
      "loss": 0.6594000339508057,
      "memory(GiB)": 62.17,
      "step": 2275,
      "token_acc": 0.5490196078431373,
      "train_speed(iter/s)": 0.252033
    },
    {
      "epoch": 0.21266672884992072,
      "grad_norm": 18.825801849365234,
      "learning_rate": 8.504289444237226e-06,
      "loss": 0.723018741607666,
      "memory(GiB)": 62.17,
      "step": 2280,
      "train_speed(iter/s)": 0.252019
    },
    {
      "epoch": 0.21313310325529336,
      "grad_norm": 19.00181007385254,
      "learning_rate": 8.522939201790378e-06,
      "loss": 0.6824009895324707,
      "memory(GiB)": 62.17,
      "step": 2285,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 0.21359947766066598,
      "grad_norm": 20.58592414855957,
      "learning_rate": 8.54158895934353e-06,
      "loss": 0.6687736511230469,
      "memory(GiB)": 62.17,
      "step": 2290,
      "train_speed(iter/s)": 0.252062
    },
    {
      "epoch": 0.21406585206603862,
      "grad_norm": 17.83116340637207,
      "learning_rate": 8.560238716896681e-06,
      "loss": 0.5971378803253173,
      "memory(GiB)": 62.17,
      "step": 2295,
      "train_speed(iter/s)": 0.252099
    },
    {
      "epoch": 0.21453222647141124,
      "grad_norm": 17.315532684326172,
      "learning_rate": 8.578888474449833e-06,
      "loss": 0.6577837944030762,
      "memory(GiB)": 62.17,
      "step": 2300,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 0.21499860087678388,
      "grad_norm": 14.07945442199707,
      "learning_rate": 8.597538232002984e-06,
      "loss": 0.6460051536560059,
      "memory(GiB)": 62.17,
      "step": 2305,
      "train_speed(iter/s)": 0.252156
    },
    {
      "epoch": 0.21546497528215652,
      "grad_norm": 7.886376857757568,
      "learning_rate": 8.616187989556136e-06,
      "loss": 0.6120547771453857,
      "memory(GiB)": 62.17,
      "step": 2310,
      "token_acc": 0.6778846153846154,
      "train_speed(iter/s)": 0.252168
    },
    {
      "epoch": 0.21593134968752914,
      "grad_norm": 13.68683910369873,
      "learning_rate": 8.634837747109287e-06,
      "loss": 0.6546862125396729,
      "memory(GiB)": 62.17,
      "step": 2315,
      "token_acc": 0.2903225806451613,
      "train_speed(iter/s)": 0.252199
    },
    {
      "epoch": 0.21639772409290178,
      "grad_norm": 24.378429412841797,
      "learning_rate": 8.65348750466244e-06,
      "loss": 0.6722145080566406,
      "memory(GiB)": 62.17,
      "step": 2320,
      "train_speed(iter/s)": 0.252225
    },
    {
      "epoch": 0.21686409849827443,
      "grad_norm": 12.031867027282715,
      "learning_rate": 8.672137262215592e-06,
      "loss": 0.6308738708496093,
      "memory(GiB)": 62.17,
      "step": 2325,
      "token_acc": 0.39344262295081966,
      "train_speed(iter/s)": 0.252245
    },
    {
      "epoch": 0.21733047290364704,
      "grad_norm": 13.048638343811035,
      "learning_rate": 8.690787019768744e-06,
      "loss": 0.610646915435791,
      "memory(GiB)": 62.17,
      "step": 2330,
      "train_speed(iter/s)": 0.252255
    },
    {
      "epoch": 0.2177968473090197,
      "grad_norm": 11.067055702209473,
      "learning_rate": 8.709436777321895e-06,
      "loss": 0.6645281791687012,
      "memory(GiB)": 62.17,
      "step": 2335,
      "token_acc": 0.49606299212598426,
      "train_speed(iter/s)": 0.252226
    },
    {
      "epoch": 0.2182632217143923,
      "grad_norm": 14.198235511779785,
      "learning_rate": 8.728086534875047e-06,
      "loss": 0.5983171463012695,
      "memory(GiB)": 62.17,
      "step": 2340,
      "train_speed(iter/s)": 0.252199
    },
    {
      "epoch": 0.21872959611976495,
      "grad_norm": 13.017641067504883,
      "learning_rate": 8.7467362924282e-06,
      "loss": 0.6239345073699951,
      "memory(GiB)": 62.17,
      "step": 2345,
      "token_acc": 0.7727272727272727,
      "train_speed(iter/s)": 0.252247
    },
    {
      "epoch": 0.2191959705251376,
      "grad_norm": 19.18171501159668,
      "learning_rate": 8.765386049981352e-06,
      "loss": 0.6568900585174561,
      "memory(GiB)": 62.17,
      "step": 2350,
      "token_acc": 0.4489795918367347,
      "train_speed(iter/s)": 0.25223
    },
    {
      "epoch": 0.2196623449305102,
      "grad_norm": 14.718324661254883,
      "learning_rate": 8.784035807534502e-06,
      "loss": 0.6029397010803222,
      "memory(GiB)": 62.17,
      "step": 2355,
      "train_speed(iter/s)": 0.252247
    },
    {
      "epoch": 0.22012871933588285,
      "grad_norm": 11.595650672912598,
      "learning_rate": 8.802685565087655e-06,
      "loss": 0.6613173961639405,
      "memory(GiB)": 62.17,
      "step": 2360,
      "token_acc": 0.5666666666666667,
      "train_speed(iter/s)": 0.252239
    },
    {
      "epoch": 0.2205950937412555,
      "grad_norm": 13.384615898132324,
      "learning_rate": 8.821335322640806e-06,
      "loss": 0.6443560123443604,
      "memory(GiB)": 62.17,
      "step": 2365,
      "train_speed(iter/s)": 0.252262
    },
    {
      "epoch": 0.2210614681466281,
      "grad_norm": 17.885669708251953,
      "learning_rate": 8.839985080193958e-06,
      "loss": 0.7091313362121582,
      "memory(GiB)": 62.17,
      "step": 2370,
      "train_speed(iter/s)": 0.252274
    },
    {
      "epoch": 0.22152784255200075,
      "grad_norm": 19.745208740234375,
      "learning_rate": 8.85863483774711e-06,
      "loss": 0.6129339218139649,
      "memory(GiB)": 62.17,
      "step": 2375,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.252259
    },
    {
      "epoch": 0.22199421695737337,
      "grad_norm": 22.2078800201416,
      "learning_rate": 8.877284595300261e-06,
      "loss": 0.5873524665832519,
      "memory(GiB)": 62.17,
      "step": 2380,
      "train_speed(iter/s)": 0.252277
    },
    {
      "epoch": 0.222460591362746,
      "grad_norm": 14.62194538116455,
      "learning_rate": 8.895934352853414e-06,
      "loss": 0.659916353225708,
      "memory(GiB)": 62.17,
      "step": 2385,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.252294
    },
    {
      "epoch": 0.22292696576811866,
      "grad_norm": 16.048450469970703,
      "learning_rate": 8.914584110406566e-06,
      "loss": 0.651147985458374,
      "memory(GiB)": 62.17,
      "step": 2390,
      "token_acc": 0.3492063492063492,
      "train_speed(iter/s)": 0.252285
    },
    {
      "epoch": 0.22339334017349127,
      "grad_norm": 18.6436767578125,
      "learning_rate": 8.933233867959718e-06,
      "loss": 0.6538097381591796,
      "memory(GiB)": 62.17,
      "step": 2395,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.252267
    },
    {
      "epoch": 0.22385971457886392,
      "grad_norm": 19.05050277709961,
      "learning_rate": 8.951883625512869e-06,
      "loss": 0.6752886295318603,
      "memory(GiB)": 62.17,
      "step": 2400,
      "train_speed(iter/s)": 0.252268
    },
    {
      "epoch": 0.22432608898423653,
      "grad_norm": 21.614118576049805,
      "learning_rate": 8.97053338306602e-06,
      "loss": 0.6472405910491943,
      "memory(GiB)": 62.17,
      "step": 2405,
      "token_acc": 0.6962025316455697,
      "train_speed(iter/s)": 0.252262
    },
    {
      "epoch": 0.22479246338960918,
      "grad_norm": 30.483440399169922,
      "learning_rate": 8.989183140619174e-06,
      "loss": 0.7031034469604492,
      "memory(GiB)": 62.17,
      "step": 2410,
      "token_acc": 0.8641975308641975,
      "train_speed(iter/s)": 0.252252
    },
    {
      "epoch": 0.22525883779498182,
      "grad_norm": 9.585442543029785,
      "learning_rate": 9.007832898172324e-06,
      "loss": 0.6713173866271973,
      "memory(GiB)": 62.17,
      "step": 2415,
      "token_acc": 0.4318181818181818,
      "train_speed(iter/s)": 0.25224
    },
    {
      "epoch": 0.22572521220035444,
      "grad_norm": 12.00192928314209,
      "learning_rate": 9.026482655725475e-06,
      "loss": 0.6173913955688477,
      "memory(GiB)": 62.17,
      "step": 2420,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.25226
    },
    {
      "epoch": 0.22619158660572708,
      "grad_norm": 19.153244018554688,
      "learning_rate": 9.045132413278627e-06,
      "loss": 0.6652711391448974,
      "memory(GiB)": 62.17,
      "step": 2425,
      "token_acc": 0.45098039215686275,
      "train_speed(iter/s)": 0.252265
    },
    {
      "epoch": 0.22665796101109972,
      "grad_norm": 13.744402885437012,
      "learning_rate": 9.06378217083178e-06,
      "loss": 0.6016509056091308,
      "memory(GiB)": 62.17,
      "step": 2430,
      "train_speed(iter/s)": 0.252298
    },
    {
      "epoch": 0.22712433541647234,
      "grad_norm": 7.406866073608398,
      "learning_rate": 9.082431928384932e-06,
      "loss": 0.7012748718261719,
      "memory(GiB)": 62.17,
      "step": 2435,
      "token_acc": 0.8795180722891566,
      "train_speed(iter/s)": 0.252279
    },
    {
      "epoch": 0.22759070982184498,
      "grad_norm": 8.491008758544922,
      "learning_rate": 9.101081685938083e-06,
      "loss": 0.5802472591400146,
      "memory(GiB)": 62.17,
      "step": 2440,
      "train_speed(iter/s)": 0.252297
    },
    {
      "epoch": 0.2280570842272176,
      "grad_norm": 20.3810977935791,
      "learning_rate": 9.119731443491235e-06,
      "loss": 0.6352419853210449,
      "memory(GiB)": 62.17,
      "step": 2445,
      "train_speed(iter/s)": 0.252325
    },
    {
      "epoch": 0.22852345863259024,
      "grad_norm": 14.476198196411133,
      "learning_rate": 9.138381201044387e-06,
      "loss": 0.6546830177307129,
      "memory(GiB)": 62.17,
      "step": 2450,
      "train_speed(iter/s)": 0.252314
    },
    {
      "epoch": 0.2289898330379629,
      "grad_norm": 15.53343677520752,
      "learning_rate": 9.15703095859754e-06,
      "loss": 0.6235345840454102,
      "memory(GiB)": 62.17,
      "step": 2455,
      "token_acc": 0.4807692307692308,
      "train_speed(iter/s)": 0.252331
    },
    {
      "epoch": 0.2294562074433355,
      "grad_norm": 25.435867309570312,
      "learning_rate": 9.175680716150691e-06,
      "loss": 0.6343881607055664,
      "memory(GiB)": 62.17,
      "step": 2460,
      "token_acc": 0.5223880597014925,
      "train_speed(iter/s)": 0.252369
    },
    {
      "epoch": 0.22992258184870815,
      "grad_norm": 36.22317886352539,
      "learning_rate": 9.194330473703843e-06,
      "loss": 0.7058827400207519,
      "memory(GiB)": 62.17,
      "step": 2465,
      "train_speed(iter/s)": 0.252411
    },
    {
      "epoch": 0.23038895625408076,
      "grad_norm": 12.873272895812988,
      "learning_rate": 9.212980231256995e-06,
      "loss": 0.6558905601501465,
      "memory(GiB)": 62.17,
      "step": 2470,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.252416
    },
    {
      "epoch": 0.2308553306594534,
      "grad_norm": 18.132686614990234,
      "learning_rate": 9.231629988810146e-06,
      "loss": 0.6388163566589355,
      "memory(GiB)": 62.17,
      "step": 2475,
      "token_acc": 0.4146341463414634,
      "train_speed(iter/s)": 0.252438
    },
    {
      "epoch": 0.23132170506482605,
      "grad_norm": 13.092702865600586,
      "learning_rate": 9.250279746363298e-06,
      "loss": 0.6664896488189698,
      "memory(GiB)": 62.17,
      "step": 2480,
      "train_speed(iter/s)": 0.252482
    },
    {
      "epoch": 0.23178807947019867,
      "grad_norm": 16.79343605041504,
      "learning_rate": 9.26892950391645e-06,
      "loss": 0.6897128105163575,
      "memory(GiB)": 62.17,
      "step": 2485,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25249
    },
    {
      "epoch": 0.2322544538755713,
      "grad_norm": 18.209482192993164,
      "learning_rate": 9.287579261469601e-06,
      "loss": 0.6899092197418213,
      "memory(GiB)": 62.17,
      "step": 2490,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.252543
    },
    {
      "epoch": 0.23272082828094395,
      "grad_norm": 20.495071411132812,
      "learning_rate": 9.306229019022754e-06,
      "loss": 0.687758493423462,
      "memory(GiB)": 62.17,
      "step": 2495,
      "train_speed(iter/s)": 0.252543
    },
    {
      "epoch": 0.23318720268631657,
      "grad_norm": 9.046577453613281,
      "learning_rate": 9.324878776575906e-06,
      "loss": 0.6804199695587159,
      "memory(GiB)": 62.17,
      "step": 2500,
      "train_speed(iter/s)": 0.252559
    },
    {
      "epoch": 0.2336535770916892,
      "grad_norm": 21.735340118408203,
      "learning_rate": 9.343528534129057e-06,
      "loss": 0.6528851509094238,
      "memory(GiB)": 62.17,
      "step": 2505,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.252564
    },
    {
      "epoch": 0.23411995149706183,
      "grad_norm": 8.090928077697754,
      "learning_rate": 9.362178291682209e-06,
      "loss": 0.6831672668457032,
      "memory(GiB)": 62.17,
      "step": 2510,
      "token_acc": 0.3953488372093023,
      "train_speed(iter/s)": 0.252596
    },
    {
      "epoch": 0.23458632590243447,
      "grad_norm": 10.482458114624023,
      "learning_rate": 9.38082804923536e-06,
      "loss": 0.6341225624084472,
      "memory(GiB)": 62.17,
      "step": 2515,
      "train_speed(iter/s)": 0.252598
    },
    {
      "epoch": 0.23505270030780712,
      "grad_norm": 14.70026969909668,
      "learning_rate": 9.399477806788514e-06,
      "loss": 0.6307250022888183,
      "memory(GiB)": 62.17,
      "step": 2520,
      "token_acc": 0.45,
      "train_speed(iter/s)": 0.252616
    },
    {
      "epoch": 0.23551907471317973,
      "grad_norm": 19.474937438964844,
      "learning_rate": 9.418127564341665e-06,
      "loss": 0.5947713851928711,
      "memory(GiB)": 62.17,
      "step": 2525,
      "token_acc": 0.5566037735849056,
      "train_speed(iter/s)": 0.252633
    },
    {
      "epoch": 0.23598544911855238,
      "grad_norm": 13.527084350585938,
      "learning_rate": 9.436777321894817e-06,
      "loss": 0.6626876831054688,
      "memory(GiB)": 62.17,
      "step": 2530,
      "train_speed(iter/s)": 0.25262
    },
    {
      "epoch": 0.23645182352392502,
      "grad_norm": 24.131406784057617,
      "learning_rate": 9.455427079447967e-06,
      "loss": 0.6627018451690674,
      "memory(GiB)": 62.17,
      "step": 2535,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.252674
    },
    {
      "epoch": 0.23691819792929764,
      "grad_norm": 20.305461883544922,
      "learning_rate": 9.47407683700112e-06,
      "loss": 0.6320087432861328,
      "memory(GiB)": 62.17,
      "step": 2540,
      "train_speed(iter/s)": 0.252682
    },
    {
      "epoch": 0.23738457233467028,
      "grad_norm": 9.448407173156738,
      "learning_rate": 9.492726594554272e-06,
      "loss": 0.658384132385254,
      "memory(GiB)": 62.17,
      "step": 2545,
      "token_acc": 0.898876404494382,
      "train_speed(iter/s)": 0.252685
    },
    {
      "epoch": 0.2378509467400429,
      "grad_norm": 21.873926162719727,
      "learning_rate": 9.511376352107423e-06,
      "loss": 0.6835556030273438,
      "memory(GiB)": 62.17,
      "step": 2550,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.252701
    },
    {
      "epoch": 0.23831732114541554,
      "grad_norm": 20.46870231628418,
      "learning_rate": 9.530026109660575e-06,
      "loss": 0.6562372207641601,
      "memory(GiB)": 62.17,
      "step": 2555,
      "token_acc": 0.43103448275862066,
      "train_speed(iter/s)": 0.252656
    },
    {
      "epoch": 0.23878369555078818,
      "grad_norm": 22.088584899902344,
      "learning_rate": 9.548675867213726e-06,
      "loss": 0.6706534385681152,
      "memory(GiB)": 62.17,
      "step": 2560,
      "train_speed(iter/s)": 0.252639
    },
    {
      "epoch": 0.2392500699561608,
      "grad_norm": 17.85317039489746,
      "learning_rate": 9.56732562476688e-06,
      "loss": 0.6642901420593261,
      "memory(GiB)": 62.17,
      "step": 2565,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.252622
    },
    {
      "epoch": 0.23971644436153344,
      "grad_norm": 8.384767532348633,
      "learning_rate": 9.585975382320031e-06,
      "loss": 0.6548426151275635,
      "memory(GiB)": 62.17,
      "step": 2570,
      "token_acc": 0.504950495049505,
      "train_speed(iter/s)": 0.25262
    },
    {
      "epoch": 0.24018281876690606,
      "grad_norm": 12.444215774536133,
      "learning_rate": 9.604625139873183e-06,
      "loss": 0.6738784790039063,
      "memory(GiB)": 62.17,
      "step": 2575,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.25263
    },
    {
      "epoch": 0.2406491931722787,
      "grad_norm": 10.895191192626953,
      "learning_rate": 9.623274897426334e-06,
      "loss": 0.6119955539703369,
      "memory(GiB)": 62.17,
      "step": 2580,
      "token_acc": 0.84,
      "train_speed(iter/s)": 0.252628
    },
    {
      "epoch": 0.24111556757765135,
      "grad_norm": 19.317920684814453,
      "learning_rate": 9.641924654979486e-06,
      "loss": 0.6195825576782227,
      "memory(GiB)": 62.17,
      "step": 2585,
      "train_speed(iter/s)": 0.252649
    },
    {
      "epoch": 0.24158194198302396,
      "grad_norm": 18.357847213745117,
      "learning_rate": 9.660574412532639e-06,
      "loss": 0.6135167598724365,
      "memory(GiB)": 62.17,
      "step": 2590,
      "train_speed(iter/s)": 0.252635
    },
    {
      "epoch": 0.2420483163883966,
      "grad_norm": 7.63726806640625,
      "learning_rate": 9.679224170085789e-06,
      "loss": 0.6561915397644043,
      "memory(GiB)": 62.17,
      "step": 2595,
      "token_acc": 0.7337662337662337,
      "train_speed(iter/s)": 0.252628
    },
    {
      "epoch": 0.24251469079376925,
      "grad_norm": 11.205409049987793,
      "learning_rate": 9.69787392763894e-06,
      "loss": 0.6267797470092773,
      "memory(GiB)": 62.17,
      "step": 2600,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.25266
    },
    {
      "epoch": 0.24298106519914187,
      "grad_norm": 9.205306053161621,
      "learning_rate": 9.716523685192092e-06,
      "loss": 0.6083670616149902,
      "memory(GiB)": 62.17,
      "step": 2605,
      "train_speed(iter/s)": 0.252651
    },
    {
      "epoch": 0.2434474396045145,
      "grad_norm": 12.367506980895996,
      "learning_rate": 9.735173442745245e-06,
      "loss": 0.6130194664001465,
      "memory(GiB)": 62.17,
      "step": 2610,
      "token_acc": 0.3181818181818182,
      "train_speed(iter/s)": 0.252649
    },
    {
      "epoch": 0.24391381400988713,
      "grad_norm": 10.360567092895508,
      "learning_rate": 9.753823200298397e-06,
      "loss": 0.6154788494110107,
      "memory(GiB)": 62.17,
      "step": 2615,
      "token_acc": 0.3409090909090909,
      "train_speed(iter/s)": 0.252678
    },
    {
      "epoch": 0.24438018841525977,
      "grad_norm": 17.85171890258789,
      "learning_rate": 9.772472957851549e-06,
      "loss": 0.746298885345459,
      "memory(GiB)": 62.17,
      "step": 2620,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.252671
    },
    {
      "epoch": 0.2448465628206324,
      "grad_norm": 12.773937225341797,
      "learning_rate": 9.7911227154047e-06,
      "loss": 0.6552183151245117,
      "memory(GiB)": 62.17,
      "step": 2625,
      "token_acc": 0.6129032258064516,
      "train_speed(iter/s)": 0.252699
    },
    {
      "epoch": 0.24531293722600503,
      "grad_norm": 22.467519760131836,
      "learning_rate": 9.809772472957852e-06,
      "loss": 0.6708625793457031,
      "memory(GiB)": 62.17,
      "step": 2630,
      "train_speed(iter/s)": 0.252723
    },
    {
      "epoch": 0.24577931163137767,
      "grad_norm": 12.590497970581055,
      "learning_rate": 9.828422230511005e-06,
      "loss": 0.6732925415039063,
      "memory(GiB)": 62.17,
      "step": 2635,
      "train_speed(iter/s)": 0.252716
    },
    {
      "epoch": 0.24624568603675032,
      "grad_norm": 10.171735763549805,
      "learning_rate": 9.847071988064157e-06,
      "loss": 0.6399045944213867,
      "memory(GiB)": 62.17,
      "step": 2640,
      "train_speed(iter/s)": 0.252697
    },
    {
      "epoch": 0.24671206044212293,
      "grad_norm": 5.900382995605469,
      "learning_rate": 9.865721745617308e-06,
      "loss": 0.6273941993713379,
      "memory(GiB)": 62.17,
      "step": 2645,
      "token_acc": 0.8026315789473685,
      "train_speed(iter/s)": 0.252705
    },
    {
      "epoch": 0.24717843484749558,
      "grad_norm": 26.795076370239258,
      "learning_rate": 9.88437150317046e-06,
      "loss": 0.7268101692199707,
      "memory(GiB)": 62.17,
      "step": 2650,
      "train_speed(iter/s)": 0.25269
    },
    {
      "epoch": 0.2476448092528682,
      "grad_norm": 18.982101440429688,
      "learning_rate": 9.903021260723611e-06,
      "loss": 0.686002254486084,
      "memory(GiB)": 62.17,
      "step": 2655,
      "token_acc": 0.4868421052631579,
      "train_speed(iter/s)": 0.252715
    },
    {
      "epoch": 0.24811118365824084,
      "grad_norm": 7.9113240242004395,
      "learning_rate": 9.921671018276763e-06,
      "loss": 0.7231151580810546,
      "memory(GiB)": 62.17,
      "step": 2660,
      "token_acc": 0.390625,
      "train_speed(iter/s)": 0.252713
    },
    {
      "epoch": 0.24857755806361348,
      "grad_norm": 15.485579490661621,
      "learning_rate": 9.940320775829914e-06,
      "loss": 0.7073670864105225,
      "memory(GiB)": 62.17,
      "step": 2665,
      "token_acc": 0.8288770053475936,
      "train_speed(iter/s)": 0.252736
    },
    {
      "epoch": 0.2490439324689861,
      "grad_norm": 8.927393913269043,
      "learning_rate": 9.958970533383066e-06,
      "loss": 0.6306100368499756,
      "memory(GiB)": 62.17,
      "step": 2670,
      "train_speed(iter/s)": 0.252724
    },
    {
      "epoch": 0.24951030687435874,
      "grad_norm": 20.06386375427246,
      "learning_rate": 9.97762029093622e-06,
      "loss": 0.6468748569488525,
      "memory(GiB)": 62.17,
      "step": 2675,
      "train_speed(iter/s)": 0.252728
    },
    {
      "epoch": 0.24997668127973136,
      "grad_norm": 13.987184524536133,
      "learning_rate": 9.99627004848937e-06,
      "loss": 0.637957763671875,
      "memory(GiB)": 62.17,
      "step": 2680,
      "token_acc": 0.3050847457627119,
      "train_speed(iter/s)": 0.252727
    },
    {
      "epoch": 0.250443055685104,
      "grad_norm": 12.406564712524414,
      "learning_rate": 9.999999847764929e-06,
      "loss": 0.5919284820556641,
      "memory(GiB)": 62.17,
      "step": 2685,
      "token_acc": 0.3644067796610169,
      "train_speed(iter/s)": 0.252734
    },
    {
      "epoch": 0.2509094300904766,
      "grad_norm": 13.789671897888184,
      "learning_rate": 9.999999229309967e-06,
      "loss": 0.6056517124176025,
      "memory(GiB)": 62.17,
      "step": 2690,
      "train_speed(iter/s)": 0.252753
    },
    {
      "epoch": 0.2513758044958493,
      "grad_norm": 7.4060282707214355,
      "learning_rate": 9.999998135120482e-06,
      "loss": 0.6259072303771973,
      "memory(GiB)": 62.17,
      "step": 2695,
      "train_speed(iter/s)": 0.252749
    },
    {
      "epoch": 0.2518421789012219,
      "grad_norm": 17.98369789123535,
      "learning_rate": 9.999996565196576e-06,
      "loss": 0.6218691825866699,
      "memory(GiB)": 62.17,
      "step": 2700,
      "train_speed(iter/s)": 0.252756
    },
    {
      "epoch": 0.2523085533065945,
      "grad_norm": 40.03813934326172,
      "learning_rate": 9.9999945195384e-06,
      "loss": 0.6856225490570068,
      "memory(GiB)": 62.17,
      "step": 2705,
      "train_speed(iter/s)": 0.252789
    },
    {
      "epoch": 0.2527749277119672,
      "grad_norm": 8.393588066101074,
      "learning_rate": 9.999991998146149e-06,
      "loss": 0.6704384803771972,
      "memory(GiB)": 67.44,
      "step": 2710,
      "token_acc": 0.7604790419161677,
      "train_speed(iter/s)": 0.252775
    },
    {
      "epoch": 0.2532413021173398,
      "grad_norm": 7.204401016235352,
      "learning_rate": 9.99998900102006e-06,
      "loss": 0.6016728401184082,
      "memory(GiB)": 67.44,
      "step": 2715,
      "train_speed(iter/s)": 0.252767
    },
    {
      "epoch": 0.2537076765227124,
      "grad_norm": 8.82178783416748,
      "learning_rate": 9.999985528160423e-06,
      "loss": 0.5695421695709229,
      "memory(GiB)": 67.44,
      "step": 2720,
      "train_speed(iter/s)": 0.252776
    },
    {
      "epoch": 0.2541740509280851,
      "grad_norm": 15.598730087280273,
      "learning_rate": 9.999981579567565e-06,
      "loss": 0.6468422889709473,
      "memory(GiB)": 67.44,
      "step": 2725,
      "token_acc": 0.5230769230769231,
      "train_speed(iter/s)": 0.25274
    },
    {
      "epoch": 0.2546404253334577,
      "grad_norm": 20.137022018432617,
      "learning_rate": 9.999977155241862e-06,
      "loss": 0.6699275016784668,
      "memory(GiB)": 67.44,
      "step": 2730,
      "train_speed(iter/s)": 0.252741
    },
    {
      "epoch": 0.2551067997388303,
      "grad_norm": 24.583133697509766,
      "learning_rate": 9.999972255183736e-06,
      "loss": 0.6353895664215088,
      "memory(GiB)": 67.44,
      "step": 2735,
      "token_acc": 0.7528089887640449,
      "train_speed(iter/s)": 0.252739
    },
    {
      "epoch": 0.25557317414420294,
      "grad_norm": 14.932859420776367,
      "learning_rate": 9.999966879393652e-06,
      "loss": 0.6154529571533203,
      "memory(GiB)": 67.44,
      "step": 2740,
      "train_speed(iter/s)": 0.252731
    },
    {
      "epoch": 0.2560395485495756,
      "grad_norm": 16.70600128173828,
      "learning_rate": 9.999961027872123e-06,
      "loss": 0.6293547630310059,
      "memory(GiB)": 67.44,
      "step": 2745,
      "train_speed(iter/s)": 0.252739
    },
    {
      "epoch": 0.25650592295494823,
      "grad_norm": 12.943504333496094,
      "learning_rate": 9.999954700619706e-06,
      "loss": 0.6239521026611328,
      "memory(GiB)": 67.44,
      "step": 2750,
      "token_acc": 0.8846153846153846,
      "train_speed(iter/s)": 0.252775
    },
    {
      "epoch": 0.25697229736032084,
      "grad_norm": 9.302803039550781,
      "learning_rate": 9.999947897637e-06,
      "loss": 0.5795038223266602,
      "memory(GiB)": 67.44,
      "step": 2755,
      "token_acc": 0.8348623853211009,
      "train_speed(iter/s)": 0.252794
    },
    {
      "epoch": 0.2574386717656935,
      "grad_norm": 13.456811904907227,
      "learning_rate": 9.999940618924655e-06,
      "loss": 0.5737096309661865,
      "memory(GiB)": 67.44,
      "step": 2760,
      "train_speed(iter/s)": 0.252809
    },
    {
      "epoch": 0.25790504617106613,
      "grad_norm": 16.927263259887695,
      "learning_rate": 9.999932864483362e-06,
      "loss": 0.6134072303771972,
      "memory(GiB)": 67.44,
      "step": 2765,
      "token_acc": 0.4574468085106383,
      "train_speed(iter/s)": 0.252813
    },
    {
      "epoch": 0.25837142057643875,
      "grad_norm": 6.742459774017334,
      "learning_rate": 9.999924634313861e-06,
      "loss": 0.6177404880523681,
      "memory(GiB)": 67.44,
      "step": 2770,
      "token_acc": 0.4803921568627451,
      "train_speed(iter/s)": 0.252818
    },
    {
      "epoch": 0.2588377949818114,
      "grad_norm": 5.318719387054443,
      "learning_rate": 9.999915928416933e-06,
      "loss": 0.6257699966430664,
      "memory(GiB)": 67.44,
      "step": 2775,
      "token_acc": 0.3898305084745763,
      "train_speed(iter/s)": 0.252836
    },
    {
      "epoch": 0.25930416938718404,
      "grad_norm": 7.300972938537598,
      "learning_rate": 9.999906746793407e-06,
      "loss": 0.6119312286376953,
      "memory(GiB)": 67.44,
      "step": 2780,
      "train_speed(iter/s)": 0.252864
    },
    {
      "epoch": 0.25977054379255665,
      "grad_norm": 7.117703914642334,
      "learning_rate": 9.999897089444157e-06,
      "loss": 0.6082076072692871,
      "memory(GiB)": 67.44,
      "step": 2785,
      "token_acc": 0.5416666666666666,
      "train_speed(iter/s)": 0.252851
    },
    {
      "epoch": 0.2602369181979293,
      "grad_norm": 24.999727249145508,
      "learning_rate": 9.999886956370102e-06,
      "loss": 0.6059868335723877,
      "memory(GiB)": 67.44,
      "step": 2790,
      "train_speed(iter/s)": 0.252831
    },
    {
      "epoch": 0.26070329260330194,
      "grad_norm": 24.461376190185547,
      "learning_rate": 9.999876347572204e-06,
      "loss": 0.6921416759490967,
      "memory(GiB)": 67.44,
      "step": 2795,
      "train_speed(iter/s)": 0.252849
    },
    {
      "epoch": 0.26116966700867456,
      "grad_norm": 18.524396896362305,
      "learning_rate": 9.999865263051476e-06,
      "loss": 0.7191124439239502,
      "memory(GiB)": 67.44,
      "step": 2800,
      "token_acc": 0.8269230769230769,
      "train_speed(iter/s)": 0.252826
    },
    {
      "epoch": 0.26163604141404717,
      "grad_norm": 16.27431297302246,
      "learning_rate": 9.99985370280897e-06,
      "loss": 0.6568318367004394,
      "memory(GiB)": 67.44,
      "step": 2805,
      "train_speed(iter/s)": 0.252854
    },
    {
      "epoch": 0.26210241581941984,
      "grad_norm": 12.636087417602539,
      "learning_rate": 9.999841666845786e-06,
      "loss": 0.6477484703063965,
      "memory(GiB)": 67.44,
      "step": 2810,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.252866
    },
    {
      "epoch": 0.26256879022479246,
      "grad_norm": 11.819149017333984,
      "learning_rate": 9.99982915516307e-06,
      "loss": 0.595731544494629,
      "memory(GiB)": 67.44,
      "step": 2815,
      "train_speed(iter/s)": 0.252882
    },
    {
      "epoch": 0.2630351646301651,
      "grad_norm": 12.687555313110352,
      "learning_rate": 9.999816167762011e-06,
      "loss": 0.6922054290771484,
      "memory(GiB)": 67.44,
      "step": 2820,
      "token_acc": 0.4107142857142857,
      "train_speed(iter/s)": 0.252888
    },
    {
      "epoch": 0.26350153903553775,
      "grad_norm": 20.16313934326172,
      "learning_rate": 9.999802704643848e-06,
      "loss": 0.6052667140960694,
      "memory(GiB)": 67.44,
      "step": 2825,
      "train_speed(iter/s)": 0.252876
    },
    {
      "epoch": 0.26396791344091036,
      "grad_norm": 15.081018447875977,
      "learning_rate": 9.99978876580986e-06,
      "loss": 0.6541717529296875,
      "memory(GiB)": 67.44,
      "step": 2830,
      "token_acc": 0.3018867924528302,
      "train_speed(iter/s)": 0.252875
    },
    {
      "epoch": 0.264434287846283,
      "grad_norm": 10.327178955078125,
      "learning_rate": 9.99977435126137e-06,
      "loss": 0.5986374855041504,
      "memory(GiB)": 67.44,
      "step": 2835,
      "train_speed(iter/s)": 0.252887
    },
    {
      "epoch": 0.26490066225165565,
      "grad_norm": 18.107040405273438,
      "learning_rate": 9.999759460999757e-06,
      "loss": 0.6124319076538086,
      "memory(GiB)": 67.44,
      "step": 2840,
      "token_acc": 0.603448275862069,
      "train_speed(iter/s)": 0.252902
    },
    {
      "epoch": 0.26536703665702827,
      "grad_norm": 12.67278003692627,
      "learning_rate": 9.999744095026431e-06,
      "loss": 0.5851400375366211,
      "memory(GiB)": 67.44,
      "step": 2845,
      "token_acc": 0.4375,
      "train_speed(iter/s)": 0.252929
    },
    {
      "epoch": 0.2658334110624009,
      "grad_norm": 4.533482074737549,
      "learning_rate": 9.999728253342857e-06,
      "loss": 0.6309155464172364,
      "memory(GiB)": 67.44,
      "step": 2850,
      "train_speed(iter/s)": 0.25291
    },
    {
      "epoch": 0.26629978546777355,
      "grad_norm": 11.587343215942383,
      "learning_rate": 9.999711935950541e-06,
      "loss": 0.6232301712036132,
      "memory(GiB)": 67.44,
      "step": 2855,
      "train_speed(iter/s)": 0.252919
    },
    {
      "epoch": 0.26676615987314617,
      "grad_norm": 12.33057689666748,
      "learning_rate": 9.999695142851037e-06,
      "loss": 0.6143747806549072,
      "memory(GiB)": 67.44,
      "step": 2860,
      "train_speed(iter/s)": 0.25291
    },
    {
      "epoch": 0.2672325342785188,
      "grad_norm": 9.407552719116211,
      "learning_rate": 9.999677874045942e-06,
      "loss": 0.6596058368682861,
      "memory(GiB)": 67.44,
      "step": 2865,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.252927
    },
    {
      "epoch": 0.2676989086838914,
      "grad_norm": 13.889372825622559,
      "learning_rate": 9.999660129536898e-06,
      "loss": 0.6433503150939941,
      "memory(GiB)": 67.44,
      "step": 2870,
      "train_speed(iter/s)": 0.252965
    },
    {
      "epoch": 0.2681652830892641,
      "grad_norm": 10.03330135345459,
      "learning_rate": 9.999641909325597e-06,
      "loss": 0.608620548248291,
      "memory(GiB)": 67.44,
      "step": 2875,
      "train_speed(iter/s)": 0.25298
    },
    {
      "epoch": 0.2686316574946367,
      "grad_norm": 5.267341136932373,
      "learning_rate": 9.999623213413769e-06,
      "loss": 0.6418509006500244,
      "memory(GiB)": 67.44,
      "step": 2880,
      "token_acc": 0.40425531914893614,
      "train_speed(iter/s)": 0.252979
    },
    {
      "epoch": 0.2690980319000093,
      "grad_norm": 6.075701713562012,
      "learning_rate": 9.999604041803194e-06,
      "loss": 0.6550672054290771,
      "memory(GiB)": 67.44,
      "step": 2885,
      "train_speed(iter/s)": 0.252981
    },
    {
      "epoch": 0.269564406305382,
      "grad_norm": 8.704212188720703,
      "learning_rate": 9.999584394495696e-06,
      "loss": 0.6455496788024903,
      "memory(GiB)": 67.44,
      "step": 2890,
      "train_speed(iter/s)": 0.252996
    },
    {
      "epoch": 0.2700307807107546,
      "grad_norm": 12.790424346923828,
      "learning_rate": 9.999564271493143e-06,
      "loss": 0.6023807048797607,
      "memory(GiB)": 67.44,
      "step": 2895,
      "train_speed(iter/s)": 0.253005
    },
    {
      "epoch": 0.2704971551161272,
      "grad_norm": 11.095949172973633,
      "learning_rate": 9.999543672797454e-06,
      "loss": 0.6334352493286133,
      "memory(GiB)": 67.44,
      "step": 2900,
      "token_acc": 0.8817204301075269,
      "train_speed(iter/s)": 0.253
    },
    {
      "epoch": 0.2709635295214999,
      "grad_norm": 7.097005367279053,
      "learning_rate": 9.999522598410583e-06,
      "loss": 0.6279093742370605,
      "memory(GiB)": 67.44,
      "step": 2905,
      "token_acc": 0.8840579710144928,
      "train_speed(iter/s)": 0.253021
    },
    {
      "epoch": 0.2714299039268725,
      "grad_norm": 12.308854103088379,
      "learning_rate": 9.99950104833454e-06,
      "loss": 0.598863172531128,
      "memory(GiB)": 67.44,
      "step": 2910,
      "token_acc": 0.44761904761904764,
      "train_speed(iter/s)": 0.253044
    },
    {
      "epoch": 0.2718962783322451,
      "grad_norm": 18.19838523864746,
      "learning_rate": 9.999479022571374e-06,
      "loss": 0.6381216049194336,
      "memory(GiB)": 67.44,
      "step": 2915,
      "token_acc": 0.8543689320388349,
      "train_speed(iter/s)": 0.253055
    },
    {
      "epoch": 0.2723626527376178,
      "grad_norm": 24.44304656982422,
      "learning_rate": 9.999456521123178e-06,
      "loss": 0.6174750328063965,
      "memory(GiB)": 67.44,
      "step": 2920,
      "token_acc": 0.5471698113207547,
      "train_speed(iter/s)": 0.25304
    },
    {
      "epoch": 0.2728290271429904,
      "grad_norm": 15.806352615356445,
      "learning_rate": 9.999433543992097e-06,
      "loss": 0.6811147689819336,
      "memory(GiB)": 67.44,
      "step": 2925,
      "train_speed(iter/s)": 0.253044
    },
    {
      "epoch": 0.273295401548363,
      "grad_norm": 12.316401481628418,
      "learning_rate": 9.999410091180315e-06,
      "loss": 0.6033192634582519,
      "memory(GiB)": 67.44,
      "step": 2930,
      "token_acc": 0.8987341772151899,
      "train_speed(iter/s)": 0.253049
    },
    {
      "epoch": 0.2737617759537357,
      "grad_norm": 13.183638572692871,
      "learning_rate": 9.999386162690063e-06,
      "loss": 0.5763996124267579,
      "memory(GiB)": 67.44,
      "step": 2935,
      "train_speed(iter/s)": 0.25303
    },
    {
      "epoch": 0.2742281503591083,
      "grad_norm": 12.76721477508545,
      "learning_rate": 9.99936175852362e-06,
      "loss": 0.622044563293457,
      "memory(GiB)": 67.44,
      "step": 2940,
      "train_speed(iter/s)": 0.253059
    },
    {
      "epoch": 0.2746945247644809,
      "grad_norm": 21.635290145874023,
      "learning_rate": 9.999336878683309e-06,
      "loss": 0.5831369400024414,
      "memory(GiB)": 67.44,
      "step": 2945,
      "train_speed(iter/s)": 0.253055
    },
    {
      "epoch": 0.27516089916985353,
      "grad_norm": 10.155932426452637,
      "learning_rate": 9.99931152317149e-06,
      "loss": 0.6367108345031738,
      "memory(GiB)": 67.44,
      "step": 2950,
      "token_acc": 0.6875,
      "train_speed(iter/s)": 0.253035
    },
    {
      "epoch": 0.2756272735752262,
      "grad_norm": 12.802558898925781,
      "learning_rate": 9.999285691990583e-06,
      "loss": 0.6092627048492432,
      "memory(GiB)": 67.44,
      "step": 2955,
      "train_speed(iter/s)": 0.25308
    },
    {
      "epoch": 0.2760936479805988,
      "grad_norm": 8.525651931762695,
      "learning_rate": 9.999259385143042e-06,
      "loss": 0.6118044853210449,
      "memory(GiB)": 67.44,
      "step": 2960,
      "train_speed(iter/s)": 0.253073
    },
    {
      "epoch": 0.27656002238597144,
      "grad_norm": 18.816219329833984,
      "learning_rate": 9.999232602631372e-06,
      "loss": 0.6750175476074218,
      "memory(GiB)": 67.44,
      "step": 2965,
      "train_speed(iter/s)": 0.253067
    },
    {
      "epoch": 0.2770263967913441,
      "grad_norm": 16.99590301513672,
      "learning_rate": 9.99920534445812e-06,
      "loss": 0.6419601917266846,
      "memory(GiB)": 67.44,
      "step": 2970,
      "train_speed(iter/s)": 0.253098
    },
    {
      "epoch": 0.2774927711967167,
      "grad_norm": 10.079752922058105,
      "learning_rate": 9.999177610625878e-06,
      "loss": 0.6317691802978516,
      "memory(GiB)": 67.44,
      "step": 2975,
      "token_acc": 0.38181818181818183,
      "train_speed(iter/s)": 0.253095
    },
    {
      "epoch": 0.27795914560208934,
      "grad_norm": 14.243120193481445,
      "learning_rate": 9.999149401137288e-06,
      "loss": 0.6183422565460205,
      "memory(GiB)": 67.44,
      "step": 2980,
      "train_speed(iter/s)": 0.253105
    },
    {
      "epoch": 0.278425520007462,
      "grad_norm": 12.204408645629883,
      "learning_rate": 9.999120715995035e-06,
      "loss": 0.6571391582489013,
      "memory(GiB)": 67.44,
      "step": 2985,
      "train_speed(iter/s)": 0.253133
    },
    {
      "epoch": 0.27889189441283463,
      "grad_norm": 14.098135948181152,
      "learning_rate": 9.999091555201844e-06,
      "loss": 0.5713176727294922,
      "memory(GiB)": 67.44,
      "step": 2990,
      "train_speed(iter/s)": 0.253194
    },
    {
      "epoch": 0.27935826881820724,
      "grad_norm": 9.5954008102417,
      "learning_rate": 9.999061918760492e-06,
      "loss": 0.6017914772033691,
      "memory(GiB)": 67.44,
      "step": 2995,
      "token_acc": 0.7443609022556391,
      "train_speed(iter/s)": 0.253219
    },
    {
      "epoch": 0.2798246432235799,
      "grad_norm": 12.202272415161133,
      "learning_rate": 9.999031806673798e-06,
      "loss": 0.6309865474700928,
      "memory(GiB)": 67.44,
      "step": 3000,
      "train_speed(iter/s)": 0.253232
    },
    {
      "epoch": 0.28029101762895253,
      "grad_norm": 13.888272285461426,
      "learning_rate": 9.999001218944628e-06,
      "loss": 0.6429818153381348,
      "memory(GiB)": 67.44,
      "step": 3005,
      "token_acc": 0.7610619469026548,
      "train_speed(iter/s)": 0.253256
    },
    {
      "epoch": 0.28075739203432515,
      "grad_norm": 12.158670425415039,
      "learning_rate": 9.998970155575892e-06,
      "loss": 0.6003944396972656,
      "memory(GiB)": 67.44,
      "step": 3010,
      "train_speed(iter/s)": 0.253114
    },
    {
      "epoch": 0.28122376643969776,
      "grad_norm": 9.472729682922363,
      "learning_rate": 9.998938616570545e-06,
      "loss": 0.6012434482574462,
      "memory(GiB)": 67.44,
      "step": 3015,
      "train_speed(iter/s)": 0.25309
    },
    {
      "epoch": 0.28169014084507044,
      "grad_norm": 10.746199607849121,
      "learning_rate": 9.998906601931589e-06,
      "loss": 0.5817777633666992,
      "memory(GiB)": 67.44,
      "step": 3020,
      "train_speed(iter/s)": 0.253086
    },
    {
      "epoch": 0.28215651525044305,
      "grad_norm": 15.890499114990234,
      "learning_rate": 9.998874111662067e-06,
      "loss": 0.6122401714324951,
      "memory(GiB)": 67.44,
      "step": 3025,
      "token_acc": 0.3898305084745763,
      "train_speed(iter/s)": 0.253081
    },
    {
      "epoch": 0.28262288965581567,
      "grad_norm": 24.49274253845215,
      "learning_rate": 9.998841145765075e-06,
      "loss": 0.6199076175689697,
      "memory(GiB)": 67.44,
      "step": 3030,
      "train_speed(iter/s)": 0.253075
    },
    {
      "epoch": 0.28308926406118834,
      "grad_norm": 13.204558372497559,
      "learning_rate": 9.998807704243747e-06,
      "loss": 0.6931004524230957,
      "memory(GiB)": 67.44,
      "step": 3035,
      "token_acc": 0.8712871287128713,
      "train_speed(iter/s)": 0.253079
    },
    {
      "epoch": 0.28355563846656096,
      "grad_norm": 15.414655685424805,
      "learning_rate": 9.998773787101264e-06,
      "loss": 0.6914796829223633,
      "memory(GiB)": 67.44,
      "step": 3040,
      "train_speed(iter/s)": 0.253085
    },
    {
      "epoch": 0.28402201287193357,
      "grad_norm": 6.284354209899902,
      "learning_rate": 9.998739394340855e-06,
      "loss": 0.6462891578674317,
      "memory(GiB)": 67.44,
      "step": 3045,
      "token_acc": 0.39473684210526316,
      "train_speed(iter/s)": 0.253095
    },
    {
      "epoch": 0.28448838727730624,
      "grad_norm": 18.26542091369629,
      "learning_rate": 9.998704525965792e-06,
      "loss": 0.6295570373535156,
      "memory(GiB)": 67.44,
      "step": 3050,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253081
    },
    {
      "epoch": 0.28495476168267886,
      "grad_norm": 8.071002960205078,
      "learning_rate": 9.998669181979392e-06,
      "loss": 0.6267510414123535,
      "memory(GiB)": 67.44,
      "step": 3055,
      "train_speed(iter/s)": 0.253072
    },
    {
      "epoch": 0.2854211360880515,
      "grad_norm": 13.882761001586914,
      "learning_rate": 9.998633362385018e-06,
      "loss": 0.5881103515625,
      "memory(GiB)": 67.44,
      "step": 3060,
      "train_speed(iter/s)": 0.253094
    },
    {
      "epoch": 0.28588751049342415,
      "grad_norm": 15.5934419631958,
      "learning_rate": 9.998597067186077e-06,
      "loss": 0.6311726570129395,
      "memory(GiB)": 67.44,
      "step": 3065,
      "token_acc": 0.797979797979798,
      "train_speed(iter/s)": 0.253086
    },
    {
      "epoch": 0.28635388489879676,
      "grad_norm": 16.01129722595215,
      "learning_rate": 9.998560296386027e-06,
      "loss": 0.6141474723815918,
      "memory(GiB)": 67.44,
      "step": 3070,
      "train_speed(iter/s)": 0.253088
    },
    {
      "epoch": 0.2868202593041694,
      "grad_norm": 10.101591110229492,
      "learning_rate": 9.99852304998836e-06,
      "loss": 0.5960719108581543,
      "memory(GiB)": 67.44,
      "step": 3075,
      "train_speed(iter/s)": 0.25308
    },
    {
      "epoch": 0.287286633709542,
      "grad_norm": 29.130998611450195,
      "learning_rate": 9.998485327996624e-06,
      "loss": 0.588402509689331,
      "memory(GiB)": 67.44,
      "step": 3080,
      "train_speed(iter/s)": 0.253081
    },
    {
      "epoch": 0.28775300811491467,
      "grad_norm": 24.6174259185791,
      "learning_rate": 9.998447130414408e-06,
      "loss": 0.6471741199493408,
      "memory(GiB)": 67.44,
      "step": 3085,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.253101
    },
    {
      "epoch": 0.2882193825202873,
      "grad_norm": 30.160139083862305,
      "learning_rate": 9.998408457245345e-06,
      "loss": 0.606440258026123,
      "memory(GiB)": 67.44,
      "step": 3090,
      "train_speed(iter/s)": 0.253109
    },
    {
      "epoch": 0.2886857569256599,
      "grad_norm": 24.556787490844727,
      "learning_rate": 9.998369308493114e-06,
      "loss": 0.6054380893707275,
      "memory(GiB)": 67.44,
      "step": 3095,
      "token_acc": 0.8229166666666666,
      "train_speed(iter/s)": 0.253103
    },
    {
      "epoch": 0.28915213133103257,
      "grad_norm": 16.919231414794922,
      "learning_rate": 9.998329684161444e-06,
      "loss": 0.6026579380035401,
      "memory(GiB)": 67.44,
      "step": 3100,
      "token_acc": 0.8478260869565217,
      "train_speed(iter/s)": 0.253115
    },
    {
      "epoch": 0.2896185057364052,
      "grad_norm": 14.110411643981934,
      "learning_rate": 9.998289584254101e-06,
      "loss": 0.6290392398834228,
      "memory(GiB)": 67.44,
      "step": 3105,
      "token_acc": 0.39473684210526316,
      "train_speed(iter/s)": 0.253096
    },
    {
      "epoch": 0.2900848801417778,
      "grad_norm": 14.98965835571289,
      "learning_rate": 9.998249008774901e-06,
      "loss": 0.6163933753967286,
      "memory(GiB)": 67.44,
      "step": 3110,
      "train_speed(iter/s)": 0.253103
    },
    {
      "epoch": 0.2905512545471505,
      "grad_norm": 12.275195121765137,
      "learning_rate": 9.998207957727707e-06,
      "loss": 0.6195103645324707,
      "memory(GiB)": 67.44,
      "step": 3115,
      "train_speed(iter/s)": 0.253116
    },
    {
      "epoch": 0.2910176289525231,
      "grad_norm": 17.592885971069336,
      "learning_rate": 9.998166431116421e-06,
      "loss": 0.5588254928588867,
      "memory(GiB)": 67.44,
      "step": 3120,
      "token_acc": 0.6607142857142857,
      "train_speed(iter/s)": 0.25312
    },
    {
      "epoch": 0.2914840033578957,
      "grad_norm": 12.224102973937988,
      "learning_rate": 9.998124428944997e-06,
      "loss": 0.6097492218017578,
      "memory(GiB)": 67.44,
      "step": 3125,
      "train_speed(iter/s)": 0.253112
    },
    {
      "epoch": 0.2919503777632684,
      "grad_norm": 12.358510971069336,
      "learning_rate": 9.99808195121743e-06,
      "loss": 0.6596705436706543,
      "memory(GiB)": 67.44,
      "step": 3130,
      "token_acc": 0.8761904761904762,
      "train_speed(iter/s)": 0.253141
    },
    {
      "epoch": 0.292416752168641,
      "grad_norm": 13.69210147857666,
      "learning_rate": 9.998038997937764e-06,
      "loss": 0.5894656658172608,
      "memory(GiB)": 67.44,
      "step": 3135,
      "train_speed(iter/s)": 0.25315
    },
    {
      "epoch": 0.2928831265740136,
      "grad_norm": 11.35926342010498,
      "learning_rate": 9.997995569110083e-06,
      "loss": 0.6223914146423339,
      "memory(GiB)": 67.44,
      "step": 3140,
      "train_speed(iter/s)": 0.253146
    },
    {
      "epoch": 0.2933495009793862,
      "grad_norm": 24.639175415039062,
      "learning_rate": 9.997951664738522e-06,
      "loss": 0.6352512836456299,
      "memory(GiB)": 67.44,
      "step": 3145,
      "token_acc": 0.5967741935483871,
      "train_speed(iter/s)": 0.253155
    },
    {
      "epoch": 0.2938158753847589,
      "grad_norm": 18.985258102416992,
      "learning_rate": 9.997907284827255e-06,
      "loss": 0.6505534648895264,
      "memory(GiB)": 67.44,
      "step": 3150,
      "train_speed(iter/s)": 0.253155
    },
    {
      "epoch": 0.2942822497901315,
      "grad_norm": 16.45485496520996,
      "learning_rate": 9.997862429380507e-06,
      "loss": 0.6207180023193359,
      "memory(GiB)": 67.44,
      "step": 3155,
      "train_speed(iter/s)": 0.253184
    },
    {
      "epoch": 0.2947486241955041,
      "grad_norm": 12.704483032226562,
      "learning_rate": 9.997817098402544e-06,
      "loss": 0.6306052684783936,
      "memory(GiB)": 67.44,
      "step": 3160,
      "token_acc": 0.7007874015748031,
      "train_speed(iter/s)": 0.253177
    },
    {
      "epoch": 0.2952149986008768,
      "grad_norm": 20.236976623535156,
      "learning_rate": 9.997771291897683e-06,
      "loss": 0.6185968399047852,
      "memory(GiB)": 67.44,
      "step": 3165,
      "token_acc": 0.7443609022556391,
      "train_speed(iter/s)": 0.253197
    },
    {
      "epoch": 0.2956813730062494,
      "grad_norm": 15.993420600891113,
      "learning_rate": 9.997725009870276e-06,
      "loss": 0.6556883811950683,
      "memory(GiB)": 67.44,
      "step": 3170,
      "token_acc": 0.8947368421052632,
      "train_speed(iter/s)": 0.25321
    },
    {
      "epoch": 0.29614774741162203,
      "grad_norm": 12.697260856628418,
      "learning_rate": 9.997678252324732e-06,
      "loss": 0.6401780128479004,
      "memory(GiB)": 67.44,
      "step": 3175,
      "train_speed(iter/s)": 0.253237
    },
    {
      "epoch": 0.2966141218169947,
      "grad_norm": 11.479901313781738,
      "learning_rate": 9.997631019265497e-06,
      "loss": 0.6293354511260987,
      "memory(GiB)": 67.44,
      "step": 3180,
      "train_speed(iter/s)": 0.253235
    },
    {
      "epoch": 0.2970804962223673,
      "grad_norm": 10.969558715820312,
      "learning_rate": 9.997583310697068e-06,
      "loss": 0.6728277206420898,
      "memory(GiB)": 67.44,
      "step": 3185,
      "train_speed(iter/s)": 0.253199
    },
    {
      "epoch": 0.29754687062773993,
      "grad_norm": 10.966659545898438,
      "learning_rate": 9.997535126623981e-06,
      "loss": 0.627624797821045,
      "memory(GiB)": 67.44,
      "step": 3190,
      "token_acc": 0.53125,
      "train_speed(iter/s)": 0.253205
    },
    {
      "epoch": 0.2980132450331126,
      "grad_norm": 14.756160736083984,
      "learning_rate": 9.997486467050823e-06,
      "loss": 0.6667770862579345,
      "memory(GiB)": 67.44,
      "step": 3195,
      "train_speed(iter/s)": 0.253201
    },
    {
      "epoch": 0.2984796194384852,
      "grad_norm": 7.9916768074035645,
      "learning_rate": 9.997437331982222e-06,
      "loss": 0.5873544216156006,
      "memory(GiB)": 67.44,
      "step": 3200,
      "train_speed(iter/s)": 0.253193
    },
    {
      "epoch": 0.29894599384385784,
      "grad_norm": 14.496696472167969,
      "learning_rate": 9.997387721422853e-06,
      "loss": 0.6245254039764404,
      "memory(GiB)": 67.44,
      "step": 3205,
      "train_speed(iter/s)": 0.253179
    },
    {
      "epoch": 0.2994123682492305,
      "grad_norm": 6.233725070953369,
      "learning_rate": 9.99733763537744e-06,
      "loss": 0.6355367660522461,
      "memory(GiB)": 67.44,
      "step": 3210,
      "token_acc": 0.36538461538461536,
      "train_speed(iter/s)": 0.253198
    },
    {
      "epoch": 0.2998787426546031,
      "grad_norm": 9.127157211303711,
      "learning_rate": 9.997287073850744e-06,
      "loss": 0.6099298477172852,
      "memory(GiB)": 67.44,
      "step": 3215,
      "token_acc": 0.4358974358974359,
      "train_speed(iter/s)": 0.2532
    },
    {
      "epoch": 0.30034511705997574,
      "grad_norm": 15.506805419921875,
      "learning_rate": 9.997236036847576e-06,
      "loss": 0.5695637226104736,
      "memory(GiB)": 67.44,
      "step": 3220,
      "train_speed(iter/s)": 0.253199
    },
    {
      "epoch": 0.30081149146534836,
      "grad_norm": 10.409175872802734,
      "learning_rate": 9.997184524372794e-06,
      "loss": 0.5795401096343994,
      "memory(GiB)": 67.44,
      "step": 3225,
      "train_speed(iter/s)": 0.253182
    },
    {
      "epoch": 0.30127786587072103,
      "grad_norm": 21.588136672973633,
      "learning_rate": 9.9971325364313e-06,
      "loss": 0.5751580715179443,
      "memory(GiB)": 67.44,
      "step": 3230,
      "train_speed(iter/s)": 0.253201
    },
    {
      "epoch": 0.30174424027609364,
      "grad_norm": 10.477682113647461,
      "learning_rate": 9.99708007302804e-06,
      "loss": 0.5833733558654786,
      "memory(GiB)": 67.44,
      "step": 3235,
      "token_acc": 0.4411764705882353,
      "train_speed(iter/s)": 0.253217
    },
    {
      "epoch": 0.30221061468146626,
      "grad_norm": 7.975887775421143,
      "learning_rate": 9.997027134168003e-06,
      "loss": 0.6232122421264649,
      "memory(GiB)": 67.44,
      "step": 3240,
      "token_acc": 0.6595744680851063,
      "train_speed(iter/s)": 0.253209
    },
    {
      "epoch": 0.30267698908683893,
      "grad_norm": 12.105390548706055,
      "learning_rate": 9.99697371985623e-06,
      "loss": 0.5947151184082031,
      "memory(GiB)": 67.44,
      "step": 3245,
      "token_acc": 0.3888888888888889,
      "train_speed(iter/s)": 0.253214
    },
    {
      "epoch": 0.30314336349221155,
      "grad_norm": 11.298819541931152,
      "learning_rate": 9.996919830097797e-06,
      "loss": 0.599393081665039,
      "memory(GiB)": 67.44,
      "step": 3250,
      "token_acc": 0.803921568627451,
      "train_speed(iter/s)": 0.253209
    },
    {
      "epoch": 0.30360973789758416,
      "grad_norm": 7.6916375160217285,
      "learning_rate": 9.99686546489784e-06,
      "loss": 0.5928820133209228,
      "memory(GiB)": 67.44,
      "step": 3255,
      "token_acc": 0.42592592592592593,
      "train_speed(iter/s)": 0.253197
    },
    {
      "epoch": 0.30407611230295684,
      "grad_norm": 11.631089210510254,
      "learning_rate": 9.996810624261525e-06,
      "loss": 0.5919366836547851,
      "memory(GiB)": 67.44,
      "step": 3260,
      "token_acc": 0.5194805194805194,
      "train_speed(iter/s)": 0.253201
    },
    {
      "epoch": 0.30454248670832945,
      "grad_norm": 31.42722511291504,
      "learning_rate": 9.996755308194072e-06,
      "loss": 0.6501657485961914,
      "memory(GiB)": 67.44,
      "step": 3265,
      "token_acc": 0.38181818181818183,
      "train_speed(iter/s)": 0.253194
    },
    {
      "epoch": 0.30500886111370207,
      "grad_norm": 7.850787162780762,
      "learning_rate": 9.996699516700746e-06,
      "loss": 0.6433275699615478,
      "memory(GiB)": 67.44,
      "step": 3270,
      "token_acc": 0.8482142857142857,
      "train_speed(iter/s)": 0.253165
    },
    {
      "epoch": 0.30547523551907474,
      "grad_norm": 12.820066452026367,
      "learning_rate": 9.996643249786853e-06,
      "loss": 0.6104804992675781,
      "memory(GiB)": 67.44,
      "step": 3275,
      "token_acc": 0.8045977011494253,
      "train_speed(iter/s)": 0.253159
    },
    {
      "epoch": 0.30594160992444736,
      "grad_norm": 10.79754638671875,
      "learning_rate": 9.996586507457746e-06,
      "loss": 0.6115350246429443,
      "memory(GiB)": 67.44,
      "step": 3280,
      "token_acc": 0.4888888888888889,
      "train_speed(iter/s)": 0.253158
    },
    {
      "epoch": 0.30640798432981997,
      "grad_norm": 9.441926002502441,
      "learning_rate": 9.996529289718827e-06,
      "loss": 0.6226877212524414,
      "memory(GiB)": 67.44,
      "step": 3285,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.253168
    },
    {
      "epoch": 0.3068743587351926,
      "grad_norm": 12.735411643981934,
      "learning_rate": 9.996471596575536e-06,
      "loss": 0.664849853515625,
      "memory(GiB)": 67.44,
      "step": 3290,
      "token_acc": 0.39285714285714285,
      "train_speed(iter/s)": 0.253178
    },
    {
      "epoch": 0.30734073314056526,
      "grad_norm": 8.703474998474121,
      "learning_rate": 9.996413428033367e-06,
      "loss": 0.6061724662780762,
      "memory(GiB)": 67.44,
      "step": 3295,
      "train_speed(iter/s)": 0.253195
    },
    {
      "epoch": 0.3078071075459379,
      "grad_norm": 11.233224868774414,
      "learning_rate": 9.996354784097851e-06,
      "loss": 0.5944731712341309,
      "memory(GiB)": 67.44,
      "step": 3300,
      "train_speed(iter/s)": 0.253214
    },
    {
      "epoch": 0.3082734819513105,
      "grad_norm": 12.49700927734375,
      "learning_rate": 9.996295664774568e-06,
      "loss": 0.6293366432189942,
      "memory(GiB)": 67.44,
      "step": 3305,
      "train_speed(iter/s)": 0.253221
    },
    {
      "epoch": 0.30873985635668316,
      "grad_norm": 10.799164772033691,
      "learning_rate": 9.996236070069145e-06,
      "loss": 0.6492050647735595,
      "memory(GiB)": 67.44,
      "step": 3310,
      "train_speed(iter/s)": 0.253209
    },
    {
      "epoch": 0.3092062307620558,
      "grad_norm": 13.269484519958496,
      "learning_rate": 9.996175999987252e-06,
      "loss": 0.6216896057128907,
      "memory(GiB)": 67.44,
      "step": 3315,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.253207
    },
    {
      "epoch": 0.3096726051674284,
      "grad_norm": 8.392813682556152,
      "learning_rate": 9.996115454534603e-06,
      "loss": 0.5630627632141113,
      "memory(GiB)": 67.44,
      "step": 3320,
      "token_acc": 0.8105263157894737,
      "train_speed(iter/s)": 0.253199
    },
    {
      "epoch": 0.31013897957280107,
      "grad_norm": 9.852921485900879,
      "learning_rate": 9.99605443371696e-06,
      "loss": 0.5595833778381347,
      "memory(GiB)": 67.44,
      "step": 3325,
      "token_acc": 0.5977011494252874,
      "train_speed(iter/s)": 0.253199
    },
    {
      "epoch": 0.3106053539781737,
      "grad_norm": 19.19260025024414,
      "learning_rate": 9.995992937540127e-06,
      "loss": 0.6648372173309326,
      "memory(GiB)": 67.44,
      "step": 3330,
      "token_acc": 0.3953488372093023,
      "train_speed(iter/s)": 0.253208
    },
    {
      "epoch": 0.3110717283835463,
      "grad_norm": 11.29632568359375,
      "learning_rate": 9.995930966009957e-06,
      "loss": 0.6399909019470215,
      "memory(GiB)": 67.44,
      "step": 3335,
      "train_speed(iter/s)": 0.253222
    },
    {
      "epoch": 0.31153810278891897,
      "grad_norm": 7.9422221183776855,
      "learning_rate": 9.995868519132346e-06,
      "loss": 0.6224884033203125,
      "memory(GiB)": 67.44,
      "step": 3340,
      "token_acc": 0.34,
      "train_speed(iter/s)": 0.253238
    },
    {
      "epoch": 0.3120044771942916,
      "grad_norm": 14.399942398071289,
      "learning_rate": 9.995805596913236e-06,
      "loss": 0.5706991195678711,
      "memory(GiB)": 67.44,
      "step": 3345,
      "train_speed(iter/s)": 0.253247
    },
    {
      "epoch": 0.3124708515996642,
      "grad_norm": 15.626651763916016,
      "learning_rate": 9.995742199358613e-06,
      "loss": 0.6265752792358399,
      "memory(GiB)": 67.44,
      "step": 3350,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.253239
    },
    {
      "epoch": 0.3129372260050368,
      "grad_norm": 9.377087593078613,
      "learning_rate": 9.995678326474509e-06,
      "loss": 0.6181363105773926,
      "memory(GiB)": 67.44,
      "step": 3355,
      "token_acc": 0.6857142857142857,
      "train_speed(iter/s)": 0.253219
    },
    {
      "epoch": 0.3134036004104095,
      "grad_norm": 17.353553771972656,
      "learning_rate": 9.995613978267004e-06,
      "loss": 0.5902396678924561,
      "memory(GiB)": 67.44,
      "step": 3360,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25321
    },
    {
      "epoch": 0.3138699748157821,
      "grad_norm": 5.121847152709961,
      "learning_rate": 9.995549154742216e-06,
      "loss": 0.6278647422790528,
      "memory(GiB)": 67.44,
      "step": 3365,
      "train_speed(iter/s)": 0.253237
    },
    {
      "epoch": 0.3143363492211547,
      "grad_norm": 12.073156356811523,
      "learning_rate": 9.995483855906317e-06,
      "loss": 0.6219192504882812,
      "memory(GiB)": 67.44,
      "step": 3370,
      "token_acc": 0.8709677419354839,
      "train_speed(iter/s)": 0.253245
    },
    {
      "epoch": 0.3148027236265274,
      "grad_norm": 12.127965927124023,
      "learning_rate": 9.995418081765515e-06,
      "loss": 0.6018784523010254,
      "memory(GiB)": 67.44,
      "step": 3375,
      "train_speed(iter/s)": 0.25327
    },
    {
      "epoch": 0.3152690980319,
      "grad_norm": 6.573653221130371,
      "learning_rate": 9.995351832326075e-06,
      "loss": 0.59201021194458,
      "memory(GiB)": 67.44,
      "step": 3380,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.253281
    },
    {
      "epoch": 0.3157354724372726,
      "grad_norm": 8.294912338256836,
      "learning_rate": 9.995285107594295e-06,
      "loss": 0.6211456775665283,
      "memory(GiB)": 67.44,
      "step": 3385,
      "token_acc": 0.4673913043478261,
      "train_speed(iter/s)": 0.253263
    },
    {
      "epoch": 0.3162018468426453,
      "grad_norm": 14.297306060791016,
      "learning_rate": 9.995217907576525e-06,
      "loss": 0.5698533535003663,
      "memory(GiB)": 67.44,
      "step": 3390,
      "train_speed(iter/s)": 0.253278
    },
    {
      "epoch": 0.3166682212480179,
      "grad_norm": 10.457667350769043,
      "learning_rate": 9.995150232279159e-06,
      "loss": 0.5895512580871582,
      "memory(GiB)": 67.44,
      "step": 3395,
      "token_acc": 0.42592592592592593,
      "train_speed(iter/s)": 0.25327
    },
    {
      "epoch": 0.3171345956533905,
      "grad_norm": 11.007922172546387,
      "learning_rate": 9.995082081708638e-06,
      "loss": 0.6271703243255615,
      "memory(GiB)": 67.44,
      "step": 3400,
      "token_acc": 0.44,
      "train_speed(iter/s)": 0.25328
    },
    {
      "epoch": 0.3176009700587632,
      "grad_norm": 19.352703094482422,
      "learning_rate": 9.995013455871442e-06,
      "loss": 0.5515745639801025,
      "memory(GiB)": 67.44,
      "step": 3405,
      "token_acc": 0.673469387755102,
      "train_speed(iter/s)": 0.253296
    },
    {
      "epoch": 0.3180673444641358,
      "grad_norm": 11.039804458618164,
      "learning_rate": 9.994944354774105e-06,
      "loss": 0.5916183471679688,
      "memory(GiB)": 67.44,
      "step": 3410,
      "token_acc": 0.7482014388489209,
      "train_speed(iter/s)": 0.253299
    },
    {
      "epoch": 0.31853371886950843,
      "grad_norm": 17.258380889892578,
      "learning_rate": 9.994874778423201e-06,
      "loss": 0.5976800918579102,
      "memory(GiB)": 67.44,
      "step": 3415,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.253295
    },
    {
      "epoch": 0.31900009327488105,
      "grad_norm": 9.492003440856934,
      "learning_rate": 9.994804726825347e-06,
      "loss": 0.5731581687927246,
      "memory(GiB)": 67.44,
      "step": 3420,
      "train_speed(iter/s)": 0.253302
    },
    {
      "epoch": 0.3194664676802537,
      "grad_norm": 14.355409622192383,
      "learning_rate": 9.99473419998721e-06,
      "loss": 0.605449104309082,
      "memory(GiB)": 67.44,
      "step": 3425,
      "token_acc": 0.8409090909090909,
      "train_speed(iter/s)": 0.253294
    },
    {
      "epoch": 0.31993284208562633,
      "grad_norm": 14.243882179260254,
      "learning_rate": 9.994663197915502e-06,
      "loss": 0.577846908569336,
      "memory(GiB)": 67.44,
      "step": 3430,
      "train_speed(iter/s)": 0.253286
    },
    {
      "epoch": 0.32039921649099895,
      "grad_norm": 7.767961502075195,
      "learning_rate": 9.994591720616976e-06,
      "loss": 0.6235226631164551,
      "memory(GiB)": 67.44,
      "step": 3435,
      "token_acc": 0.4090909090909091,
      "train_speed(iter/s)": 0.253281
    },
    {
      "epoch": 0.3208655908963716,
      "grad_norm": 16.609527587890625,
      "learning_rate": 9.994519768098436e-06,
      "loss": 0.6184371948242188,
      "memory(GiB)": 67.44,
      "step": 3440,
      "token_acc": 0.41732283464566927,
      "train_speed(iter/s)": 0.253279
    },
    {
      "epoch": 0.32133196530174424,
      "grad_norm": 11.530060768127441,
      "learning_rate": 9.994447340366724e-06,
      "loss": 0.5536849498748779,
      "memory(GiB)": 67.44,
      "step": 3445,
      "train_speed(iter/s)": 0.253284
    },
    {
      "epoch": 0.32179833970711685,
      "grad_norm": 13.97160530090332,
      "learning_rate": 9.994374437428733e-06,
      "loss": 0.5548471450805664,
      "memory(GiB)": 67.44,
      "step": 3450,
      "train_speed(iter/s)": 0.253263
    },
    {
      "epoch": 0.3222647141124895,
      "grad_norm": 11.346861839294434,
      "learning_rate": 9.9943010592914e-06,
      "loss": 0.5466268539428711,
      "memory(GiB)": 67.44,
      "step": 3455,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.253268
    },
    {
      "epoch": 0.32273108851786214,
      "grad_norm": 25.14781379699707,
      "learning_rate": 9.994227205961708e-06,
      "loss": 0.6389049053192138,
      "memory(GiB)": 67.44,
      "step": 3460,
      "token_acc": 0.41935483870967744,
      "train_speed(iter/s)": 0.253284
    },
    {
      "epoch": 0.32319746292323476,
      "grad_norm": 28.856281280517578,
      "learning_rate": 9.994152877446682e-06,
      "loss": 0.5708332538604737,
      "memory(GiB)": 67.44,
      "step": 3465,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.253289
    },
    {
      "epoch": 0.32366383732860743,
      "grad_norm": 8.017857551574707,
      "learning_rate": 9.994078073753394e-06,
      "loss": 0.5617085456848144,
      "memory(GiB)": 67.44,
      "step": 3470,
      "token_acc": 0.4222222222222222,
      "train_speed(iter/s)": 0.253312
    },
    {
      "epoch": 0.32413021173398004,
      "grad_norm": 135.4456787109375,
      "learning_rate": 9.994002794888962e-06,
      "loss": 0.6049147129058838,
      "memory(GiB)": 67.44,
      "step": 3475,
      "train_speed(iter/s)": 0.253311
    },
    {
      "epoch": 0.32459658613935266,
      "grad_norm": 14.756868362426758,
      "learning_rate": 9.993927040860549e-06,
      "loss": 0.6272761344909668,
      "memory(GiB)": 67.44,
      "step": 3480,
      "token_acc": 0.42028985507246375,
      "train_speed(iter/s)": 0.253314
    },
    {
      "epoch": 0.32506296054472533,
      "grad_norm": 48.86337661743164,
      "learning_rate": 9.993850811675362e-06,
      "loss": 0.5944548606872558,
      "memory(GiB)": 67.44,
      "step": 3485,
      "train_speed(iter/s)": 0.253318
    },
    {
      "epoch": 0.32552933495009795,
      "grad_norm": 10.106894493103027,
      "learning_rate": 9.993774107340655e-06,
      "loss": 0.5846900463104248,
      "memory(GiB)": 67.44,
      "step": 3490,
      "train_speed(iter/s)": 0.253349
    },
    {
      "epoch": 0.32599570935547056,
      "grad_norm": 6.655063629150391,
      "learning_rate": 9.993696927863724e-06,
      "loss": 0.5755355358123779,
      "memory(GiB)": 67.44,
      "step": 3495,
      "token_acc": 0.4090909090909091,
      "train_speed(iter/s)": 0.253384
    },
    {
      "epoch": 0.3264620837608432,
      "grad_norm": 11.874530792236328,
      "learning_rate": 9.993619273251913e-06,
      "loss": 0.5725414276123046,
      "memory(GiB)": 67.44,
      "step": 3500,
      "token_acc": 0.46551724137931033,
      "train_speed(iter/s)": 0.253389
    },
    {
      "epoch": 0.32692845816621585,
      "grad_norm": 7.418087959289551,
      "learning_rate": 9.993541143512613e-06,
      "loss": 0.5740116119384766,
      "memory(GiB)": 67.44,
      "step": 3505,
      "token_acc": 0.425531914893617,
      "train_speed(iter/s)": 0.253415
    },
    {
      "epoch": 0.32739483257158847,
      "grad_norm": 12.518401145935059,
      "learning_rate": 9.993462538653255e-06,
      "loss": 0.6491196632385254,
      "memory(GiB)": 67.44,
      "step": 3510,
      "token_acc": 0.7183098591549296,
      "train_speed(iter/s)": 0.253402
    },
    {
      "epoch": 0.3278612069769611,
      "grad_norm": 26.33504867553711,
      "learning_rate": 9.993383458681321e-06,
      "loss": 0.5911168098449707,
      "memory(GiB)": 67.44,
      "step": 3515,
      "token_acc": 0.6068376068376068,
      "train_speed(iter/s)": 0.253421
    },
    {
      "epoch": 0.32832758138233376,
      "grad_norm": 13.666891098022461,
      "learning_rate": 9.993303903604333e-06,
      "loss": 0.6062886238098144,
      "memory(GiB)": 67.44,
      "step": 3520,
      "train_speed(iter/s)": 0.253435
    },
    {
      "epoch": 0.32879395578770637,
      "grad_norm": 9.565762519836426,
      "learning_rate": 9.99322387342986e-06,
      "loss": 0.6126898765563965,
      "memory(GiB)": 67.44,
      "step": 3525,
      "train_speed(iter/s)": 0.253441
    },
    {
      "epoch": 0.329260330193079,
      "grad_norm": 15.81586742401123,
      "learning_rate": 9.993143368165517e-06,
      "loss": 0.6038127899169922,
      "memory(GiB)": 67.44,
      "step": 3530,
      "train_speed(iter/s)": 0.253467
    },
    {
      "epoch": 0.32972670459845166,
      "grad_norm": 15.05648422241211,
      "learning_rate": 9.993062387818967e-06,
      "loss": 0.58490891456604,
      "memory(GiB)": 67.44,
      "step": 3535,
      "train_speed(iter/s)": 0.25347
    },
    {
      "epoch": 0.3301930790038243,
      "grad_norm": 14.015914916992188,
      "learning_rate": 9.99298093239791e-06,
      "loss": 0.5883450508117676,
      "memory(GiB)": 67.44,
      "step": 3540,
      "train_speed(iter/s)": 0.253467
    },
    {
      "epoch": 0.3306594534091969,
      "grad_norm": 14.091657638549805,
      "learning_rate": 9.992899001910098e-06,
      "loss": 0.5830341339111328,
      "memory(GiB)": 67.44,
      "step": 3545,
      "token_acc": 0.8163265306122449,
      "train_speed(iter/s)": 0.253458
    },
    {
      "epoch": 0.33112582781456956,
      "grad_norm": 9.38573932647705,
      "learning_rate": 9.992816596363327e-06,
      "loss": 0.6325272560119629,
      "memory(GiB)": 67.44,
      "step": 3550,
      "train_speed(iter/s)": 0.253446
    },
    {
      "epoch": 0.3315922022199422,
      "grad_norm": 15.165987014770508,
      "learning_rate": 9.99273371576544e-06,
      "loss": 0.598539161682129,
      "memory(GiB)": 67.44,
      "step": 3555,
      "train_speed(iter/s)": 0.253449
    },
    {
      "epoch": 0.3320585766253148,
      "grad_norm": 11.132975578308105,
      "learning_rate": 9.992650360124318e-06,
      "loss": 0.5622635841369629,
      "memory(GiB)": 67.44,
      "step": 3560,
      "token_acc": 0.40384615384615385,
      "train_speed(iter/s)": 0.253467
    },
    {
      "epoch": 0.3325249510306874,
      "grad_norm": 7.688213348388672,
      "learning_rate": 9.992566529447895e-06,
      "loss": 0.5763468742370605,
      "memory(GiB)": 67.44,
      "step": 3565,
      "train_speed(iter/s)": 0.253481
    },
    {
      "epoch": 0.3329913254360601,
      "grad_norm": 9.49152660369873,
      "learning_rate": 9.992482223744146e-06,
      "loss": 0.6175514221191406,
      "memory(GiB)": 67.44,
      "step": 3570,
      "train_speed(iter/s)": 0.253484
    },
    {
      "epoch": 0.3334576998414327,
      "grad_norm": 5.321049213409424,
      "learning_rate": 9.992397443021094e-06,
      "loss": 0.532374095916748,
      "memory(GiB)": 67.44,
      "step": 3575,
      "token_acc": 0.5172413793103449,
      "train_speed(iter/s)": 0.253468
    },
    {
      "epoch": 0.3339240742468053,
      "grad_norm": 11.6321439743042,
      "learning_rate": 9.992312187286805e-06,
      "loss": 0.5707850456237793,
      "memory(GiB)": 67.44,
      "step": 3580,
      "train_speed(iter/s)": 0.253467
    },
    {
      "epoch": 0.334390448652178,
      "grad_norm": 9.295014381408691,
      "learning_rate": 9.992226456549392e-06,
      "loss": 0.6135513305664062,
      "memory(GiB)": 67.44,
      "step": 3585,
      "train_speed(iter/s)": 0.253484
    },
    {
      "epoch": 0.3348568230575506,
      "grad_norm": 9.299206733703613,
      "learning_rate": 9.992140250817008e-06,
      "loss": 0.5811171531677246,
      "memory(GiB)": 67.44,
      "step": 3590,
      "token_acc": 0.4489795918367347,
      "train_speed(iter/s)": 0.253477
    },
    {
      "epoch": 0.3353231974629232,
      "grad_norm": 15.610466957092285,
      "learning_rate": 9.99205357009786e-06,
      "loss": 0.5836852073669434,
      "memory(GiB)": 67.44,
      "step": 3595,
      "train_speed(iter/s)": 0.253472
    },
    {
      "epoch": 0.3357895718682959,
      "grad_norm": 19.63086700439453,
      "learning_rate": 9.991966414400192e-06,
      "loss": 0.6736255645751953,
      "memory(GiB)": 67.44,
      "step": 3600,
      "train_speed(iter/s)": 0.253468
    },
    {
      "epoch": 0.3362559462736685,
      "grad_norm": 9.489665985107422,
      "learning_rate": 9.991878783732296e-06,
      "loss": 0.6490819931030274,
      "memory(GiB)": 67.44,
      "step": 3605,
      "train_speed(iter/s)": 0.253486
    },
    {
      "epoch": 0.3367223206790411,
      "grad_norm": 9.002969741821289,
      "learning_rate": 9.991790678102515e-06,
      "loss": 0.6495358943939209,
      "memory(GiB)": 67.44,
      "step": 3610,
      "token_acc": 0.7928571428571428,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.3371886950844138,
      "grad_norm": 11.327653884887695,
      "learning_rate": 9.991702097519227e-06,
      "loss": 0.6455322265625,
      "memory(GiB)": 67.44,
      "step": 3615,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253523
    },
    {
      "epoch": 0.3376550694897864,
      "grad_norm": 20.883861541748047,
      "learning_rate": 9.991613041990862e-06,
      "loss": 0.6372745513916016,
      "memory(GiB)": 67.44,
      "step": 3620,
      "token_acc": 0.6304347826086957,
      "train_speed(iter/s)": 0.253528
    },
    {
      "epoch": 0.338121443895159,
      "grad_norm": 11.676892280578613,
      "learning_rate": 9.99152351152589e-06,
      "loss": 0.6413401603698731,
      "memory(GiB)": 67.44,
      "step": 3625,
      "token_acc": 0.3939393939393939,
      "train_speed(iter/s)": 0.253525
    },
    {
      "epoch": 0.33858781830053164,
      "grad_norm": 12.417604446411133,
      "learning_rate": 9.991433506132838e-06,
      "loss": 0.6514007568359375,
      "memory(GiB)": 67.44,
      "step": 3630,
      "train_speed(iter/s)": 0.253522
    },
    {
      "epoch": 0.3390541927059043,
      "grad_norm": 13.625262260437012,
      "learning_rate": 9.99134302582026e-06,
      "loss": 0.6190677642822265,
      "memory(GiB)": 67.44,
      "step": 3635,
      "token_acc": 0.3090909090909091,
      "train_speed(iter/s)": 0.253487
    },
    {
      "epoch": 0.3395205671112769,
      "grad_norm": 18.76422691345215,
      "learning_rate": 9.991252070596773e-06,
      "loss": 0.6571332454681397,
      "memory(GiB)": 67.44,
      "step": 3640,
      "train_speed(iter/s)": 0.253479
    },
    {
      "epoch": 0.33998694151664954,
      "grad_norm": 12.099043846130371,
      "learning_rate": 9.991160640471025e-06,
      "loss": 0.5827873706817627,
      "memory(GiB)": 67.44,
      "step": 3645,
      "train_speed(iter/s)": 0.253508
    },
    {
      "epoch": 0.3404533159220222,
      "grad_norm": 11.618046760559082,
      "learning_rate": 9.991068735451719e-06,
      "loss": 0.6026205062866211,
      "memory(GiB)": 67.44,
      "step": 3650,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.253531
    },
    {
      "epoch": 0.34091969032739483,
      "grad_norm": 12.703926086425781,
      "learning_rate": 9.990976355547596e-06,
      "loss": 0.5795609951019287,
      "memory(GiB)": 67.44,
      "step": 3655,
      "train_speed(iter/s)": 0.253526
    },
    {
      "epoch": 0.34138606473276745,
      "grad_norm": 12.325838088989258,
      "learning_rate": 9.99088350076745e-06,
      "loss": 0.6125473499298095,
      "memory(GiB)": 67.44,
      "step": 3660,
      "token_acc": 0.8586956521739131,
      "train_speed(iter/s)": 0.25355
    },
    {
      "epoch": 0.3418524391381401,
      "grad_norm": 13.131409645080566,
      "learning_rate": 9.990790171120112e-06,
      "loss": 0.6291013717651367,
      "memory(GiB)": 67.44,
      "step": 3665,
      "token_acc": 0.39473684210526316,
      "train_speed(iter/s)": 0.253546
    },
    {
      "epoch": 0.34231881354351273,
      "grad_norm": 13.697549819946289,
      "learning_rate": 9.990696366614467e-06,
      "loss": 0.5951249122619628,
      "memory(GiB)": 67.44,
      "step": 3670,
      "train_speed(iter/s)": 0.253547
    },
    {
      "epoch": 0.34278518794888535,
      "grad_norm": 8.656197547912598,
      "learning_rate": 9.990602087259433e-06,
      "loss": 0.5511098861694336,
      "memory(GiB)": 67.44,
      "step": 3675,
      "token_acc": 0.5818181818181818,
      "train_speed(iter/s)": 0.253581
    },
    {
      "epoch": 0.343251562354258,
      "grad_norm": 10.865219116210938,
      "learning_rate": 9.990507333063986e-06,
      "loss": 0.5968794345855712,
      "memory(GiB)": 67.44,
      "step": 3680,
      "token_acc": 0.4716981132075472,
      "train_speed(iter/s)": 0.253579
    },
    {
      "epoch": 0.34371793675963064,
      "grad_norm": 9.084835052490234,
      "learning_rate": 9.990412104037142e-06,
      "loss": 0.5826672554016114,
      "memory(GiB)": 67.44,
      "step": 3685,
      "train_speed(iter/s)": 0.253569
    },
    {
      "epoch": 0.34418431116500325,
      "grad_norm": 20.68560028076172,
      "learning_rate": 9.990316400187957e-06,
      "loss": 0.5853034973144531,
      "memory(GiB)": 67.44,
      "step": 3690,
      "token_acc": 0.7961783439490446,
      "train_speed(iter/s)": 0.253562
    },
    {
      "epoch": 0.3446506855703759,
      "grad_norm": 9.5689697265625,
      "learning_rate": 9.990220221525539e-06,
      "loss": 0.6353429794311524,
      "memory(GiB)": 67.44,
      "step": 3695,
      "train_speed(iter/s)": 0.253559
    },
    {
      "epoch": 0.34511705997574854,
      "grad_norm": 11.006431579589844,
      "learning_rate": 9.990123568059042e-06,
      "loss": 0.579229736328125,
      "memory(GiB)": 67.44,
      "step": 3700,
      "train_speed(iter/s)": 0.253535
    },
    {
      "epoch": 0.34558343438112116,
      "grad_norm": 7.321854114532471,
      "learning_rate": 9.990026439797657e-06,
      "loss": 0.5947200775146484,
      "memory(GiB)": 67.44,
      "step": 3705,
      "token_acc": 0.5042735042735043,
      "train_speed(iter/s)": 0.253538
    },
    {
      "epoch": 0.3460498087864938,
      "grad_norm": 6.575976371765137,
      "learning_rate": 9.98992883675063e-06,
      "loss": 0.6070561408996582,
      "memory(GiB)": 67.44,
      "step": 3710,
      "token_acc": 0.47540983606557374,
      "train_speed(iter/s)": 0.253546
    },
    {
      "epoch": 0.34651618319186644,
      "grad_norm": 5.029444217681885,
      "learning_rate": 9.989830758927247e-06,
      "loss": 0.5774379253387452,
      "memory(GiB)": 67.44,
      "step": 3715,
      "token_acc": 0.3854166666666667,
      "train_speed(iter/s)": 0.253547
    },
    {
      "epoch": 0.34698255759723906,
      "grad_norm": 10.774103164672852,
      "learning_rate": 9.989732206336839e-06,
      "loss": 0.6428146362304688,
      "memory(GiB)": 67.44,
      "step": 3720,
      "train_speed(iter/s)": 0.253541
    },
    {
      "epoch": 0.3474489320026117,
      "grad_norm": 11.183571815490723,
      "learning_rate": 9.989633178988782e-06,
      "loss": 0.5640315532684326,
      "memory(GiB)": 67.44,
      "step": 3725,
      "train_speed(iter/s)": 0.253546
    },
    {
      "epoch": 0.34791530640798435,
      "grad_norm": 5.808257102966309,
      "learning_rate": 9.989533676892497e-06,
      "loss": 0.6025868415832519,
      "memory(GiB)": 67.44,
      "step": 3730,
      "train_speed(iter/s)": 0.253538
    },
    {
      "epoch": 0.34838168081335696,
      "grad_norm": 7.687677383422852,
      "learning_rate": 9.989433700057455e-06,
      "loss": 0.5760406494140625,
      "memory(GiB)": 67.44,
      "step": 3735,
      "token_acc": 0.8645833333333334,
      "train_speed(iter/s)": 0.253537
    },
    {
      "epoch": 0.3488480552187296,
      "grad_norm": 7.108997344970703,
      "learning_rate": 9.98933324849317e-06,
      "loss": 0.5893392562866211,
      "memory(GiB)": 67.44,
      "step": 3740,
      "token_acc": 0.5272727272727272,
      "train_speed(iter/s)": 0.253538
    },
    {
      "epoch": 0.34931442962410225,
      "grad_norm": 13.06785774230957,
      "learning_rate": 9.989232322209192e-06,
      "loss": 0.5792162895202637,
      "memory(GiB)": 67.44,
      "step": 3745,
      "train_speed(iter/s)": 0.253546
    },
    {
      "epoch": 0.34978080402947487,
      "grad_norm": 7.124832630157471,
      "learning_rate": 9.989130921215128e-06,
      "loss": 0.6185039520263672,
      "memory(GiB)": 67.44,
      "step": 3750,
      "train_speed(iter/s)": 0.253537
    },
    {
      "epoch": 0.3502471784348475,
      "grad_norm": 15.227919578552246,
      "learning_rate": 9.98902904552063e-06,
      "loss": 0.587834358215332,
      "memory(GiB)": 67.44,
      "step": 3755,
      "token_acc": 0.5567010309278351,
      "train_speed(iter/s)": 0.253541
    },
    {
      "epoch": 0.35071355284022016,
      "grad_norm": 6.716182708740234,
      "learning_rate": 9.988926695135384e-06,
      "loss": 0.6081466674804688,
      "memory(GiB)": 67.44,
      "step": 3760,
      "token_acc": 0.5681818181818182,
      "train_speed(iter/s)": 0.253558
    },
    {
      "epoch": 0.35117992724559277,
      "grad_norm": 14.541167259216309,
      "learning_rate": 9.988823870069133e-06,
      "loss": 0.5222327709197998,
      "memory(GiB)": 67.44,
      "step": 3765,
      "train_speed(iter/s)": 0.253566
    },
    {
      "epoch": 0.3516463016509654,
      "grad_norm": 8.38536548614502,
      "learning_rate": 9.98872057033166e-06,
      "loss": 0.5613750457763672,
      "memory(GiB)": 67.44,
      "step": 3770,
      "train_speed(iter/s)": 0.253391
    },
    {
      "epoch": 0.352112676056338,
      "grad_norm": 10.358341217041016,
      "learning_rate": 9.988616795932791e-06,
      "loss": 0.628156042098999,
      "memory(GiB)": 67.44,
      "step": 3775,
      "train_speed(iter/s)": 0.253367
    },
    {
      "epoch": 0.3525790504617107,
      "grad_norm": 14.068138122558594,
      "learning_rate": 9.988512546882403e-06,
      "loss": 0.6285712242126464,
      "memory(GiB)": 67.44,
      "step": 3780,
      "token_acc": 0.49122807017543857,
      "train_speed(iter/s)": 0.253369
    },
    {
      "epoch": 0.3530454248670833,
      "grad_norm": 11.026009559631348,
      "learning_rate": 9.988407823190413e-06,
      "loss": 0.5675148963928223,
      "memory(GiB)": 67.44,
      "step": 3785,
      "token_acc": 0.5189873417721519,
      "train_speed(iter/s)": 0.253374
    },
    {
      "epoch": 0.3535117992724559,
      "grad_norm": 21.362255096435547,
      "learning_rate": 9.988302624866787e-06,
      "loss": 0.5937701225280761,
      "memory(GiB)": 67.44,
      "step": 3790,
      "token_acc": 0.5471698113207547,
      "train_speed(iter/s)": 0.253381
    },
    {
      "epoch": 0.3539781736778286,
      "grad_norm": 12.364947319030762,
      "learning_rate": 9.988196951921531e-06,
      "loss": 0.5912362098693847,
      "memory(GiB)": 67.44,
      "step": 3795,
      "token_acc": 0.5945945945945946,
      "train_speed(iter/s)": 0.253391
    },
    {
      "epoch": 0.3544445480832012,
      "grad_norm": 8.024696350097656,
      "learning_rate": 9.988090804364704e-06,
      "loss": 0.5953597068786621,
      "memory(GiB)": 67.44,
      "step": 3800,
      "train_speed(iter/s)": 0.25339
    },
    {
      "epoch": 0.3549109224885738,
      "grad_norm": 5.292505264282227,
      "learning_rate": 9.987984182206402e-06,
      "loss": 0.5888778686523437,
      "memory(GiB)": 67.44,
      "step": 3805,
      "train_speed(iter/s)": 0.2534
    },
    {
      "epoch": 0.3553772968939465,
      "grad_norm": 11.925390243530273,
      "learning_rate": 9.987877085456771e-06,
      "loss": 0.6139346122741699,
      "memory(GiB)": 67.44,
      "step": 3810,
      "token_acc": 0.5370370370370371,
      "train_speed(iter/s)": 0.253389
    },
    {
      "epoch": 0.3558436712993191,
      "grad_norm": 8.599058151245117,
      "learning_rate": 9.987769514126e-06,
      "loss": 0.5706347465515137,
      "memory(GiB)": 67.44,
      "step": 3815,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.253394
    },
    {
      "epoch": 0.3563100457046917,
      "grad_norm": 5.2313642501831055,
      "learning_rate": 9.987661468224325e-06,
      "loss": 0.5843676567077637,
      "memory(GiB)": 67.44,
      "step": 3820,
      "token_acc": 0.6304347826086957,
      "train_speed(iter/s)": 0.253405
    },
    {
      "epoch": 0.3567764201100644,
      "grad_norm": 12.908405303955078,
      "learning_rate": 9.987552947762029e-06,
      "loss": 0.6602182865142823,
      "memory(GiB)": 67.44,
      "step": 3825,
      "train_speed(iter/s)": 0.253422
    },
    {
      "epoch": 0.357242794515437,
      "grad_norm": 10.245726585388184,
      "learning_rate": 9.987443952749432e-06,
      "loss": 0.569533395767212,
      "memory(GiB)": 67.44,
      "step": 3830,
      "train_speed(iter/s)": 0.25341
    },
    {
      "epoch": 0.3577091689208096,
      "grad_norm": 11.999449729919434,
      "learning_rate": 9.987334483196907e-06,
      "loss": 0.5350314140319824,
      "memory(GiB)": 67.44,
      "step": 3835,
      "token_acc": 0.8131868131868132,
      "train_speed(iter/s)": 0.253401
    },
    {
      "epoch": 0.35817554332618223,
      "grad_norm": 9.187193870544434,
      "learning_rate": 9.98722453911487e-06,
      "loss": 0.618565559387207,
      "memory(GiB)": 67.44,
      "step": 3840,
      "token_acc": 0.8829787234042553,
      "train_speed(iter/s)": 0.2534
    },
    {
      "epoch": 0.3586419177315549,
      "grad_norm": 7.0139479637146,
      "learning_rate": 9.987114120513782e-06,
      "loss": 0.5726469993591309,
      "memory(GiB)": 67.44,
      "step": 3845,
      "token_acc": 0.5869565217391305,
      "train_speed(iter/s)": 0.253415
    },
    {
      "epoch": 0.3591082921369275,
      "grad_norm": 6.869377136230469,
      "learning_rate": 9.987003227404148e-06,
      "loss": 0.5481169700622559,
      "memory(GiB)": 67.44,
      "step": 3850,
      "token_acc": 0.6865671641791045,
      "train_speed(iter/s)": 0.253434
    },
    {
      "epoch": 0.35957466654230014,
      "grad_norm": 4.7164225578308105,
      "learning_rate": 9.986891859796522e-06,
      "loss": 0.5720312118530273,
      "memory(GiB)": 67.44,
      "step": 3855,
      "token_acc": 0.6883116883116883,
      "train_speed(iter/s)": 0.25343
    },
    {
      "epoch": 0.3600410409476728,
      "grad_norm": 9.41077709197998,
      "learning_rate": 9.986780017701495e-06,
      "loss": 0.559803819656372,
      "memory(GiB)": 67.44,
      "step": 3860,
      "token_acc": 0.8860759493670886,
      "train_speed(iter/s)": 0.25343
    },
    {
      "epoch": 0.3605074153530454,
      "grad_norm": 9.619216918945312,
      "learning_rate": 9.986667701129713e-06,
      "loss": 0.619851016998291,
      "memory(GiB)": 67.44,
      "step": 3865,
      "token_acc": 0.5206611570247934,
      "train_speed(iter/s)": 0.253435
    },
    {
      "epoch": 0.36097378975841804,
      "grad_norm": 15.011107444763184,
      "learning_rate": 9.986554910091861e-06,
      "loss": 0.5896186828613281,
      "memory(GiB)": 67.44,
      "step": 3870,
      "train_speed(iter/s)": 0.253431
    },
    {
      "epoch": 0.3614401641637907,
      "grad_norm": 7.7820611000061035,
      "learning_rate": 9.98644164459867e-06,
      "loss": 0.5535592555999755,
      "memory(GiB)": 67.44,
      "step": 3875,
      "token_acc": 0.5566037735849056,
      "train_speed(iter/s)": 0.253438
    },
    {
      "epoch": 0.3619065385691633,
      "grad_norm": 10.915488243103027,
      "learning_rate": 9.98632790466092e-06,
      "loss": 0.5106432914733887,
      "memory(GiB)": 67.44,
      "step": 3880,
      "train_speed(iter/s)": 0.253449
    },
    {
      "epoch": 0.36237291297453594,
      "grad_norm": 12.082287788391113,
      "learning_rate": 9.986213690289427e-06,
      "loss": 0.5405996799468994,
      "memory(GiB)": 67.44,
      "step": 3885,
      "token_acc": 0.7769230769230769,
      "train_speed(iter/s)": 0.253477
    },
    {
      "epoch": 0.3628392873799086,
      "grad_norm": 13.4488525390625,
      "learning_rate": 9.986099001495064e-06,
      "loss": 0.5576305389404297,
      "memory(GiB)": 67.44,
      "step": 3890,
      "train_speed(iter/s)": 0.253478
    },
    {
      "epoch": 0.36330566178528123,
      "grad_norm": 20.74915313720703,
      "learning_rate": 9.985983838288742e-06,
      "loss": 0.6223217010498047,
      "memory(GiB)": 67.44,
      "step": 3895,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.253488
    },
    {
      "epoch": 0.36377203619065385,
      "grad_norm": 11.021007537841797,
      "learning_rate": 9.985868200681415e-06,
      "loss": 0.5999728202819824,
      "memory(GiB)": 67.44,
      "step": 3900,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.253495
    },
    {
      "epoch": 0.36423841059602646,
      "grad_norm": 7.146580696105957,
      "learning_rate": 9.98575208868409e-06,
      "loss": 0.5839797019958496,
      "memory(GiB)": 67.44,
      "step": 3905,
      "train_speed(iter/s)": 0.253488
    },
    {
      "epoch": 0.36470478500139913,
      "grad_norm": 7.2324137687683105,
      "learning_rate": 9.985635502307811e-06,
      "loss": 0.6013709545135498,
      "memory(GiB)": 67.44,
      "step": 3910,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.253511
    },
    {
      "epoch": 0.36517115940677175,
      "grad_norm": 5.283449172973633,
      "learning_rate": 9.985518441563675e-06,
      "loss": 0.557740592956543,
      "memory(GiB)": 67.44,
      "step": 3915,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.253496
    },
    {
      "epoch": 0.36563753381214437,
      "grad_norm": 9.047585487365723,
      "learning_rate": 9.985400906462816e-06,
      "loss": 0.5846418857574462,
      "memory(GiB)": 67.44,
      "step": 3920,
      "token_acc": 0.875,
      "train_speed(iter/s)": 0.25351
    },
    {
      "epoch": 0.36610390821751704,
      "grad_norm": 8.245107650756836,
      "learning_rate": 9.985282897016419e-06,
      "loss": 0.5560087203979492,
      "memory(GiB)": 67.44,
      "step": 3925,
      "token_acc": 0.3972602739726027,
      "train_speed(iter/s)": 0.253501
    },
    {
      "epoch": 0.36657028262288965,
      "grad_norm": 12.248579025268555,
      "learning_rate": 9.98516441323571e-06,
      "loss": 0.5437510490417481,
      "memory(GiB)": 67.44,
      "step": 3930,
      "token_acc": 0.8691588785046729,
      "train_speed(iter/s)": 0.253474
    },
    {
      "epoch": 0.36703665702826227,
      "grad_norm": 13.401988983154297,
      "learning_rate": 9.985045455131968e-06,
      "loss": 0.5851932048797608,
      "memory(GiB)": 67.44,
      "step": 3935,
      "train_speed(iter/s)": 0.253488
    },
    {
      "epoch": 0.36750303143363494,
      "grad_norm": 11.215213775634766,
      "learning_rate": 9.984926022716505e-06,
      "loss": 0.5832062244415284,
      "memory(GiB)": 67.44,
      "step": 3940,
      "token_acc": 0.6818181818181818,
      "train_speed(iter/s)": 0.253488
    },
    {
      "epoch": 0.36796940583900756,
      "grad_norm": 13.350874900817871,
      "learning_rate": 9.984806116000687e-06,
      "loss": 0.6193130493164063,
      "memory(GiB)": 67.44,
      "step": 3945,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.3684357802443802,
      "grad_norm": 9.94919490814209,
      "learning_rate": 9.984685734995925e-06,
      "loss": 0.5606053352355957,
      "memory(GiB)": 67.44,
      "step": 3950,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.36890215464975284,
      "grad_norm": 11.66055965423584,
      "learning_rate": 9.98456487971367e-06,
      "loss": 0.5833440780639648,
      "memory(GiB)": 67.44,
      "step": 3955,
      "train_speed(iter/s)": 0.253492
    },
    {
      "epoch": 0.36936852905512546,
      "grad_norm": 9.124428749084473,
      "learning_rate": 9.984443550165422e-06,
      "loss": 0.5693818092346191,
      "memory(GiB)": 67.44,
      "step": 3960,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.253499
    },
    {
      "epoch": 0.3698349034604981,
      "grad_norm": 9.805068969726562,
      "learning_rate": 9.984321746362727e-06,
      "loss": 0.5489653587341309,
      "memory(GiB)": 67.44,
      "step": 3965,
      "train_speed(iter/s)": 0.253512
    },
    {
      "epoch": 0.37030127786587075,
      "grad_norm": 4.071971893310547,
      "learning_rate": 9.98419946831717e-06,
      "loss": 0.5659017562866211,
      "memory(GiB)": 67.44,
      "step": 3970,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.253502
    },
    {
      "epoch": 0.37076765227124336,
      "grad_norm": 8.495123863220215,
      "learning_rate": 9.984076716040389e-06,
      "loss": 0.5674989700317383,
      "memory(GiB)": 67.44,
      "step": 3975,
      "token_acc": 0.40476190476190477,
      "train_speed(iter/s)": 0.25352
    },
    {
      "epoch": 0.371234026676616,
      "grad_norm": 18.536151885986328,
      "learning_rate": 9.983953489544062e-06,
      "loss": 0.5935463905334473,
      "memory(GiB)": 67.44,
      "step": 3980,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.253526
    },
    {
      "epoch": 0.3717004010819886,
      "grad_norm": 9.946956634521484,
      "learning_rate": 9.983829788839914e-06,
      "loss": 0.57210693359375,
      "memory(GiB)": 67.44,
      "step": 3985,
      "token_acc": 0.47674418604651164,
      "train_speed(iter/s)": 0.25353
    },
    {
      "epoch": 0.37216677548736127,
      "grad_norm": 16.54277992248535,
      "learning_rate": 9.983705613939713e-06,
      "loss": 0.5697676181793213,
      "memory(GiB)": 67.44,
      "step": 3990,
      "train_speed(iter/s)": 0.25354
    },
    {
      "epoch": 0.3726331498927339,
      "grad_norm": 10.044817924499512,
      "learning_rate": 9.983580964855277e-06,
      "loss": 0.5755181312561035,
      "memory(GiB)": 67.44,
      "step": 3995,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.253533
    },
    {
      "epoch": 0.3730995242981065,
      "grad_norm": 10.51734447479248,
      "learning_rate": 9.983455841598466e-06,
      "loss": 0.593402624130249,
      "memory(GiB)": 67.44,
      "step": 4000,
      "token_acc": 0.8514851485148515,
      "train_speed(iter/s)": 0.253518
    },
    {
      "epoch": 0.37356589870347917,
      "grad_norm": 9.59521484375,
      "learning_rate": 9.983330244181183e-06,
      "loss": 0.584796667098999,
      "memory(GiB)": 67.44,
      "step": 4005,
      "train_speed(iter/s)": 0.25305
    },
    {
      "epoch": 0.3740322731088518,
      "grad_norm": 6.717479228973389,
      "learning_rate": 9.983204172615376e-06,
      "loss": 0.5773298263549804,
      "memory(GiB)": 67.44,
      "step": 4010,
      "token_acc": 0.36666666666666664,
      "train_speed(iter/s)": 0.253053
    },
    {
      "epoch": 0.3744986475142244,
      "grad_norm": 10.508831977844238,
      "learning_rate": 9.983077626913045e-06,
      "loss": 0.5633035182952881,
      "memory(GiB)": 67.44,
      "step": 4015,
      "train_speed(iter/s)": 0.253062
    },
    {
      "epoch": 0.3749650219195971,
      "grad_norm": 9.473142623901367,
      "learning_rate": 9.982950607086229e-06,
      "loss": 0.5789699554443359,
      "memory(GiB)": 67.44,
      "step": 4020,
      "train_speed(iter/s)": 0.253048
    },
    {
      "epoch": 0.3754313963249697,
      "grad_norm": 14.721196174621582,
      "learning_rate": 9.982823113147013e-06,
      "loss": 0.5646307945251465,
      "memory(GiB)": 67.44,
      "step": 4025,
      "train_speed(iter/s)": 0.253063
    },
    {
      "epoch": 0.3758977707303423,
      "grad_norm": 7.690385818481445,
      "learning_rate": 9.982695145107526e-06,
      "loss": 0.5642518997192383,
      "memory(GiB)": 67.44,
      "step": 4030,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.253074
    },
    {
      "epoch": 0.376364145135715,
      "grad_norm": 10.785016059875488,
      "learning_rate": 9.982566702979948e-06,
      "loss": 0.5858209133148193,
      "memory(GiB)": 67.44,
      "step": 4035,
      "token_acc": 0.7058823529411765,
      "train_speed(iter/s)": 0.253076
    },
    {
      "epoch": 0.3768305195410876,
      "grad_norm": 15.206947326660156,
      "learning_rate": 9.982437786776496e-06,
      "loss": 0.6441039085388184,
      "memory(GiB)": 67.44,
      "step": 4040,
      "token_acc": 0.5423728813559322,
      "train_speed(iter/s)": 0.253086
    },
    {
      "epoch": 0.3772968939464602,
      "grad_norm": 14.530044555664062,
      "learning_rate": 9.982308396509437e-06,
      "loss": 0.5442278385162354,
      "memory(GiB)": 67.44,
      "step": 4045,
      "train_speed(iter/s)": 0.253111
    },
    {
      "epoch": 0.3777632683518328,
      "grad_norm": 7.652324199676514,
      "learning_rate": 9.982178532191084e-06,
      "loss": 0.5634652614593506,
      "memory(GiB)": 67.44,
      "step": 4050,
      "token_acc": 0.4339622641509434,
      "train_speed(iter/s)": 0.253113
    },
    {
      "epoch": 0.3782296427572055,
      "grad_norm": 10.413718223571777,
      "learning_rate": 9.982048193833791e-06,
      "loss": 0.573323917388916,
      "memory(GiB)": 67.44,
      "step": 4055,
      "train_speed(iter/s)": 0.25311
    },
    {
      "epoch": 0.3786960171625781,
      "grad_norm": 12.062127113342285,
      "learning_rate": 9.98191738144996e-06,
      "loss": 0.5594650268554687,
      "memory(GiB)": 67.44,
      "step": 4060,
      "token_acc": 0.47572815533980584,
      "train_speed(iter/s)": 0.253098
    },
    {
      "epoch": 0.37916239156795073,
      "grad_norm": 17.90703582763672,
      "learning_rate": 9.981786095052037e-06,
      "loss": 0.615456485748291,
      "memory(GiB)": 67.44,
      "step": 4065,
      "train_speed(iter/s)": 0.253114
    },
    {
      "epoch": 0.3796287659733234,
      "grad_norm": 11.654165267944336,
      "learning_rate": 9.981654334652513e-06,
      "loss": 0.60396728515625,
      "memory(GiB)": 67.44,
      "step": 4070,
      "train_speed(iter/s)": 0.253136
    },
    {
      "epoch": 0.380095140378696,
      "grad_norm": 18.67783546447754,
      "learning_rate": 9.981522100263928e-06,
      "loss": 0.5715192317962646,
      "memory(GiB)": 67.44,
      "step": 4075,
      "token_acc": 0.3582089552238806,
      "train_speed(iter/s)": 0.253163
    },
    {
      "epoch": 0.38056151478406863,
      "grad_norm": 20.691415786743164,
      "learning_rate": 9.981389391898859e-06,
      "loss": 0.5974315643310547,
      "memory(GiB)": 67.44,
      "step": 4080,
      "token_acc": 0.4830508474576271,
      "train_speed(iter/s)": 0.253158
    },
    {
      "epoch": 0.3810278891894413,
      "grad_norm": 9.605266571044922,
      "learning_rate": 9.981256209569934e-06,
      "loss": 0.5693470478057862,
      "memory(GiB)": 67.44,
      "step": 4085,
      "train_speed(iter/s)": 0.253165
    },
    {
      "epoch": 0.3814942635948139,
      "grad_norm": 9.555702209472656,
      "learning_rate": 9.981122553289828e-06,
      "loss": 0.6322458267211915,
      "memory(GiB)": 67.44,
      "step": 4090,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.253158
    },
    {
      "epoch": 0.38196063800018654,
      "grad_norm": 6.628213405609131,
      "learning_rate": 9.980988423071253e-06,
      "loss": 0.6084953308105469,
      "memory(GiB)": 67.44,
      "step": 4095,
      "train_speed(iter/s)": 0.253157
    },
    {
      "epoch": 0.3824270124055592,
      "grad_norm": 9.586057662963867,
      "learning_rate": 9.980853818926977e-06,
      "loss": 0.6061253547668457,
      "memory(GiB)": 67.44,
      "step": 4100,
      "token_acc": 0.7659574468085106,
      "train_speed(iter/s)": 0.253161
    },
    {
      "epoch": 0.3828933868109318,
      "grad_norm": 12.611132621765137,
      "learning_rate": 9.980718740869804e-06,
      "loss": 0.5979864120483398,
      "memory(GiB)": 67.44,
      "step": 4105,
      "token_acc": 0.4772727272727273,
      "train_speed(iter/s)": 0.253149
    },
    {
      "epoch": 0.38335976121630444,
      "grad_norm": 7.170371055603027,
      "learning_rate": 9.980583188912585e-06,
      "loss": 0.5819136619567871,
      "memory(GiB)": 67.44,
      "step": 4110,
      "token_acc": 0.41304347826086957,
      "train_speed(iter/s)": 0.253151
    },
    {
      "epoch": 0.38382613562167706,
      "grad_norm": 7.973959445953369,
      "learning_rate": 9.980447163068219e-06,
      "loss": 0.547746229171753,
      "memory(GiB)": 67.44,
      "step": 4115,
      "train_speed(iter/s)": 0.253168
    },
    {
      "epoch": 0.3842925100270497,
      "grad_norm": 6.401829719543457,
      "learning_rate": 9.980310663349645e-06,
      "loss": 0.575889778137207,
      "memory(GiB)": 67.44,
      "step": 4120,
      "token_acc": 0.8953488372093024,
      "train_speed(iter/s)": 0.253171
    },
    {
      "epoch": 0.38475888443242234,
      "grad_norm": 11.178400993347168,
      "learning_rate": 9.980173689769858e-06,
      "loss": 0.5936013221740722,
      "memory(GiB)": 67.44,
      "step": 4125,
      "train_speed(iter/s)": 0.253188
    },
    {
      "epoch": 0.38522525883779496,
      "grad_norm": 6.5136919021606445,
      "learning_rate": 9.980036242341885e-06,
      "loss": 0.5698807716369629,
      "memory(GiB)": 67.44,
      "step": 4130,
      "token_acc": 0.81,
      "train_speed(iter/s)": 0.253186
    },
    {
      "epoch": 0.38569163324316763,
      "grad_norm": 16.17327880859375,
      "learning_rate": 9.979898321078805e-06,
      "loss": 0.5872326850891113,
      "memory(GiB)": 67.44,
      "step": 4135,
      "train_speed(iter/s)": 0.253195
    },
    {
      "epoch": 0.38615800764854025,
      "grad_norm": 5.886950492858887,
      "learning_rate": 9.97975992599374e-06,
      "loss": 0.5754203796386719,
      "memory(GiB)": 67.44,
      "step": 4140,
      "train_speed(iter/s)": 0.253185
    },
    {
      "epoch": 0.38662438205391286,
      "grad_norm": 5.197858810424805,
      "learning_rate": 9.979621057099859e-06,
      "loss": 0.5802205085754395,
      "memory(GiB)": 67.44,
      "step": 4145,
      "train_speed(iter/s)": 0.253185
    },
    {
      "epoch": 0.38709075645928553,
      "grad_norm": 5.736783504486084,
      "learning_rate": 9.979481714410374e-06,
      "loss": 0.5643129825592041,
      "memory(GiB)": 67.44,
      "step": 4150,
      "token_acc": 0.5434782608695652,
      "train_speed(iter/s)": 0.253189
    },
    {
      "epoch": 0.38755713086465815,
      "grad_norm": 5.581007480621338,
      "learning_rate": 9.979341897938543e-06,
      "loss": 0.5183215141296387,
      "memory(GiB)": 67.44,
      "step": 4155,
      "token_acc": 0.8695652173913043,
      "train_speed(iter/s)": 0.253205
    },
    {
      "epoch": 0.38802350527003077,
      "grad_norm": 8.098102569580078,
      "learning_rate": 9.979201607697671e-06,
      "loss": 0.530840253829956,
      "memory(GiB)": 67.44,
      "step": 4160,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.253208
    },
    {
      "epoch": 0.38848987967540344,
      "grad_norm": 8.591179847717285,
      "learning_rate": 9.979060843701106e-06,
      "loss": 0.6025997161865234,
      "memory(GiB)": 67.44,
      "step": 4165,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.25322
    },
    {
      "epoch": 0.38895625408077605,
      "grad_norm": 6.782850742340088,
      "learning_rate": 9.978919605962238e-06,
      "loss": 0.5775674343109131,
      "memory(GiB)": 67.44,
      "step": 4170,
      "token_acc": 0.4657534246575342,
      "train_speed(iter/s)": 0.25323
    },
    {
      "epoch": 0.38942262848614867,
      "grad_norm": 5.743956089019775,
      "learning_rate": 9.978777894494506e-06,
      "loss": 0.5623038291931153,
      "memory(GiB)": 67.44,
      "step": 4175,
      "train_speed(iter/s)": 0.253231
    },
    {
      "epoch": 0.3898890028915213,
      "grad_norm": 8.853001594543457,
      "learning_rate": 9.978635709311398e-06,
      "loss": 0.6067556381225586,
      "memory(GiB)": 67.44,
      "step": 4180,
      "token_acc": 0.4605263157894737,
      "train_speed(iter/s)": 0.253229
    },
    {
      "epoch": 0.39035537729689396,
      "grad_norm": 10.30982494354248,
      "learning_rate": 9.978493050426438e-06,
      "loss": 0.5746651649475097,
      "memory(GiB)": 67.44,
      "step": 4185,
      "token_acc": 0.4536082474226804,
      "train_speed(iter/s)": 0.253223
    },
    {
      "epoch": 0.3908217517022666,
      "grad_norm": 20.172672271728516,
      "learning_rate": 9.9783499178532e-06,
      "loss": 0.6753668308258056,
      "memory(GiB)": 67.44,
      "step": 4190,
      "train_speed(iter/s)": 0.25322
    },
    {
      "epoch": 0.3912881261076392,
      "grad_norm": 21.943519592285156,
      "learning_rate": 9.978206311605305e-06,
      "loss": 0.6625209808349609,
      "memory(GiB)": 67.44,
      "step": 4195,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.253239
    },
    {
      "epoch": 0.39175450051301186,
      "grad_norm": 14.546015739440918,
      "learning_rate": 9.978062231696415e-06,
      "loss": 0.6311278343200684,
      "memory(GiB)": 67.44,
      "step": 4200,
      "train_speed(iter/s)": 0.25324
    },
    {
      "epoch": 0.3922208749183845,
      "grad_norm": 18.079212188720703,
      "learning_rate": 9.977917678140239e-06,
      "loss": 0.6542209625244141,
      "memory(GiB)": 67.44,
      "step": 4205,
      "train_speed(iter/s)": 0.253242
    },
    {
      "epoch": 0.3926872493237571,
      "grad_norm": 19.858234405517578,
      "learning_rate": 9.97777265095053e-06,
      "loss": 0.6590925216674804,
      "memory(GiB)": 67.44,
      "step": 4210,
      "train_speed(iter/s)": 0.253255
    },
    {
      "epoch": 0.39315362372912976,
      "grad_norm": 17.10072135925293,
      "learning_rate": 9.977627150141089e-06,
      "loss": 0.6705479621887207,
      "memory(GiB)": 67.44,
      "step": 4215,
      "train_speed(iter/s)": 0.253254
    },
    {
      "epoch": 0.3936199981345024,
      "grad_norm": 10.749399185180664,
      "learning_rate": 9.977481175725755e-06,
      "loss": 0.6703173637390136,
      "memory(GiB)": 67.44,
      "step": 4220,
      "token_acc": 0.4489795918367347,
      "train_speed(iter/s)": 0.253252
    },
    {
      "epoch": 0.394086372539875,
      "grad_norm": 7.091413497924805,
      "learning_rate": 9.977334727718426e-06,
      "loss": 0.6001461029052735,
      "memory(GiB)": 67.44,
      "step": 4225,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.25325
    },
    {
      "epoch": 0.39455274694524767,
      "grad_norm": 3.250969171524048,
      "learning_rate": 9.977187806133027e-06,
      "loss": 0.5677108287811279,
      "memory(GiB)": 67.44,
      "step": 4230,
      "token_acc": 0.5737704918032787,
      "train_speed(iter/s)": 0.253245
    },
    {
      "epoch": 0.3950191213506203,
      "grad_norm": 6.0854644775390625,
      "learning_rate": 9.977040410983543e-06,
      "loss": 0.5809665203094483,
      "memory(GiB)": 67.44,
      "step": 4235,
      "token_acc": 0.3870967741935484,
      "train_speed(iter/s)": 0.253252
    },
    {
      "epoch": 0.3954854957559929,
      "grad_norm": 5.225831508636475,
      "learning_rate": 9.976892542283994e-06,
      "loss": 0.5446568012237549,
      "memory(GiB)": 67.44,
      "step": 4240,
      "token_acc": 0.5614035087719298,
      "train_speed(iter/s)": 0.253253
    },
    {
      "epoch": 0.39595187016136557,
      "grad_norm": 9.516080856323242,
      "learning_rate": 9.976744200048451e-06,
      "loss": 0.5446323871612548,
      "memory(GiB)": 67.44,
      "step": 4245,
      "token_acc": 0.39622641509433965,
      "train_speed(iter/s)": 0.253259
    },
    {
      "epoch": 0.3964182445667382,
      "grad_norm": 17.652786254882812,
      "learning_rate": 9.976595384291032e-06,
      "loss": 0.6349640369415284,
      "memory(GiB)": 67.44,
      "step": 4250,
      "token_acc": 0.5531914893617021,
      "train_speed(iter/s)": 0.253271
    },
    {
      "epoch": 0.3968846189721108,
      "grad_norm": 17.052703857421875,
      "learning_rate": 9.97644609502589e-06,
      "loss": 0.6090795993804932,
      "memory(GiB)": 67.44,
      "step": 4255,
      "token_acc": 0.85,
      "train_speed(iter/s)": 0.25329
    },
    {
      "epoch": 0.3973509933774834,
      "grad_norm": 17.762449264526367,
      "learning_rate": 9.976296332267232e-06,
      "loss": 0.6144660472869873,
      "memory(GiB)": 67.44,
      "step": 4260,
      "train_speed(iter/s)": 0.253308
    },
    {
      "epoch": 0.3978173677828561,
      "grad_norm": 12.53318977355957,
      "learning_rate": 9.97614609602931e-06,
      "loss": 0.6194994926452637,
      "memory(GiB)": 67.44,
      "step": 4265,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.253309
    },
    {
      "epoch": 0.3982837421882287,
      "grad_norm": 8.36727237701416,
      "learning_rate": 9.975995386326415e-06,
      "loss": 0.604860782623291,
      "memory(GiB)": 67.44,
      "step": 4270,
      "train_speed(iter/s)": 0.253319
    },
    {
      "epoch": 0.3987501165936013,
      "grad_norm": 11.122243881225586,
      "learning_rate": 9.97584420317289e-06,
      "loss": 0.5562936305999756,
      "memory(GiB)": 67.44,
      "step": 4275,
      "token_acc": 0.8765432098765432,
      "train_speed(iter/s)": 0.25332
    },
    {
      "epoch": 0.399216490998974,
      "grad_norm": 8.348841667175293,
      "learning_rate": 9.975692546583115e-06,
      "loss": 0.5988238334655762,
      "memory(GiB)": 67.44,
      "step": 4280,
      "train_speed(iter/s)": 0.25331
    },
    {
      "epoch": 0.3996828654043466,
      "grad_norm": 8.881263732910156,
      "learning_rate": 9.975540416571522e-06,
      "loss": 0.5653592109680176,
      "memory(GiB)": 67.44,
      "step": 4285,
      "token_acc": 0.45132743362831856,
      "train_speed(iter/s)": 0.253324
    },
    {
      "epoch": 0.4001492398097192,
      "grad_norm": 19.93613624572754,
      "learning_rate": 9.975387813152589e-06,
      "loss": 0.5688375949859619,
      "memory(GiB)": 67.44,
      "step": 4290,
      "token_acc": 0.4619289340101523,
      "train_speed(iter/s)": 0.253317
    },
    {
      "epoch": 0.4006156142150919,
      "grad_norm": 9.016033172607422,
      "learning_rate": 9.975234736340829e-06,
      "loss": 0.5769370079040528,
      "memory(GiB)": 67.44,
      "step": 4295,
      "train_speed(iter/s)": 0.253315
    },
    {
      "epoch": 0.4010819886204645,
      "grad_norm": 9.077780723571777,
      "learning_rate": 9.975081186150813e-06,
      "loss": 0.570188331604004,
      "memory(GiB)": 67.44,
      "step": 4300,
      "train_speed(iter/s)": 0.253327
    },
    {
      "epoch": 0.40154836302583713,
      "grad_norm": 10.787874221801758,
      "learning_rate": 9.974927162597146e-06,
      "loss": 0.5333581924438476,
      "memory(GiB)": 67.44,
      "step": 4305,
      "train_speed(iter/s)": 0.253337
    },
    {
      "epoch": 0.4020147374312098,
      "grad_norm": 6.201026916503906,
      "learning_rate": 9.974772665694487e-06,
      "loss": 0.5673025131225586,
      "memory(GiB)": 67.44,
      "step": 4310,
      "token_acc": 0.48223350253807107,
      "train_speed(iter/s)": 0.253358
    },
    {
      "epoch": 0.4024811118365824,
      "grad_norm": 8.549131393432617,
      "learning_rate": 9.974617695457534e-06,
      "loss": 0.5309601306915284,
      "memory(GiB)": 67.44,
      "step": 4315,
      "train_speed(iter/s)": 0.253365
    },
    {
      "epoch": 0.40294748624195503,
      "grad_norm": 12.775240898132324,
      "learning_rate": 9.97446225190103e-06,
      "loss": 0.5327648162841797,
      "memory(GiB)": 67.44,
      "step": 4320,
      "token_acc": 0.4657534246575342,
      "train_speed(iter/s)": 0.253368
    },
    {
      "epoch": 0.40341386064732765,
      "grad_norm": 10.637116432189941,
      "learning_rate": 9.97430633503977e-06,
      "loss": 0.5662577629089356,
      "memory(GiB)": 67.44,
      "step": 4325,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.253375
    },
    {
      "epoch": 0.4038802350527003,
      "grad_norm": 5.587825298309326,
      "learning_rate": 9.974149944888582e-06,
      "loss": 0.5812252521514892,
      "memory(GiB)": 67.44,
      "step": 4330,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.253385
    },
    {
      "epoch": 0.40434660945807294,
      "grad_norm": 8.101577758789062,
      "learning_rate": 9.973993081462354e-06,
      "loss": 0.5444910049438476,
      "memory(GiB)": 67.44,
      "step": 4335,
      "train_speed(iter/s)": 0.253365
    },
    {
      "epoch": 0.40481298386344555,
      "grad_norm": 5.140851974487305,
      "learning_rate": 9.973835744776004e-06,
      "loss": 0.5957176208496093,
      "memory(GiB)": 67.44,
      "step": 4340,
      "train_speed(iter/s)": 0.253366
    },
    {
      "epoch": 0.4052793582688182,
      "grad_norm": 8.808006286621094,
      "learning_rate": 9.973677934844508e-06,
      "loss": 0.5954808235168457,
      "memory(GiB)": 67.44,
      "step": 4345,
      "token_acc": 0.2982456140350877,
      "train_speed(iter/s)": 0.253357
    },
    {
      "epoch": 0.40574573267419084,
      "grad_norm": 4.712512969970703,
      "learning_rate": 9.973519651682876e-06,
      "loss": 0.5819921016693115,
      "memory(GiB)": 67.44,
      "step": 4350,
      "train_speed(iter/s)": 0.253375
    },
    {
      "epoch": 0.40621210707956346,
      "grad_norm": 13.939288139343262,
      "learning_rate": 9.97336089530617e-06,
      "loss": 0.5523247718811035,
      "memory(GiB)": 67.44,
      "step": 4355,
      "train_speed(iter/s)": 0.253388
    },
    {
      "epoch": 0.4066784814849361,
      "grad_norm": 5.611318588256836,
      "learning_rate": 9.973201665729498e-06,
      "loss": 0.5677842140197754,
      "memory(GiB)": 67.44,
      "step": 4360,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.253379
    },
    {
      "epoch": 0.40714485589030874,
      "grad_norm": 5.916405200958252,
      "learning_rate": 9.973041962968007e-06,
      "loss": 0.5867773532867432,
      "memory(GiB)": 67.44,
      "step": 4365,
      "token_acc": 0.38095238095238093,
      "train_speed(iter/s)": 0.253379
    },
    {
      "epoch": 0.40761123029568136,
      "grad_norm": 6.318897724151611,
      "learning_rate": 9.972881787036892e-06,
      "loss": 0.579811954498291,
      "memory(GiB)": 67.44,
      "step": 4370,
      "train_speed(iter/s)": 0.253392
    },
    {
      "epoch": 0.40807760470105403,
      "grad_norm": 12.00912857055664,
      "learning_rate": 9.972721137951395e-06,
      "loss": 0.5693556785583496,
      "memory(GiB)": 67.44,
      "step": 4375,
      "token_acc": 0.4307692307692308,
      "train_speed(iter/s)": 0.253395
    },
    {
      "epoch": 0.40854397910642665,
      "grad_norm": 7.727280616760254,
      "learning_rate": 9.9725600157268e-06,
      "loss": 0.5682494640350342,
      "memory(GiB)": 67.44,
      "step": 4380,
      "token_acc": 0.559322033898305,
      "train_speed(iter/s)": 0.253394
    },
    {
      "epoch": 0.40901035351179926,
      "grad_norm": 6.712843418121338,
      "learning_rate": 9.97239842037844e-06,
      "loss": 0.5718001365661621,
      "memory(GiB)": 67.44,
      "step": 4385,
      "token_acc": 0.44,
      "train_speed(iter/s)": 0.253401
    },
    {
      "epoch": 0.4094767279171719,
      "grad_norm": 13.479743957519531,
      "learning_rate": 9.972236351921687e-06,
      "loss": 0.5635470390319824,
      "memory(GiB)": 67.44,
      "step": 4390,
      "token_acc": 0.44,
      "train_speed(iter/s)": 0.253411
    },
    {
      "epoch": 0.40994310232254455,
      "grad_norm": 9.324478149414062,
      "learning_rate": 9.97207381037196e-06,
      "loss": 0.5550914764404297,
      "memory(GiB)": 67.44,
      "step": 4395,
      "train_speed(iter/s)": 0.253401
    },
    {
      "epoch": 0.41040947672791717,
      "grad_norm": 7.006814956665039,
      "learning_rate": 9.97191079574473e-06,
      "loss": 0.5750687599182129,
      "memory(GiB)": 67.44,
      "step": 4400,
      "token_acc": 0.41304347826086957,
      "train_speed(iter/s)": 0.253395
    },
    {
      "epoch": 0.4108758511332898,
      "grad_norm": 9.286473274230957,
      "learning_rate": 9.971747308055503e-06,
      "loss": 0.6081666946411133,
      "memory(GiB)": 67.44,
      "step": 4405,
      "token_acc": 0.52,
      "train_speed(iter/s)": 0.253403
    },
    {
      "epoch": 0.41134222553866245,
      "grad_norm": 7.342601299285889,
      "learning_rate": 9.971583347319836e-06,
      "loss": 0.5505303382873535,
      "memory(GiB)": 67.44,
      "step": 4410,
      "token_acc": 0.5818181818181818,
      "train_speed(iter/s)": 0.253418
    },
    {
      "epoch": 0.41180859994403507,
      "grad_norm": 11.335927963256836,
      "learning_rate": 9.971418913553328e-06,
      "loss": 0.592724609375,
      "memory(GiB)": 67.44,
      "step": 4415,
      "token_acc": 0.42424242424242425,
      "train_speed(iter/s)": 0.253416
    },
    {
      "epoch": 0.4122749743494077,
      "grad_norm": 9.620758056640625,
      "learning_rate": 9.971254006771625e-06,
      "loss": 0.6128017902374268,
      "memory(GiB)": 67.44,
      "step": 4420,
      "train_speed(iter/s)": 0.25341
    },
    {
      "epoch": 0.41274134875478036,
      "grad_norm": 10.770821571350098,
      "learning_rate": 9.971088626990419e-06,
      "loss": 0.5813840866088867,
      "memory(GiB)": 67.44,
      "step": 4425,
      "train_speed(iter/s)": 0.253422
    },
    {
      "epoch": 0.413207723160153,
      "grad_norm": 5.122837066650391,
      "learning_rate": 9.970922774225442e-06,
      "loss": 0.5558654308319092,
      "memory(GiB)": 67.44,
      "step": 4430,
      "train_speed(iter/s)": 0.253439
    },
    {
      "epoch": 0.4136740975655256,
      "grad_norm": 10.816972732543945,
      "learning_rate": 9.970756448492478e-06,
      "loss": 0.5591731071472168,
      "memory(GiB)": 67.44,
      "step": 4435,
      "train_speed(iter/s)": 0.25345
    },
    {
      "epoch": 0.41414047197089826,
      "grad_norm": 12.783820152282715,
      "learning_rate": 9.97058964980735e-06,
      "loss": 0.5681772232055664,
      "memory(GiB)": 67.44,
      "step": 4440,
      "token_acc": 0.4714285714285714,
      "train_speed(iter/s)": 0.253448
    },
    {
      "epoch": 0.4146068463762709,
      "grad_norm": 7.980434894561768,
      "learning_rate": 9.970422378185929e-06,
      "loss": 0.5405702114105224,
      "memory(GiB)": 67.44,
      "step": 4445,
      "train_speed(iter/s)": 0.253469
    },
    {
      "epoch": 0.4150732207816435,
      "grad_norm": 7.999815940856934,
      "learning_rate": 9.970254633644132e-06,
      "loss": 0.5579821586608886,
      "memory(GiB)": 67.44,
      "step": 4450,
      "train_speed(iter/s)": 0.253474
    },
    {
      "epoch": 0.41553959518701616,
      "grad_norm": 5.240880012512207,
      "learning_rate": 9.970086416197916e-06,
      "loss": 0.5695523262023926,
      "memory(GiB)": 67.44,
      "step": 4455,
      "token_acc": 0.8695652173913043,
      "train_speed(iter/s)": 0.253496
    },
    {
      "epoch": 0.4160059695923888,
      "grad_norm": 50.30561065673828,
      "learning_rate": 9.969917725863289e-06,
      "loss": 0.526302433013916,
      "memory(GiB)": 67.44,
      "step": 4460,
      "token_acc": 0.43283582089552236,
      "train_speed(iter/s)": 0.253503
    },
    {
      "epoch": 0.4164723439977614,
      "grad_norm": 13.628739356994629,
      "learning_rate": 9.9697485626563e-06,
      "loss": 0.5970756530761718,
      "memory(GiB)": 67.44,
      "step": 4465,
      "token_acc": 0.4752475247524752,
      "train_speed(iter/s)": 0.253515
    },
    {
      "epoch": 0.416938718403134,
      "grad_norm": 15.901206970214844,
      "learning_rate": 9.969578926593046e-06,
      "loss": 0.6774136543273925,
      "memory(GiB)": 67.44,
      "step": 4470,
      "token_acc": 0.41904761904761906,
      "train_speed(iter/s)": 0.253509
    },
    {
      "epoch": 0.4174050928085067,
      "grad_norm": 11.56649112701416,
      "learning_rate": 9.969408817689666e-06,
      "loss": 0.5757270336151123,
      "memory(GiB)": 67.44,
      "step": 4475,
      "train_speed(iter/s)": 0.253513
    },
    {
      "epoch": 0.4178714672138793,
      "grad_norm": 9.63366413116455,
      "learning_rate": 9.969238235962344e-06,
      "loss": 0.5641087532043457,
      "memory(GiB)": 67.44,
      "step": 4480,
      "token_acc": 0.3592233009708738,
      "train_speed(iter/s)": 0.253519
    },
    {
      "epoch": 0.4183378416192519,
      "grad_norm": 3.168708562850952,
      "learning_rate": 9.969067181427314e-06,
      "loss": 0.5811294555664063,
      "memory(GiB)": 67.44,
      "step": 4485,
      "token_acc": 0.9431818181818182,
      "train_speed(iter/s)": 0.253532
    },
    {
      "epoch": 0.4188042160246246,
      "grad_norm": 11.05728816986084,
      "learning_rate": 9.968895654100848e-06,
      "loss": 0.575279712677002,
      "memory(GiB)": 67.44,
      "step": 4490,
      "token_acc": 0.568,
      "train_speed(iter/s)": 0.253537
    },
    {
      "epoch": 0.4192705904299972,
      "grad_norm": 8.230598449707031,
      "learning_rate": 9.968723653999268e-06,
      "loss": 0.5495105743408203,
      "memory(GiB)": 67.44,
      "step": 4495,
      "train_speed(iter/s)": 0.25353
    },
    {
      "epoch": 0.4197369648353698,
      "grad_norm": 6.6736578941345215,
      "learning_rate": 9.968551181138938e-06,
      "loss": 0.5531764984130859,
      "memory(GiB)": 67.44,
      "step": 4500,
      "token_acc": 0.8640776699029126,
      "train_speed(iter/s)": 0.253532
    },
    {
      "epoch": 0.4202033392407425,
      "grad_norm": 6.3568010330200195,
      "learning_rate": 9.968378235536272e-06,
      "loss": 0.6096683502197265,
      "memory(GiB)": 67.44,
      "step": 4505,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.253522
    },
    {
      "epoch": 0.4206697136461151,
      "grad_norm": 7.159750461578369,
      "learning_rate": 9.96820481720772e-06,
      "loss": 0.5892532348632813,
      "memory(GiB)": 67.44,
      "step": 4510,
      "train_speed(iter/s)": 0.253518
    },
    {
      "epoch": 0.4211360880514877,
      "grad_norm": 8.916625022888184,
      "learning_rate": 9.968030926169784e-06,
      "loss": 0.5700171947479248,
      "memory(GiB)": 67.44,
      "step": 4515,
      "train_speed(iter/s)": 0.253515
    },
    {
      "epoch": 0.4216024624568604,
      "grad_norm": 4.774589538574219,
      "learning_rate": 9.967856562439011e-06,
      "loss": 0.6046698570251465,
      "memory(GiB)": 67.44,
      "step": 4520,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.253298
    },
    {
      "epoch": 0.422068836862233,
      "grad_norm": 6.58476448059082,
      "learning_rate": 9.967681726031991e-06,
      "loss": 0.5544854164123535,
      "memory(GiB)": 67.44,
      "step": 4525,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.253285
    },
    {
      "epoch": 0.4225352112676056,
      "grad_norm": 10.429143905639648,
      "learning_rate": 9.967506416965355e-06,
      "loss": 0.559348201751709,
      "memory(GiB)": 67.44,
      "step": 4530,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.253286
    },
    {
      "epoch": 0.42300158567297824,
      "grad_norm": 8.628915786743164,
      "learning_rate": 9.96733063525579e-06,
      "loss": 0.5792441368103027,
      "memory(GiB)": 67.44,
      "step": 4535,
      "token_acc": 0.44776119402985076,
      "train_speed(iter/s)": 0.253277
    },
    {
      "epoch": 0.4234679600783509,
      "grad_norm": 6.342166900634766,
      "learning_rate": 9.967154380920014e-06,
      "loss": 0.5941008567810059,
      "memory(GiB)": 67.44,
      "step": 4540,
      "train_speed(iter/s)": 0.253273
    },
    {
      "epoch": 0.42393433448372353,
      "grad_norm": 7.006351947784424,
      "learning_rate": 9.966977653974803e-06,
      "loss": 0.6007437705993652,
      "memory(GiB)": 67.44,
      "step": 4545,
      "token_acc": 0.4418604651162791,
      "train_speed(iter/s)": 0.253265
    },
    {
      "epoch": 0.42440070888909615,
      "grad_norm": 11.3121337890625,
      "learning_rate": 9.966800454436967e-06,
      "loss": 0.6178171634674072,
      "memory(GiB)": 67.44,
      "step": 4550,
      "token_acc": 0.9191919191919192,
      "train_speed(iter/s)": 0.253252
    },
    {
      "epoch": 0.4248670832944688,
      "grad_norm": 5.867896556854248,
      "learning_rate": 9.96662278232337e-06,
      "loss": 0.543110704421997,
      "memory(GiB)": 67.44,
      "step": 4555,
      "token_acc": 0.6216216216216216,
      "train_speed(iter/s)": 0.253241
    },
    {
      "epoch": 0.42533345769984143,
      "grad_norm": 10.251006126403809,
      "learning_rate": 9.966444637650914e-06,
      "loss": 0.5747978210449218,
      "memory(GiB)": 67.44,
      "step": 4560,
      "train_speed(iter/s)": 0.25325
    },
    {
      "epoch": 0.42579983210521405,
      "grad_norm": 8.474689483642578,
      "learning_rate": 9.966266020436552e-06,
      "loss": 0.5979355812072754,
      "memory(GiB)": 67.44,
      "step": 4565,
      "token_acc": 0.5698924731182796,
      "train_speed(iter/s)": 0.253263
    },
    {
      "epoch": 0.4262662065105867,
      "grad_norm": 8.021738052368164,
      "learning_rate": 9.966086930697276e-06,
      "loss": 0.5127532482147217,
      "memory(GiB)": 67.44,
      "step": 4570,
      "train_speed(iter/s)": 0.253259
    },
    {
      "epoch": 0.42673258091595934,
      "grad_norm": 10.633275985717773,
      "learning_rate": 9.965907368450126e-06,
      "loss": 0.6071805953979492,
      "memory(GiB)": 67.44,
      "step": 4575,
      "token_acc": 0.3627450980392157,
      "train_speed(iter/s)": 0.253271
    },
    {
      "epoch": 0.42719895532133195,
      "grad_norm": 9.95261001586914,
      "learning_rate": 9.96572733371219e-06,
      "loss": 0.6619326591491699,
      "memory(GiB)": 67.44,
      "step": 4580,
      "token_acc": 0.37209302325581395,
      "train_speed(iter/s)": 0.253289
    },
    {
      "epoch": 0.4276653297267046,
      "grad_norm": 5.123415470123291,
      "learning_rate": 9.965546826500595e-06,
      "loss": 0.5799271106719971,
      "memory(GiB)": 67.44,
      "step": 4585,
      "train_speed(iter/s)": 0.253292
    },
    {
      "epoch": 0.42813170413207724,
      "grad_norm": 9.397086143493652,
      "learning_rate": 9.965365846832513e-06,
      "loss": 0.5320555686950683,
      "memory(GiB)": 67.44,
      "step": 4590,
      "token_acc": 0.50920245398773,
      "train_speed(iter/s)": 0.2533
    },
    {
      "epoch": 0.42859807853744986,
      "grad_norm": 6.588409423828125,
      "learning_rate": 9.96518439472517e-06,
      "loss": 0.5563755035400391,
      "memory(GiB)": 67.44,
      "step": 4595,
      "train_speed(iter/s)": 0.253313
    },
    {
      "epoch": 0.42906445294282247,
      "grad_norm": 7.470824241638184,
      "learning_rate": 9.965002470195827e-06,
      "loss": 0.5729725360870361,
      "memory(GiB)": 67.44,
      "step": 4600,
      "token_acc": 0.5083798882681564,
      "train_speed(iter/s)": 0.253323
    },
    {
      "epoch": 0.42953082734819514,
      "grad_norm": 11.361727714538574,
      "learning_rate": 9.964820073261793e-06,
      "loss": 0.5593723297119141,
      "memory(GiB)": 67.44,
      "step": 4605,
      "token_acc": 0.6382978723404256,
      "train_speed(iter/s)": 0.253334
    },
    {
      "epoch": 0.42999720175356776,
      "grad_norm": 6.701949596405029,
      "learning_rate": 9.964637203940427e-06,
      "loss": 0.5488274574279786,
      "memory(GiB)": 67.44,
      "step": 4610,
      "train_speed(iter/s)": 0.253326
    },
    {
      "epoch": 0.4304635761589404,
      "grad_norm": 13.089677810668945,
      "learning_rate": 9.96445386224912e-06,
      "loss": 0.5459611415863037,
      "memory(GiB)": 67.44,
      "step": 4615,
      "train_speed(iter/s)": 0.253324
    },
    {
      "epoch": 0.43092995056431305,
      "grad_norm": 11.254648208618164,
      "learning_rate": 9.964270048205324e-06,
      "loss": 0.5631253719329834,
      "memory(GiB)": 67.44,
      "step": 4620,
      "train_speed(iter/s)": 0.25334
    },
    {
      "epoch": 0.43139632496968566,
      "grad_norm": 5.434345245361328,
      "learning_rate": 9.964085761826526e-06,
      "loss": 0.5500496864318848,
      "memory(GiB)": 67.44,
      "step": 4625,
      "train_speed(iter/s)": 0.253353
    },
    {
      "epoch": 0.4318626993750583,
      "grad_norm": 8.928735733032227,
      "learning_rate": 9.963901003130258e-06,
      "loss": 0.5805663108825684,
      "memory(GiB)": 67.44,
      "step": 4630,
      "train_speed(iter/s)": 0.25335
    },
    {
      "epoch": 0.43232907378043095,
      "grad_norm": 12.492708206176758,
      "learning_rate": 9.963715772134103e-06,
      "loss": 0.5649262428283691,
      "memory(GiB)": 67.44,
      "step": 4635,
      "train_speed(iter/s)": 0.253357
    },
    {
      "epoch": 0.43279544818580357,
      "grad_norm": 10.905402183532715,
      "learning_rate": 9.963530068855685e-06,
      "loss": 0.5714571952819825,
      "memory(GiB)": 67.44,
      "step": 4640,
      "train_speed(iter/s)": 0.253368
    },
    {
      "epoch": 0.4332618225911762,
      "grad_norm": 8.669698715209961,
      "learning_rate": 9.963343893312669e-06,
      "loss": 0.48377056121826173,
      "memory(GiB)": 67.44,
      "step": 4645,
      "train_speed(iter/s)": 0.253369
    },
    {
      "epoch": 0.43372819699654885,
      "grad_norm": 6.926114559173584,
      "learning_rate": 9.963157245522771e-06,
      "loss": 0.5365228652954102,
      "memory(GiB)": 67.44,
      "step": 4650,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.253367
    },
    {
      "epoch": 0.43419457140192147,
      "grad_norm": 5.291569709777832,
      "learning_rate": 9.962970125503753e-06,
      "loss": 0.5789400100708008,
      "memory(GiB)": 67.44,
      "step": 4655,
      "token_acc": 0.883495145631068,
      "train_speed(iter/s)": 0.253376
    },
    {
      "epoch": 0.4346609458072941,
      "grad_norm": 8.82544994354248,
      "learning_rate": 9.962782533273414e-06,
      "loss": 0.5539756298065186,
      "memory(GiB)": 67.44,
      "step": 4660,
      "token_acc": 0.5925925925925926,
      "train_speed(iter/s)": 0.253371
    },
    {
      "epoch": 0.4351273202126667,
      "grad_norm": 7.6149797439575195,
      "learning_rate": 9.962594468849606e-06,
      "loss": 0.5692458152770996,
      "memory(GiB)": 67.44,
      "step": 4665,
      "token_acc": 0.9142857142857143,
      "train_speed(iter/s)": 0.253388
    },
    {
      "epoch": 0.4355936946180394,
      "grad_norm": 9.571650505065918,
      "learning_rate": 9.962405932250223e-06,
      "loss": 0.5654802322387695,
      "memory(GiB)": 67.44,
      "step": 4670,
      "train_speed(iter/s)": 0.253387
    },
    {
      "epoch": 0.436060069023412,
      "grad_norm": 11.490055084228516,
      "learning_rate": 9.962216923493202e-06,
      "loss": 0.6006255149841309,
      "memory(GiB)": 67.44,
      "step": 4675,
      "train_speed(iter/s)": 0.25339
    },
    {
      "epoch": 0.4365264434287846,
      "grad_norm": 5.622356414794922,
      "learning_rate": 9.962027442596527e-06,
      "loss": 0.5975757598876953,
      "memory(GiB)": 67.44,
      "step": 4680,
      "train_speed(iter/s)": 0.253389
    },
    {
      "epoch": 0.4369928178341573,
      "grad_norm": 9.202714920043945,
      "learning_rate": 9.961837489578226e-06,
      "loss": 0.5703788757324219,
      "memory(GiB)": 67.44,
      "step": 4685,
      "token_acc": 0.36923076923076925,
      "train_speed(iter/s)": 0.253378
    },
    {
      "epoch": 0.4374591922395299,
      "grad_norm": 9.446940422058105,
      "learning_rate": 9.961647064456373e-06,
      "loss": 0.5684584617614746,
      "memory(GiB)": 67.44,
      "step": 4690,
      "token_acc": 0.6206896551724138,
      "train_speed(iter/s)": 0.253388
    },
    {
      "epoch": 0.4379255666449025,
      "grad_norm": 8.658340454101562,
      "learning_rate": 9.961456167249089e-06,
      "loss": 0.56136474609375,
      "memory(GiB)": 67.44,
      "step": 4695,
      "token_acc": 0.4435483870967742,
      "train_speed(iter/s)": 0.253385
    },
    {
      "epoch": 0.4383919410502752,
      "grad_norm": 7.932689189910889,
      "learning_rate": 9.961264797974532e-06,
      "loss": 0.6084582328796386,
      "memory(GiB)": 67.44,
      "step": 4700,
      "token_acc": 0.5942028985507246,
      "train_speed(iter/s)": 0.253401
    },
    {
      "epoch": 0.4388583154556478,
      "grad_norm": 7.806217670440674,
      "learning_rate": 9.961072956650915e-06,
      "loss": 0.5760812759399414,
      "memory(GiB)": 67.44,
      "step": 4705,
      "train_speed(iter/s)": 0.253406
    },
    {
      "epoch": 0.4393246898610204,
      "grad_norm": 7.486582279205322,
      "learning_rate": 9.960880643296487e-06,
      "loss": 0.5488129615783691,
      "memory(GiB)": 67.44,
      "step": 4710,
      "token_acc": 0.8552631578947368,
      "train_speed(iter/s)": 0.253398
    },
    {
      "epoch": 0.4397910642663931,
      "grad_norm": 9.50025463104248,
      "learning_rate": 9.960687857929549e-06,
      "loss": 0.5530890464782715,
      "memory(GiB)": 67.44,
      "step": 4715,
      "train_speed(iter/s)": 0.253404
    },
    {
      "epoch": 0.4402574386717657,
      "grad_norm": 7.679833889007568,
      "learning_rate": 9.960494600568444e-06,
      "loss": 0.540951156616211,
      "memory(GiB)": 67.44,
      "step": 4720,
      "train_speed(iter/s)": 0.253405
    },
    {
      "epoch": 0.4407238130771383,
      "grad_norm": 7.680553436279297,
      "learning_rate": 9.960300871231559e-06,
      "loss": 0.5514832496643066,
      "memory(GiB)": 67.44,
      "step": 4725,
      "token_acc": 0.7189542483660131,
      "train_speed(iter/s)": 0.253418
    },
    {
      "epoch": 0.441190187482511,
      "grad_norm": 7.513479232788086,
      "learning_rate": 9.960106669937326e-06,
      "loss": 0.5352892398834228,
      "memory(GiB)": 67.44,
      "step": 4730,
      "train_speed(iter/s)": 0.253433
    },
    {
      "epoch": 0.4416565618878836,
      "grad_norm": 9.066604614257812,
      "learning_rate": 9.959911996704224e-06,
      "loss": 0.5595788955688477,
      "memory(GiB)": 67.44,
      "step": 4735,
      "token_acc": 0.3877551020408163,
      "train_speed(iter/s)": 0.253446
    },
    {
      "epoch": 0.4421229362932562,
      "grad_norm": 7.179762363433838,
      "learning_rate": 9.959716851550775e-06,
      "loss": 0.586042833328247,
      "memory(GiB)": 67.44,
      "step": 4740,
      "token_acc": 0.3409090909090909,
      "train_speed(iter/s)": 0.253442
    },
    {
      "epoch": 0.44258931069862884,
      "grad_norm": 8.233550071716309,
      "learning_rate": 9.959521234495546e-06,
      "loss": 0.5028904914855957,
      "memory(GiB)": 67.44,
      "step": 4745,
      "token_acc": 0.6792452830188679,
      "train_speed(iter/s)": 0.253441
    },
    {
      "epoch": 0.4430556851040015,
      "grad_norm": 5.776814937591553,
      "learning_rate": 9.959325145557148e-06,
      "loss": 0.5567716598510742,
      "memory(GiB)": 67.44,
      "step": 4750,
      "token_acc": 0.46938775510204084,
      "train_speed(iter/s)": 0.253465
    },
    {
      "epoch": 0.4435220595093741,
      "grad_norm": 9.778119087219238,
      "learning_rate": 9.959128584754243e-06,
      "loss": 0.5810986995697022,
      "memory(GiB)": 67.44,
      "step": 4755,
      "train_speed(iter/s)": 0.253471
    },
    {
      "epoch": 0.44398843391474674,
      "grad_norm": 4.767136096954346,
      "learning_rate": 9.958931552105528e-06,
      "loss": 0.5725811004638672,
      "memory(GiB)": 67.44,
      "step": 4760,
      "train_speed(iter/s)": 0.25347
    },
    {
      "epoch": 0.4444548083201194,
      "grad_norm": 6.348512172698975,
      "learning_rate": 9.958734047629752e-06,
      "loss": 0.5724488258361816,
      "memory(GiB)": 67.44,
      "step": 4765,
      "token_acc": 0.5876288659793815,
      "train_speed(iter/s)": 0.253466
    },
    {
      "epoch": 0.444921182725492,
      "grad_norm": 12.379652976989746,
      "learning_rate": 9.958536071345709e-06,
      "loss": 0.5912615776062011,
      "memory(GiB)": 67.44,
      "step": 4770,
      "token_acc": 0.4878048780487805,
      "train_speed(iter/s)": 0.253453
    },
    {
      "epoch": 0.44538755713086464,
      "grad_norm": 14.964749336242676,
      "learning_rate": 9.958337623272234e-06,
      "loss": 0.554774284362793,
      "memory(GiB)": 67.44,
      "step": 4775,
      "train_speed(iter/s)": 0.25346
    },
    {
      "epoch": 0.4458539315362373,
      "grad_norm": 14.471942901611328,
      "learning_rate": 9.958138703428206e-06,
      "loss": 0.5319795131683349,
      "memory(GiB)": 67.44,
      "step": 4780,
      "token_acc": 0.7938144329896907,
      "train_speed(iter/s)": 0.253462
    },
    {
      "epoch": 0.44632030594160993,
      "grad_norm": 11.007952690124512,
      "learning_rate": 9.957939311832555e-06,
      "loss": 0.5578043460845947,
      "memory(GiB)": 67.44,
      "step": 4785,
      "train_speed(iter/s)": 0.253474
    },
    {
      "epoch": 0.44678668034698255,
      "grad_norm": 10.726179122924805,
      "learning_rate": 9.957739448504253e-06,
      "loss": 0.5719199180603027,
      "memory(GiB)": 67.44,
      "step": 4790,
      "train_speed(iter/s)": 0.253472
    },
    {
      "epoch": 0.4472530547523552,
      "grad_norm": 7.498542308807373,
      "learning_rate": 9.957539113462316e-06,
      "loss": 0.5493971347808838,
      "memory(GiB)": 67.44,
      "step": 4795,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.253468
    },
    {
      "epoch": 0.44771942915772783,
      "grad_norm": 10.715123176574707,
      "learning_rate": 9.957338306725803e-06,
      "loss": 0.5223956108093262,
      "memory(GiB)": 67.44,
      "step": 4800,
      "train_speed(iter/s)": 0.253472
    },
    {
      "epoch": 0.44818580356310045,
      "grad_norm": 9.373615264892578,
      "learning_rate": 9.95713702831382e-06,
      "loss": 0.5280664443969727,
      "memory(GiB)": 67.44,
      "step": 4805,
      "train_speed(iter/s)": 0.253465
    },
    {
      "epoch": 0.44865217796847306,
      "grad_norm": 5.383333206176758,
      "learning_rate": 9.956935278245522e-06,
      "loss": 0.526832103729248,
      "memory(GiB)": 67.44,
      "step": 4810,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.44911855237384574,
      "grad_norm": 8.58373737335205,
      "learning_rate": 9.956733056540102e-06,
      "loss": 0.5481707572937011,
      "memory(GiB)": 67.44,
      "step": 4815,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.25348
    },
    {
      "epoch": 0.44958492677921835,
      "grad_norm": 6.886306285858154,
      "learning_rate": 9.956530363216804e-06,
      "loss": 0.5434056758880615,
      "memory(GiB)": 67.44,
      "step": 4820,
      "train_speed(iter/s)": 0.253492
    },
    {
      "epoch": 0.45005130118459097,
      "grad_norm": 7.438082218170166,
      "learning_rate": 9.956327198294906e-06,
      "loss": 0.5700231075286866,
      "memory(GiB)": 67.44,
      "step": 4825,
      "token_acc": 0.49056603773584906,
      "train_speed(iter/s)": 0.253505
    },
    {
      "epoch": 0.45051767558996364,
      "grad_norm": 4.801167964935303,
      "learning_rate": 9.956123561793747e-06,
      "loss": 0.5851881027221679,
      "memory(GiB)": 67.44,
      "step": 4830,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.25352
    },
    {
      "epoch": 0.45098404999533626,
      "grad_norm": 5.765872001647949,
      "learning_rate": 9.955919453732696e-06,
      "loss": 0.5220892429351807,
      "memory(GiB)": 67.44,
      "step": 4835,
      "train_speed(iter/s)": 0.253541
    },
    {
      "epoch": 0.45145042440070887,
      "grad_norm": 6.680317401885986,
      "learning_rate": 9.955714874131178e-06,
      "loss": 0.5536128520965576,
      "memory(GiB)": 67.44,
      "step": 4840,
      "train_speed(iter/s)": 0.253537
    },
    {
      "epoch": 0.45191679880608154,
      "grad_norm": 6.90887975692749,
      "learning_rate": 9.955509823008656e-06,
      "loss": 0.5588748931884766,
      "memory(GiB)": 67.44,
      "step": 4845,
      "train_speed(iter/s)": 0.253538
    },
    {
      "epoch": 0.45238317321145416,
      "grad_norm": 6.216128349304199,
      "learning_rate": 9.95530430038464e-06,
      "loss": 0.5583728790283203,
      "memory(GiB)": 67.44,
      "step": 4850,
      "train_speed(iter/s)": 0.253534
    },
    {
      "epoch": 0.4528495476168268,
      "grad_norm": 11.0901460647583,
      "learning_rate": 9.955098306278684e-06,
      "loss": 0.6173978328704834,
      "memory(GiB)": 67.44,
      "step": 4855,
      "train_speed(iter/s)": 0.253545
    },
    {
      "epoch": 0.45331592202219945,
      "grad_norm": 5.9356231689453125,
      "learning_rate": 9.95489184071039e-06,
      "loss": 0.5467716217041015,
      "memory(GiB)": 67.44,
      "step": 4860,
      "train_speed(iter/s)": 0.253552
    },
    {
      "epoch": 0.45378229642757206,
      "grad_norm": 8.0690279006958,
      "learning_rate": 9.954684903699402e-06,
      "loss": 0.4884920597076416,
      "memory(GiB)": 67.44,
      "step": 4865,
      "token_acc": 0.8737864077669902,
      "train_speed(iter/s)": 0.253572
    },
    {
      "epoch": 0.4542486708329447,
      "grad_norm": 8.070904731750488,
      "learning_rate": 9.954477495265407e-06,
      "loss": 0.49651203155517576,
      "memory(GiB)": 67.44,
      "step": 4870,
      "train_speed(iter/s)": 0.253575
    },
    {
      "epoch": 0.4547150452383173,
      "grad_norm": 6.288454055786133,
      "learning_rate": 9.95426961542814e-06,
      "loss": 0.5619894981384277,
      "memory(GiB)": 67.44,
      "step": 4875,
      "train_speed(iter/s)": 0.253577
    },
    {
      "epoch": 0.45518141964368997,
      "grad_norm": 4.308431148529053,
      "learning_rate": 9.954061264207383e-06,
      "loss": 0.5676884174346923,
      "memory(GiB)": 67.44,
      "step": 4880,
      "train_speed(iter/s)": 0.253579
    },
    {
      "epoch": 0.4556477940490626,
      "grad_norm": 10.457878112792969,
      "learning_rate": 9.953852441622958e-06,
      "loss": 0.5195049285888672,
      "memory(GiB)": 67.44,
      "step": 4885,
      "token_acc": 0.4968553459119497,
      "train_speed(iter/s)": 0.253577
    },
    {
      "epoch": 0.4561141684544352,
      "grad_norm": 6.414034366607666,
      "learning_rate": 9.953643147694735e-06,
      "loss": 0.5932436943054199,
      "memory(GiB)": 67.44,
      "step": 4890,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253594
    },
    {
      "epoch": 0.45658054285980787,
      "grad_norm": 6.752201080322266,
      "learning_rate": 9.953433382442623e-06,
      "loss": 0.5352936744689941,
      "memory(GiB)": 67.44,
      "step": 4895,
      "train_speed(iter/s)": 0.253601
    },
    {
      "epoch": 0.4570469172651805,
      "grad_norm": 7.057641983032227,
      "learning_rate": 9.953223145886586e-06,
      "loss": 0.5275216102600098,
      "memory(GiB)": 67.44,
      "step": 4900,
      "train_speed(iter/s)": 0.253609
    },
    {
      "epoch": 0.4575132916705531,
      "grad_norm": 4.292744159698486,
      "learning_rate": 9.953012438046625e-06,
      "loss": 0.5580636978149414,
      "memory(GiB)": 67.44,
      "step": 4905,
      "train_speed(iter/s)": 0.253598
    },
    {
      "epoch": 0.4579796660759258,
      "grad_norm": 13.049981117248535,
      "learning_rate": 9.95280125894279e-06,
      "loss": 0.575873327255249,
      "memory(GiB)": 67.44,
      "step": 4910,
      "token_acc": 0.4090909090909091,
      "train_speed(iter/s)": 0.25361
    },
    {
      "epoch": 0.4584460404812984,
      "grad_norm": 11.170884132385254,
      "learning_rate": 9.952589608595172e-06,
      "loss": 0.5621832370758056,
      "memory(GiB)": 67.44,
      "step": 4915,
      "train_speed(iter/s)": 0.253614
    },
    {
      "epoch": 0.458912414886671,
      "grad_norm": 13.708497047424316,
      "learning_rate": 9.95237748702391e-06,
      "loss": 0.586527156829834,
      "memory(GiB)": 67.44,
      "step": 4920,
      "train_speed(iter/s)": 0.25361
    },
    {
      "epoch": 0.4593787892920437,
      "grad_norm": 8.793079376220703,
      "learning_rate": 9.952164894249185e-06,
      "loss": 0.631618595123291,
      "memory(GiB)": 67.44,
      "step": 4925,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.253608
    },
    {
      "epoch": 0.4598451636974163,
      "grad_norm": 9.621599197387695,
      "learning_rate": 9.951951830291226e-06,
      "loss": 0.5469695091247558,
      "memory(GiB)": 67.44,
      "step": 4930,
      "token_acc": 0.8083832335329342,
      "train_speed(iter/s)": 0.253601
    },
    {
      "epoch": 0.4603115381027889,
      "grad_norm": 10.596879005432129,
      "learning_rate": 9.951738295170308e-06,
      "loss": 0.5876070022583008,
      "memory(GiB)": 67.44,
      "step": 4935,
      "train_speed(iter/s)": 0.253596
    },
    {
      "epoch": 0.4607779125081615,
      "grad_norm": 4.952895641326904,
      "learning_rate": 9.951524288906742e-06,
      "loss": 0.5194025039672852,
      "memory(GiB)": 67.44,
      "step": 4940,
      "train_speed(iter/s)": 0.253589
    },
    {
      "epoch": 0.4612442869135342,
      "grad_norm": 6.834590911865234,
      "learning_rate": 9.951309811520895e-06,
      "loss": 0.5403362274169922,
      "memory(GiB)": 67.44,
      "step": 4945,
      "train_speed(iter/s)": 0.253608
    },
    {
      "epoch": 0.4617106613189068,
      "grad_norm": 7.303616523742676,
      "learning_rate": 9.951094863033173e-06,
      "loss": 0.6172048568725585,
      "memory(GiB)": 67.44,
      "step": 4950,
      "train_speed(iter/s)": 0.253607
    },
    {
      "epoch": 0.46217703572427943,
      "grad_norm": 15.50696086883545,
      "learning_rate": 9.950879443464026e-06,
      "loss": 0.5815799713134766,
      "memory(GiB)": 67.44,
      "step": 4955,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.253609
    },
    {
      "epoch": 0.4626434101296521,
      "grad_norm": 17.199275970458984,
      "learning_rate": 9.95066355283395e-06,
      "loss": 0.5822288513183593,
      "memory(GiB)": 67.44,
      "step": 4960,
      "train_speed(iter/s)": 0.253614
    },
    {
      "epoch": 0.4631097845350247,
      "grad_norm": 13.747204780578613,
      "learning_rate": 9.95044719116349e-06,
      "loss": 0.6224781036376953,
      "memory(GiB)": 67.44,
      "step": 4965,
      "train_speed(iter/s)": 0.253637
    },
    {
      "epoch": 0.46357615894039733,
      "grad_norm": 6.187570095062256,
      "learning_rate": 9.950230358473229e-06,
      "loss": 0.5504858016967773,
      "memory(GiB)": 67.44,
      "step": 4970,
      "train_speed(iter/s)": 0.253642
    },
    {
      "epoch": 0.46404253334577,
      "grad_norm": 6.906955242156982,
      "learning_rate": 9.9500130547838e-06,
      "loss": 0.5207778930664062,
      "memory(GiB)": 67.44,
      "step": 4975,
      "train_speed(iter/s)": 0.253648
    },
    {
      "epoch": 0.4645089077511426,
      "grad_norm": 9.694537162780762,
      "learning_rate": 9.949795280115876e-06,
      "loss": 0.5547443866729737,
      "memory(GiB)": 67.44,
      "step": 4980,
      "token_acc": 0.4945054945054945,
      "train_speed(iter/s)": 0.253669
    },
    {
      "epoch": 0.46497528215651523,
      "grad_norm": 5.854322910308838,
      "learning_rate": 9.949577034490181e-06,
      "loss": 0.5514239311218262,
      "memory(GiB)": 67.44,
      "step": 4985,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253676
    },
    {
      "epoch": 0.4654416565618879,
      "grad_norm": 9.846309661865234,
      "learning_rate": 9.94935831792748e-06,
      "loss": 0.5051540851593017,
      "memory(GiB)": 67.44,
      "step": 4990,
      "train_speed(iter/s)": 0.253676
    },
    {
      "epoch": 0.4659080309672605,
      "grad_norm": 6.6976847648620605,
      "learning_rate": 9.949139130448579e-06,
      "loss": 0.5260241508483887,
      "memory(GiB)": 67.44,
      "step": 4995,
      "train_speed(iter/s)": 0.253681
    },
    {
      "epoch": 0.46637440537263314,
      "grad_norm": 7.275278091430664,
      "learning_rate": 9.948919472074336e-06,
      "loss": 0.5445187568664551,
      "memory(GiB)": 67.44,
      "step": 5000,
      "train_speed(iter/s)": 0.253687
    },
    {
      "epoch": 0.4668407797780058,
      "grad_norm": 9.327771186828613,
      "learning_rate": 9.948699342825651e-06,
      "loss": 0.5675114631652832,
      "memory(GiB)": 67.44,
      "step": 5005,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.253671
    },
    {
      "epoch": 0.4673071541833784,
      "grad_norm": 6.582474231719971,
      "learning_rate": 9.94847874272347e-06,
      "loss": 0.5408143997192383,
      "memory(GiB)": 67.44,
      "step": 5010,
      "train_speed(iter/s)": 0.253654
    },
    {
      "epoch": 0.46777352858875104,
      "grad_norm": 8.187195777893066,
      "learning_rate": 9.948257671788781e-06,
      "loss": 0.5615520000457763,
      "memory(GiB)": 67.44,
      "step": 5015,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253664
    },
    {
      "epoch": 0.46823990299412366,
      "grad_norm": 7.518077850341797,
      "learning_rate": 9.948036130042616e-06,
      "loss": 0.5688070297241211,
      "memory(GiB)": 67.44,
      "step": 5020,
      "train_speed(iter/s)": 0.253667
    },
    {
      "epoch": 0.46870627739949633,
      "grad_norm": 7.280913829803467,
      "learning_rate": 9.947814117506058e-06,
      "loss": 0.5594696521759033,
      "memory(GiB)": 67.44,
      "step": 5025,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253659
    },
    {
      "epoch": 0.46917265180486895,
      "grad_norm": 4.505434513092041,
      "learning_rate": 9.947591634200227e-06,
      "loss": 0.5068802833557129,
      "memory(GiB)": 67.44,
      "step": 5030,
      "train_speed(iter/s)": 0.253662
    },
    {
      "epoch": 0.46963902621024156,
      "grad_norm": 7.3138628005981445,
      "learning_rate": 9.947368680146294e-06,
      "loss": 0.576550817489624,
      "memory(GiB)": 67.44,
      "step": 5035,
      "train_speed(iter/s)": 0.25366
    },
    {
      "epoch": 0.47010540061561423,
      "grad_norm": 10.843402862548828,
      "learning_rate": 9.947145255365473e-06,
      "loss": 0.5559818744659424,
      "memory(GiB)": 67.44,
      "step": 5040,
      "token_acc": 0.8817204301075269,
      "train_speed(iter/s)": 0.253679
    },
    {
      "epoch": 0.47057177502098685,
      "grad_norm": 9.662784576416016,
      "learning_rate": 9.94692135987902e-06,
      "loss": 0.5431357860565186,
      "memory(GiB)": 67.44,
      "step": 5045,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.25368
    },
    {
      "epoch": 0.47103814942635946,
      "grad_norm": 6.651328086853027,
      "learning_rate": 9.946696993708239e-06,
      "loss": 0.5718425750732422,
      "memory(GiB)": 67.44,
      "step": 5050,
      "train_speed(iter/s)": 0.253424
    },
    {
      "epoch": 0.47150452383173214,
      "grad_norm": 8.241462707519531,
      "learning_rate": 9.946472156874478e-06,
      "loss": 0.5929553031921386,
      "memory(GiB)": 67.44,
      "step": 5055,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.253416
    },
    {
      "epoch": 0.47197089823710475,
      "grad_norm": 7.6089558601379395,
      "learning_rate": 9.946246849399128e-06,
      "loss": 0.5545712471008301,
      "memory(GiB)": 67.44,
      "step": 5060,
      "train_speed(iter/s)": 0.253372
    },
    {
      "epoch": 0.47243727264247737,
      "grad_norm": 6.894871711730957,
      "learning_rate": 9.946021071303628e-06,
      "loss": 0.5624217987060547,
      "memory(GiB)": 67.44,
      "step": 5065,
      "train_speed(iter/s)": 0.253366
    },
    {
      "epoch": 0.47290364704785004,
      "grad_norm": 6.4346771240234375,
      "learning_rate": 9.945794822609461e-06,
      "loss": 0.5617586135864258,
      "memory(GiB)": 67.44,
      "step": 5070,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.253358
    },
    {
      "epoch": 0.47337002145322266,
      "grad_norm": 7.2387213706970215,
      "learning_rate": 9.945568103338153e-06,
      "loss": 0.517455005645752,
      "memory(GiB)": 67.44,
      "step": 5075,
      "token_acc": 0.425531914893617,
      "train_speed(iter/s)": 0.253324
    },
    {
      "epoch": 0.47383639585859527,
      "grad_norm": 12.805832862854004,
      "learning_rate": 9.945340913511273e-06,
      "loss": 0.5534523010253907,
      "memory(GiB)": 67.44,
      "step": 5080,
      "train_speed(iter/s)": 0.253275
    },
    {
      "epoch": 0.4743027702639679,
      "grad_norm": 6.256122589111328,
      "learning_rate": 9.94511325315044e-06,
      "loss": 0.5486013412475585,
      "memory(GiB)": 67.44,
      "step": 5085,
      "train_speed(iter/s)": 0.253276
    },
    {
      "epoch": 0.47476914466934056,
      "grad_norm": 6.284685134887695,
      "learning_rate": 9.944885122277316e-06,
      "loss": 0.5177781581878662,
      "memory(GiB)": 67.44,
      "step": 5090,
      "token_acc": 0.3333333333333333,
      "train_speed(iter/s)": 0.253272
    },
    {
      "epoch": 0.4752355190747132,
      "grad_norm": 4.801791191101074,
      "learning_rate": 9.944656520913605e-06,
      "loss": 0.5114276885986329,
      "memory(GiB)": 67.44,
      "step": 5095,
      "token_acc": 0.956989247311828,
      "train_speed(iter/s)": 0.253269
    },
    {
      "epoch": 0.4757018934800858,
      "grad_norm": 7.252965927124023,
      "learning_rate": 9.944427449081058e-06,
      "loss": 0.5373547077178955,
      "memory(GiB)": 67.44,
      "step": 5100,
      "train_speed(iter/s)": 0.253263
    },
    {
      "epoch": 0.47616826788545846,
      "grad_norm": 9.211435317993164,
      "learning_rate": 9.944197906801471e-06,
      "loss": 0.557563591003418,
      "memory(GiB)": 67.44,
      "step": 5105,
      "train_speed(iter/s)": 0.253276
    },
    {
      "epoch": 0.4766346422908311,
      "grad_norm": 9.048652648925781,
      "learning_rate": 9.943967894096686e-06,
      "loss": 0.5248189926147461,
      "memory(GiB)": 67.44,
      "step": 5110,
      "token_acc": 0.36538461538461536,
      "train_speed(iter/s)": 0.253267
    },
    {
      "epoch": 0.4771010166962037,
      "grad_norm": 7.894883632659912,
      "learning_rate": 9.943737410988582e-06,
      "loss": 0.5425891399383544,
      "memory(GiB)": 67.44,
      "step": 5115,
      "token_acc": 0.423728813559322,
      "train_speed(iter/s)": 0.253262
    },
    {
      "epoch": 0.47756739110157637,
      "grad_norm": 11.073223114013672,
      "learning_rate": 9.943506457499097e-06,
      "loss": 0.5526417255401611,
      "memory(GiB)": 67.44,
      "step": 5120,
      "train_speed(iter/s)": 0.253244
    },
    {
      "epoch": 0.478033765506949,
      "grad_norm": 11.659854888916016,
      "learning_rate": 9.9432750336502e-06,
      "loss": 0.5964658737182618,
      "memory(GiB)": 67.44,
      "step": 5125,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.253257
    },
    {
      "epoch": 0.4785001399123216,
      "grad_norm": 8.287492752075195,
      "learning_rate": 9.943043139463913e-06,
      "loss": 0.5764967918395996,
      "memory(GiB)": 67.44,
      "step": 5130,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.253252
    },
    {
      "epoch": 0.47896651431769427,
      "grad_norm": 6.689345359802246,
      "learning_rate": 9.942810774962297e-06,
      "loss": 0.5553813934326172,
      "memory(GiB)": 67.44,
      "step": 5135,
      "train_speed(iter/s)": 0.253248
    },
    {
      "epoch": 0.4794328887230669,
      "grad_norm": 4.1098551750183105,
      "learning_rate": 9.942577940167461e-06,
      "loss": 0.5279988765716552,
      "memory(GiB)": 67.44,
      "step": 5140,
      "token_acc": 0.37777777777777777,
      "train_speed(iter/s)": 0.253247
    },
    {
      "epoch": 0.4798992631284395,
      "grad_norm": 5.168011665344238,
      "learning_rate": 9.942344635101563e-06,
      "loss": 0.5350732803344727,
      "memory(GiB)": 67.44,
      "step": 5145,
      "token_acc": 0.41509433962264153,
      "train_speed(iter/s)": 0.253245
    },
    {
      "epoch": 0.4803656375338121,
      "grad_norm": 6.3663787841796875,
      "learning_rate": 9.942110859786798e-06,
      "loss": 0.5558594703674317,
      "memory(GiB)": 67.44,
      "step": 5150,
      "train_speed(iter/s)": 0.253248
    },
    {
      "epoch": 0.4808320119391848,
      "grad_norm": 4.525081634521484,
      "learning_rate": 9.941876614245406e-06,
      "loss": 0.5498445510864258,
      "memory(GiB)": 67.44,
      "step": 5155,
      "token_acc": 0.43636363636363634,
      "train_speed(iter/s)": 0.253267
    },
    {
      "epoch": 0.4812983863445574,
      "grad_norm": 10.752695083618164,
      "learning_rate": 9.94164189849968e-06,
      "loss": 0.531552505493164,
      "memory(GiB)": 67.44,
      "step": 5160,
      "train_speed(iter/s)": 0.253269
    },
    {
      "epoch": 0.48176476074993,
      "grad_norm": 33.31549835205078,
      "learning_rate": 9.941406712571953e-06,
      "loss": 0.533097791671753,
      "memory(GiB)": 67.44,
      "step": 5165,
      "train_speed(iter/s)": 0.253281
    },
    {
      "epoch": 0.4822311351553027,
      "grad_norm": 8.329023361206055,
      "learning_rate": 9.941171056484597e-06,
      "loss": 0.5920221328735351,
      "memory(GiB)": 67.44,
      "step": 5170,
      "train_speed(iter/s)": 0.253266
    },
    {
      "epoch": 0.4826975095606753,
      "grad_norm": 7.940021514892578,
      "learning_rate": 9.940934930260036e-06,
      "loss": 0.5255874633789063,
      "memory(GiB)": 67.44,
      "step": 5175,
      "train_speed(iter/s)": 0.25327
    },
    {
      "epoch": 0.4831638839660479,
      "grad_norm": 5.666842937469482,
      "learning_rate": 9.94069833392074e-06,
      "loss": 0.6063762664794922,
      "memory(GiB)": 67.44,
      "step": 5180,
      "train_speed(iter/s)": 0.253268
    },
    {
      "epoch": 0.4836302583714206,
      "grad_norm": 8.489006042480469,
      "learning_rate": 9.940461267489214e-06,
      "loss": 0.531524658203125,
      "memory(GiB)": 67.44,
      "step": 5185,
      "train_speed(iter/s)": 0.253261
    },
    {
      "epoch": 0.4840966327767932,
      "grad_norm": 5.685215950012207,
      "learning_rate": 9.94022373098802e-06,
      "loss": 0.5704621791839599,
      "memory(GiB)": 67.44,
      "step": 5190,
      "token_acc": 0.5283018867924528,
      "train_speed(iter/s)": 0.253247
    },
    {
      "epoch": 0.48456300718216583,
      "grad_norm": 6.816339492797852,
      "learning_rate": 9.939985724439758e-06,
      "loss": 0.5412860870361328,
      "memory(GiB)": 67.44,
      "step": 5195,
      "train_speed(iter/s)": 0.253264
    },
    {
      "epoch": 0.4850293815875385,
      "grad_norm": 5.347014427185059,
      "learning_rate": 9.939747247867071e-06,
      "loss": 0.5239099979400634,
      "memory(GiB)": 67.44,
      "step": 5200,
      "train_speed(iter/s)": 0.253275
    },
    {
      "epoch": 0.4854957559929111,
      "grad_norm": 7.303589344024658,
      "learning_rate": 9.93950830129265e-06,
      "loss": 0.5181153297424317,
      "memory(GiB)": 67.44,
      "step": 5205,
      "train_speed(iter/s)": 0.253287
    },
    {
      "epoch": 0.48596213039828373,
      "grad_norm": 7.672534465789795,
      "learning_rate": 9.939268884739231e-06,
      "loss": 0.5658546447753906,
      "memory(GiB)": 67.44,
      "step": 5210,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.25329
    },
    {
      "epoch": 0.4864285048036564,
      "grad_norm": 8.469684600830078,
      "learning_rate": 9.939028998229595e-06,
      "loss": 0.5200257301330566,
      "memory(GiB)": 67.44,
      "step": 5215,
      "train_speed(iter/s)": 0.253307
    },
    {
      "epoch": 0.486894879209029,
      "grad_norm": 8.067046165466309,
      "learning_rate": 9.938788641786563e-06,
      "loss": 0.5284822940826416,
      "memory(GiB)": 67.44,
      "step": 5220,
      "token_acc": 0.5142857142857142,
      "train_speed(iter/s)": 0.253329
    },
    {
      "epoch": 0.48736125361440163,
      "grad_norm": 3.5246152877807617,
      "learning_rate": 9.938547815433006e-06,
      "loss": 0.5454398632049561,
      "memory(GiB)": 67.44,
      "step": 5225,
      "token_acc": 0.6229508196721312,
      "train_speed(iter/s)": 0.253321
    },
    {
      "epoch": 0.48782762801977425,
      "grad_norm": 4.122017860412598,
      "learning_rate": 9.938306519191838e-06,
      "loss": 0.5323067665100097,
      "memory(GiB)": 67.44,
      "step": 5230,
      "train_speed(iter/s)": 0.253314
    },
    {
      "epoch": 0.4882940024251469,
      "grad_norm": 9.119024276733398,
      "learning_rate": 9.938064753086018e-06,
      "loss": 0.5300502777099609,
      "memory(GiB)": 67.44,
      "step": 5235,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253311
    },
    {
      "epoch": 0.48876037683051954,
      "grad_norm": 5.183811187744141,
      "learning_rate": 9.93782251713855e-06,
      "loss": 0.5344240188598632,
      "memory(GiB)": 67.44,
      "step": 5240,
      "train_speed(iter/s)": 0.253328
    },
    {
      "epoch": 0.48922675123589215,
      "grad_norm": 4.405287742614746,
      "learning_rate": 9.93757981137248e-06,
      "loss": 0.5315706253051757,
      "memory(GiB)": 67.44,
      "step": 5245,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.253316
    },
    {
      "epoch": 0.4896931256412648,
      "grad_norm": 6.451190948486328,
      "learning_rate": 9.937336635810902e-06,
      "loss": 0.552918529510498,
      "memory(GiB)": 67.44,
      "step": 5250,
      "token_acc": 0.6170212765957447,
      "train_speed(iter/s)": 0.253323
    },
    {
      "epoch": 0.49015950004663744,
      "grad_norm": 7.211639881134033,
      "learning_rate": 9.93709299047695e-06,
      "loss": 0.5736211776733399,
      "memory(GiB)": 67.44,
      "step": 5255,
      "train_speed(iter/s)": 0.253324
    },
    {
      "epoch": 0.49062587445201006,
      "grad_norm": 11.926742553710938,
      "learning_rate": 9.936848875393812e-06,
      "loss": 0.5156406879425048,
      "memory(GiB)": 67.44,
      "step": 5260,
      "train_speed(iter/s)": 0.253316
    },
    {
      "epoch": 0.49109224885738273,
      "grad_norm": 10.246413230895996,
      "learning_rate": 9.93660429058471e-06,
      "loss": 0.5005330562591552,
      "memory(GiB)": 67.44,
      "step": 5265,
      "token_acc": 0.47692307692307695,
      "train_speed(iter/s)": 0.253297
    },
    {
      "epoch": 0.49155862326275535,
      "grad_norm": 5.772336483001709,
      "learning_rate": 9.936359236072919e-06,
      "loss": 0.5480059623718262,
      "memory(GiB)": 67.44,
      "step": 5270,
      "train_speed(iter/s)": 0.253298
    },
    {
      "epoch": 0.49202499766812796,
      "grad_norm": 7.7880754470825195,
      "learning_rate": 9.936113711881754e-06,
      "loss": 0.5870896816253662,
      "memory(GiB)": 67.44,
      "step": 5275,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.253289
    },
    {
      "epoch": 0.49249137207350063,
      "grad_norm": 7.198903560638428,
      "learning_rate": 9.935867718034573e-06,
      "loss": 0.5678971767425537,
      "memory(GiB)": 67.44,
      "step": 5280,
      "token_acc": 0.3673469387755102,
      "train_speed(iter/s)": 0.253283
    },
    {
      "epoch": 0.49295774647887325,
      "grad_norm": 11.353928565979004,
      "learning_rate": 9.935621254554786e-06,
      "loss": 0.55284423828125,
      "memory(GiB)": 67.44,
      "step": 5285,
      "train_speed(iter/s)": 0.253275
    },
    {
      "epoch": 0.49342412088424586,
      "grad_norm": 7.562506198883057,
      "learning_rate": 9.935374321465841e-06,
      "loss": 0.6272992610931396,
      "memory(GiB)": 67.44,
      "step": 5290,
      "token_acc": 0.35135135135135137,
      "train_speed(iter/s)": 0.253275
    },
    {
      "epoch": 0.4938904952896185,
      "grad_norm": 10.585638999938965,
      "learning_rate": 9.93512691879123e-06,
      "loss": 0.5586404800415039,
      "memory(GiB)": 67.44,
      "step": 5295,
      "train_speed(iter/s)": 0.253268
    },
    {
      "epoch": 0.49435686969499115,
      "grad_norm": 16.259042739868164,
      "learning_rate": 9.934879046554499e-06,
      "loss": 0.539922046661377,
      "memory(GiB)": 67.44,
      "step": 5300,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253277
    },
    {
      "epoch": 0.49482324410036377,
      "grad_norm": 5.193523406982422,
      "learning_rate": 9.934630704779229e-06,
      "loss": 0.5151725292205811,
      "memory(GiB)": 67.44,
      "step": 5305,
      "train_speed(iter/s)": 0.253291
    },
    {
      "epoch": 0.4952896185057364,
      "grad_norm": 8.702996253967285,
      "learning_rate": 9.93438189348905e-06,
      "loss": 0.5668891906738281,
      "memory(GiB)": 67.44,
      "step": 5310,
      "train_speed(iter/s)": 0.253307
    },
    {
      "epoch": 0.49575599291110906,
      "grad_norm": 5.765815734863281,
      "learning_rate": 9.934132612707631e-06,
      "loss": 0.5299536705017089,
      "memory(GiB)": 67.44,
      "step": 5315,
      "token_acc": 0.7913043478260869,
      "train_speed(iter/s)": 0.253319
    },
    {
      "epoch": 0.49622236731648167,
      "grad_norm": 4.627767086029053,
      "learning_rate": 9.933882862458697e-06,
      "loss": 0.5439789295196533,
      "memory(GiB)": 67.44,
      "step": 5320,
      "train_speed(iter/s)": 0.253328
    },
    {
      "epoch": 0.4966887417218543,
      "grad_norm": 5.6244425773620605,
      "learning_rate": 9.933632642766005e-06,
      "loss": 0.5590151309967041,
      "memory(GiB)": 67.44,
      "step": 5325,
      "train_speed(iter/s)": 0.253337
    },
    {
      "epoch": 0.49715511612722696,
      "grad_norm": 9.316264152526855,
      "learning_rate": 9.933381953653367e-06,
      "loss": 0.5143791675567627,
      "memory(GiB)": 67.44,
      "step": 5330,
      "train_speed(iter/s)": 0.253331
    },
    {
      "epoch": 0.4976214905325996,
      "grad_norm": 4.746077060699463,
      "learning_rate": 9.933130795144634e-06,
      "loss": 0.5276329517364502,
      "memory(GiB)": 67.44,
      "step": 5335,
      "train_speed(iter/s)": 0.253334
    },
    {
      "epoch": 0.4980878649379722,
      "grad_norm": 9.9075927734375,
      "learning_rate": 9.932879167263703e-06,
      "loss": 0.5593299865722656,
      "memory(GiB)": 67.44,
      "step": 5340,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.253333
    },
    {
      "epoch": 0.49855423934334486,
      "grad_norm": 7.999965190887451,
      "learning_rate": 9.932627070034515e-06,
      "loss": 0.5260631561279296,
      "memory(GiB)": 67.44,
      "step": 5345,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.25332
    },
    {
      "epoch": 0.4990206137487175,
      "grad_norm": 6.557283878326416,
      "learning_rate": 9.932374503481057e-06,
      "loss": 0.5747989654541016,
      "memory(GiB)": 67.44,
      "step": 5350,
      "token_acc": 0.3275862068965517,
      "train_speed(iter/s)": 0.253318
    },
    {
      "epoch": 0.4994869881540901,
      "grad_norm": 4.427194595336914,
      "learning_rate": 9.932121467627358e-06,
      "loss": 0.5923898220062256,
      "memory(GiB)": 67.44,
      "step": 5355,
      "token_acc": 0.4864864864864865,
      "train_speed(iter/s)": 0.253318
    },
    {
      "epoch": 0.4999533625594627,
      "grad_norm": 5.24354887008667,
      "learning_rate": 9.931867962497497e-06,
      "loss": 0.560064697265625,
      "memory(GiB)": 67.44,
      "step": 5360,
      "token_acc": 0.35294117647058826,
      "train_speed(iter/s)": 0.25331
    },
    {
      "epoch": 0.5004197369648353,
      "grad_norm": 7.900291919708252,
      "learning_rate": 9.931613988115592e-06,
      "loss": 0.5558032989501953,
      "memory(GiB)": 67.44,
      "step": 5365,
      "token_acc": 0.8037974683544303,
      "train_speed(iter/s)": 0.253305
    },
    {
      "epoch": 0.500886111370208,
      "grad_norm": 8.758716583251953,
      "learning_rate": 9.931359544505807e-06,
      "loss": 0.49329710006713867,
      "memory(GiB)": 67.44,
      "step": 5370,
      "train_speed(iter/s)": 0.253307
    },
    {
      "epoch": 0.5013524857755807,
      "grad_norm": 5.584100723266602,
      "learning_rate": 9.931104631692354e-06,
      "loss": 0.5685879707336425,
      "memory(GiB)": 67.44,
      "step": 5375,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.253308
    },
    {
      "epoch": 0.5018188601809532,
      "grad_norm": 9.624048233032227,
      "learning_rate": 9.930849249699484e-06,
      "loss": 0.5665070533752441,
      "memory(GiB)": 67.44,
      "step": 5380,
      "token_acc": 0.4772727272727273,
      "train_speed(iter/s)": 0.253314
    },
    {
      "epoch": 0.5022852345863259,
      "grad_norm": 5.451943397521973,
      "learning_rate": 9.930593398551501e-06,
      "loss": 0.537388277053833,
      "memory(GiB)": 67.44,
      "step": 5385,
      "token_acc": 0.9047619047619048,
      "train_speed(iter/s)": 0.253305
    },
    {
      "epoch": 0.5027516089916986,
      "grad_norm": 8.709200859069824,
      "learning_rate": 9.930337078272743e-06,
      "loss": 0.576779556274414,
      "memory(GiB)": 67.44,
      "step": 5390,
      "train_speed(iter/s)": 0.253294
    },
    {
      "epoch": 0.5032179833970711,
      "grad_norm": 12.118752479553223,
      "learning_rate": 9.9300802888876e-06,
      "loss": 0.5668772220611572,
      "memory(GiB)": 67.44,
      "step": 5395,
      "token_acc": 0.9203539823008849,
      "train_speed(iter/s)": 0.253306
    },
    {
      "epoch": 0.5036843578024438,
      "grad_norm": 10.183575630187988,
      "learning_rate": 9.929823030420505e-06,
      "loss": 0.546783447265625,
      "memory(GiB)": 67.44,
      "step": 5400,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.253311
    },
    {
      "epoch": 0.5041507322078165,
      "grad_norm": 11.384628295898438,
      "learning_rate": 9.929565302895936e-06,
      "loss": 0.5732683181762696,
      "memory(GiB)": 67.44,
      "step": 5405,
      "train_speed(iter/s)": 0.253305
    },
    {
      "epoch": 0.504617106613189,
      "grad_norm": 10.756088256835938,
      "learning_rate": 9.929307106338414e-06,
      "loss": 0.5473602294921875,
      "memory(GiB)": 67.44,
      "step": 5410,
      "train_speed(iter/s)": 0.25332
    },
    {
      "epoch": 0.5050834810185617,
      "grad_norm": 7.72598123550415,
      "learning_rate": 9.929048440772506e-06,
      "loss": 0.5784441947937011,
      "memory(GiB)": 67.44,
      "step": 5415,
      "train_speed(iter/s)": 0.253323
    },
    {
      "epoch": 0.5055498554239344,
      "grad_norm": 3.5805320739746094,
      "learning_rate": 9.928789306222824e-06,
      "loss": 0.6111149787902832,
      "memory(GiB)": 67.44,
      "step": 5420,
      "token_acc": 0.5642857142857143,
      "train_speed(iter/s)": 0.25332
    },
    {
      "epoch": 0.5060162298293069,
      "grad_norm": 9.337319374084473,
      "learning_rate": 9.928529702714023e-06,
      "loss": 0.5343019485473632,
      "memory(GiB)": 67.44,
      "step": 5425,
      "train_speed(iter/s)": 0.253327
    },
    {
      "epoch": 0.5064826042346796,
      "grad_norm": 5.942059516906738,
      "learning_rate": 9.928269630270802e-06,
      "loss": 0.5195477485656739,
      "memory(GiB)": 67.44,
      "step": 5430,
      "token_acc": 0.4925373134328358,
      "train_speed(iter/s)": 0.253323
    },
    {
      "epoch": 0.5069489786400523,
      "grad_norm": 5.0598273277282715,
      "learning_rate": 9.928009088917909e-06,
      "loss": 0.5393014430999756,
      "memory(GiB)": 67.44,
      "step": 5435,
      "train_speed(iter/s)": 0.253341
    },
    {
      "epoch": 0.5074153530454248,
      "grad_norm": 4.260642051696777,
      "learning_rate": 9.927748078680131e-06,
      "loss": 0.4995624542236328,
      "memory(GiB)": 67.44,
      "step": 5440,
      "token_acc": 0.6590909090909091,
      "train_speed(iter/s)": 0.253339
    },
    {
      "epoch": 0.5078817274507975,
      "grad_norm": 5.116968154907227,
      "learning_rate": 9.927486599582305e-06,
      "loss": 0.568953561782837,
      "memory(GiB)": 67.44,
      "step": 5445,
      "train_speed(iter/s)": 0.253352
    },
    {
      "epoch": 0.5083481018561702,
      "grad_norm": 6.051009654998779,
      "learning_rate": 9.927224651649307e-06,
      "loss": 0.5124166965484619,
      "memory(GiB)": 67.44,
      "step": 5450,
      "token_acc": 0.4117647058823529,
      "train_speed(iter/s)": 0.253351
    },
    {
      "epoch": 0.5088144762615427,
      "grad_norm": 4.433638572692871,
      "learning_rate": 9.926962234906064e-06,
      "loss": 0.5577419757843017,
      "memory(GiB)": 67.44,
      "step": 5455,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.25335
    },
    {
      "epoch": 0.5092808506669154,
      "grad_norm": 3.5945723056793213,
      "learning_rate": 9.926699349377541e-06,
      "loss": 0.5151465892791748,
      "memory(GiB)": 67.44,
      "step": 5460,
      "token_acc": 0.5121951219512195,
      "train_speed(iter/s)": 0.253357
    },
    {
      "epoch": 0.509747225072288,
      "grad_norm": 4.678009033203125,
      "learning_rate": 9.926435995088753e-06,
      "loss": 0.5507015228271485,
      "memory(GiB)": 67.44,
      "step": 5465,
      "token_acc": 0.7246376811594203,
      "train_speed(iter/s)": 0.253368
    },
    {
      "epoch": 0.5102135994776607,
      "grad_norm": 7.5927629470825195,
      "learning_rate": 9.926172172064757e-06,
      "loss": 0.5482672214508056,
      "memory(GiB)": 67.44,
      "step": 5470,
      "train_speed(iter/s)": 0.253371
    },
    {
      "epoch": 0.5106799738830333,
      "grad_norm": 12.603126525878906,
      "learning_rate": 9.925907880330651e-06,
      "loss": 0.5349468231201172,
      "memory(GiB)": 67.44,
      "step": 5475,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.253384
    },
    {
      "epoch": 0.5111463482884059,
      "grad_norm": 17.42034339904785,
      "learning_rate": 9.925643119911588e-06,
      "loss": 0.49086723327636717,
      "memory(GiB)": 67.44,
      "step": 5480,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.253379
    },
    {
      "epoch": 0.5116127226937786,
      "grad_norm": 10.713451385498047,
      "learning_rate": 9.925377890832755e-06,
      "loss": 0.5446702003479004,
      "memory(GiB)": 67.44,
      "step": 5485,
      "train_speed(iter/s)": 0.253392
    },
    {
      "epoch": 0.5120790970991512,
      "grad_norm": 5.896779537200928,
      "learning_rate": 9.925112193119387e-06,
      "loss": 0.5628789901733399,
      "memory(GiB)": 67.44,
      "step": 5490,
      "token_acc": 0.6181818181818182,
      "train_speed(iter/s)": 0.253392
    },
    {
      "epoch": 0.5125454715045238,
      "grad_norm": 9.437027931213379,
      "learning_rate": 9.924846026796768e-06,
      "loss": 0.5344716072082519,
      "memory(GiB)": 67.44,
      "step": 5495,
      "train_speed(iter/s)": 0.253396
    },
    {
      "epoch": 0.5130118459098965,
      "grad_norm": 8.639691352844238,
      "learning_rate": 9.92457939189022e-06,
      "loss": 0.5342649459838867,
      "memory(GiB)": 67.44,
      "step": 5500,
      "token_acc": 0.8854166666666666,
      "train_speed(iter/s)": 0.253408
    },
    {
      "epoch": 0.5134782203152691,
      "grad_norm": 6.146170616149902,
      "learning_rate": 9.924312288425114e-06,
      "loss": 0.6010680675506592,
      "memory(GiB)": 67.44,
      "step": 5505,
      "token_acc": 0.4225352112676056,
      "train_speed(iter/s)": 0.253423
    },
    {
      "epoch": 0.5139445947206417,
      "grad_norm": 8.333544731140137,
      "learning_rate": 9.924044716426862e-06,
      "loss": 0.543817138671875,
      "memory(GiB)": 67.44,
      "step": 5510,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253423
    },
    {
      "epoch": 0.5144109691260144,
      "grad_norm": 7.313511371612549,
      "learning_rate": 9.923776675920927e-06,
      "loss": 0.5935949325561524,
      "memory(GiB)": 67.44,
      "step": 5515,
      "train_speed(iter/s)": 0.253426
    },
    {
      "epoch": 0.514877343531387,
      "grad_norm": 7.761127948760986,
      "learning_rate": 9.923508166932807e-06,
      "loss": 0.5081770896911622,
      "memory(GiB)": 67.44,
      "step": 5520,
      "train_speed(iter/s)": 0.253426
    },
    {
      "epoch": 0.5153437179367596,
      "grad_norm": 6.896851062774658,
      "learning_rate": 9.923239189488052e-06,
      "loss": 0.5505141258239746,
      "memory(GiB)": 67.44,
      "step": 5525,
      "train_speed(iter/s)": 0.253426
    },
    {
      "epoch": 0.5158100923421323,
      "grad_norm": 9.62095832824707,
      "learning_rate": 9.922969743612255e-06,
      "loss": 0.5304943561553955,
      "memory(GiB)": 67.44,
      "step": 5530,
      "train_speed(iter/s)": 0.253431
    },
    {
      "epoch": 0.5162764667475049,
      "grad_norm": 4.995391845703125,
      "learning_rate": 9.922699829331054e-06,
      "loss": 0.5350321769714356,
      "memory(GiB)": 67.44,
      "step": 5535,
      "token_acc": 0.3854166666666667,
      "train_speed(iter/s)": 0.253416
    },
    {
      "epoch": 0.5167428411528775,
      "grad_norm": 4.583176612854004,
      "learning_rate": 9.922429446670127e-06,
      "loss": 0.5588162422180176,
      "memory(GiB)": 67.44,
      "step": 5540,
      "token_acc": 0.5178571428571429,
      "train_speed(iter/s)": 0.253417
    },
    {
      "epoch": 0.5172092155582502,
      "grad_norm": 8.406903266906738,
      "learning_rate": 9.922158595655203e-06,
      "loss": 0.5656169891357422,
      "memory(GiB)": 67.44,
      "step": 5545,
      "train_speed(iter/s)": 0.253429
    },
    {
      "epoch": 0.5176755899636228,
      "grad_norm": 9.646893501281738,
      "learning_rate": 9.921887276312053e-06,
      "loss": 0.5198325157165528,
      "memory(GiB)": 67.44,
      "step": 5550,
      "train_speed(iter/s)": 0.253424
    },
    {
      "epoch": 0.5181419643689954,
      "grad_norm": 8.514915466308594,
      "learning_rate": 9.921615488666488e-06,
      "loss": 0.558619499206543,
      "memory(GiB)": 67.44,
      "step": 5555,
      "train_speed(iter/s)": 0.25343
    },
    {
      "epoch": 0.5186083387743681,
      "grad_norm": 7.927107334136963,
      "learning_rate": 9.921343232744373e-06,
      "loss": 0.5132312774658203,
      "memory(GiB)": 67.44,
      "step": 5560,
      "token_acc": 0.8681318681318682,
      "train_speed(iter/s)": 0.253431
    },
    {
      "epoch": 0.5190747131797407,
      "grad_norm": 7.46028995513916,
      "learning_rate": 9.921070508571609e-06,
      "loss": 0.539423131942749,
      "memory(GiB)": 67.44,
      "step": 5565,
      "token_acc": 0.64,
      "train_speed(iter/s)": 0.253445
    },
    {
      "epoch": 0.5195410875851133,
      "grad_norm": 6.034483909606934,
      "learning_rate": 9.920797316174145e-06,
      "loss": 0.5466023445129394,
      "memory(GiB)": 67.44,
      "step": 5570,
      "token_acc": 0.4434782608695652,
      "train_speed(iter/s)": 0.253445
    },
    {
      "epoch": 0.520007461990486,
      "grad_norm": 6.612499237060547,
      "learning_rate": 9.920523655577977e-06,
      "loss": 0.5480958461761475,
      "memory(GiB)": 67.44,
      "step": 5575,
      "train_speed(iter/s)": 0.253446
    },
    {
      "epoch": 0.5204738363958586,
      "grad_norm": 4.39168643951416,
      "learning_rate": 9.92024952680914e-06,
      "loss": 0.5375255584716797,
      "memory(GiB)": 67.44,
      "step": 5580,
      "train_speed(iter/s)": 0.253437
    },
    {
      "epoch": 0.5209402108012312,
      "grad_norm": 4.874692916870117,
      "learning_rate": 9.919974929893719e-06,
      "loss": 0.6147361755371094,
      "memory(GiB)": 67.44,
      "step": 5585,
      "train_speed(iter/s)": 0.253446
    },
    {
      "epoch": 0.5214065852066039,
      "grad_norm": 4.677013874053955,
      "learning_rate": 9.919699864857839e-06,
      "loss": 0.5228839874267578,
      "memory(GiB)": 67.44,
      "step": 5590,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253467
    },
    {
      "epoch": 0.5218729596119766,
      "grad_norm": 5.180063724517822,
      "learning_rate": 9.919424331727671e-06,
      "loss": 0.5387876510620118,
      "memory(GiB)": 67.44,
      "step": 5595,
      "token_acc": 0.5208333333333334,
      "train_speed(iter/s)": 0.253463
    },
    {
      "epoch": 0.5223393340173491,
      "grad_norm": 7.548459053039551,
      "learning_rate": 9.919148330529435e-06,
      "loss": 0.5581627368927002,
      "memory(GiB)": 67.44,
      "step": 5600,
      "train_speed(iter/s)": 0.253459
    },
    {
      "epoch": 0.5228057084227218,
      "grad_norm": 7.927095890045166,
      "learning_rate": 9.918871861289387e-06,
      "loss": 0.5167387962341309,
      "memory(GiB)": 67.44,
      "step": 5605,
      "train_speed(iter/s)": 0.253456
    },
    {
      "epoch": 0.5232720828280943,
      "grad_norm": 7.2608418464660645,
      "learning_rate": 9.918594924033835e-06,
      "loss": 0.5443113327026368,
      "memory(GiB)": 67.44,
      "step": 5610,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.253459
    },
    {
      "epoch": 0.523738457233467,
      "grad_norm": 6.495803356170654,
      "learning_rate": 9.91831751878913e-06,
      "loss": 0.5540116310119629,
      "memory(GiB)": 67.44,
      "step": 5615,
      "token_acc": 0.5272727272727272,
      "train_speed(iter/s)": 0.253469
    },
    {
      "epoch": 0.5242048316388397,
      "grad_norm": 6.271305084228516,
      "learning_rate": 9.918039645581664e-06,
      "loss": 0.5331827163696289,
      "memory(GiB)": 67.44,
      "step": 5620,
      "token_acc": 0.4423076923076923,
      "train_speed(iter/s)": 0.253457
    },
    {
      "epoch": 0.5246712060442122,
      "grad_norm": 5.369961738586426,
      "learning_rate": 9.917761304437873e-06,
      "loss": 0.5429437637329102,
      "memory(GiB)": 67.44,
      "step": 5625,
      "train_speed(iter/s)": 0.253461
    },
    {
      "epoch": 0.5251375804495849,
      "grad_norm": 6.171628952026367,
      "learning_rate": 9.917482495384245e-06,
      "loss": 0.5327435493469238,
      "memory(GiB)": 67.44,
      "step": 5630,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.253456
    },
    {
      "epoch": 0.5256039548549576,
      "grad_norm": 8.729866027832031,
      "learning_rate": 9.917203218447307e-06,
      "loss": 0.5161280632019043,
      "memory(GiB)": 67.44,
      "step": 5635,
      "train_speed(iter/s)": 0.253436
    },
    {
      "epoch": 0.5260703292603301,
      "grad_norm": 7.993448257446289,
      "learning_rate": 9.91692347365363e-06,
      "loss": 0.5508649826049805,
      "memory(GiB)": 67.44,
      "step": 5640,
      "train_speed(iter/s)": 0.253444
    },
    {
      "epoch": 0.5265367036657028,
      "grad_norm": 7.207347393035889,
      "learning_rate": 9.916643261029832e-06,
      "loss": 0.5002241611480713,
      "memory(GiB)": 67.44,
      "step": 5645,
      "train_speed(iter/s)": 0.253447
    },
    {
      "epoch": 0.5270030780710755,
      "grad_norm": 6.095637321472168,
      "learning_rate": 9.916362580602574e-06,
      "loss": 0.5374231338500977,
      "memory(GiB)": 67.44,
      "step": 5650,
      "train_speed(iter/s)": 0.253464
    },
    {
      "epoch": 0.527469452476448,
      "grad_norm": 9.49163818359375,
      "learning_rate": 9.91608143239856e-06,
      "loss": 0.544282054901123,
      "memory(GiB)": 67.44,
      "step": 5655,
      "token_acc": 0.7099236641221374,
      "train_speed(iter/s)": 0.253453
    },
    {
      "epoch": 0.5279358268818207,
      "grad_norm": 8.641548156738281,
      "learning_rate": 9.915799816444543e-06,
      "loss": 0.523313045501709,
      "memory(GiB)": 67.44,
      "step": 5660,
      "train_speed(iter/s)": 0.253452
    },
    {
      "epoch": 0.5284022012871934,
      "grad_norm": 7.9743123054504395,
      "learning_rate": 9.915517732767317e-06,
      "loss": 0.5622086524963379,
      "memory(GiB)": 67.44,
      "step": 5665,
      "train_speed(iter/s)": 0.253448
    },
    {
      "epoch": 0.528868575692566,
      "grad_norm": 4.87917947769165,
      "learning_rate": 9.91523518139372e-06,
      "loss": 0.4761529445648193,
      "memory(GiB)": 67.44,
      "step": 5670,
      "train_speed(iter/s)": 0.253447
    },
    {
      "epoch": 0.5293349500979386,
      "grad_norm": 5.9791741371154785,
      "learning_rate": 9.91495216235064e-06,
      "loss": 0.5177846431732178,
      "memory(GiB)": 67.44,
      "step": 5675,
      "train_speed(iter/s)": 0.253449
    },
    {
      "epoch": 0.5298013245033113,
      "grad_norm": 6.4627532958984375,
      "learning_rate": 9.914668675665003e-06,
      "loss": 0.5371599197387695,
      "memory(GiB)": 67.44,
      "step": 5680,
      "train_speed(iter/s)": 0.253437
    },
    {
      "epoch": 0.5302676989086839,
      "grad_norm": 4.756608009338379,
      "learning_rate": 9.914384721363779e-06,
      "loss": 0.5520741462707519,
      "memory(GiB)": 67.44,
      "step": 5685,
      "token_acc": 0.44642857142857145,
      "train_speed(iter/s)": 0.253438
    },
    {
      "epoch": 0.5307340733140565,
      "grad_norm": 8.396093368530273,
      "learning_rate": 9.914100299473988e-06,
      "loss": 0.5352529525756836,
      "memory(GiB)": 67.44,
      "step": 5690,
      "token_acc": 0.36363636363636365,
      "train_speed(iter/s)": 0.253441
    },
    {
      "epoch": 0.5312004477194292,
      "grad_norm": 5.584878921508789,
      "learning_rate": 9.913815410022694e-06,
      "loss": 0.4904177188873291,
      "memory(GiB)": 67.44,
      "step": 5695,
      "token_acc": 0.3902439024390244,
      "train_speed(iter/s)": 0.253439
    },
    {
      "epoch": 0.5316668221248018,
      "grad_norm": 6.466900825500488,
      "learning_rate": 9.913530053036998e-06,
      "loss": 0.5755026340484619,
      "memory(GiB)": 67.44,
      "step": 5700,
      "train_speed(iter/s)": 0.253441
    },
    {
      "epoch": 0.5321331965301744,
      "grad_norm": 3.606062650680542,
      "learning_rate": 9.913244228544057e-06,
      "loss": 0.5231620788574218,
      "memory(GiB)": 67.44,
      "step": 5705,
      "token_acc": 0.4117647058823529,
      "train_speed(iter/s)": 0.253453
    },
    {
      "epoch": 0.5325995709355471,
      "grad_norm": 8.08545207977295,
      "learning_rate": 9.91295793657106e-06,
      "loss": 0.5471807479858398,
      "memory(GiB)": 67.44,
      "step": 5710,
      "token_acc": 0.3888888888888889,
      "train_speed(iter/s)": 0.253454
    },
    {
      "epoch": 0.5330659453409197,
      "grad_norm": 4.29329252243042,
      "learning_rate": 9.912671177145252e-06,
      "loss": 0.5646335124969483,
      "memory(GiB)": 67.44,
      "step": 5715,
      "token_acc": 0.5764705882352941,
      "train_speed(iter/s)": 0.253455
    },
    {
      "epoch": 0.5335323197462923,
      "grad_norm": 5.516911506652832,
      "learning_rate": 9.912383950293916e-06,
      "loss": 0.5162309646606446,
      "memory(GiB)": 67.44,
      "step": 5720,
      "train_speed(iter/s)": 0.253462
    },
    {
      "epoch": 0.533998694151665,
      "grad_norm": 9.729327201843262,
      "learning_rate": 9.912096256044379e-06,
      "loss": 0.5790990352630615,
      "memory(GiB)": 67.44,
      "step": 5725,
      "train_speed(iter/s)": 0.253475
    },
    {
      "epoch": 0.5344650685570376,
      "grad_norm": 6.755002021789551,
      "learning_rate": 9.911808094424015e-06,
      "loss": 0.5482308387756347,
      "memory(GiB)": 67.44,
      "step": 5730,
      "train_speed(iter/s)": 0.253479
    },
    {
      "epoch": 0.5349314429624102,
      "grad_norm": 4.991807460784912,
      "learning_rate": 9.911519465460244e-06,
      "loss": 0.5292791843414306,
      "memory(GiB)": 67.44,
      "step": 5735,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.25348
    },
    {
      "epoch": 0.5353978173677828,
      "grad_norm": 8.904075622558594,
      "learning_rate": 9.911230369180524e-06,
      "loss": 0.5694484710693359,
      "memory(GiB)": 67.44,
      "step": 5740,
      "train_speed(iter/s)": 0.253471
    },
    {
      "epoch": 0.5358641917731555,
      "grad_norm": 7.510638236999512,
      "learning_rate": 9.910940805612365e-06,
      "loss": 0.4995020866394043,
      "memory(GiB)": 67.44,
      "step": 5745,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.253463
    },
    {
      "epoch": 0.5363305661785281,
      "grad_norm": 5.474316596984863,
      "learning_rate": 9.910650774783317e-06,
      "loss": 0.5384780883789062,
      "memory(GiB)": 67.44,
      "step": 5750,
      "train_speed(iter/s)": 0.25346
    },
    {
      "epoch": 0.5367969405839007,
      "grad_norm": 7.740636825561523,
      "learning_rate": 9.910360276720974e-06,
      "loss": 0.5063341140747071,
      "memory(GiB)": 67.44,
      "step": 5755,
      "token_acc": 0.8860759493670886,
      "train_speed(iter/s)": 0.253456
    },
    {
      "epoch": 0.5372633149892734,
      "grad_norm": 13.614360809326172,
      "learning_rate": 9.910069311452978e-06,
      "loss": 0.5516376495361328,
      "memory(GiB)": 67.44,
      "step": 5760,
      "train_speed(iter/s)": 0.253447
    },
    {
      "epoch": 0.537729689394646,
      "grad_norm": 7.498771667480469,
      "learning_rate": 9.909777879007015e-06,
      "loss": 0.5552980899810791,
      "memory(GiB)": 67.44,
      "step": 5765,
      "token_acc": 0.6612903225806451,
      "train_speed(iter/s)": 0.253447
    },
    {
      "epoch": 0.5381960638000186,
      "grad_norm": 7.794612407684326,
      "learning_rate": 9.909485979410808e-06,
      "loss": 0.5738200187683106,
      "memory(GiB)": 67.44,
      "step": 5770,
      "train_speed(iter/s)": 0.25345
    },
    {
      "epoch": 0.5386624382053913,
      "grad_norm": 5.770282745361328,
      "learning_rate": 9.909193612692139e-06,
      "loss": 0.5605350494384765,
      "memory(GiB)": 67.44,
      "step": 5775,
      "train_speed(iter/s)": 0.253446
    },
    {
      "epoch": 0.539128812610764,
      "grad_norm": 5.443260192871094,
      "learning_rate": 9.908900778878816e-06,
      "loss": 0.4972821235656738,
      "memory(GiB)": 67.44,
      "step": 5780,
      "train_speed(iter/s)": 0.25346
    },
    {
      "epoch": 0.5395951870161365,
      "grad_norm": 4.1209635734558105,
      "learning_rate": 9.908607477998708e-06,
      "loss": 0.5638747215270996,
      "memory(GiB)": 67.44,
      "step": 5785,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.25347
    },
    {
      "epoch": 0.5400615614215092,
      "grad_norm": 5.449648857116699,
      "learning_rate": 9.90831371007972e-06,
      "loss": 0.5733814239501953,
      "memory(GiB)": 67.44,
      "step": 5790,
      "train_speed(iter/s)": 0.253457
    },
    {
      "epoch": 0.5405279358268819,
      "grad_norm": 9.408954620361328,
      "learning_rate": 9.908019475149804e-06,
      "loss": 0.5687117099761962,
      "memory(GiB)": 67.44,
      "step": 5795,
      "train_speed(iter/s)": 0.253454
    },
    {
      "epoch": 0.5409943102322544,
      "grad_norm": 8.647418975830078,
      "learning_rate": 9.907724773236952e-06,
      "loss": 0.5758863925933838,
      "memory(GiB)": 67.44,
      "step": 5800,
      "token_acc": 0.5476190476190477,
      "train_speed(iter/s)": 0.253451
    },
    {
      "epoch": 0.5414606846376271,
      "grad_norm": 7.082557678222656,
      "learning_rate": 9.90742960436921e-06,
      "loss": 0.5256928920745849,
      "memory(GiB)": 67.44,
      "step": 5805,
      "train_speed(iter/s)": 0.253456
    },
    {
      "epoch": 0.5419270590429998,
      "grad_norm": 10.935269355773926,
      "learning_rate": 9.907133968574656e-06,
      "loss": 0.6011818408966064,
      "memory(GiB)": 67.44,
      "step": 5810,
      "token_acc": 0.8736842105263158,
      "train_speed(iter/s)": 0.253456
    },
    {
      "epoch": 0.5423934334483723,
      "grad_norm": 5.1387739181518555,
      "learning_rate": 9.906837865881422e-06,
      "loss": 0.5301535606384278,
      "memory(GiB)": 67.44,
      "step": 5815,
      "token_acc": 0.7210884353741497,
      "train_speed(iter/s)": 0.253479
    },
    {
      "epoch": 0.542859807853745,
      "grad_norm": 9.312467575073242,
      "learning_rate": 9.906541296317681e-06,
      "loss": 0.5971356391906738,
      "memory(GiB)": 67.44,
      "step": 5820,
      "train_speed(iter/s)": 0.253497
    },
    {
      "epoch": 0.5433261822591177,
      "grad_norm": 3.7725510597229004,
      "learning_rate": 9.90624425991165e-06,
      "loss": 0.5190419673919677,
      "memory(GiB)": 67.44,
      "step": 5825,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.5437925566644902,
      "grad_norm": 4.713522911071777,
      "learning_rate": 9.905946756691593e-06,
      "loss": 0.5279029846191406,
      "memory(GiB)": 67.44,
      "step": 5830,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.253489
    },
    {
      "epoch": 0.5442589310698629,
      "grad_norm": 7.771950721740723,
      "learning_rate": 9.905648786685816e-06,
      "loss": 0.5374330520629883,
      "memory(GiB)": 67.44,
      "step": 5835,
      "train_speed(iter/s)": 0.253493
    },
    {
      "epoch": 0.5447253054752356,
      "grad_norm": 7.209531307220459,
      "learning_rate": 9.905350349922666e-06,
      "loss": 0.5618691444396973,
      "memory(GiB)": 67.44,
      "step": 5840,
      "token_acc": 0.627906976744186,
      "train_speed(iter/s)": 0.253492
    },
    {
      "epoch": 0.5451916798806081,
      "grad_norm": 3.765805244445801,
      "learning_rate": 9.905051446430545e-06,
      "loss": 0.5153244495391845,
      "memory(GiB)": 67.44,
      "step": 5845,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.5456580542859808,
      "grad_norm": 7.895706653594971,
      "learning_rate": 9.904752076237887e-06,
      "loss": 0.5406486988067627,
      "memory(GiB)": 67.44,
      "step": 5850,
      "train_speed(iter/s)": 0.253495
    },
    {
      "epoch": 0.5461244286913535,
      "grad_norm": 4.543087482452393,
      "learning_rate": 9.90445223937318e-06,
      "loss": 0.5252960205078125,
      "memory(GiB)": 67.44,
      "step": 5855,
      "train_speed(iter/s)": 0.253499
    },
    {
      "epoch": 0.546590803096726,
      "grad_norm": 8.10897445678711,
      "learning_rate": 9.90415193586495e-06,
      "loss": 0.5345385551452637,
      "memory(GiB)": 67.44,
      "step": 5860,
      "train_speed(iter/s)": 0.253499
    },
    {
      "epoch": 0.5470571775020987,
      "grad_norm": 6.524754047393799,
      "learning_rate": 9.903851165741772e-06,
      "loss": 0.6211254119873046,
      "memory(GiB)": 67.44,
      "step": 5865,
      "token_acc": 0.5636363636363636,
      "train_speed(iter/s)": 0.253488
    },
    {
      "epoch": 0.5475235519074714,
      "grad_norm": 7.682181358337402,
      "learning_rate": 9.90354992903226e-06,
      "loss": 0.5219842910766601,
      "memory(GiB)": 67.44,
      "step": 5870,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.253486
    },
    {
      "epoch": 0.5479899263128439,
      "grad_norm": 5.610498428344727,
      "learning_rate": 9.90324822576508e-06,
      "loss": 0.5479578018188477,
      "memory(GiB)": 67.44,
      "step": 5875,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.5484563007182166,
      "grad_norm": 6.588624954223633,
      "learning_rate": 9.902946055968936e-06,
      "loss": 0.5180466651916504,
      "memory(GiB)": 67.44,
      "step": 5880,
      "train_speed(iter/s)": 0.253491
    },
    {
      "epoch": 0.5489226751235892,
      "grad_norm": 8.843225479125977,
      "learning_rate": 9.902643419672577e-06,
      "loss": 0.6055091857910156,
      "memory(GiB)": 67.44,
      "step": 5885,
      "train_speed(iter/s)": 0.2535
    },
    {
      "epoch": 0.5493890495289618,
      "grad_norm": 8.29872989654541,
      "learning_rate": 9.902340316904802e-06,
      "loss": 0.5235558032989502,
      "memory(GiB)": 67.44,
      "step": 5890,
      "token_acc": 0.42424242424242425,
      "train_speed(iter/s)": 0.253506
    },
    {
      "epoch": 0.5498554239343345,
      "grad_norm": 3.510617733001709,
      "learning_rate": 9.902036747694446e-06,
      "loss": 0.5245311260223389,
      "memory(GiB)": 67.44,
      "step": 5895,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.253508
    },
    {
      "epoch": 0.5503217983397071,
      "grad_norm": 5.4073991775512695,
      "learning_rate": 9.901732712070395e-06,
      "loss": 0.5518447875976562,
      "memory(GiB)": 67.44,
      "step": 5900,
      "train_speed(iter/s)": 0.253506
    },
    {
      "epoch": 0.5507881727450797,
      "grad_norm": 5.522068500518799,
      "learning_rate": 9.901428210061577e-06,
      "loss": 0.47694740295410154,
      "memory(GiB)": 67.44,
      "step": 5905,
      "token_acc": 0.45535714285714285,
      "train_speed(iter/s)": 0.253505
    },
    {
      "epoch": 0.5512545471504524,
      "grad_norm": 3.8484208583831787,
      "learning_rate": 9.901123241696964e-06,
      "loss": 0.4967156410217285,
      "memory(GiB)": 67.44,
      "step": 5910,
      "token_acc": 0.7557251908396947,
      "train_speed(iter/s)": 0.253499
    },
    {
      "epoch": 0.551720921555825,
      "grad_norm": 5.082025051116943,
      "learning_rate": 9.900817807005572e-06,
      "loss": 0.5763426780700683,
      "memory(GiB)": 67.44,
      "step": 5915,
      "train_speed(iter/s)": 0.253502
    },
    {
      "epoch": 0.5521872959611976,
      "grad_norm": 6.052198886871338,
      "learning_rate": 9.900511906016464e-06,
      "loss": 0.5606595039367676,
      "memory(GiB)": 67.44,
      "step": 5920,
      "token_acc": 0.49019607843137253,
      "train_speed(iter/s)": 0.253495
    },
    {
      "epoch": 0.5526536703665703,
      "grad_norm": 4.103489875793457,
      "learning_rate": 9.900205538758744e-06,
      "loss": 0.5355452537536621,
      "memory(GiB)": 67.44,
      "step": 5925,
      "token_acc": 0.559322033898305,
      "train_speed(iter/s)": 0.253506
    },
    {
      "epoch": 0.5531200447719429,
      "grad_norm": 3.699275016784668,
      "learning_rate": 9.899898705261564e-06,
      "loss": 0.5237232208251953,
      "memory(GiB)": 67.44,
      "step": 5930,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.5535864191773155,
      "grad_norm": 4.300332069396973,
      "learning_rate": 9.899591405554115e-06,
      "loss": 0.5429895401000977,
      "memory(GiB)": 67.44,
      "step": 5935,
      "train_speed(iter/s)": 0.25349
    },
    {
      "epoch": 0.5540527935826882,
      "grad_norm": 5.3487443923950195,
      "learning_rate": 9.899283639665638e-06,
      "loss": 0.5220776557922363,
      "memory(GiB)": 67.44,
      "step": 5940,
      "token_acc": 0.4745762711864407,
      "train_speed(iter/s)": 0.253498
    },
    {
      "epoch": 0.5545191679880608,
      "grad_norm": 4.184986114501953,
      "learning_rate": 9.898975407625413e-06,
      "loss": 0.49790229797363283,
      "memory(GiB)": 67.44,
      "step": 5945,
      "token_acc": 0.8838383838383839,
      "train_speed(iter/s)": 0.253505
    },
    {
      "epoch": 0.5549855423934335,
      "grad_norm": 3.8621344566345215,
      "learning_rate": 9.898666709462771e-06,
      "loss": 0.5396110534667968,
      "memory(GiB)": 67.44,
      "step": 5950,
      "token_acc": 0.8904109589041096,
      "train_speed(iter/s)": 0.253505
    },
    {
      "epoch": 0.5554519167988061,
      "grad_norm": 5.424039840698242,
      "learning_rate": 9.898357545207084e-06,
      "loss": 0.5381030082702637,
      "memory(GiB)": 67.44,
      "step": 5955,
      "token_acc": 0.425531914893617,
      "train_speed(iter/s)": 0.25351
    },
    {
      "epoch": 0.5559182912041787,
      "grad_norm": 8.063636779785156,
      "learning_rate": 9.898047914887767e-06,
      "loss": 0.5673470020294189,
      "memory(GiB)": 67.44,
      "step": 5960,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.253503
    },
    {
      "epoch": 0.5563846656095514,
      "grad_norm": 7.412894248962402,
      "learning_rate": 9.897737818534276e-06,
      "loss": 0.5024331092834473,
      "memory(GiB)": 67.44,
      "step": 5965,
      "token_acc": 0.9272727272727272,
      "train_speed(iter/s)": 0.25351
    },
    {
      "epoch": 0.556851040014924,
      "grad_norm": 6.649342060089111,
      "learning_rate": 9.897427256176123e-06,
      "loss": 0.507892370223999,
      "memory(GiB)": 67.44,
      "step": 5970,
      "train_speed(iter/s)": 0.253523
    },
    {
      "epoch": 0.5573174144202966,
      "grad_norm": 4.309080600738525,
      "learning_rate": 9.897116227842851e-06,
      "loss": 0.5265192985534668,
      "memory(GiB)": 67.44,
      "step": 5975,
      "train_speed(iter/s)": 0.253532
    },
    {
      "epoch": 0.5577837888256693,
      "grad_norm": 6.3127546310424805,
      "learning_rate": 9.896804733564057e-06,
      "loss": 0.5716738700866699,
      "memory(GiB)": 67.44,
      "step": 5980,
      "train_speed(iter/s)": 0.253536
    },
    {
      "epoch": 0.5582501632310419,
      "grad_norm": 14.223871231079102,
      "learning_rate": 9.896492773369377e-06,
      "loss": 0.5177162647247314,
      "memory(GiB)": 67.44,
      "step": 5985,
      "train_speed(iter/s)": 0.253547
    },
    {
      "epoch": 0.5587165376364145,
      "grad_norm": 5.341701030731201,
      "learning_rate": 9.896180347288495e-06,
      "loss": 0.5170282363891602,
      "memory(GiB)": 67.44,
      "step": 5990,
      "train_speed(iter/s)": 0.253541
    },
    {
      "epoch": 0.5591829120417872,
      "grad_norm": 4.286433696746826,
      "learning_rate": 9.895867455351134e-06,
      "loss": 0.5414856910705567,
      "memory(GiB)": 67.44,
      "step": 5995,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.253548
    },
    {
      "epoch": 0.5596492864471598,
      "grad_norm": 9.682319641113281,
      "learning_rate": 9.895554097587067e-06,
      "loss": 0.5530157089233398,
      "memory(GiB)": 67.44,
      "step": 6000,
      "token_acc": 0.9444444444444444,
      "train_speed(iter/s)": 0.253566
    },
    {
      "epoch": 0.5601156608525324,
      "grad_norm": 9.019538879394531,
      "learning_rate": 9.89524027402611e-06,
      "loss": 0.5322178840637207,
      "memory(GiB)": 67.44,
      "step": 6005,
      "train_speed(iter/s)": 0.25329
    },
    {
      "epoch": 0.5605820352579051,
      "grad_norm": 6.315774917602539,
      "learning_rate": 9.894925984698121e-06,
      "loss": 0.5132334709167481,
      "memory(GiB)": 67.44,
      "step": 6010,
      "train_speed(iter/s)": 0.253285
    },
    {
      "epoch": 0.5610484096632776,
      "grad_norm": 4.331242561340332,
      "learning_rate": 9.894611229633004e-06,
      "loss": 0.5129576206207276,
      "memory(GiB)": 67.44,
      "step": 6015,
      "token_acc": 0.896551724137931,
      "train_speed(iter/s)": 0.253295
    },
    {
      "epoch": 0.5615147840686503,
      "grad_norm": 8.468671798706055,
      "learning_rate": 9.894296008860705e-06,
      "loss": 0.5797716617584229,
      "memory(GiB)": 67.44,
      "step": 6020,
      "token_acc": 0.65625,
      "train_speed(iter/s)": 0.253296
    },
    {
      "epoch": 0.561981158474023,
      "grad_norm": 6.710559368133545,
      "learning_rate": 9.893980322411218e-06,
      "loss": 0.5708539009094238,
      "memory(GiB)": 67.44,
      "step": 6025,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253304
    },
    {
      "epoch": 0.5624475328793955,
      "grad_norm": 6.807936668395996,
      "learning_rate": 9.893664170314581e-06,
      "loss": 0.5083279132843017,
      "memory(GiB)": 67.44,
      "step": 6030,
      "train_speed(iter/s)": 0.253296
    },
    {
      "epoch": 0.5629139072847682,
      "grad_norm": 6.554131031036377,
      "learning_rate": 9.893347552600874e-06,
      "loss": 0.553532075881958,
      "memory(GiB)": 67.44,
      "step": 6035,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.253299
    },
    {
      "epoch": 0.5633802816901409,
      "grad_norm": 5.28062629699707,
      "learning_rate": 9.89303046930022e-06,
      "loss": 0.5255180835723877,
      "memory(GiB)": 67.44,
      "step": 6040,
      "train_speed(iter/s)": 0.253294
    },
    {
      "epoch": 0.5638466560955134,
      "grad_norm": 6.913018226623535,
      "learning_rate": 9.892712920442791e-06,
      "loss": 0.5033933639526367,
      "memory(GiB)": 67.44,
      "step": 6045,
      "train_speed(iter/s)": 0.253314
    },
    {
      "epoch": 0.5643130305008861,
      "grad_norm": 8.158227920532227,
      "learning_rate": 9.8923949060588e-06,
      "loss": 0.5548683166503906,
      "memory(GiB)": 67.44,
      "step": 6050,
      "token_acc": 0.7112676056338029,
      "train_speed(iter/s)": 0.253313
    },
    {
      "epoch": 0.5647794049062588,
      "grad_norm": 4.259340286254883,
      "learning_rate": 9.892076426178506e-06,
      "loss": 0.4916236877441406,
      "memory(GiB)": 67.44,
      "step": 6055,
      "train_speed(iter/s)": 0.253326
    },
    {
      "epoch": 0.5652457793116313,
      "grad_norm": 7.701147556304932,
      "learning_rate": 9.89175748083221e-06,
      "loss": 0.5338274955749511,
      "memory(GiB)": 67.44,
      "step": 6060,
      "train_speed(iter/s)": 0.25333
    },
    {
      "epoch": 0.565712153717004,
      "grad_norm": 6.005561351776123,
      "learning_rate": 9.891438070050257e-06,
      "loss": 0.5200802326202393,
      "memory(GiB)": 67.44,
      "step": 6065,
      "train_speed(iter/s)": 0.253328
    },
    {
      "epoch": 0.5661785281223767,
      "grad_norm": 6.2121453285217285,
      "learning_rate": 9.891118193863043e-06,
      "loss": 0.5615766525268555,
      "memory(GiB)": 67.44,
      "step": 6070,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.253335
    },
    {
      "epoch": 0.5666449025277492,
      "grad_norm": 10.494677543640137,
      "learning_rate": 9.890797852300998e-06,
      "loss": 0.5033987045288086,
      "memory(GiB)": 67.44,
      "step": 6075,
      "train_speed(iter/s)": 0.253341
    },
    {
      "epoch": 0.5671112769331219,
      "grad_norm": 6.625967979431152,
      "learning_rate": 9.890477045394605e-06,
      "loss": 0.5774281978607178,
      "memory(GiB)": 67.44,
      "step": 6080,
      "train_speed(iter/s)": 0.253346
    },
    {
      "epoch": 0.5675776513384946,
      "grad_norm": 5.325131416320801,
      "learning_rate": 9.890155773174387e-06,
      "loss": 0.5194959163665771,
      "memory(GiB)": 67.44,
      "step": 6085,
      "train_speed(iter/s)": 0.253354
    },
    {
      "epoch": 0.5680440257438671,
      "grad_norm": 5.965561866760254,
      "learning_rate": 9.889834035670912e-06,
      "loss": 0.48638081550598145,
      "memory(GiB)": 67.44,
      "step": 6090,
      "train_speed(iter/s)": 0.253354
    },
    {
      "epoch": 0.5685104001492398,
      "grad_norm": 5.441127300262451,
      "learning_rate": 9.88951183291479e-06,
      "loss": 0.5432226181030273,
      "memory(GiB)": 67.44,
      "step": 6095,
      "train_speed(iter/s)": 0.253358
    },
    {
      "epoch": 0.5689767745546125,
      "grad_norm": 3.736820936203003,
      "learning_rate": 9.889189164936681e-06,
      "loss": 0.5067985534667969,
      "memory(GiB)": 67.44,
      "step": 6100,
      "token_acc": 0.6307692307692307,
      "train_speed(iter/s)": 0.253364
    },
    {
      "epoch": 0.569443148959985,
      "grad_norm": 4.681936264038086,
      "learning_rate": 9.888866031767284e-06,
      "loss": 0.5379021167755127,
      "memory(GiB)": 67.44,
      "step": 6105,
      "token_acc": 0.5576923076923077,
      "train_speed(iter/s)": 0.253371
    },
    {
      "epoch": 0.5699095233653577,
      "grad_norm": 13.54443359375,
      "learning_rate": 9.888542433437345e-06,
      "loss": 0.5267281532287598,
      "memory(GiB)": 67.44,
      "step": 6110,
      "token_acc": 0.4485981308411215,
      "train_speed(iter/s)": 0.25337
    },
    {
      "epoch": 0.5703758977707304,
      "grad_norm": 13.19937515258789,
      "learning_rate": 9.888218369977653e-06,
      "loss": 0.5202342987060546,
      "memory(GiB)": 67.44,
      "step": 6115,
      "train_speed(iter/s)": 0.253388
    },
    {
      "epoch": 0.570842272176103,
      "grad_norm": 11.661611557006836,
      "learning_rate": 9.887893841419041e-06,
      "loss": 0.5387904167175293,
      "memory(GiB)": 67.44,
      "step": 6120,
      "train_speed(iter/s)": 0.253397
    },
    {
      "epoch": 0.5713086465814756,
      "grad_norm": 8.207687377929688,
      "learning_rate": 9.887568847792388e-06,
      "loss": 0.5738547325134278,
      "memory(GiB)": 67.44,
      "step": 6125,
      "train_speed(iter/s)": 0.253398
    },
    {
      "epoch": 0.5717750209868483,
      "grad_norm": 5.7900872230529785,
      "learning_rate": 9.887243389128615e-06,
      "loss": 0.55794358253479,
      "memory(GiB)": 67.44,
      "step": 6130,
      "token_acc": 0.8666666666666667,
      "train_speed(iter/s)": 0.2534
    },
    {
      "epoch": 0.5722413953922209,
      "grad_norm": 7.199126243591309,
      "learning_rate": 9.88691746545869e-06,
      "loss": 0.550049877166748,
      "memory(GiB)": 67.44,
      "step": 6135,
      "train_speed(iter/s)": 0.253413
    },
    {
      "epoch": 0.5727077697975935,
      "grad_norm": 5.883105754852295,
      "learning_rate": 9.886591076813623e-06,
      "loss": 0.5021875381469727,
      "memory(GiB)": 67.44,
      "step": 6140,
      "train_speed(iter/s)": 0.253428
    },
    {
      "epoch": 0.5731741442029662,
      "grad_norm": 5.876614570617676,
      "learning_rate": 9.886264223224468e-06,
      "loss": 0.5367851257324219,
      "memory(GiB)": 67.44,
      "step": 6145,
      "train_speed(iter/s)": 0.25343
    },
    {
      "epoch": 0.5736405186083388,
      "grad_norm": 6.421753406524658,
      "learning_rate": 9.885936904722325e-06,
      "loss": 0.5257923603057861,
      "memory(GiB)": 67.44,
      "step": 6150,
      "train_speed(iter/s)": 0.253438
    },
    {
      "epoch": 0.5741068930137114,
      "grad_norm": 11.564896583557129,
      "learning_rate": 9.885609121338336e-06,
      "loss": 0.5171566963195801,
      "memory(GiB)": 67.44,
      "step": 6155,
      "token_acc": 0.3584905660377358,
      "train_speed(iter/s)": 0.253442
    },
    {
      "epoch": 0.574573267419084,
      "grad_norm": 6.9263200759887695,
      "learning_rate": 9.885280873103692e-06,
      "loss": 0.5216426372528076,
      "memory(GiB)": 67.44,
      "step": 6160,
      "token_acc": 0.5609756097560976,
      "train_speed(iter/s)": 0.253454
    },
    {
      "epoch": 0.5750396418244567,
      "grad_norm": 8.36163330078125,
      "learning_rate": 9.88495216004962e-06,
      "loss": 0.5104382514953614,
      "memory(GiB)": 67.44,
      "step": 6165,
      "token_acc": 0.5873015873015873,
      "train_speed(iter/s)": 0.253461
    },
    {
      "epoch": 0.5755060162298293,
      "grad_norm": 4.4268012046813965,
      "learning_rate": 9.884622982207398e-06,
      "loss": 0.49217529296875,
      "memory(GiB)": 67.44,
      "step": 6170,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.253471
    },
    {
      "epoch": 0.5759723906352019,
      "grad_norm": 10.688663482666016,
      "learning_rate": 9.884293339608348e-06,
      "loss": 0.5148595333099365,
      "memory(GiB)": 67.44,
      "step": 6175,
      "token_acc": 0.6415094339622641,
      "train_speed(iter/s)": 0.253468
    },
    {
      "epoch": 0.5764387650405746,
      "grad_norm": 5.100829124450684,
      "learning_rate": 9.883963232283833e-06,
      "loss": 0.5566415786743164,
      "memory(GiB)": 67.44,
      "step": 6180,
      "token_acc": 0.3787878787878788,
      "train_speed(iter/s)": 0.253465
    },
    {
      "epoch": 0.5769051394459472,
      "grad_norm": 5.0912675857543945,
      "learning_rate": 9.883632660265261e-06,
      "loss": 0.5652409076690674,
      "memory(GiB)": 67.44,
      "step": 6185,
      "token_acc": 0.48314606741573035,
      "train_speed(iter/s)": 0.253461
    },
    {
      "epoch": 0.5773715138513198,
      "grad_norm": 5.538951873779297,
      "learning_rate": 9.883301623584087e-06,
      "loss": 0.5396616935729981,
      "memory(GiB)": 67.44,
      "step": 6190,
      "token_acc": 0.9175257731958762,
      "train_speed(iter/s)": 0.253456
    },
    {
      "epoch": 0.5778378882566925,
      "grad_norm": 7.650030136108398,
      "learning_rate": 9.882970122271806e-06,
      "loss": 0.5472085475921631,
      "memory(GiB)": 67.44,
      "step": 6195,
      "train_speed(iter/s)": 0.253468
    },
    {
      "epoch": 0.5783042626620651,
      "grad_norm": 5.264434814453125,
      "learning_rate": 9.882638156359961e-06,
      "loss": 0.5302398681640625,
      "memory(GiB)": 67.44,
      "step": 6200,
      "train_speed(iter/s)": 0.253481
    },
    {
      "epoch": 0.5787706370674377,
      "grad_norm": 8.377264022827148,
      "learning_rate": 9.882305725880136e-06,
      "loss": 0.5640133857727051,
      "memory(GiB)": 67.44,
      "step": 6205,
      "train_speed(iter/s)": 0.253471
    },
    {
      "epoch": 0.5792370114728104,
      "grad_norm": 5.194094657897949,
      "learning_rate": 9.881972830863962e-06,
      "loss": 0.4929360866546631,
      "memory(GiB)": 67.44,
      "step": 6210,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.253469
    },
    {
      "epoch": 0.579703385878183,
      "grad_norm": 8.811701774597168,
      "learning_rate": 9.881639471343114e-06,
      "loss": 0.5805008888244629,
      "memory(GiB)": 67.44,
      "step": 6215,
      "train_speed(iter/s)": 0.253469
    },
    {
      "epoch": 0.5801697602835556,
      "grad_norm": 7.569365978240967,
      "learning_rate": 9.881305647349306e-06,
      "loss": 0.5344612121582031,
      "memory(GiB)": 67.44,
      "step": 6220,
      "train_speed(iter/s)": 0.253474
    },
    {
      "epoch": 0.5806361346889283,
      "grad_norm": 8.170132637023926,
      "learning_rate": 9.880971358914304e-06,
      "loss": 0.49845457077026367,
      "memory(GiB)": 67.44,
      "step": 6225,
      "train_speed(iter/s)": 0.253482
    },
    {
      "epoch": 0.581102509094301,
      "grad_norm": 5.240560531616211,
      "learning_rate": 9.880636606069914e-06,
      "loss": 0.4913285732269287,
      "memory(GiB)": 67.44,
      "step": 6230,
      "train_speed(iter/s)": 0.253483
    },
    {
      "epoch": 0.5815688834996735,
      "grad_norm": 4.293078422546387,
      "learning_rate": 9.880301388847985e-06,
      "loss": 0.541919755935669,
      "memory(GiB)": 67.44,
      "step": 6235,
      "train_speed(iter/s)": 0.253498
    },
    {
      "epoch": 0.5820352579050462,
      "grad_norm": 5.573566436767578,
      "learning_rate": 9.879965707280413e-06,
      "loss": 0.536495304107666,
      "memory(GiB)": 67.44,
      "step": 6240,
      "train_speed(iter/s)": 0.253515
    },
    {
      "epoch": 0.5825016323104188,
      "grad_norm": 7.988020896911621,
      "learning_rate": 9.879629561399138e-06,
      "loss": 0.5614644527435303,
      "memory(GiB)": 67.44,
      "step": 6245,
      "train_speed(iter/s)": 0.253519
    },
    {
      "epoch": 0.5829680067157914,
      "grad_norm": 4.812214374542236,
      "learning_rate": 9.879292951236142e-06,
      "loss": 0.5084919929504395,
      "memory(GiB)": 67.44,
      "step": 6250,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.253532
    },
    {
      "epoch": 0.5834343811211641,
      "grad_norm": 5.9648332595825195,
      "learning_rate": 9.878955876823452e-06,
      "loss": 0.5183236598968506,
      "memory(GiB)": 67.44,
      "step": 6255,
      "train_speed(iter/s)": 0.253531
    },
    {
      "epoch": 0.5839007555265368,
      "grad_norm": 6.452895641326904,
      "learning_rate": 9.87861833819314e-06,
      "loss": 0.5382441520690918,
      "memory(GiB)": 67.44,
      "step": 6260,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.253532
    },
    {
      "epoch": 0.5843671299319093,
      "grad_norm": 5.148748874664307,
      "learning_rate": 9.878280335377324e-06,
      "loss": 0.5697350978851319,
      "memory(GiB)": 67.44,
      "step": 6265,
      "token_acc": 0.8817204301075269,
      "train_speed(iter/s)": 0.253534
    },
    {
      "epoch": 0.584833504337282,
      "grad_norm": 5.457209587097168,
      "learning_rate": 9.87794186840816e-06,
      "loss": 0.5006856918334961,
      "memory(GiB)": 67.44,
      "step": 6270,
      "train_speed(iter/s)": 0.253544
    },
    {
      "epoch": 0.5852998787426547,
      "grad_norm": 8.950328826904297,
      "learning_rate": 9.877602937317854e-06,
      "loss": 0.5178586959838867,
      "memory(GiB)": 67.44,
      "step": 6275,
      "train_speed(iter/s)": 0.253539
    },
    {
      "epoch": 0.5857662531480272,
      "grad_norm": 8.107276916503906,
      "learning_rate": 9.877263542138657e-06,
      "loss": 0.47985191345214845,
      "memory(GiB)": 67.44,
      "step": 6280,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.253546
    },
    {
      "epoch": 0.5862326275533999,
      "grad_norm": 6.329423427581787,
      "learning_rate": 9.876923682902856e-06,
      "loss": 0.548520565032959,
      "memory(GiB)": 67.44,
      "step": 6285,
      "token_acc": 0.8777777777777778,
      "train_speed(iter/s)": 0.253546
    },
    {
      "epoch": 0.5866990019587724,
      "grad_norm": 9.18973159790039,
      "learning_rate": 9.876583359642791e-06,
      "loss": 0.5923128604888916,
      "memory(GiB)": 67.44,
      "step": 6290,
      "train_speed(iter/s)": 0.253545
    },
    {
      "epoch": 0.5871653763641451,
      "grad_norm": 7.2749834060668945,
      "learning_rate": 9.876242572390844e-06,
      "loss": 0.5566725254058837,
      "memory(GiB)": 67.44,
      "step": 6295,
      "train_speed(iter/s)": 0.253541
    },
    {
      "epoch": 0.5876317507695178,
      "grad_norm": 6.256485462188721,
      "learning_rate": 9.875901321179434e-06,
      "loss": 0.5005714416503906,
      "memory(GiB)": 67.44,
      "step": 6300,
      "token_acc": 0.5370370370370371,
      "train_speed(iter/s)": 0.253537
    },
    {
      "epoch": 0.5880981251748904,
      "grad_norm": 4.728127956390381,
      "learning_rate": 9.875559606041037e-06,
      "loss": 0.5087875843048095,
      "memory(GiB)": 67.44,
      "step": 6305,
      "train_speed(iter/s)": 0.253537
    },
    {
      "epoch": 0.588564499580263,
      "grad_norm": 5.1799702644348145,
      "learning_rate": 9.875217427008162e-06,
      "loss": 0.5070194244384766,
      "memory(GiB)": 67.44,
      "step": 6310,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.253531
    },
    {
      "epoch": 0.5890308739856357,
      "grad_norm": 3.6292262077331543,
      "learning_rate": 9.874874784113368e-06,
      "loss": 0.5161759376525878,
      "memory(GiB)": 67.44,
      "step": 6315,
      "token_acc": 0.8013245033112583,
      "train_speed(iter/s)": 0.253541
    },
    {
      "epoch": 0.5894972483910083,
      "grad_norm": 5.636674404144287,
      "learning_rate": 9.874531677389255e-06,
      "loss": 0.47699365615844724,
      "memory(GiB)": 67.44,
      "step": 6320,
      "train_speed(iter/s)": 0.253539
    },
    {
      "epoch": 0.5899636227963809,
      "grad_norm": 11.611326217651367,
      "learning_rate": 9.87418810686847e-06,
      "loss": 0.495665454864502,
      "memory(GiB)": 67.44,
      "step": 6325,
      "token_acc": 0.9012345679012346,
      "train_speed(iter/s)": 0.253531
    },
    {
      "epoch": 0.5904299972017536,
      "grad_norm": 10.73554801940918,
      "learning_rate": 9.8738440725837e-06,
      "loss": 0.5550313949584961,
      "memory(GiB)": 67.44,
      "step": 6330,
      "token_acc": 0.3870967741935484,
      "train_speed(iter/s)": 0.253525
    },
    {
      "epoch": 0.5908963716071262,
      "grad_norm": 5.360098361968994,
      "learning_rate": 9.873499574567681e-06,
      "loss": 0.5181085586547851,
      "memory(GiB)": 67.44,
      "step": 6335,
      "token_acc": 0.6909090909090909,
      "train_speed(iter/s)": 0.253542
    },
    {
      "epoch": 0.5913627460124988,
      "grad_norm": 8.75585651397705,
      "learning_rate": 9.873154612853192e-06,
      "loss": 0.5778768539428711,
      "memory(GiB)": 67.44,
      "step": 6340,
      "token_acc": 0.864406779661017,
      "train_speed(iter/s)": 0.253546
    },
    {
      "epoch": 0.5918291204178715,
      "grad_norm": 11.413469314575195,
      "learning_rate": 9.872809187473054e-06,
      "loss": 0.5575488090515137,
      "memory(GiB)": 67.44,
      "step": 6345,
      "token_acc": 0.9550561797752809,
      "train_speed(iter/s)": 0.253539
    },
    {
      "epoch": 0.5922954948232441,
      "grad_norm": 15.516487121582031,
      "learning_rate": 9.872463298460132e-06,
      "loss": 0.5261972427368165,
      "memory(GiB)": 67.44,
      "step": 6350,
      "train_speed(iter/s)": 0.253545
    },
    {
      "epoch": 0.5927618692286167,
      "grad_norm": 8.64868450164795,
      "learning_rate": 9.872116945847339e-06,
      "loss": 0.5587272644042969,
      "memory(GiB)": 67.44,
      "step": 6355,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.253545
    },
    {
      "epoch": 0.5932282436339894,
      "grad_norm": 10.30521297454834,
      "learning_rate": 9.871770129667626e-06,
      "loss": 0.5846833705902099,
      "memory(GiB)": 67.44,
      "step": 6360,
      "token_acc": 0.71875,
      "train_speed(iter/s)": 0.253558
    },
    {
      "epoch": 0.593694618039362,
      "grad_norm": 4.020097732543945,
      "learning_rate": 9.871422849953993e-06,
      "loss": 0.5497324943542481,
      "memory(GiB)": 67.44,
      "step": 6365,
      "train_speed(iter/s)": 0.253551
    },
    {
      "epoch": 0.5941609924447346,
      "grad_norm": 6.830291271209717,
      "learning_rate": 9.871075106739483e-06,
      "loss": 0.5810272216796875,
      "memory(GiB)": 67.44,
      "step": 6370,
      "train_speed(iter/s)": 0.253553
    },
    {
      "epoch": 0.5946273668501073,
      "grad_norm": 8.610631942749023,
      "learning_rate": 9.870726900057182e-06,
      "loss": 0.5112139701843261,
      "memory(GiB)": 67.44,
      "step": 6375,
      "train_speed(iter/s)": 0.253554
    },
    {
      "epoch": 0.5950937412554799,
      "grad_norm": 7.122512340545654,
      "learning_rate": 9.87037822994022e-06,
      "loss": 0.5489683628082276,
      "memory(GiB)": 67.44,
      "step": 6380,
      "token_acc": 0.5692307692307692,
      "train_speed(iter/s)": 0.253552
    },
    {
      "epoch": 0.5955601156608525,
      "grad_norm": 6.68821907043457,
      "learning_rate": 9.870029096421773e-06,
      "loss": 0.529561185836792,
      "memory(GiB)": 67.44,
      "step": 6385,
      "train_speed(iter/s)": 0.253549
    },
    {
      "epoch": 0.5960264900662252,
      "grad_norm": 8.826035499572754,
      "learning_rate": 9.869679499535062e-06,
      "loss": 0.52779541015625,
      "memory(GiB)": 67.44,
      "step": 6390,
      "train_speed(iter/s)": 0.253551
    },
    {
      "epoch": 0.5964928644715978,
      "grad_norm": 3.461254596710205,
      "learning_rate": 9.869329439313347e-06,
      "loss": 0.5355129241943359,
      "memory(GiB)": 67.44,
      "step": 6395,
      "token_acc": 0.8888888888888888,
      "train_speed(iter/s)": 0.253556
    },
    {
      "epoch": 0.5969592388769704,
      "grad_norm": 8.258235931396484,
      "learning_rate": 9.868978915789937e-06,
      "loss": 0.5348270416259766,
      "memory(GiB)": 67.44,
      "step": 6400,
      "token_acc": 0.5111111111111111,
      "train_speed(iter/s)": 0.253552
    },
    {
      "epoch": 0.5974256132823431,
      "grad_norm": 9.647782325744629,
      "learning_rate": 9.86862792899818e-06,
      "loss": 0.5069501876831055,
      "memory(GiB)": 67.44,
      "step": 6405,
      "train_speed(iter/s)": 0.253558
    },
    {
      "epoch": 0.5978919876877157,
      "grad_norm": 11.202799797058105,
      "learning_rate": 9.868276478971476e-06,
      "loss": 0.5486734867095947,
      "memory(GiB)": 67.44,
      "step": 6410,
      "train_speed(iter/s)": 0.253563
    },
    {
      "epoch": 0.5983583620930883,
      "grad_norm": 5.473191738128662,
      "learning_rate": 9.867924565743261e-06,
      "loss": 0.49965248107910154,
      "memory(GiB)": 67.44,
      "step": 6415,
      "train_speed(iter/s)": 0.253568
    },
    {
      "epoch": 0.598824736498461,
      "grad_norm": 5.101795196533203,
      "learning_rate": 9.867572189347021e-06,
      "loss": 0.498292064666748,
      "memory(GiB)": 67.44,
      "step": 6420,
      "token_acc": 0.5892857142857143,
      "train_speed(iter/s)": 0.253581
    },
    {
      "epoch": 0.5992911109038336,
      "grad_norm": 17.499727249145508,
      "learning_rate": 9.867219349816282e-06,
      "loss": 0.5630437850952148,
      "memory(GiB)": 67.44,
      "step": 6425,
      "train_speed(iter/s)": 0.253573
    },
    {
      "epoch": 0.5997574853092063,
      "grad_norm": 4.757722854614258,
      "learning_rate": 9.866866047184613e-06,
      "loss": 0.518441104888916,
      "memory(GiB)": 67.44,
      "step": 6430,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.253578
    },
    {
      "epoch": 0.6002238597145788,
      "grad_norm": 5.991572380065918,
      "learning_rate": 9.866512281485636e-06,
      "loss": 0.5332677364349365,
      "memory(GiB)": 67.44,
      "step": 6435,
      "train_speed(iter/s)": 0.2536
    },
    {
      "epoch": 0.6006902341199515,
      "grad_norm": 8.836019515991211,
      "learning_rate": 9.866158052753006e-06,
      "loss": 0.5553024768829345,
      "memory(GiB)": 67.44,
      "step": 6440,
      "token_acc": 0.7697368421052632,
      "train_speed(iter/s)": 0.2536
    },
    {
      "epoch": 0.6011566085253242,
      "grad_norm": 6.328738212585449,
      "learning_rate": 9.865803361020426e-06,
      "loss": 0.4987751007080078,
      "memory(GiB)": 67.44,
      "step": 6445,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253596
    },
    {
      "epoch": 0.6016229829306967,
      "grad_norm": 7.001774787902832,
      "learning_rate": 9.865448206321646e-06,
      "loss": 0.5681880950927735,
      "memory(GiB)": 67.44,
      "step": 6450,
      "train_speed(iter/s)": 0.253608
    },
    {
      "epoch": 0.6020893573360694,
      "grad_norm": 6.912766456604004,
      "learning_rate": 9.86509258869046e-06,
      "loss": 0.5238738059997559,
      "memory(GiB)": 67.44,
      "step": 6455,
      "token_acc": 0.43103448275862066,
      "train_speed(iter/s)": 0.253596
    },
    {
      "epoch": 0.6025557317414421,
      "grad_norm": 4.944748401641846,
      "learning_rate": 9.864736508160699e-06,
      "loss": 0.49918642044067385,
      "memory(GiB)": 67.44,
      "step": 6460,
      "token_acc": 0.9111111111111111,
      "train_speed(iter/s)": 0.253593
    },
    {
      "epoch": 0.6030221061468146,
      "grad_norm": 4.0374579429626465,
      "learning_rate": 9.864379964766247e-06,
      "loss": 0.5201974868774414,
      "memory(GiB)": 67.44,
      "step": 6465,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.253585
    },
    {
      "epoch": 0.6034884805521873,
      "grad_norm": 5.095529079437256,
      "learning_rate": 9.864022958541026e-06,
      "loss": 0.5575624465942383,
      "memory(GiB)": 67.44,
      "step": 6470,
      "train_speed(iter/s)": 0.253586
    },
    {
      "epoch": 0.60395485495756,
      "grad_norm": 6.532177925109863,
      "learning_rate": 9.863665489519003e-06,
      "loss": 0.5248387336730957,
      "memory(GiB)": 67.44,
      "step": 6475,
      "token_acc": 0.4393939393939394,
      "train_speed(iter/s)": 0.253592
    },
    {
      "epoch": 0.6044212293629325,
      "grad_norm": 8.094846725463867,
      "learning_rate": 9.863307557734192e-06,
      "loss": 0.5221145629882813,
      "memory(GiB)": 67.44,
      "step": 6480,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.253581
    },
    {
      "epoch": 0.6048876037683052,
      "grad_norm": 5.617455005645752,
      "learning_rate": 9.862949163220651e-06,
      "loss": 0.5620074272155762,
      "memory(GiB)": 67.44,
      "step": 6485,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.25359
    },
    {
      "epoch": 0.6053539781736779,
      "grad_norm": 8.070347785949707,
      "learning_rate": 9.862590306012476e-06,
      "loss": 0.528178596496582,
      "memory(GiB)": 67.44,
      "step": 6490,
      "train_speed(iter/s)": 0.253595
    },
    {
      "epoch": 0.6058203525790504,
      "grad_norm": 4.212549686431885,
      "learning_rate": 9.862230986143813e-06,
      "loss": 0.5469985008239746,
      "memory(GiB)": 67.44,
      "step": 6495,
      "train_speed(iter/s)": 0.253601
    },
    {
      "epoch": 0.6062867269844231,
      "grad_norm": 4.104673385620117,
      "learning_rate": 9.86187120364885e-06,
      "loss": 0.5119469642639161,
      "memory(GiB)": 67.44,
      "step": 6500,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.253599
    },
    {
      "epoch": 0.6067531013897958,
      "grad_norm": 7.094793796539307,
      "learning_rate": 9.861510958561819e-06,
      "loss": 0.5006991386413574,
      "memory(GiB)": 67.44,
      "step": 6505,
      "token_acc": 0.40625,
      "train_speed(iter/s)": 0.253596
    },
    {
      "epoch": 0.6072194757951683,
      "grad_norm": 4.7015700340271,
      "learning_rate": 9.861150250916998e-06,
      "loss": 0.5521377563476563,
      "memory(GiB)": 67.44,
      "step": 6510,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.253603
    },
    {
      "epoch": 0.607685850200541,
      "grad_norm": 3.7323901653289795,
      "learning_rate": 9.860789080748705e-06,
      "loss": 0.5200013637542724,
      "memory(GiB)": 67.44,
      "step": 6515,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.253614
    },
    {
      "epoch": 0.6081522246059137,
      "grad_norm": 7.428400039672852,
      "learning_rate": 9.860427448091305e-06,
      "loss": 0.5405952453613281,
      "memory(GiB)": 67.44,
      "step": 6520,
      "token_acc": 0.423728813559322,
      "train_speed(iter/s)": 0.253611
    },
    {
      "epoch": 0.6086185990112862,
      "grad_norm": 6.170363426208496,
      "learning_rate": 9.860065352979207e-06,
      "loss": 0.49048557281494143,
      "memory(GiB)": 67.44,
      "step": 6525,
      "train_speed(iter/s)": 0.253617
    },
    {
      "epoch": 0.6090849734166589,
      "grad_norm": 11.143892288208008,
      "learning_rate": 9.859702795446862e-06,
      "loss": 0.4504398822784424,
      "memory(GiB)": 67.44,
      "step": 6530,
      "token_acc": 0.7368421052631579,
      "train_speed(iter/s)": 0.25362
    },
    {
      "epoch": 0.6095513478220316,
      "grad_norm": 6.187704563140869,
      "learning_rate": 9.859339775528766e-06,
      "loss": 0.5121289253234863,
      "memory(GiB)": 67.44,
      "step": 6535,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.253613
    },
    {
      "epoch": 0.6100177222274041,
      "grad_norm": 9.792952537536621,
      "learning_rate": 9.858976293259462e-06,
      "loss": 0.5634256839752197,
      "memory(GiB)": 67.44,
      "step": 6540,
      "token_acc": 0.40350877192982454,
      "train_speed(iter/s)": 0.253599
    },
    {
      "epoch": 0.6104840966327768,
      "grad_norm": 8.478928565979004,
      "learning_rate": 9.858612348673529e-06,
      "loss": 0.567147159576416,
      "memory(GiB)": 67.44,
      "step": 6545,
      "token_acc": 0.5274725274725275,
      "train_speed(iter/s)": 0.253598
    },
    {
      "epoch": 0.6109504710381495,
      "grad_norm": 5.364739418029785,
      "learning_rate": 9.8582479418056e-06,
      "loss": 0.5274478912353515,
      "memory(GiB)": 67.44,
      "step": 6550,
      "token_acc": 0.6890243902439024,
      "train_speed(iter/s)": 0.253606
    },
    {
      "epoch": 0.611416845443522,
      "grad_norm": 7.314317226409912,
      "learning_rate": 9.857883072690346e-06,
      "loss": 0.5428411483764648,
      "memory(GiB)": 67.44,
      "step": 6555,
      "token_acc": 0.8735632183908046,
      "train_speed(iter/s)": 0.253598
    },
    {
      "epoch": 0.6118832198488947,
      "grad_norm": 9.847982406616211,
      "learning_rate": 9.857517741362482e-06,
      "loss": 0.5636984825134277,
      "memory(GiB)": 67.44,
      "step": 6560,
      "train_speed(iter/s)": 0.253594
    },
    {
      "epoch": 0.6123495942542673,
      "grad_norm": 10.701915740966797,
      "learning_rate": 9.857151947856768e-06,
      "loss": 0.5353514671325683,
      "memory(GiB)": 67.44,
      "step": 6565,
      "token_acc": 0.5168539325842697,
      "train_speed(iter/s)": 0.253592
    },
    {
      "epoch": 0.6128159686596399,
      "grad_norm": 8.987578392028809,
      "learning_rate": 9.85678569220801e-06,
      "loss": 0.5356316089630127,
      "memory(GiB)": 67.44,
      "step": 6570,
      "token_acc": 0.5476190476190477,
      "train_speed(iter/s)": 0.253594
    },
    {
      "epoch": 0.6132823430650126,
      "grad_norm": 9.471691131591797,
      "learning_rate": 9.856418974451055e-06,
      "loss": 0.5496434688568115,
      "memory(GiB)": 67.44,
      "step": 6575,
      "token_acc": 0.5581395348837209,
      "train_speed(iter/s)": 0.25361
    },
    {
      "epoch": 0.6137487174703852,
      "grad_norm": 4.390590190887451,
      "learning_rate": 9.856051794620796e-06,
      "loss": 0.5405124664306641,
      "memory(GiB)": 67.44,
      "step": 6580,
      "token_acc": 0.5230769230769231,
      "train_speed(iter/s)": 0.253617
    },
    {
      "epoch": 0.6142150918757578,
      "grad_norm": 3.7341325283050537,
      "learning_rate": 9.855684152752167e-06,
      "loss": 0.5232263088226319,
      "memory(GiB)": 67.44,
      "step": 6585,
      "train_speed(iter/s)": 0.253621
    },
    {
      "epoch": 0.6146814662811305,
      "grad_norm": 4.125522136688232,
      "learning_rate": 9.85531604888015e-06,
      "loss": 0.5385582923889161,
      "memory(GiB)": 67.44,
      "step": 6590,
      "token_acc": 0.6190476190476191,
      "train_speed(iter/s)": 0.253631
    },
    {
      "epoch": 0.6151478406865031,
      "grad_norm": 10.26660442352295,
      "learning_rate": 9.854947483039767e-06,
      "loss": 0.5501980304718017,
      "memory(GiB)": 67.44,
      "step": 6595,
      "token_acc": 0.6875,
      "train_speed(iter/s)": 0.253622
    },
    {
      "epoch": 0.6156142150918757,
      "grad_norm": 5.723423004150391,
      "learning_rate": 9.854578455266088e-06,
      "loss": 0.5479249954223633,
      "memory(GiB)": 67.44,
      "step": 6600,
      "train_speed(iter/s)": 0.253629
    },
    {
      "epoch": 0.6160805894972484,
      "grad_norm": 9.302260398864746,
      "learning_rate": 9.854208965594222e-06,
      "loss": 0.5372279644012451,
      "memory(GiB)": 67.44,
      "step": 6605,
      "token_acc": 0.7905982905982906,
      "train_speed(iter/s)": 0.253627
    },
    {
      "epoch": 0.616546963902621,
      "grad_norm": 5.789456367492676,
      "learning_rate": 9.85383901405933e-06,
      "loss": 0.5165339469909668,
      "memory(GiB)": 67.44,
      "step": 6610,
      "token_acc": 0.84375,
      "train_speed(iter/s)": 0.253619
    },
    {
      "epoch": 0.6170133383079937,
      "grad_norm": 6.977084636688232,
      "learning_rate": 9.853468600696607e-06,
      "loss": 0.5396884918212891,
      "memory(GiB)": 67.44,
      "step": 6615,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.253613
    },
    {
      "epoch": 0.6174797127133663,
      "grad_norm": 5.380164623260498,
      "learning_rate": 9.853097725541298e-06,
      "loss": 0.5170833587646484,
      "memory(GiB)": 67.44,
      "step": 6620,
      "train_speed(iter/s)": 0.253624
    },
    {
      "epoch": 0.6179460871187389,
      "grad_norm": 4.75980281829834,
      "learning_rate": 9.85272638862869e-06,
      "loss": 0.5253809928894043,
      "memory(GiB)": 67.44,
      "step": 6625,
      "train_speed(iter/s)": 0.253632
    },
    {
      "epoch": 0.6184124615241116,
      "grad_norm": 5.044056415557861,
      "learning_rate": 9.852354589994115e-06,
      "loss": 0.5200170040130615,
      "memory(GiB)": 67.44,
      "step": 6630,
      "train_speed(iter/s)": 0.253637
    },
    {
      "epoch": 0.6188788359294842,
      "grad_norm": 6.806130886077881,
      "learning_rate": 9.85198232967295e-06,
      "loss": 0.5565983295440674,
      "memory(GiB)": 67.44,
      "step": 6635,
      "train_speed(iter/s)": 0.253646
    },
    {
      "epoch": 0.6193452103348568,
      "grad_norm": 6.431849002838135,
      "learning_rate": 9.851609607700614e-06,
      "loss": 0.5698983669281006,
      "memory(GiB)": 67.44,
      "step": 6640,
      "train_speed(iter/s)": 0.253643
    },
    {
      "epoch": 0.6198115847402295,
      "grad_norm": 6.869832992553711,
      "learning_rate": 9.851236424112566e-06,
      "loss": 0.5423671245574951,
      "memory(GiB)": 67.44,
      "step": 6645,
      "train_speed(iter/s)": 0.253646
    },
    {
      "epoch": 0.6202779591456021,
      "grad_norm": 3.875976085662842,
      "learning_rate": 9.850862778944321e-06,
      "loss": 0.540448522567749,
      "memory(GiB)": 67.44,
      "step": 6650,
      "train_speed(iter/s)": 0.253645
    },
    {
      "epoch": 0.6207443335509747,
      "grad_norm": 5.315507411956787,
      "learning_rate": 9.850488672231424e-06,
      "loss": 0.5025953769683837,
      "memory(GiB)": 67.44,
      "step": 6655,
      "token_acc": 0.8734177215189873,
      "train_speed(iter/s)": 0.253642
    },
    {
      "epoch": 0.6212107079563474,
      "grad_norm": 9.430986404418945,
      "learning_rate": 9.850114104009473e-06,
      "loss": 0.46775250434875487,
      "memory(GiB)": 67.44,
      "step": 6660,
      "train_speed(iter/s)": 0.253645
    },
    {
      "epoch": 0.62167708236172,
      "grad_norm": 6.281225204467773,
      "learning_rate": 9.849739074314107e-06,
      "loss": 0.582364559173584,
      "memory(GiB)": 67.44,
      "step": 6665,
      "token_acc": 0.5285714285714286,
      "train_speed(iter/s)": 0.25364
    },
    {
      "epoch": 0.6221434567670926,
      "grad_norm": 4.065367221832275,
      "learning_rate": 9.849363583181005e-06,
      "loss": 0.5091458320617676,
      "memory(GiB)": 67.44,
      "step": 6670,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.253637
    },
    {
      "epoch": 0.6226098311724653,
      "grad_norm": 3.1657140254974365,
      "learning_rate": 9.848987630645898e-06,
      "loss": 0.5240725040435791,
      "memory(GiB)": 67.44,
      "step": 6675,
      "token_acc": 0.8095238095238095,
      "train_speed(iter/s)": 0.253649
    },
    {
      "epoch": 0.6230762055778379,
      "grad_norm": 6.547369480133057,
      "learning_rate": 9.848611216744556e-06,
      "loss": 0.5558722496032715,
      "memory(GiB)": 67.44,
      "step": 6680,
      "train_speed(iter/s)": 0.253652
    },
    {
      "epoch": 0.6235425799832105,
      "grad_norm": 5.516220569610596,
      "learning_rate": 9.848234341512795e-06,
      "loss": 0.5019032478332519,
      "memory(GiB)": 67.44,
      "step": 6685,
      "train_speed(iter/s)": 0.253665
    },
    {
      "epoch": 0.6240089543885832,
      "grad_norm": 5.6862311363220215,
      "learning_rate": 9.84785700498647e-06,
      "loss": 0.5197845458984375,
      "memory(GiB)": 67.44,
      "step": 6690,
      "train_speed(iter/s)": 0.253668
    },
    {
      "epoch": 0.6244753287939558,
      "grad_norm": 12.631762504577637,
      "learning_rate": 9.847479207201485e-06,
      "loss": 0.5761212348937989,
      "memory(GiB)": 67.44,
      "step": 6695,
      "token_acc": 0.4166666666666667,
      "train_speed(iter/s)": 0.253669
    },
    {
      "epoch": 0.6249417031993284,
      "grad_norm": 5.864691734313965,
      "learning_rate": 9.847100948193788e-06,
      "loss": 0.5703903198242187,
      "memory(GiB)": 67.44,
      "step": 6700,
      "token_acc": 0.9247311827956989,
      "train_speed(iter/s)": 0.253679
    },
    {
      "epoch": 0.6254080776047011,
      "grad_norm": 8.303492546081543,
      "learning_rate": 9.846722227999365e-06,
      "loss": 0.511548376083374,
      "memory(GiB)": 67.44,
      "step": 6705,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.253687
    },
    {
      "epoch": 0.6258744520100736,
      "grad_norm": 9.157535552978516,
      "learning_rate": 9.846343046654255e-06,
      "loss": 0.5242374420166016,
      "memory(GiB)": 67.44,
      "step": 6710,
      "train_speed(iter/s)": 0.253706
    },
    {
      "epoch": 0.6263408264154463,
      "grad_norm": 4.927406311035156,
      "learning_rate": 9.845963404194533e-06,
      "loss": 0.5211443901062012,
      "memory(GiB)": 67.44,
      "step": 6715,
      "train_speed(iter/s)": 0.253702
    },
    {
      "epoch": 0.626807200820819,
      "grad_norm": 8.26015853881836,
      "learning_rate": 9.845583300656321e-06,
      "loss": 0.5150370597839355,
      "memory(GiB)": 67.44,
      "step": 6720,
      "token_acc": 0.515625,
      "train_speed(iter/s)": 0.253708
    },
    {
      "epoch": 0.6272735752261915,
      "grad_norm": 6.413262367248535,
      "learning_rate": 9.845202736075786e-06,
      "loss": 0.48846683502197263,
      "memory(GiB)": 67.44,
      "step": 6725,
      "token_acc": 0.4411764705882353,
      "train_speed(iter/s)": 0.253715
    },
    {
      "epoch": 0.6277399496315642,
      "grad_norm": 4.460413455963135,
      "learning_rate": 9.844821710489136e-06,
      "loss": 0.5349692344665528,
      "memory(GiB)": 67.44,
      "step": 6730,
      "token_acc": 0.5138888888888888,
      "train_speed(iter/s)": 0.253718
    },
    {
      "epoch": 0.6282063240369369,
      "grad_norm": 9.799477577209473,
      "learning_rate": 9.844440223932626e-06,
      "loss": 0.4988832473754883,
      "memory(GiB)": 67.44,
      "step": 6735,
      "train_speed(iter/s)": 0.253717
    },
    {
      "epoch": 0.6286726984423094,
      "grad_norm": 6.398128509521484,
      "learning_rate": 9.84405827644255e-06,
      "loss": 0.5485560417175293,
      "memory(GiB)": 67.44,
      "step": 6740,
      "token_acc": 0.5096153846153846,
      "train_speed(iter/s)": 0.253727
    },
    {
      "epoch": 0.6291390728476821,
      "grad_norm": 6.195517539978027,
      "learning_rate": 9.843675868055253e-06,
      "loss": 0.534079647064209,
      "memory(GiB)": 67.44,
      "step": 6745,
      "token_acc": 0.5172413793103449,
      "train_speed(iter/s)": 0.253724
    },
    {
      "epoch": 0.6296054472530548,
      "grad_norm": 6.78211784362793,
      "learning_rate": 9.843292998807119e-06,
      "loss": 0.5461904525756835,
      "memory(GiB)": 67.44,
      "step": 6750,
      "train_speed(iter/s)": 0.253736
    },
    {
      "epoch": 0.6300718216584273,
      "grad_norm": 4.719863414764404,
      "learning_rate": 9.842909668734577e-06,
      "loss": 0.5263476371765137,
      "memory(GiB)": 67.44,
      "step": 6755,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.253729
    },
    {
      "epoch": 0.6305381960638,
      "grad_norm": 6.708802223205566,
      "learning_rate": 9.842525877874096e-06,
      "loss": 0.5546420097351075,
      "memory(GiB)": 67.44,
      "step": 6760,
      "train_speed(iter/s)": 0.253739
    },
    {
      "epoch": 0.6310045704691727,
      "grad_norm": 4.161558628082275,
      "learning_rate": 9.842141626262198e-06,
      "loss": 0.5575351238250732,
      "memory(GiB)": 67.44,
      "step": 6765,
      "token_acc": 0.7368421052631579,
      "train_speed(iter/s)": 0.253754
    },
    {
      "epoch": 0.6314709448745452,
      "grad_norm": 8.750155448913574,
      "learning_rate": 9.84175691393544e-06,
      "loss": 0.5043021202087402,
      "memory(GiB)": 67.44,
      "step": 6770,
      "token_acc": 0.865979381443299,
      "train_speed(iter/s)": 0.253764
    },
    {
      "epoch": 0.6319373192799179,
      "grad_norm": 7.622418403625488,
      "learning_rate": 9.841371740930428e-06,
      "loss": 0.5772939205169678,
      "memory(GiB)": 67.44,
      "step": 6775,
      "train_speed(iter/s)": 0.253763
    },
    {
      "epoch": 0.6324036936852906,
      "grad_norm": 7.8418097496032715,
      "learning_rate": 9.840986107283807e-06,
      "loss": 0.5486043930053711,
      "memory(GiB)": 67.44,
      "step": 6780,
      "token_acc": 0.45,
      "train_speed(iter/s)": 0.253773
    },
    {
      "epoch": 0.6328700680906632,
      "grad_norm": 7.367436408996582,
      "learning_rate": 9.840600013032273e-06,
      "loss": 0.5529326438903809,
      "memory(GiB)": 67.44,
      "step": 6785,
      "train_speed(iter/s)": 0.253784
    },
    {
      "epoch": 0.6333364424960358,
      "grad_norm": 4.938000202178955,
      "learning_rate": 9.84021345821256e-06,
      "loss": 0.5130605220794677,
      "memory(GiB)": 67.44,
      "step": 6790,
      "train_speed(iter/s)": 0.253787
    },
    {
      "epoch": 0.6338028169014085,
      "grad_norm": 4.2698588371276855,
      "learning_rate": 9.839826442861444e-06,
      "loss": 0.47911858558654785,
      "memory(GiB)": 67.44,
      "step": 6795,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.253793
    },
    {
      "epoch": 0.634269191306781,
      "grad_norm": 3.880425453186035,
      "learning_rate": 9.839438967015754e-06,
      "loss": 0.5097744464874268,
      "memory(GiB)": 67.44,
      "step": 6800,
      "train_speed(iter/s)": 0.253785
    },
    {
      "epoch": 0.6347355657121537,
      "grad_norm": 7.300854206085205,
      "learning_rate": 9.839051030712354e-06,
      "loss": 0.5646976470947266,
      "memory(GiB)": 67.44,
      "step": 6805,
      "token_acc": 0.875,
      "train_speed(iter/s)": 0.253794
    },
    {
      "epoch": 0.6352019401175264,
      "grad_norm": 3.934605360031128,
      "learning_rate": 9.838662633988154e-06,
      "loss": 0.5202108383178711,
      "memory(GiB)": 67.44,
      "step": 6810,
      "train_speed(iter/s)": 0.253801
    },
    {
      "epoch": 0.635668314522899,
      "grad_norm": 4.628709316253662,
      "learning_rate": 9.838273776880111e-06,
      "loss": 0.5101121425628662,
      "memory(GiB)": 67.44,
      "step": 6815,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253789
    },
    {
      "epoch": 0.6361346889282716,
      "grad_norm": 11.055768013000488,
      "learning_rate": 9.837884459425225e-06,
      "loss": 0.5053435325622558,
      "memory(GiB)": 67.44,
      "step": 6820,
      "token_acc": 0.37142857142857144,
      "train_speed(iter/s)": 0.253788
    },
    {
      "epoch": 0.6366010633336443,
      "grad_norm": 7.186440944671631,
      "learning_rate": 9.837494681660534e-06,
      "loss": 0.535405445098877,
      "memory(GiB)": 67.44,
      "step": 6825,
      "token_acc": 0.463768115942029,
      "train_speed(iter/s)": 0.253781
    },
    {
      "epoch": 0.6370674377390169,
      "grad_norm": 8.60318660736084,
      "learning_rate": 9.837104443623127e-06,
      "loss": 0.46186141967773436,
      "memory(GiB)": 67.44,
      "step": 6830,
      "token_acc": 0.509090909090909,
      "train_speed(iter/s)": 0.25378
    },
    {
      "epoch": 0.6375338121443895,
      "grad_norm": 2.417910575866699,
      "learning_rate": 9.836713745350132e-06,
      "loss": 0.5314754486083985,
      "memory(GiB)": 67.44,
      "step": 6835,
      "token_acc": 0.5368421052631579,
      "train_speed(iter/s)": 0.253781
    },
    {
      "epoch": 0.6380001865497621,
      "grad_norm": 3.5633065700531006,
      "learning_rate": 9.836322586878725e-06,
      "loss": 0.5441804885864258,
      "memory(GiB)": 67.44,
      "step": 6840,
      "train_speed(iter/s)": 0.253774
    },
    {
      "epoch": 0.6384665609551348,
      "grad_norm": 6.779713153839111,
      "learning_rate": 9.835930968246124e-06,
      "loss": 0.5155511856079101,
      "memory(GiB)": 67.44,
      "step": 6845,
      "token_acc": 0.4473684210526316,
      "train_speed(iter/s)": 0.253779
    },
    {
      "epoch": 0.6389329353605074,
      "grad_norm": 5.610547065734863,
      "learning_rate": 9.835538889489586e-06,
      "loss": 0.5299905300140381,
      "memory(GiB)": 67.44,
      "step": 6850,
      "token_acc": 0.3902439024390244,
      "train_speed(iter/s)": 0.25377
    },
    {
      "epoch": 0.63939930976588,
      "grad_norm": 5.2325439453125,
      "learning_rate": 9.83514635064642e-06,
      "loss": 0.5592465877532959,
      "memory(GiB)": 67.44,
      "step": 6855,
      "train_speed(iter/s)": 0.253765
    },
    {
      "epoch": 0.6398656841712527,
      "grad_norm": 4.160566806793213,
      "learning_rate": 9.834753351753975e-06,
      "loss": 0.4989060401916504,
      "memory(GiB)": 67.44,
      "step": 6860,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.253776
    },
    {
      "epoch": 0.6403320585766253,
      "grad_norm": 6.040341377258301,
      "learning_rate": 9.83435989284964e-06,
      "loss": 0.518974781036377,
      "memory(GiB)": 67.44,
      "step": 6865,
      "token_acc": 0.44805194805194803,
      "train_speed(iter/s)": 0.253784
    },
    {
      "epoch": 0.6407984329819979,
      "grad_norm": 10.04483413696289,
      "learning_rate": 9.833965973970857e-06,
      "loss": 0.48325419425964355,
      "memory(GiB)": 67.44,
      "step": 6870,
      "train_speed(iter/s)": 0.253784
    },
    {
      "epoch": 0.6412648073873706,
      "grad_norm": 4.898577690124512,
      "learning_rate": 9.8335715951551e-06,
      "loss": 0.518578052520752,
      "memory(GiB)": 67.44,
      "step": 6875,
      "train_speed(iter/s)": 0.25379
    },
    {
      "epoch": 0.6417311817927432,
      "grad_norm": 6.709415435791016,
      "learning_rate": 9.833176756439899e-06,
      "loss": 0.525501298904419,
      "memory(GiB)": 67.44,
      "step": 6880,
      "train_speed(iter/s)": 0.253792
    },
    {
      "epoch": 0.6421975561981158,
      "grad_norm": 7.14274787902832,
      "learning_rate": 9.832781457862817e-06,
      "loss": 0.5384667396545411,
      "memory(GiB)": 67.44,
      "step": 6885,
      "train_speed(iter/s)": 0.253793
    },
    {
      "epoch": 0.6426639306034885,
      "grad_norm": 5.282345771789551,
      "learning_rate": 9.832385699461466e-06,
      "loss": 0.45848355293273924,
      "memory(GiB)": 67.44,
      "step": 6890,
      "token_acc": 0.8865979381443299,
      "train_speed(iter/s)": 0.253786
    },
    {
      "epoch": 0.6431303050088611,
      "grad_norm": 4.545693874359131,
      "learning_rate": 9.831989481273502e-06,
      "loss": 0.5618117809295654,
      "memory(GiB)": 67.44,
      "step": 6895,
      "token_acc": 0.7185185185185186,
      "train_speed(iter/s)": 0.253782
    },
    {
      "epoch": 0.6435966794142337,
      "grad_norm": 5.772584915161133,
      "learning_rate": 9.831592803336627e-06,
      "loss": 0.5138365268707276,
      "memory(GiB)": 67.44,
      "step": 6900,
      "train_speed(iter/s)": 0.253784
    },
    {
      "epoch": 0.6440630538196064,
      "grad_norm": 8.15114974975586,
      "learning_rate": 9.831195665688578e-06,
      "loss": 0.5007087707519531,
      "memory(GiB)": 67.44,
      "step": 6905,
      "train_speed(iter/s)": 0.25379
    },
    {
      "epoch": 0.644529428224979,
      "grad_norm": 4.873805522918701,
      "learning_rate": 9.830798068367145e-06,
      "loss": 0.49846935272216797,
      "memory(GiB)": 67.44,
      "step": 6910,
      "token_acc": 0.8053691275167785,
      "train_speed(iter/s)": 0.253794
    },
    {
      "epoch": 0.6449958026303516,
      "grad_norm": 9.699060440063477,
      "learning_rate": 9.830400011410159e-06,
      "loss": 0.5427493095397949,
      "memory(GiB)": 67.44,
      "step": 6915,
      "train_speed(iter/s)": 0.253792
    },
    {
      "epoch": 0.6454621770357243,
      "grad_norm": 5.99918270111084,
      "learning_rate": 9.83000149485549e-06,
      "loss": 0.5384907722473145,
      "memory(GiB)": 67.44,
      "step": 6920,
      "token_acc": 0.7466666666666667,
      "train_speed(iter/s)": 0.253791
    },
    {
      "epoch": 0.645928551441097,
      "grad_norm": 6.453415393829346,
      "learning_rate": 9.82960251874106e-06,
      "loss": 0.5321389198303222,
      "memory(GiB)": 67.44,
      "step": 6925,
      "train_speed(iter/s)": 0.253811
    },
    {
      "epoch": 0.6463949258464695,
      "grad_norm": 4.675931930541992,
      "learning_rate": 9.829203083104827e-06,
      "loss": 0.5278664588928222,
      "memory(GiB)": 67.44,
      "step": 6930,
      "token_acc": 0.5869565217391305,
      "train_speed(iter/s)": 0.25381
    },
    {
      "epoch": 0.6468613002518422,
      "grad_norm": 6.206606388092041,
      "learning_rate": 9.828803187984798e-06,
      "loss": 0.5225375652313232,
      "memory(GiB)": 67.44,
      "step": 6935,
      "token_acc": 0.9326923076923077,
      "train_speed(iter/s)": 0.253815
    },
    {
      "epoch": 0.6473276746572149,
      "grad_norm": 3.9259989261627197,
      "learning_rate": 9.828402833419021e-06,
      "loss": 0.543370532989502,
      "memory(GiB)": 67.44,
      "step": 6940,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.253819
    },
    {
      "epoch": 0.6477940490625874,
      "grad_norm": 5.665220737457275,
      "learning_rate": 9.828002019445588e-06,
      "loss": 0.5173797607421875,
      "memory(GiB)": 67.44,
      "step": 6945,
      "token_acc": 0.4852941176470588,
      "train_speed(iter/s)": 0.253823
    },
    {
      "epoch": 0.6482604234679601,
      "grad_norm": 9.692127227783203,
      "learning_rate": 9.827600746102636e-06,
      "loss": 0.48537116050720214,
      "memory(GiB)": 67.44,
      "step": 6950,
      "train_speed(iter/s)": 0.253822
    },
    {
      "epoch": 0.6487267978733328,
      "grad_norm": 5.887535572052002,
      "learning_rate": 9.827199013428346e-06,
      "loss": 0.5348196506500245,
      "memory(GiB)": 67.44,
      "step": 6955,
      "train_speed(iter/s)": 0.253833
    },
    {
      "epoch": 0.6491931722787053,
      "grad_norm": 4.3846869468688965,
      "learning_rate": 9.826796821460939e-06,
      "loss": 0.5240414619445801,
      "memory(GiB)": 67.44,
      "step": 6960,
      "token_acc": 0.96,
      "train_speed(iter/s)": 0.253832
    },
    {
      "epoch": 0.649659546684078,
      "grad_norm": 5.81769323348999,
      "learning_rate": 9.826394170238684e-06,
      "loss": 0.5200888633728027,
      "memory(GiB)": 67.44,
      "step": 6965,
      "train_speed(iter/s)": 0.253826
    },
    {
      "epoch": 0.6501259210894507,
      "grad_norm": 7.8269853591918945,
      "learning_rate": 9.825991059799893e-06,
      "loss": 0.5314352512359619,
      "memory(GiB)": 67.44,
      "step": 6970,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.253835
    },
    {
      "epoch": 0.6505922954948232,
      "grad_norm": 5.304687023162842,
      "learning_rate": 9.825587490182919e-06,
      "loss": 0.5406029701232911,
      "memory(GiB)": 67.44,
      "step": 6975,
      "token_acc": 0.6906474820143885,
      "train_speed(iter/s)": 0.253841
    },
    {
      "epoch": 0.6510586699001959,
      "grad_norm": 7.999438285827637,
      "learning_rate": 9.82518346142616e-06,
      "loss": 0.5191595554351807,
      "memory(GiB)": 67.44,
      "step": 6980,
      "train_speed(iter/s)": 0.253836
    },
    {
      "epoch": 0.6515250443055685,
      "grad_norm": 6.421064853668213,
      "learning_rate": 9.82477897356806e-06,
      "loss": 0.51809663772583,
      "memory(GiB)": 67.44,
      "step": 6985,
      "train_speed(iter/s)": 0.253826
    },
    {
      "epoch": 0.6519914187109411,
      "grad_norm": 6.570796489715576,
      "learning_rate": 9.824374026647103e-06,
      "loss": 0.5468934535980224,
      "memory(GiB)": 67.44,
      "step": 6990,
      "train_speed(iter/s)": 0.253818
    },
    {
      "epoch": 0.6524577931163138,
      "grad_norm": 7.75594425201416,
      "learning_rate": 9.82396862070182e-06,
      "loss": 0.5683060646057129,
      "memory(GiB)": 67.44,
      "step": 6995,
      "token_acc": 0.4473684210526316,
      "train_speed(iter/s)": 0.253821
    },
    {
      "epoch": 0.6529241675216864,
      "grad_norm": 5.08544397354126,
      "learning_rate": 9.823562755770783e-06,
      "loss": 0.4957616329193115,
      "memory(GiB)": 67.44,
      "step": 7000,
      "train_speed(iter/s)": 0.253822
    },
    {
      "epoch": 0.653390541927059,
      "grad_norm": 6.89007043838501,
      "learning_rate": 9.823156431892609e-06,
      "loss": 0.5556119918823242,
      "memory(GiB)": 67.44,
      "step": 7005,
      "train_speed(iter/s)": 0.253822
    },
    {
      "epoch": 0.6538569163324317,
      "grad_norm": 7.815919876098633,
      "learning_rate": 9.822749649105958e-06,
      "loss": 0.5243504524230957,
      "memory(GiB)": 67.44,
      "step": 7010,
      "train_speed(iter/s)": 0.253819
    },
    {
      "epoch": 0.6543232907378043,
      "grad_norm": 12.742974281311035,
      "learning_rate": 9.822342407449535e-06,
      "loss": 0.48497467041015624,
      "memory(GiB)": 67.44,
      "step": 7015,
      "token_acc": 0.4861111111111111,
      "train_speed(iter/s)": 0.253829
    },
    {
      "epoch": 0.6547896651431769,
      "grad_norm": 8.873085975646973,
      "learning_rate": 9.821934706962088e-06,
      "loss": 0.5371627807617188,
      "memory(GiB)": 67.44,
      "step": 7020,
      "train_speed(iter/s)": 0.253829
    },
    {
      "epoch": 0.6552560395485496,
      "grad_norm": 7.350225925445557,
      "learning_rate": 9.821526547682408e-06,
      "loss": 0.54429030418396,
      "memory(GiB)": 67.44,
      "step": 7025,
      "token_acc": 0.39215686274509803,
      "train_speed(iter/s)": 0.253839
    },
    {
      "epoch": 0.6557224139539222,
      "grad_norm": 5.523017406463623,
      "learning_rate": 9.82111792964933e-06,
      "loss": 0.49503283500671386,
      "memory(GiB)": 67.44,
      "step": 7030,
      "train_speed(iter/s)": 0.253849
    },
    {
      "epoch": 0.6561887883592948,
      "grad_norm": 4.937464714050293,
      "learning_rate": 9.820708852901733e-06,
      "loss": 0.5062957286834717,
      "memory(GiB)": 67.44,
      "step": 7035,
      "train_speed(iter/s)": 0.253847
    },
    {
      "epoch": 0.6566551627646675,
      "grad_norm": 11.920543670654297,
      "learning_rate": 9.820299317478539e-06,
      "loss": 0.5671836376190186,
      "memory(GiB)": 67.44,
      "step": 7040,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.253847
    },
    {
      "epoch": 0.6571215371700401,
      "grad_norm": 8.009057998657227,
      "learning_rate": 9.819889323418715e-06,
      "loss": 0.5568393707275391,
      "memory(GiB)": 67.44,
      "step": 7045,
      "token_acc": 0.7973856209150327,
      "train_speed(iter/s)": 0.253857
    },
    {
      "epoch": 0.6575879115754127,
      "grad_norm": 7.392345428466797,
      "learning_rate": 9.819478870761267e-06,
      "loss": 0.5518404006958008,
      "memory(GiB)": 67.44,
      "step": 7050,
      "token_acc": 0.423728813559322,
      "train_speed(iter/s)": 0.25385
    },
    {
      "epoch": 0.6580542859807854,
      "grad_norm": 6.985515594482422,
      "learning_rate": 9.819067959545254e-06,
      "loss": 0.5350561141967773,
      "memory(GiB)": 67.44,
      "step": 7055,
      "token_acc": 0.6491228070175439,
      "train_speed(iter/s)": 0.253852
    },
    {
      "epoch": 0.658520660386158,
      "grad_norm": 3.4131863117218018,
      "learning_rate": 9.818656589809769e-06,
      "loss": 0.5509994506835938,
      "memory(GiB)": 67.44,
      "step": 7060,
      "train_speed(iter/s)": 0.253854
    },
    {
      "epoch": 0.6589870347915306,
      "grad_norm": 6.824675559997559,
      "learning_rate": 9.818244761593956e-06,
      "loss": 0.5231914520263672,
      "memory(GiB)": 67.44,
      "step": 7065,
      "token_acc": 0.6689655172413793,
      "train_speed(iter/s)": 0.253861
    },
    {
      "epoch": 0.6594534091969033,
      "grad_norm": 5.394251346588135,
      "learning_rate": 9.817832474936995e-06,
      "loss": 0.5384469985961914,
      "memory(GiB)": 67.44,
      "step": 7070,
      "token_acc": 0.34615384615384615,
      "train_speed(iter/s)": 0.253861
    },
    {
      "epoch": 0.6599197836022759,
      "grad_norm": 5.136835098266602,
      "learning_rate": 9.817419729878115e-06,
      "loss": 0.5339128494262695,
      "memory(GiB)": 67.44,
      "step": 7075,
      "train_speed(iter/s)": 0.253863
    },
    {
      "epoch": 0.6603861580076485,
      "grad_norm": 7.629251480102539,
      "learning_rate": 9.81700652645659e-06,
      "loss": 0.5142649173736572,
      "memory(GiB)": 67.44,
      "step": 7080,
      "token_acc": 0.8857142857142857,
      "train_speed(iter/s)": 0.253867
    },
    {
      "epoch": 0.6608525324130212,
      "grad_norm": 4.283776760101318,
      "learning_rate": 9.816592864711731e-06,
      "loss": 0.5053018093109131,
      "memory(GiB)": 67.44,
      "step": 7085,
      "train_speed(iter/s)": 0.253875
    },
    {
      "epoch": 0.6613189068183938,
      "grad_norm": 3.4806230068206787,
      "learning_rate": 9.816178744682901e-06,
      "loss": 0.49781203269958496,
      "memory(GiB)": 67.44,
      "step": 7090,
      "train_speed(iter/s)": 0.253884
    },
    {
      "epoch": 0.6617852812237665,
      "grad_norm": 5.135397434234619,
      "learning_rate": 9.815764166409499e-06,
      "loss": 0.5094560146331787,
      "memory(GiB)": 67.44,
      "step": 7095,
      "token_acc": 0.5178571428571429,
      "train_speed(iter/s)": 0.253875
    },
    {
      "epoch": 0.6622516556291391,
      "grad_norm": 4.587351322174072,
      "learning_rate": 9.815349129930971e-06,
      "loss": 0.485564136505127,
      "memory(GiB)": 67.44,
      "step": 7100,
      "token_acc": 0.3953488372093023,
      "train_speed(iter/s)": 0.253871
    },
    {
      "epoch": 0.6627180300345117,
      "grad_norm": 3.2654104232788086,
      "learning_rate": 9.814933635286808e-06,
      "loss": 0.48064193725585935,
      "memory(GiB)": 67.44,
      "step": 7105,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.253866
    },
    {
      "epoch": 0.6631844044398844,
      "grad_norm": 8.525918960571289,
      "learning_rate": 9.814517682516542e-06,
      "loss": 0.5161863327026367,
      "memory(GiB)": 67.44,
      "step": 7110,
      "token_acc": 0.5797101449275363,
      "train_speed(iter/s)": 0.253855
    },
    {
      "epoch": 0.663650778845257,
      "grad_norm": 9.97869873046875,
      "learning_rate": 9.81410127165975e-06,
      "loss": 0.4941282272338867,
      "memory(GiB)": 67.44,
      "step": 7115,
      "token_acc": 0.6690647482014388,
      "train_speed(iter/s)": 0.253842
    },
    {
      "epoch": 0.6641171532506296,
      "grad_norm": 4.206097602844238,
      "learning_rate": 9.813684402756054e-06,
      "loss": 0.5363681316375732,
      "memory(GiB)": 67.44,
      "step": 7120,
      "token_acc": 0.38181818181818183,
      "train_speed(iter/s)": 0.253841
    },
    {
      "epoch": 0.6645835276560023,
      "grad_norm": 5.341970443725586,
      "learning_rate": 9.813267075845115e-06,
      "loss": 0.5577698707580566,
      "memory(GiB)": 67.44,
      "step": 7125,
      "token_acc": 0.4421052631578947,
      "train_speed(iter/s)": 0.253847
    },
    {
      "epoch": 0.6650499020613748,
      "grad_norm": 7.895837306976318,
      "learning_rate": 9.81284929096664e-06,
      "loss": 0.49460463523864745,
      "memory(GiB)": 67.44,
      "step": 7130,
      "token_acc": 0.48484848484848486,
      "train_speed(iter/s)": 0.253847
    },
    {
      "epoch": 0.6655162764667475,
      "grad_norm": 5.003539562225342,
      "learning_rate": 9.812431048160382e-06,
      "loss": 0.5639846801757813,
      "memory(GiB)": 67.44,
      "step": 7135,
      "token_acc": 0.7211538461538461,
      "train_speed(iter/s)": 0.253859
    },
    {
      "epoch": 0.6659826508721202,
      "grad_norm": 5.517605304718018,
      "learning_rate": 9.812012347466135e-06,
      "loss": 0.5011625766754151,
      "memory(GiB)": 67.44,
      "step": 7140,
      "train_speed(iter/s)": 0.253859
    },
    {
      "epoch": 0.6664490252774927,
      "grad_norm": 6.492578029632568,
      "learning_rate": 9.811593188923738e-06,
      "loss": 0.5831112861633301,
      "memory(GiB)": 67.44,
      "step": 7145,
      "train_speed(iter/s)": 0.253864
    },
    {
      "epoch": 0.6669153996828654,
      "grad_norm": 4.8013176918029785,
      "learning_rate": 9.811173572573072e-06,
      "loss": 0.5430544853210449,
      "memory(GiB)": 67.44,
      "step": 7150,
      "token_acc": 0.5660377358490566,
      "train_speed(iter/s)": 0.253861
    },
    {
      "epoch": 0.6673817740882381,
      "grad_norm": 6.354349613189697,
      "learning_rate": 9.81075349845406e-06,
      "loss": 0.5016016960144043,
      "memory(GiB)": 67.44,
      "step": 7155,
      "train_speed(iter/s)": 0.253873
    },
    {
      "epoch": 0.6678481484936106,
      "grad_norm": 4.371802806854248,
      "learning_rate": 9.810332966606673e-06,
      "loss": 0.46832098960876467,
      "memory(GiB)": 67.44,
      "step": 7160,
      "train_speed(iter/s)": 0.253875
    },
    {
      "epoch": 0.6683145228989833,
      "grad_norm": 6.006113052368164,
      "learning_rate": 9.809911977070923e-06,
      "loss": 0.5116536140441894,
      "memory(GiB)": 67.44,
      "step": 7165,
      "token_acc": 0.4230769230769231,
      "train_speed(iter/s)": 0.253888
    },
    {
      "epoch": 0.668780897304356,
      "grad_norm": 7.661343097686768,
      "learning_rate": 9.809490529886865e-06,
      "loss": 0.5251631736755371,
      "memory(GiB)": 67.44,
      "step": 7170,
      "train_speed(iter/s)": 0.25389
    },
    {
      "epoch": 0.6692472717097285,
      "grad_norm": 8.332918167114258,
      "learning_rate": 9.8090686250946e-06,
      "loss": 0.5272930145263672,
      "memory(GiB)": 67.44,
      "step": 7175,
      "token_acc": 0.4634146341463415,
      "train_speed(iter/s)": 0.253888
    },
    {
      "epoch": 0.6697136461151012,
      "grad_norm": 11.782195091247559,
      "learning_rate": 9.808646262734269e-06,
      "loss": 0.5372093200683594,
      "memory(GiB)": 67.44,
      "step": 7180,
      "train_speed(iter/s)": 0.253909
    },
    {
      "epoch": 0.6701800205204739,
      "grad_norm": 9.726602554321289,
      "learning_rate": 9.80822344284606e-06,
      "loss": 0.5425684452056885,
      "memory(GiB)": 67.44,
      "step": 7185,
      "train_speed(iter/s)": 0.253907
    },
    {
      "epoch": 0.6706463949258464,
      "grad_norm": 4.572440147399902,
      "learning_rate": 9.807800165470203e-06,
      "loss": 0.538730239868164,
      "memory(GiB)": 67.44,
      "step": 7190,
      "token_acc": 0.5806451612903226,
      "train_speed(iter/s)": 0.253918
    },
    {
      "epoch": 0.6711127693312191,
      "grad_norm": 6.999277114868164,
      "learning_rate": 9.807376430646971e-06,
      "loss": 0.5118902206420899,
      "memory(GiB)": 67.44,
      "step": 7195,
      "train_speed(iter/s)": 0.25391
    },
    {
      "epoch": 0.6715791437365918,
      "grad_norm": 7.995311737060547,
      "learning_rate": 9.806952238416681e-06,
      "loss": 0.5438454627990723,
      "memory(GiB)": 67.44,
      "step": 7200,
      "token_acc": 0.8987341772151899,
      "train_speed(iter/s)": 0.253926
    },
    {
      "epoch": 0.6720455181419643,
      "grad_norm": 4.271446704864502,
      "learning_rate": 9.806527588819692e-06,
      "loss": 0.532926368713379,
      "memory(GiB)": 67.44,
      "step": 7205,
      "train_speed(iter/s)": 0.253914
    },
    {
      "epoch": 0.672511892547337,
      "grad_norm": 4.5905303955078125,
      "learning_rate": 9.806102481896412e-06,
      "loss": 0.48531856536865237,
      "memory(GiB)": 67.44,
      "step": 7210,
      "train_speed(iter/s)": 0.253921
    },
    {
      "epoch": 0.6729782669527097,
      "grad_norm": 3.4236299991607666,
      "learning_rate": 9.805676917687285e-06,
      "loss": 0.47417488098144533,
      "memory(GiB)": 67.44,
      "step": 7215,
      "token_acc": 0.793939393939394,
      "train_speed(iter/s)": 0.253922
    },
    {
      "epoch": 0.6734446413580822,
      "grad_norm": 4.20452880859375,
      "learning_rate": 9.805250896232806e-06,
      "loss": 0.5080474853515625,
      "memory(GiB)": 67.44,
      "step": 7220,
      "token_acc": 0.4939759036144578,
      "train_speed(iter/s)": 0.25393
    },
    {
      "epoch": 0.6739110157634549,
      "grad_norm": 12.441695213317871,
      "learning_rate": 9.804824417573504e-06,
      "loss": 0.5254025459289551,
      "memory(GiB)": 67.44,
      "step": 7225,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253931
    },
    {
      "epoch": 0.6743773901688276,
      "grad_norm": 10.530496597290039,
      "learning_rate": 9.80439748174996e-06,
      "loss": 0.5320740699768066,
      "memory(GiB)": 67.44,
      "step": 7230,
      "train_speed(iter/s)": 0.253939
    },
    {
      "epoch": 0.6748437645742001,
      "grad_norm": 8.1884183883667,
      "learning_rate": 9.8039700888028e-06,
      "loss": 0.5074669361114502,
      "memory(GiB)": 67.44,
      "step": 7235,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.253947
    },
    {
      "epoch": 0.6753101389795728,
      "grad_norm": 5.106139659881592,
      "learning_rate": 9.803542238772682e-06,
      "loss": 0.5117311954498291,
      "memory(GiB)": 67.44,
      "step": 7240,
      "token_acc": 0.4827586206896552,
      "train_speed(iter/s)": 0.253948
    },
    {
      "epoch": 0.6757765133849455,
      "grad_norm": 2.7142693996429443,
      "learning_rate": 9.80311393170032e-06,
      "loss": 0.5026274681091308,
      "memory(GiB)": 67.44,
      "step": 7245,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.253941
    },
    {
      "epoch": 0.676242887790318,
      "grad_norm": 4.1345133781433105,
      "learning_rate": 9.80268516762646e-06,
      "loss": 0.5978588104248047,
      "memory(GiB)": 67.44,
      "step": 7250,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.253945
    },
    {
      "epoch": 0.6767092621956907,
      "grad_norm": 11.3357515335083,
      "learning_rate": 9.802255946591903e-06,
      "loss": 0.5327702522277832,
      "memory(GiB)": 67.44,
      "step": 7255,
      "token_acc": 0.49019607843137253,
      "train_speed(iter/s)": 0.253947
    },
    {
      "epoch": 0.6771756366010633,
      "grad_norm": 6.104199409484863,
      "learning_rate": 9.801826268637488e-06,
      "loss": 0.4832431793212891,
      "memory(GiB)": 67.44,
      "step": 7260,
      "train_speed(iter/s)": 0.253954
    },
    {
      "epoch": 0.677642011006436,
      "grad_norm": 3.948060989379883,
      "learning_rate": 9.801396133804094e-06,
      "loss": 0.5317389011383057,
      "memory(GiB)": 67.44,
      "step": 7265,
      "train_speed(iter/s)": 0.253944
    },
    {
      "epoch": 0.6781083854118086,
      "grad_norm": 6.203268527984619,
      "learning_rate": 9.80096554213265e-06,
      "loss": 0.5381085872650146,
      "memory(GiB)": 67.44,
      "step": 7270,
      "token_acc": 0.4358974358974359,
      "train_speed(iter/s)": 0.253952
    },
    {
      "epoch": 0.6785747598171812,
      "grad_norm": 11.742744445800781,
      "learning_rate": 9.800534493664124e-06,
      "loss": 0.5072714805603027,
      "memory(GiB)": 67.44,
      "step": 7275,
      "train_speed(iter/s)": 0.253948
    },
    {
      "epoch": 0.6790411342225539,
      "grad_norm": 9.101426124572754,
      "learning_rate": 9.80010298843953e-06,
      "loss": 0.524404239654541,
      "memory(GiB)": 67.44,
      "step": 7280,
      "token_acc": 0.5737704918032787,
      "train_speed(iter/s)": 0.25395
    },
    {
      "epoch": 0.6795075086279265,
      "grad_norm": 5.325688362121582,
      "learning_rate": 9.799671026499921e-06,
      "loss": 0.5358904361724853,
      "memory(GiB)": 67.44,
      "step": 7285,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.25396
    },
    {
      "epoch": 0.6799738830332991,
      "grad_norm": 6.165543079376221,
      "learning_rate": 9.799238607886403e-06,
      "loss": 0.4866324424743652,
      "memory(GiB)": 67.44,
      "step": 7290,
      "token_acc": 0.5660377358490566,
      "train_speed(iter/s)": 0.253956
    },
    {
      "epoch": 0.6804402574386718,
      "grad_norm": 8.89482307434082,
      "learning_rate": 9.798805732640115e-06,
      "loss": 0.5523427963256836,
      "memory(GiB)": 67.44,
      "step": 7295,
      "token_acc": 0.5818181818181818,
      "train_speed(iter/s)": 0.253946
    },
    {
      "epoch": 0.6809066318440444,
      "grad_norm": 7.796532154083252,
      "learning_rate": 9.798372400802244e-06,
      "loss": 0.5204180240631103,
      "memory(GiB)": 67.44,
      "step": 7300,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.253953
    },
    {
      "epoch": 0.681373006249417,
      "grad_norm": 8.690526008605957,
      "learning_rate": 9.797938612414022e-06,
      "loss": 0.5168177604675293,
      "memory(GiB)": 67.44,
      "step": 7305,
      "train_speed(iter/s)": 0.253952
    },
    {
      "epoch": 0.6818393806547897,
      "grad_norm": 7.690730571746826,
      "learning_rate": 9.79750436751672e-06,
      "loss": 0.5188029289245606,
      "memory(GiB)": 67.44,
      "step": 7310,
      "token_acc": 0.8732394366197183,
      "train_speed(iter/s)": 0.253947
    },
    {
      "epoch": 0.6823057550601623,
      "grad_norm": 6.412694931030273,
      "learning_rate": 9.797069666151657e-06,
      "loss": 0.5120516300201416,
      "memory(GiB)": 67.44,
      "step": 7315,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.253941
    },
    {
      "epoch": 0.6827721294655349,
      "grad_norm": 7.699547290802002,
      "learning_rate": 9.796634508360193e-06,
      "loss": 0.5483845233917236,
      "memory(GiB)": 67.44,
      "step": 7320,
      "token_acc": 0.475,
      "train_speed(iter/s)": 0.253944
    },
    {
      "epoch": 0.6832385038709076,
      "grad_norm": 4.378347396850586,
      "learning_rate": 9.796198894183732e-06,
      "loss": 0.5520059585571289,
      "memory(GiB)": 67.44,
      "step": 7325,
      "train_speed(iter/s)": 0.253931
    },
    {
      "epoch": 0.6837048782762802,
      "grad_norm": 5.571950435638428,
      "learning_rate": 9.795762823663721e-06,
      "loss": 0.503800630569458,
      "memory(GiB)": 67.44,
      "step": 7330,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.253943
    },
    {
      "epoch": 0.6841712526816528,
      "grad_norm": 7.115365505218506,
      "learning_rate": 9.795326296841651e-06,
      "loss": 0.5304100036621093,
      "memory(GiB)": 67.44,
      "step": 7335,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.253935
    },
    {
      "epoch": 0.6846376270870255,
      "grad_norm": 5.150783061981201,
      "learning_rate": 9.794889313759056e-06,
      "loss": 0.5450786590576172,
      "memory(GiB)": 67.44,
      "step": 7340,
      "token_acc": 0.559322033898305,
      "train_speed(iter/s)": 0.25394
    },
    {
      "epoch": 0.6851040014923981,
      "grad_norm": 7.549808502197266,
      "learning_rate": 9.794451874457514e-06,
      "loss": 0.5324692726135254,
      "memory(GiB)": 67.44,
      "step": 7345,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.253943
    },
    {
      "epoch": 0.6855703758977707,
      "grad_norm": 5.064990520477295,
      "learning_rate": 9.794013978978648e-06,
      "loss": 0.4656505584716797,
      "memory(GiB)": 67.44,
      "step": 7350,
      "train_speed(iter/s)": 0.253952
    },
    {
      "epoch": 0.6860367503031434,
      "grad_norm": 4.350268840789795,
      "learning_rate": 9.793575627364116e-06,
      "loss": 0.4882800102233887,
      "memory(GiB)": 67.44,
      "step": 7355,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.253952
    },
    {
      "epoch": 0.686503124708516,
      "grad_norm": 5.374025821685791,
      "learning_rate": 9.793136819655632e-06,
      "loss": 0.5056761741638184,
      "memory(GiB)": 67.44,
      "step": 7360,
      "token_acc": 0.5145631067961165,
      "train_speed(iter/s)": 0.25396
    },
    {
      "epoch": 0.6869694991138886,
      "grad_norm": 4.04974889755249,
      "learning_rate": 9.792697555894947e-06,
      "loss": 0.5495572090148926,
      "memory(GiB)": 67.44,
      "step": 7365,
      "train_speed(iter/s)": 0.253957
    },
    {
      "epoch": 0.6874358735192613,
      "grad_norm": 9.044812202453613,
      "learning_rate": 9.792257836123852e-06,
      "loss": 0.49725661277770994,
      "memory(GiB)": 67.44,
      "step": 7370,
      "train_speed(iter/s)": 0.253959
    },
    {
      "epoch": 0.687902247924634,
      "grad_norm": 7.093966484069824,
      "learning_rate": 9.791817660384187e-06,
      "loss": 0.5050729751586914,
      "memory(GiB)": 67.44,
      "step": 7375,
      "token_acc": 0.7484276729559748,
      "train_speed(iter/s)": 0.253952
    },
    {
      "epoch": 0.6883686223300065,
      "grad_norm": 3.290611743927002,
      "learning_rate": 9.791377028717835e-06,
      "loss": 0.4820086002349854,
      "memory(GiB)": 67.44,
      "step": 7380,
      "token_acc": 0.7588652482269503,
      "train_speed(iter/s)": 0.253953
    },
    {
      "epoch": 0.6888349967353792,
      "grad_norm": 3.260274887084961,
      "learning_rate": 9.790935941166718e-06,
      "loss": 0.4689279079437256,
      "memory(GiB)": 67.44,
      "step": 7385,
      "train_speed(iter/s)": 0.25396
    },
    {
      "epoch": 0.6893013711407519,
      "grad_norm": 4.236502647399902,
      "learning_rate": 9.790494397772804e-06,
      "loss": 0.5229323387145997,
      "memory(GiB)": 67.44,
      "step": 7390,
      "train_speed(iter/s)": 0.253976
    },
    {
      "epoch": 0.6897677455461244,
      "grad_norm": 7.200675010681152,
      "learning_rate": 9.790052398578104e-06,
      "loss": 0.49188919067382814,
      "memory(GiB)": 67.44,
      "step": 7395,
      "train_speed(iter/s)": 0.253975
    },
    {
      "epoch": 0.6902341199514971,
      "grad_norm": 5.935575485229492,
      "learning_rate": 9.789609943624676e-06,
      "loss": 0.5739440441131591,
      "memory(GiB)": 67.44,
      "step": 7400,
      "train_speed(iter/s)": 0.253975
    },
    {
      "epoch": 0.6907004943568696,
      "grad_norm": 3.842665433883667,
      "learning_rate": 9.789167032954619e-06,
      "loss": 0.5365453720092773,
      "memory(GiB)": 67.44,
      "step": 7405,
      "train_speed(iter/s)": 0.253984
    },
    {
      "epoch": 0.6911668687622423,
      "grad_norm": 16.643301010131836,
      "learning_rate": 9.788723666610069e-06,
      "loss": 0.5310874938964844,
      "memory(GiB)": 67.44,
      "step": 7410,
      "token_acc": 0.9156626506024096,
      "train_speed(iter/s)": 0.253985
    },
    {
      "epoch": 0.691633243167615,
      "grad_norm": 4.454357624053955,
      "learning_rate": 9.788279844633215e-06,
      "loss": 0.5089805126190186,
      "memory(GiB)": 67.44,
      "step": 7415,
      "train_speed(iter/s)": 0.254
    },
    {
      "epoch": 0.6920996175729875,
      "grad_norm": 4.088143825531006,
      "learning_rate": 9.787835567066285e-06,
      "loss": 0.5022553920745849,
      "memory(GiB)": 67.44,
      "step": 7420,
      "train_speed(iter/s)": 0.254006
    },
    {
      "epoch": 0.6925659919783602,
      "grad_norm": 4.245355606079102,
      "learning_rate": 9.787390833951548e-06,
      "loss": 0.5115784645080567,
      "memory(GiB)": 67.44,
      "step": 7425,
      "train_speed(iter/s)": 0.254004
    },
    {
      "epoch": 0.6930323663837329,
      "grad_norm": 2.653855562210083,
      "learning_rate": 9.786945645331325e-06,
      "loss": 0.5226807117462158,
      "memory(GiB)": 67.44,
      "step": 7430,
      "token_acc": 0.6111111111111112,
      "train_speed(iter/s)": 0.25399
    },
    {
      "epoch": 0.6934987407891055,
      "grad_norm": 5.590957164764404,
      "learning_rate": 9.786500001247968e-06,
      "loss": 0.5375874042510986,
      "memory(GiB)": 67.44,
      "step": 7435,
      "train_speed(iter/s)": 0.253987
    },
    {
      "epoch": 0.6939651151944781,
      "grad_norm": 4.929335594177246,
      "learning_rate": 9.786053901743882e-06,
      "loss": 0.544239091873169,
      "memory(GiB)": 67.44,
      "step": 7440,
      "train_speed(iter/s)": 0.25398
    },
    {
      "epoch": 0.6944314895998508,
      "grad_norm": 5.936305046081543,
      "learning_rate": 9.78560734686151e-06,
      "loss": 0.5193795204162598,
      "memory(GiB)": 67.44,
      "step": 7445,
      "train_speed(iter/s)": 0.253969
    },
    {
      "epoch": 0.6948978640052234,
      "grad_norm": 7.443017482757568,
      "learning_rate": 9.785160336643341e-06,
      "loss": 0.510008716583252,
      "memory(GiB)": 67.44,
      "step": 7450,
      "train_speed(iter/s)": 0.253967
    },
    {
      "epoch": 0.695364238410596,
      "grad_norm": 5.513338565826416,
      "learning_rate": 9.784712871131908e-06,
      "loss": 0.5005746841430664,
      "memory(GiB)": 67.44,
      "step": 7455,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.253978
    },
    {
      "epoch": 0.6958306128159687,
      "grad_norm": 8.459136009216309,
      "learning_rate": 9.784264950369785e-06,
      "loss": 0.5034268379211426,
      "memory(GiB)": 67.44,
      "step": 7460,
      "train_speed(iter/s)": 0.253967
    },
    {
      "epoch": 0.6962969872213413,
      "grad_norm": 5.614597320556641,
      "learning_rate": 9.783816574399589e-06,
      "loss": 0.5239885330200196,
      "memory(GiB)": 67.44,
      "step": 7465,
      "token_acc": 0.9320388349514563,
      "train_speed(iter/s)": 0.253969
    },
    {
      "epoch": 0.6967633616267139,
      "grad_norm": 7.8670549392700195,
      "learning_rate": 9.783367743263984e-06,
      "loss": 0.4889814376831055,
      "memory(GiB)": 67.44,
      "step": 7470,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25397
    },
    {
      "epoch": 0.6972297360320866,
      "grad_norm": 8.66334056854248,
      "learning_rate": 9.782918457005675e-06,
      "loss": 0.5330924034118653,
      "memory(GiB)": 67.44,
      "step": 7475,
      "token_acc": 0.5106382978723404,
      "train_speed(iter/s)": 0.253974
    },
    {
      "epoch": 0.6976961104374592,
      "grad_norm": 6.571107864379883,
      "learning_rate": 9.782468715667406e-06,
      "loss": 0.5554060935974121,
      "memory(GiB)": 67.44,
      "step": 7480,
      "token_acc": 0.5426829268292683,
      "train_speed(iter/s)": 0.253975
    },
    {
      "epoch": 0.6981624848428318,
      "grad_norm": 4.129189968109131,
      "learning_rate": 9.782018519291974e-06,
      "loss": 0.5124374389648437,
      "memory(GiB)": 67.44,
      "step": 7485,
      "token_acc": 0.8828828828828829,
      "train_speed(iter/s)": 0.253967
    },
    {
      "epoch": 0.6986288592482045,
      "grad_norm": 19.148162841796875,
      "learning_rate": 9.78156786792221e-06,
      "loss": 0.5658906459808349,
      "memory(GiB)": 67.44,
      "step": 7490,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.253962
    },
    {
      "epoch": 0.6990952336535771,
      "grad_norm": 7.058945655822754,
      "learning_rate": 9.781116761600993e-06,
      "loss": 0.5030726432800293,
      "memory(GiB)": 67.44,
      "step": 7495,
      "train_speed(iter/s)": 0.253974
    },
    {
      "epoch": 0.6995616080589497,
      "grad_norm": 4.959261894226074,
      "learning_rate": 9.780665200371246e-06,
      "loss": 0.4877328395843506,
      "memory(GiB)": 67.44,
      "step": 7500,
      "train_speed(iter/s)": 0.253973
    },
    {
      "epoch": 0.7000279824643224,
      "grad_norm": 4.1494903564453125,
      "learning_rate": 9.780213184275932e-06,
      "loss": 0.5134172439575195,
      "memory(GiB)": 67.44,
      "step": 7505,
      "train_speed(iter/s)": 0.253973
    },
    {
      "epoch": 0.700494356869695,
      "grad_norm": 10.432615280151367,
      "learning_rate": 9.77976071335806e-06,
      "loss": 0.5145482063293457,
      "memory(GiB)": 67.44,
      "step": 7510,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.253971
    },
    {
      "epoch": 0.7009607312750676,
      "grad_norm": 6.837496757507324,
      "learning_rate": 9.779307787660678e-06,
      "loss": 0.5377556800842285,
      "memory(GiB)": 67.44,
      "step": 7515,
      "token_acc": 0.7716535433070866,
      "train_speed(iter/s)": 0.253977
    },
    {
      "epoch": 0.7014271056804403,
      "grad_norm": 6.78993034362793,
      "learning_rate": 9.778854407226886e-06,
      "loss": 0.5088406085968018,
      "memory(GiB)": 67.44,
      "step": 7520,
      "token_acc": 0.8548387096774194,
      "train_speed(iter/s)": 0.253848
    },
    {
      "epoch": 0.7018934800858129,
      "grad_norm": 9.445755004882812,
      "learning_rate": 9.778400572099816e-06,
      "loss": 0.5413733005523682,
      "memory(GiB)": 67.44,
      "step": 7525,
      "token_acc": 0.5102040816326531,
      "train_speed(iter/s)": 0.253851
    },
    {
      "epoch": 0.7023598544911855,
      "grad_norm": 6.762411117553711,
      "learning_rate": 9.777946282322655e-06,
      "loss": 0.5324837684631347,
      "memory(GiB)": 67.44,
      "step": 7530,
      "token_acc": 0.574468085106383,
      "train_speed(iter/s)": 0.253845
    },
    {
      "epoch": 0.7028262288965581,
      "grad_norm": 7.278432369232178,
      "learning_rate": 9.777491537938622e-06,
      "loss": 0.534859037399292,
      "memory(GiB)": 67.44,
      "step": 7535,
      "train_speed(iter/s)": 0.25385
    },
    {
      "epoch": 0.7032926033019308,
      "grad_norm": 7.192469120025635,
      "learning_rate": 9.777036338990986e-06,
      "loss": 0.559822940826416,
      "memory(GiB)": 67.44,
      "step": 7540,
      "train_speed(iter/s)": 0.253856
    },
    {
      "epoch": 0.7037589777073034,
      "grad_norm": 6.81140661239624,
      "learning_rate": 9.776580685523059e-06,
      "loss": 0.5581114292144775,
      "memory(GiB)": 67.44,
      "step": 7545,
      "train_speed(iter/s)": 0.253856
    },
    {
      "epoch": 0.704225352112676,
      "grad_norm": 5.557941436767578,
      "learning_rate": 9.776124577578194e-06,
      "loss": 0.5197962760925293,
      "memory(GiB)": 67.44,
      "step": 7550,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.253852
    },
    {
      "epoch": 0.7046917265180487,
      "grad_norm": 4.20559549331665,
      "learning_rate": 9.77566801519979e-06,
      "loss": 0.5064503669738769,
      "memory(GiB)": 67.44,
      "step": 7555,
      "train_speed(iter/s)": 0.253845
    },
    {
      "epoch": 0.7051581009234213,
      "grad_norm": 6.521240234375,
      "learning_rate": 9.775210998431286e-06,
      "loss": 0.5511173248291016,
      "memory(GiB)": 67.44,
      "step": 7560,
      "token_acc": 0.43478260869565216,
      "train_speed(iter/s)": 0.253835
    },
    {
      "epoch": 0.7056244753287939,
      "grad_norm": 7.730512619018555,
      "learning_rate": 9.774753527316165e-06,
      "loss": 0.5128028869628907,
      "memory(GiB)": 67.44,
      "step": 7565,
      "train_speed(iter/s)": 0.253821
    },
    {
      "epoch": 0.7060908497341666,
      "grad_norm": 4.665524959564209,
      "learning_rate": 9.774295601897955e-06,
      "loss": 0.49908156394958497,
      "memory(GiB)": 67.44,
      "step": 7570,
      "token_acc": 0.762589928057554,
      "train_speed(iter/s)": 0.253838
    },
    {
      "epoch": 0.7065572241395393,
      "grad_norm": 7.056331634521484,
      "learning_rate": 9.773837222220226e-06,
      "loss": 0.5026946067810059,
      "memory(GiB)": 67.44,
      "step": 7575,
      "train_speed(iter/s)": 0.253842
    },
    {
      "epoch": 0.7070235985449118,
      "grad_norm": 5.82171106338501,
      "learning_rate": 9.773378388326593e-06,
      "loss": 0.5138778686523438,
      "memory(GiB)": 67.44,
      "step": 7580,
      "train_speed(iter/s)": 0.253842
    },
    {
      "epoch": 0.7074899729502845,
      "grad_norm": 5.028899192810059,
      "learning_rate": 9.77291910026071e-06,
      "loss": 0.5158101558685303,
      "memory(GiB)": 67.44,
      "step": 7585,
      "train_speed(iter/s)": 0.253694
    },
    {
      "epoch": 0.7079563473556572,
      "grad_norm": 4.439821720123291,
      "learning_rate": 9.772459358066278e-06,
      "loss": 0.5121222019195557,
      "memory(GiB)": 67.44,
      "step": 7590,
      "token_acc": 0.5045045045045045,
      "train_speed(iter/s)": 0.253677
    },
    {
      "epoch": 0.7084227217610297,
      "grad_norm": 4.731002330780029,
      "learning_rate": 9.77199916178704e-06,
      "loss": 0.5299813270568847,
      "memory(GiB)": 67.44,
      "step": 7595,
      "token_acc": 0.68125,
      "train_speed(iter/s)": 0.253677
    },
    {
      "epoch": 0.7088890961664024,
      "grad_norm": 8.78300666809082,
      "learning_rate": 9.771538511466781e-06,
      "loss": 0.5216853618621826,
      "memory(GiB)": 67.44,
      "step": 7600,
      "train_speed(iter/s)": 0.253678
    },
    {
      "epoch": 0.7093554705717751,
      "grad_norm": 5.25036096572876,
      "learning_rate": 9.771077407149331e-06,
      "loss": 0.5451444625854492,
      "memory(GiB)": 67.44,
      "step": 7605,
      "token_acc": 0.42592592592592593,
      "train_speed(iter/s)": 0.25368
    },
    {
      "epoch": 0.7098218449771476,
      "grad_norm": 5.578368663787842,
      "learning_rate": 9.770615848878566e-06,
      "loss": 0.5724482059478759,
      "memory(GiB)": 67.44,
      "step": 7610,
      "token_acc": 0.4186046511627907,
      "train_speed(iter/s)": 0.253679
    },
    {
      "epoch": 0.7102882193825203,
      "grad_norm": 5.394526481628418,
      "learning_rate": 9.7701538366984e-06,
      "loss": 0.5339457988739014,
      "memory(GiB)": 67.44,
      "step": 7615,
      "train_speed(iter/s)": 0.25369
    },
    {
      "epoch": 0.710754593787893,
      "grad_norm": 5.0804877281188965,
      "learning_rate": 9.76969137065279e-06,
      "loss": 0.5232700347900391,
      "memory(GiB)": 67.44,
      "step": 7620,
      "token_acc": 0.3968253968253968,
      "train_speed(iter/s)": 0.253683
    },
    {
      "epoch": 0.7112209681932655,
      "grad_norm": 5.630377769470215,
      "learning_rate": 9.769228450785738e-06,
      "loss": 0.5184074401855469,
      "memory(GiB)": 67.44,
      "step": 7625,
      "train_speed(iter/s)": 0.253682
    },
    {
      "epoch": 0.7116873425986382,
      "grad_norm": 5.003477573394775,
      "learning_rate": 9.768765077141293e-06,
      "loss": 0.5639711380004883,
      "memory(GiB)": 67.44,
      "step": 7630,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.253685
    },
    {
      "epoch": 0.7121537170040109,
      "grad_norm": 3.2554540634155273,
      "learning_rate": 9.76830124976354e-06,
      "loss": 0.4903096675872803,
      "memory(GiB)": 67.44,
      "step": 7635,
      "token_acc": 0.8316831683168316,
      "train_speed(iter/s)": 0.253672
    },
    {
      "epoch": 0.7126200914093834,
      "grad_norm": 10.480871200561523,
      "learning_rate": 9.767836968696613e-06,
      "loss": 0.49894213676452637,
      "memory(GiB)": 67.44,
      "step": 7640,
      "token_acc": 0.4811320754716981,
      "train_speed(iter/s)": 0.253667
    },
    {
      "epoch": 0.7130864658147561,
      "grad_norm": 7.689562797546387,
      "learning_rate": 9.767372233984685e-06,
      "loss": 0.4882986068725586,
      "memory(GiB)": 67.44,
      "step": 7645,
      "train_speed(iter/s)": 0.253666
    },
    {
      "epoch": 0.7135528402201288,
      "grad_norm": 4.87584924697876,
      "learning_rate": 9.766907045671976e-06,
      "loss": 0.47719459533691405,
      "memory(GiB)": 67.44,
      "step": 7650,
      "train_speed(iter/s)": 0.253658
    },
    {
      "epoch": 0.7140192146255013,
      "grad_norm": 5.768083572387695,
      "learning_rate": 9.766441403802746e-06,
      "loss": 0.5361672401428222,
      "memory(GiB)": 67.44,
      "step": 7655,
      "train_speed(iter/s)": 0.253655
    },
    {
      "epoch": 0.714485589030874,
      "grad_norm": 3.705859661102295,
      "learning_rate": 9.7659753084213e-06,
      "loss": 0.5292141914367676,
      "memory(GiB)": 67.44,
      "step": 7660,
      "token_acc": 0.4909090909090909,
      "train_speed(iter/s)": 0.253664
    },
    {
      "epoch": 0.7149519634362467,
      "grad_norm": 4.234471321105957,
      "learning_rate": 9.765508759571986e-06,
      "loss": 0.5092020988464355,
      "memory(GiB)": 67.44,
      "step": 7665,
      "token_acc": 0.5471698113207547,
      "train_speed(iter/s)": 0.253654
    },
    {
      "epoch": 0.7154183378416192,
      "grad_norm": 7.231120586395264,
      "learning_rate": 9.765041757299194e-06,
      "loss": 0.5015291213989258,
      "memory(GiB)": 67.44,
      "step": 7670,
      "token_acc": 0.9139784946236559,
      "train_speed(iter/s)": 0.253648
    },
    {
      "epoch": 0.7158847122469919,
      "grad_norm": 4.688546657562256,
      "learning_rate": 9.764574301647359e-06,
      "loss": 0.4871984004974365,
      "memory(GiB)": 67.44,
      "step": 7675,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.253643
    },
    {
      "epoch": 0.7163510866523645,
      "grad_norm": 4.61987829208374,
      "learning_rate": 9.764106392660954e-06,
      "loss": 0.5272037029266358,
      "memory(GiB)": 67.44,
      "step": 7680,
      "train_speed(iter/s)": 0.25365
    },
    {
      "epoch": 0.7168174610577371,
      "grad_norm": 4.970952987670898,
      "learning_rate": 9.763638030384503e-06,
      "loss": 0.49487104415893557,
      "memory(GiB)": 67.44,
      "step": 7685,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.253646
    },
    {
      "epoch": 0.7172838354631098,
      "grad_norm": 5.536442279815674,
      "learning_rate": 9.763169214862569e-06,
      "loss": 0.49437389373779295,
      "memory(GiB)": 67.44,
      "step": 7690,
      "train_speed(iter/s)": 0.253642
    },
    {
      "epoch": 0.7177502098684824,
      "grad_norm": 3.8248095512390137,
      "learning_rate": 9.762699946139757e-06,
      "loss": 0.5045137405395508,
      "memory(GiB)": 67.44,
      "step": 7695,
      "train_speed(iter/s)": 0.25364
    },
    {
      "epoch": 0.718216584273855,
      "grad_norm": 4.600127696990967,
      "learning_rate": 9.762230224260716e-06,
      "loss": 0.5271264553070069,
      "memory(GiB)": 67.44,
      "step": 7700,
      "token_acc": 0.7121212121212122,
      "train_speed(iter/s)": 0.253635
    },
    {
      "epoch": 0.7186829586792277,
      "grad_norm": 3.4886417388916016,
      "learning_rate": 9.761760049270142e-06,
      "loss": 0.5135688781738281,
      "memory(GiB)": 67.44,
      "step": 7705,
      "token_acc": 0.35714285714285715,
      "train_speed(iter/s)": 0.253645
    },
    {
      "epoch": 0.7191493330846003,
      "grad_norm": 2.996220588684082,
      "learning_rate": 9.761289421212765e-06,
      "loss": 0.5414852142333985,
      "memory(GiB)": 67.44,
      "step": 7710,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.253647
    },
    {
      "epoch": 0.7196157074899729,
      "grad_norm": 3.8778138160705566,
      "learning_rate": 9.760818340133369e-06,
      "loss": 0.5353935241699219,
      "memory(GiB)": 67.44,
      "step": 7715,
      "token_acc": 0.43137254901960786,
      "train_speed(iter/s)": 0.253655
    },
    {
      "epoch": 0.7200820818953456,
      "grad_norm": 5.4109063148498535,
      "learning_rate": 9.760346806076774e-06,
      "loss": 0.4998898506164551,
      "memory(GiB)": 67.44,
      "step": 7720,
      "train_speed(iter/s)": 0.253666
    },
    {
      "epoch": 0.7205484563007182,
      "grad_norm": 9.644006729125977,
      "learning_rate": 9.759874819087845e-06,
      "loss": 0.5298375129699707,
      "memory(GiB)": 67.44,
      "step": 7725,
      "train_speed(iter/s)": 0.25367
    },
    {
      "epoch": 0.7210148307060908,
      "grad_norm": 12.881646156311035,
      "learning_rate": 9.75940237921149e-06,
      "loss": 0.5503865242004394,
      "memory(GiB)": 67.44,
      "step": 7730,
      "token_acc": 0.42613636363636365,
      "train_speed(iter/s)": 0.253669
    },
    {
      "epoch": 0.7214812051114635,
      "grad_norm": 12.376837730407715,
      "learning_rate": 9.75892948649266e-06,
      "loss": 0.5025351047515869,
      "memory(GiB)": 67.44,
      "step": 7735,
      "token_acc": 0.5869565217391305,
      "train_speed(iter/s)": 0.25367
    },
    {
      "epoch": 0.7219475795168361,
      "grad_norm": 9.9247407913208,
      "learning_rate": 9.75845614097635e-06,
      "loss": 0.5344242095947266,
      "memory(GiB)": 67.44,
      "step": 7740,
      "train_speed(iter/s)": 0.253679
    },
    {
      "epoch": 0.7224139539222088,
      "grad_norm": 9.447463989257812,
      "learning_rate": 9.757982342707597e-06,
      "loss": 0.5215564727783203,
      "memory(GiB)": 67.44,
      "step": 7745,
      "token_acc": 0.6095238095238096,
      "train_speed(iter/s)": 0.253688
    },
    {
      "epoch": 0.7228803283275814,
      "grad_norm": 11.019290924072266,
      "learning_rate": 9.75750809173148e-06,
      "loss": 0.5549864768981934,
      "memory(GiB)": 67.44,
      "step": 7750,
      "token_acc": 0.3076923076923077,
      "train_speed(iter/s)": 0.253696
    },
    {
      "epoch": 0.723346702732954,
      "grad_norm": 12.016775131225586,
      "learning_rate": 9.757033388093127e-06,
      "loss": 0.555786418914795,
      "memory(GiB)": 67.44,
      "step": 7755,
      "train_speed(iter/s)": 0.253699
    },
    {
      "epoch": 0.7238130771383267,
      "grad_norm": 7.414364814758301,
      "learning_rate": 9.7565582318377e-06,
      "loss": 0.5229090690612793,
      "memory(GiB)": 67.44,
      "step": 7760,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.253693
    },
    {
      "epoch": 0.7242794515436993,
      "grad_norm": 6.491664409637451,
      "learning_rate": 9.75608262301041e-06,
      "loss": 0.5599005222320557,
      "memory(GiB)": 67.44,
      "step": 7765,
      "token_acc": 0.5047619047619047,
      "train_speed(iter/s)": 0.253687
    },
    {
      "epoch": 0.7247458259490719,
      "grad_norm": 5.349355697631836,
      "learning_rate": 9.755606561656509e-06,
      "loss": 0.5151040077209472,
      "memory(GiB)": 67.44,
      "step": 7770,
      "train_speed(iter/s)": 0.253689
    },
    {
      "epoch": 0.7252122003544446,
      "grad_norm": 25.49944305419922,
      "learning_rate": 9.755130047821294e-06,
      "loss": 0.5063280582427978,
      "memory(GiB)": 67.44,
      "step": 7775,
      "train_speed(iter/s)": 0.253691
    },
    {
      "epoch": 0.7256785747598172,
      "grad_norm": 6.68772029876709,
      "learning_rate": 9.754653081550106e-06,
      "loss": 0.5245681762695312,
      "memory(GiB)": 67.44,
      "step": 7780,
      "token_acc": 0.9222222222222223,
      "train_speed(iter/s)": 0.253696
    },
    {
      "epoch": 0.7261449491651898,
      "grad_norm": 7.6393232345581055,
      "learning_rate": 9.75417566288832e-06,
      "loss": 0.5503805637359619,
      "memory(GiB)": 67.44,
      "step": 7785,
      "token_acc": 0.38461538461538464,
      "train_speed(iter/s)": 0.253697
    },
    {
      "epoch": 0.7266113235705625,
      "grad_norm": 4.313320159912109,
      "learning_rate": 9.75369779188137e-06,
      "loss": 0.5009080410003662,
      "memory(GiB)": 67.44,
      "step": 7790,
      "train_speed(iter/s)": 0.253698
    },
    {
      "epoch": 0.7270776979759351,
      "grad_norm": 8.08514404296875,
      "learning_rate": 9.753219468574715e-06,
      "loss": 0.4854097843170166,
      "memory(GiB)": 67.44,
      "step": 7795,
      "train_speed(iter/s)": 0.253696
    },
    {
      "epoch": 0.7275440723813077,
      "grad_norm": 8.15850830078125,
      "learning_rate": 9.752740693013872e-06,
      "loss": 0.4902564525604248,
      "memory(GiB)": 67.44,
      "step": 7800,
      "train_speed(iter/s)": 0.253699
    },
    {
      "epoch": 0.7280104467866804,
      "grad_norm": 4.593198299407959,
      "learning_rate": 9.752261465244394e-06,
      "loss": 0.52867112159729,
      "memory(GiB)": 67.44,
      "step": 7805,
      "token_acc": 0.616580310880829,
      "train_speed(iter/s)": 0.253707
    },
    {
      "epoch": 0.7284768211920529,
      "grad_norm": 6.231152534484863,
      "learning_rate": 9.751781785311876e-06,
      "loss": 0.5202311515808106,
      "memory(GiB)": 67.44,
      "step": 7810,
      "train_speed(iter/s)": 0.253707
    },
    {
      "epoch": 0.7289431955974256,
      "grad_norm": 5.562979698181152,
      "learning_rate": 9.75130165326196e-06,
      "loss": 0.49149656295776367,
      "memory(GiB)": 67.44,
      "step": 7815,
      "train_speed(iter/s)": 0.253718
    },
    {
      "epoch": 0.7294095700027983,
      "grad_norm": 4.593335151672363,
      "learning_rate": 9.750821069140329e-06,
      "loss": 0.48452253341674806,
      "memory(GiB)": 67.44,
      "step": 7820,
      "token_acc": 0.5277777777777778,
      "train_speed(iter/s)": 0.253717
    },
    {
      "epoch": 0.7298759444081708,
      "grad_norm": 4.691941261291504,
      "learning_rate": 9.750340032992707e-06,
      "loss": 0.5503585815429688,
      "memory(GiB)": 67.44,
      "step": 7825,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.253718
    },
    {
      "epoch": 0.7303423188135435,
      "grad_norm": 5.587502956390381,
      "learning_rate": 9.749858544864865e-06,
      "loss": 0.5428706645965576,
      "memory(GiB)": 67.44,
      "step": 7830,
      "token_acc": 0.5225225225225225,
      "train_speed(iter/s)": 0.253711
    },
    {
      "epoch": 0.7308086932189162,
      "grad_norm": 6.485442161560059,
      "learning_rate": 9.749376604802617e-06,
      "loss": 0.5542748451232911,
      "memory(GiB)": 67.44,
      "step": 7835,
      "train_speed(iter/s)": 0.253719
    },
    {
      "epoch": 0.7312750676242887,
      "grad_norm": 3.355954647064209,
      "learning_rate": 9.748894212851813e-06,
      "loss": 0.5093730449676513,
      "memory(GiB)": 67.44,
      "step": 7840,
      "train_speed(iter/s)": 0.253721
    },
    {
      "epoch": 0.7317414420296614,
      "grad_norm": 7.480174541473389,
      "learning_rate": 9.748411369058355e-06,
      "loss": 0.4958952903747559,
      "memory(GiB)": 67.44,
      "step": 7845,
      "token_acc": 0.4533333333333333,
      "train_speed(iter/s)": 0.253721
    },
    {
      "epoch": 0.7322078164350341,
      "grad_norm": 7.924178600311279,
      "learning_rate": 9.747928073468184e-06,
      "loss": 0.5120458126068115,
      "memory(GiB)": 67.44,
      "step": 7850,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.253714
    },
    {
      "epoch": 0.7326741908404066,
      "grad_norm": 6.217078685760498,
      "learning_rate": 9.747444326127283e-06,
      "loss": 0.5588850975036621,
      "memory(GiB)": 67.44,
      "step": 7855,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.253725
    },
    {
      "epoch": 0.7331405652457793,
      "grad_norm": 13.086806297302246,
      "learning_rate": 9.746960127081678e-06,
      "loss": 0.5140949249267578,
      "memory(GiB)": 67.44,
      "step": 7860,
      "train_speed(iter/s)": 0.253725
    },
    {
      "epoch": 0.733606939651152,
      "grad_norm": 6.702550411224365,
      "learning_rate": 9.746475476377442e-06,
      "loss": 0.5142255306243897,
      "memory(GiB)": 67.44,
      "step": 7865,
      "token_acc": 0.9021739130434783,
      "train_speed(iter/s)": 0.253724
    },
    {
      "epoch": 0.7340733140565245,
      "grad_norm": 4.733740329742432,
      "learning_rate": 9.745990374060684e-06,
      "loss": 0.49724340438842773,
      "memory(GiB)": 67.44,
      "step": 7870,
      "token_acc": 0.6444444444444445,
      "train_speed(iter/s)": 0.253721
    },
    {
      "epoch": 0.7345396884618972,
      "grad_norm": 7.090538501739502,
      "learning_rate": 9.745504820177564e-06,
      "loss": 0.517946434020996,
      "memory(GiB)": 67.44,
      "step": 7875,
      "train_speed(iter/s)": 0.253718
    },
    {
      "epoch": 0.7350060628672699,
      "grad_norm": 5.949926376342773,
      "learning_rate": 9.745018814774278e-06,
      "loss": 0.5413045883178711,
      "memory(GiB)": 67.44,
      "step": 7880,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.253729
    },
    {
      "epoch": 0.7354724372726424,
      "grad_norm": 3.4088268280029297,
      "learning_rate": 9.744532357897069e-06,
      "loss": 0.5222333908081055,
      "memory(GiB)": 67.44,
      "step": 7885,
      "train_speed(iter/s)": 0.253733
    },
    {
      "epoch": 0.7359388116780151,
      "grad_norm": 6.394344806671143,
      "learning_rate": 9.744045449592224e-06,
      "loss": 0.5336651802062988,
      "memory(GiB)": 67.44,
      "step": 7890,
      "token_acc": 0.89,
      "train_speed(iter/s)": 0.253734
    },
    {
      "epoch": 0.7364051860833878,
      "grad_norm": 4.894899368286133,
      "learning_rate": 9.743558089906069e-06,
      "loss": 0.4911602020263672,
      "memory(GiB)": 67.44,
      "step": 7895,
      "train_speed(iter/s)": 0.253737
    },
    {
      "epoch": 0.7368715604887603,
      "grad_norm": 5.4949870109558105,
      "learning_rate": 9.743070278884972e-06,
      "loss": 0.49101958274841306,
      "memory(GiB)": 67.44,
      "step": 7900,
      "token_acc": 0.9019607843137255,
      "train_speed(iter/s)": 0.253736
    },
    {
      "epoch": 0.737337934894133,
      "grad_norm": 5.913761138916016,
      "learning_rate": 9.742582016575352e-06,
      "loss": 0.49256362915039065,
      "memory(GiB)": 67.44,
      "step": 7905,
      "token_acc": 0.44285714285714284,
      "train_speed(iter/s)": 0.253738
    },
    {
      "epoch": 0.7378043092995057,
      "grad_norm": 3.443011999130249,
      "learning_rate": 9.74209330302366e-06,
      "loss": 0.49901275634765624,
      "memory(GiB)": 67.44,
      "step": 7910,
      "token_acc": 0.912621359223301,
      "train_speed(iter/s)": 0.25373
    },
    {
      "epoch": 0.7382706837048782,
      "grad_norm": 4.99254035949707,
      "learning_rate": 9.741604138276402e-06,
      "loss": 0.5026078701019288,
      "memory(GiB)": 67.44,
      "step": 7915,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.253729
    },
    {
      "epoch": 0.7387370581102509,
      "grad_norm": 4.896634578704834,
      "learning_rate": 9.741114522380115e-06,
      "loss": 0.5059139251708984,
      "memory(GiB)": 67.44,
      "step": 7920,
      "train_speed(iter/s)": 0.253725
    },
    {
      "epoch": 0.7392034325156236,
      "grad_norm": 7.376274585723877,
      "learning_rate": 9.740624455381387e-06,
      "loss": 0.44908885955810546,
      "memory(GiB)": 67.44,
      "step": 7925,
      "train_speed(iter/s)": 0.25372
    },
    {
      "epoch": 0.7396698069209962,
      "grad_norm": 6.250192642211914,
      "learning_rate": 9.740133937326846e-06,
      "loss": 0.4914048194885254,
      "memory(GiB)": 67.44,
      "step": 7930,
      "train_speed(iter/s)": 0.253715
    },
    {
      "epoch": 0.7401361813263688,
      "grad_norm": 3.6671879291534424,
      "learning_rate": 9.739642968263163e-06,
      "loss": 0.4769462585449219,
      "memory(GiB)": 67.44,
      "step": 7935,
      "token_acc": 0.6176470588235294,
      "train_speed(iter/s)": 0.253716
    },
    {
      "epoch": 0.7406025557317415,
      "grad_norm": 6.324900150299072,
      "learning_rate": 9.739151548237053e-06,
      "loss": 0.4894662857055664,
      "memory(GiB)": 67.44,
      "step": 7940,
      "train_speed(iter/s)": 0.253729
    },
    {
      "epoch": 0.7410689301371141,
      "grad_norm": 4.161059379577637,
      "learning_rate": 9.738659677295273e-06,
      "loss": 0.5397495269775391,
      "memory(GiB)": 67.44,
      "step": 7945,
      "token_acc": 0.5041322314049587,
      "train_speed(iter/s)": 0.253732
    },
    {
      "epoch": 0.7415353045424867,
      "grad_norm": 4.569282054901123,
      "learning_rate": 9.738167355484621e-06,
      "loss": 0.5408654689788819,
      "memory(GiB)": 67.44,
      "step": 7950,
      "train_speed(iter/s)": 0.253741
    },
    {
      "epoch": 0.7420016789478593,
      "grad_norm": 5.4333815574646,
      "learning_rate": 9.737674582851942e-06,
      "loss": 0.5685197353363037,
      "memory(GiB)": 67.44,
      "step": 7955,
      "train_speed(iter/s)": 0.253748
    },
    {
      "epoch": 0.742468053353232,
      "grad_norm": 10.88866901397705,
      "learning_rate": 9.737181359444122e-06,
      "loss": 0.5755653381347656,
      "memory(GiB)": 67.44,
      "step": 7960,
      "token_acc": 0.3114754098360656,
      "train_speed(iter/s)": 0.253754
    },
    {
      "epoch": 0.7429344277586046,
      "grad_norm": 11.661384582519531,
      "learning_rate": 9.736687685308087e-06,
      "loss": 0.5545840263366699,
      "memory(GiB)": 67.44,
      "step": 7965,
      "train_speed(iter/s)": 0.253755
    },
    {
      "epoch": 0.7434008021639772,
      "grad_norm": 8.102724075317383,
      "learning_rate": 9.736193560490813e-06,
      "loss": 0.5100154876708984,
      "memory(GiB)": 67.44,
      "step": 7970,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253758
    },
    {
      "epoch": 0.7438671765693499,
      "grad_norm": 5.183413982391357,
      "learning_rate": 9.73569898503931e-06,
      "loss": 0.5294332504272461,
      "memory(GiB)": 67.44,
      "step": 7975,
      "train_speed(iter/s)": 0.253761
    },
    {
      "epoch": 0.7443335509747225,
      "grad_norm": 6.738396644592285,
      "learning_rate": 9.735203959000638e-06,
      "loss": 0.5175348281860351,
      "memory(GiB)": 67.44,
      "step": 7980,
      "token_acc": 0.44642857142857145,
      "train_speed(iter/s)": 0.253757
    },
    {
      "epoch": 0.7447999253800951,
      "grad_norm": 4.7044548988342285,
      "learning_rate": 9.734708482421895e-06,
      "loss": 0.49906039237976074,
      "memory(GiB)": 67.44,
      "step": 7985,
      "train_speed(iter/s)": 0.25376
    },
    {
      "epoch": 0.7452662997854678,
      "grad_norm": 7.2748823165893555,
      "learning_rate": 9.734212555350227e-06,
      "loss": 0.5625759124755859,
      "memory(GiB)": 67.44,
      "step": 7990,
      "train_speed(iter/s)": 0.253769
    },
    {
      "epoch": 0.7457326741908404,
      "grad_norm": 8.801671028137207,
      "learning_rate": 9.733716177832819e-06,
      "loss": 0.6250875473022461,
      "memory(GiB)": 67.44,
      "step": 7995,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253777
    },
    {
      "epoch": 0.746199048596213,
      "grad_norm": 11.102011680603027,
      "learning_rate": 9.733219349916899e-06,
      "loss": 0.5120739936828613,
      "memory(GiB)": 67.44,
      "step": 8000,
      "token_acc": 0.5742574257425742,
      "train_speed(iter/s)": 0.253795
    },
    {
      "epoch": 0.7466654230015857,
      "grad_norm": 8.252169609069824,
      "learning_rate": 9.732722071649739e-06,
      "loss": 0.5670994758605957,
      "memory(GiB)": 67.44,
      "step": 8005,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.253585
    },
    {
      "epoch": 0.7471317974069583,
      "grad_norm": 7.613254070281982,
      "learning_rate": 9.732224343078651e-06,
      "loss": 0.48836479187011717,
      "memory(GiB)": 67.44,
      "step": 8010,
      "train_speed(iter/s)": 0.253587
    },
    {
      "epoch": 0.7475981718123309,
      "grad_norm": 5.963310718536377,
      "learning_rate": 9.731726164250996e-06,
      "loss": 0.5243733406066895,
      "memory(GiB)": 67.44,
      "step": 8015,
      "train_speed(iter/s)": 0.253588
    },
    {
      "epoch": 0.7480645462177036,
      "grad_norm": 4.3164496421813965,
      "learning_rate": 9.731227535214175e-06,
      "loss": 0.47796359062194826,
      "memory(GiB)": 67.44,
      "step": 8020,
      "train_speed(iter/s)": 0.253583
    },
    {
      "epoch": 0.7485309206230762,
      "grad_norm": 4.420438766479492,
      "learning_rate": 9.730728456015627e-06,
      "loss": 0.531898307800293,
      "memory(GiB)": 67.44,
      "step": 8025,
      "token_acc": 0.40350877192982454,
      "train_speed(iter/s)": 0.253582
    },
    {
      "epoch": 0.7489972950284488,
      "grad_norm": 5.1085205078125,
      "learning_rate": 9.73022892670284e-06,
      "loss": 0.5008624076843262,
      "memory(GiB)": 67.44,
      "step": 8030,
      "token_acc": 0.3076923076923077,
      "train_speed(iter/s)": 0.253578
    },
    {
      "epoch": 0.7494636694338215,
      "grad_norm": 4.481435775756836,
      "learning_rate": 9.729728947323343e-06,
      "loss": 0.5225230693817139,
      "memory(GiB)": 67.44,
      "step": 8035,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.25358
    },
    {
      "epoch": 0.7499300438391941,
      "grad_norm": 5.922427177429199,
      "learning_rate": 9.729228517924706e-06,
      "loss": 0.5223358631134033,
      "memory(GiB)": 67.44,
      "step": 8040,
      "train_speed(iter/s)": 0.253575
    },
    {
      "epoch": 0.7503964182445667,
      "grad_norm": 5.270279884338379,
      "learning_rate": 9.728727638554545e-06,
      "loss": 0.5086485862731933,
      "memory(GiB)": 67.44,
      "step": 8045,
      "train_speed(iter/s)": 0.25357
    },
    {
      "epoch": 0.7508627926499394,
      "grad_norm": 5.600255966186523,
      "learning_rate": 9.728226309260515e-06,
      "loss": 0.5089432716369628,
      "memory(GiB)": 67.44,
      "step": 8050,
      "train_speed(iter/s)": 0.25357
    },
    {
      "epoch": 0.751329167055312,
      "grad_norm": 5.193181991577148,
      "learning_rate": 9.727724530090319e-06,
      "loss": 0.5043249130249023,
      "memory(GiB)": 67.44,
      "step": 8055,
      "train_speed(iter/s)": 0.253575
    },
    {
      "epoch": 0.7517955414606846,
      "grad_norm": 3.9196219444274902,
      "learning_rate": 9.727222301091699e-06,
      "loss": 0.4929365634918213,
      "memory(GiB)": 67.44,
      "step": 8060,
      "train_speed(iter/s)": 0.253581
    },
    {
      "epoch": 0.7522619158660573,
      "grad_norm": 8.474625587463379,
      "learning_rate": 9.726719622312436e-06,
      "loss": 0.49778361320495607,
      "memory(GiB)": 67.44,
      "step": 8065,
      "token_acc": 0.765625,
      "train_speed(iter/s)": 0.253576
    },
    {
      "epoch": 0.75272829027143,
      "grad_norm": 5.4475274085998535,
      "learning_rate": 9.726216493800366e-06,
      "loss": 0.5056325912475585,
      "memory(GiB)": 67.44,
      "step": 8070,
      "train_speed(iter/s)": 0.253582
    },
    {
      "epoch": 0.7531946646768025,
      "grad_norm": 4.5115251541137695,
      "learning_rate": 9.725712915603353e-06,
      "loss": 0.4598844528198242,
      "memory(GiB)": 67.44,
      "step": 8075,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.25358
    },
    {
      "epoch": 0.7536610390821752,
      "grad_norm": 6.005695343017578,
      "learning_rate": 9.725208887769316e-06,
      "loss": 0.5547886371612549,
      "memory(GiB)": 67.44,
      "step": 8080,
      "train_speed(iter/s)": 0.253581
    },
    {
      "epoch": 0.7541274134875477,
      "grad_norm": 8.01628303527832,
      "learning_rate": 9.724704410346209e-06,
      "loss": 0.5331283569335937,
      "memory(GiB)": 67.44,
      "step": 8085,
      "train_speed(iter/s)": 0.253589
    },
    {
      "epoch": 0.7545937878929204,
      "grad_norm": 6.38249397277832,
      "learning_rate": 9.724199483382033e-06,
      "loss": 0.5167543411254882,
      "memory(GiB)": 67.44,
      "step": 8090,
      "train_speed(iter/s)": 0.253591
    },
    {
      "epoch": 0.7550601622982931,
      "grad_norm": 5.472616195678711,
      "learning_rate": 9.723694106924828e-06,
      "loss": 0.4916861057281494,
      "memory(GiB)": 67.44,
      "step": 8095,
      "token_acc": 0.3888888888888889,
      "train_speed(iter/s)": 0.253601
    },
    {
      "epoch": 0.7555265367036657,
      "grad_norm": 4.022602081298828,
      "learning_rate": 9.723188281022682e-06,
      "loss": 0.487227725982666,
      "memory(GiB)": 67.44,
      "step": 8100,
      "train_speed(iter/s)": 0.253603
    },
    {
      "epoch": 0.7559929111090383,
      "grad_norm": 3.3607611656188965,
      "learning_rate": 9.722682005723718e-06,
      "loss": 0.45783109664916993,
      "memory(GiB)": 67.44,
      "step": 8105,
      "token_acc": 0.6190476190476191,
      "train_speed(iter/s)": 0.253606
    },
    {
      "epoch": 0.756459285514411,
      "grad_norm": 4.29161262512207,
      "learning_rate": 9.722175281076113e-06,
      "loss": 0.48583669662475587,
      "memory(GiB)": 67.44,
      "step": 8110,
      "train_speed(iter/s)": 0.253613
    },
    {
      "epoch": 0.7569256599197836,
      "grad_norm": 5.662795066833496,
      "learning_rate": 9.721668107128077e-06,
      "loss": 0.5077787876129151,
      "memory(GiB)": 67.44,
      "step": 8115,
      "train_speed(iter/s)": 0.253603
    },
    {
      "epoch": 0.7573920343251562,
      "grad_norm": 9.460306167602539,
      "learning_rate": 9.721160483927865e-06,
      "loss": 0.4856121063232422,
      "memory(GiB)": 67.44,
      "step": 8120,
      "train_speed(iter/s)": 0.25359
    },
    {
      "epoch": 0.7578584087305289,
      "grad_norm": 4.313090801239014,
      "learning_rate": 9.720652411523777e-06,
      "loss": 0.5033788204193115,
      "memory(GiB)": 67.44,
      "step": 8125,
      "train_speed(iter/s)": 0.253601
    },
    {
      "epoch": 0.7583247831359015,
      "grad_norm": 6.757660388946533,
      "learning_rate": 9.720143889964153e-06,
      "loss": 0.5225100517272949,
      "memory(GiB)": 67.44,
      "step": 8130,
      "train_speed(iter/s)": 0.253605
    },
    {
      "epoch": 0.7587911575412741,
      "grad_norm": 5.701797008514404,
      "learning_rate": 9.71963491929738e-06,
      "loss": 0.5144959449768066,
      "memory(GiB)": 67.44,
      "step": 8135,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.253609
    },
    {
      "epoch": 0.7592575319466468,
      "grad_norm": 4.448390007019043,
      "learning_rate": 9.719125499571884e-06,
      "loss": 0.5039391040802002,
      "memory(GiB)": 67.44,
      "step": 8140,
      "train_speed(iter/s)": 0.253626
    },
    {
      "epoch": 0.7597239063520194,
      "grad_norm": 7.946887016296387,
      "learning_rate": 9.718615630836134e-06,
      "loss": 0.5574245452880859,
      "memory(GiB)": 67.44,
      "step": 8145,
      "token_acc": 0.5208333333333334,
      "train_speed(iter/s)": 0.253624
    },
    {
      "epoch": 0.760190280757392,
      "grad_norm": 8.315194129943848,
      "learning_rate": 9.718105313138641e-06,
      "loss": 0.5148907661437988,
      "memory(GiB)": 67.44,
      "step": 8150,
      "train_speed(iter/s)": 0.253622
    },
    {
      "epoch": 0.7606566551627647,
      "grad_norm": 5.108281135559082,
      "learning_rate": 9.717594546527964e-06,
      "loss": 0.553615951538086,
      "memory(GiB)": 67.44,
      "step": 8155,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.253635
    },
    {
      "epoch": 0.7611230295681373,
      "grad_norm": 4.618207931518555,
      "learning_rate": 9.7170833310527e-06,
      "loss": 0.5092864990234375,
      "memory(GiB)": 67.44,
      "step": 8160,
      "token_acc": 0.44696969696969696,
      "train_speed(iter/s)": 0.253634
    },
    {
      "epoch": 0.7615894039735099,
      "grad_norm": 6.878044605255127,
      "learning_rate": 9.716571666761485e-06,
      "loss": 0.5038878440856933,
      "memory(GiB)": 67.44,
      "step": 8165,
      "train_speed(iter/s)": 0.25363
    },
    {
      "epoch": 0.7620557783788826,
      "grad_norm": 4.983809471130371,
      "learning_rate": 9.716059553703008e-06,
      "loss": 0.5456562995910644,
      "memory(GiB)": 67.44,
      "step": 8170,
      "token_acc": 0.8214285714285714,
      "train_speed(iter/s)": 0.25363
    },
    {
      "epoch": 0.7625221527842552,
      "grad_norm": 6.7860002517700195,
      "learning_rate": 9.715546991925993e-06,
      "loss": 0.5139262676239014,
      "memory(GiB)": 67.44,
      "step": 8175,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.253633
    },
    {
      "epoch": 0.7629885271896278,
      "grad_norm": 4.496447563171387,
      "learning_rate": 9.715033981479207e-06,
      "loss": 0.46354169845581056,
      "memory(GiB)": 67.44,
      "step": 8180,
      "train_speed(iter/s)": 0.253638
    },
    {
      "epoch": 0.7634549015950005,
      "grad_norm": 7.445134162902832,
      "learning_rate": 9.714520522411463e-06,
      "loss": 0.49272913932800294,
      "memory(GiB)": 67.44,
      "step": 8185,
      "token_acc": 0.7483443708609272,
      "train_speed(iter/s)": 0.253635
    },
    {
      "epoch": 0.7639212760003731,
      "grad_norm": 9.640233993530273,
      "learning_rate": 9.714006614771614e-06,
      "loss": 0.5991229057312012,
      "memory(GiB)": 67.44,
      "step": 8190,
      "train_speed(iter/s)": 0.253623
    },
    {
      "epoch": 0.7643876504057457,
      "grad_norm": 6.2158613204956055,
      "learning_rate": 9.713492258608558e-06,
      "loss": 0.4907137393951416,
      "memory(GiB)": 67.44,
      "step": 8195,
      "token_acc": 0.8791208791208791,
      "train_speed(iter/s)": 0.253627
    },
    {
      "epoch": 0.7648540248111184,
      "grad_norm": 4.621025562286377,
      "learning_rate": 9.712977453971235e-06,
      "loss": 0.49711222648620607,
      "memory(GiB)": 67.44,
      "step": 8200,
      "train_speed(iter/s)": 0.253624
    },
    {
      "epoch": 0.765320399216491,
      "grad_norm": 6.668947696685791,
      "learning_rate": 9.712462200908624e-06,
      "loss": 0.5458009719848633,
      "memory(GiB)": 67.44,
      "step": 8205,
      "train_speed(iter/s)": 0.253626
    },
    {
      "epoch": 0.7657867736218636,
      "grad_norm": 8.712059020996094,
      "learning_rate": 9.711946499469754e-06,
      "loss": 0.4985377788543701,
      "memory(GiB)": 67.44,
      "step": 8210,
      "train_speed(iter/s)": 0.253633
    },
    {
      "epoch": 0.7662531480272363,
      "grad_norm": 6.731545448303223,
      "learning_rate": 9.711430349703688e-06,
      "loss": 0.548759937286377,
      "memory(GiB)": 67.44,
      "step": 8215,
      "train_speed(iter/s)": 0.253641
    },
    {
      "epoch": 0.7667195224326089,
      "grad_norm": 4.654331684112549,
      "learning_rate": 9.710913751659539e-06,
      "loss": 0.5131998062133789,
      "memory(GiB)": 67.44,
      "step": 8220,
      "train_speed(iter/s)": 0.25366
    },
    {
      "epoch": 0.7671858968379816,
      "grad_norm": 3.0919346809387207,
      "learning_rate": 9.710396705386458e-06,
      "loss": 0.5036861419677734,
      "memory(GiB)": 67.44,
      "step": 8225,
      "token_acc": 0.8235294117647058,
      "train_speed(iter/s)": 0.253656
    },
    {
      "epoch": 0.7676522712433541,
      "grad_norm": 5.028031349182129,
      "learning_rate": 9.709879210933644e-06,
      "loss": 0.4685668468475342,
      "memory(GiB)": 67.44,
      "step": 8230,
      "train_speed(iter/s)": 0.253653
    },
    {
      "epoch": 0.7681186456487268,
      "grad_norm": 3.536417007446289,
      "learning_rate": 9.70936126835033e-06,
      "loss": 0.5246243953704834,
      "memory(GiB)": 67.44,
      "step": 8235,
      "train_speed(iter/s)": 0.253649
    },
    {
      "epoch": 0.7685850200540995,
      "grad_norm": 4.056468963623047,
      "learning_rate": 9.708842877685798e-06,
      "loss": 0.490204906463623,
      "memory(GiB)": 67.44,
      "step": 8240,
      "token_acc": 0.7748344370860927,
      "train_speed(iter/s)": 0.253654
    },
    {
      "epoch": 0.769051394459472,
      "grad_norm": 5.625170707702637,
      "learning_rate": 9.708324038989374e-06,
      "loss": 0.47793731689453123,
      "memory(GiB)": 67.44,
      "step": 8245,
      "token_acc": 0.9438202247191011,
      "train_speed(iter/s)": 0.253659
    },
    {
      "epoch": 0.7695177688648447,
      "grad_norm": 4.115976810455322,
      "learning_rate": 9.707804752310421e-06,
      "loss": 0.5281148910522461,
      "memory(GiB)": 67.44,
      "step": 8250,
      "train_speed(iter/s)": 0.253661
    },
    {
      "epoch": 0.7699841432702174,
      "grad_norm": 3.641136884689331,
      "learning_rate": 9.707285017698349e-06,
      "loss": 0.5329367637634277,
      "memory(GiB)": 67.44,
      "step": 8255,
      "train_speed(iter/s)": 0.253554
    },
    {
      "epoch": 0.7704505176755899,
      "grad_norm": 3.5742430686950684,
      "learning_rate": 9.706764835202609e-06,
      "loss": 0.4988269805908203,
      "memory(GiB)": 67.44,
      "step": 8260,
      "train_speed(iter/s)": 0.253558
    },
    {
      "epoch": 0.7709168920809626,
      "grad_norm": 5.821506023406982,
      "learning_rate": 9.706244204872693e-06,
      "loss": 0.5251410484313965,
      "memory(GiB)": 67.44,
      "step": 8265,
      "train_speed(iter/s)": 0.253562
    },
    {
      "epoch": 0.7713832664863353,
      "grad_norm": 5.080464839935303,
      "learning_rate": 9.70572312675814e-06,
      "loss": 0.5538475513458252,
      "memory(GiB)": 67.44,
      "step": 8270,
      "token_acc": 0.8255813953488372,
      "train_speed(iter/s)": 0.253561
    },
    {
      "epoch": 0.7718496408917078,
      "grad_norm": 5.915680408477783,
      "learning_rate": 9.705201600908528e-06,
      "loss": 0.46158452033996583,
      "memory(GiB)": 67.44,
      "step": 8275,
      "token_acc": 0.9174311926605505,
      "train_speed(iter/s)": 0.253559
    },
    {
      "epoch": 0.7723160152970805,
      "grad_norm": 4.1805338859558105,
      "learning_rate": 9.704679627373478e-06,
      "loss": 0.48434863090515134,
      "memory(GiB)": 67.44,
      "step": 8280,
      "train_speed(iter/s)": 0.253565
    },
    {
      "epoch": 0.7727823897024532,
      "grad_norm": 3.827328681945801,
      "learning_rate": 9.704157206202656e-06,
      "loss": 0.49512596130371095,
      "memory(GiB)": 67.44,
      "step": 8285,
      "train_speed(iter/s)": 0.253568
    },
    {
      "epoch": 0.7732487641078257,
      "grad_norm": 6.17778205871582,
      "learning_rate": 9.703634337445764e-06,
      "loss": 0.5127344131469727,
      "memory(GiB)": 67.44,
      "step": 8290,
      "train_speed(iter/s)": 0.253565
    },
    {
      "epoch": 0.7737151385131984,
      "grad_norm": 6.563394069671631,
      "learning_rate": 9.703111021152558e-06,
      "loss": 0.4965876579284668,
      "memory(GiB)": 67.44,
      "step": 8295,
      "train_speed(iter/s)": 0.253573
    },
    {
      "epoch": 0.7741815129185711,
      "grad_norm": 3.659665822982788,
      "learning_rate": 9.702587257372825e-06,
      "loss": 0.5074700355529785,
      "memory(GiB)": 67.44,
      "step": 8300,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.253568
    },
    {
      "epoch": 0.7746478873239436,
      "grad_norm": 7.610287666320801,
      "learning_rate": 9.702063046156401e-06,
      "loss": 0.5391340255737305,
      "memory(GiB)": 67.44,
      "step": 8305,
      "token_acc": 0.421875,
      "train_speed(iter/s)": 0.253563
    },
    {
      "epoch": 0.7751142617293163,
      "grad_norm": 6.404224395751953,
      "learning_rate": 9.701538387553165e-06,
      "loss": 0.4904184341430664,
      "memory(GiB)": 67.44,
      "step": 8310,
      "train_speed(iter/s)": 0.253569
    },
    {
      "epoch": 0.775580636134689,
      "grad_norm": 5.627153396606445,
      "learning_rate": 9.701013281613033e-06,
      "loss": 0.49213595390319825,
      "memory(GiB)": 67.44,
      "step": 8315,
      "token_acc": 0.5963302752293578,
      "train_speed(iter/s)": 0.253576
    },
    {
      "epoch": 0.7760470105400615,
      "grad_norm": 4.327734470367432,
      "learning_rate": 9.70048772838597e-06,
      "loss": 0.5547898292541504,
      "memory(GiB)": 67.44,
      "step": 8320,
      "token_acc": 0.8472222222222222,
      "train_speed(iter/s)": 0.253575
    },
    {
      "epoch": 0.7765133849454342,
      "grad_norm": 3.5131304264068604,
      "learning_rate": 9.699961727921978e-06,
      "loss": 0.5162291526794434,
      "memory(GiB)": 67.44,
      "step": 8325,
      "token_acc": 0.5102040816326531,
      "train_speed(iter/s)": 0.253575
    },
    {
      "epoch": 0.7769797593508069,
      "grad_norm": 4.597408771514893,
      "learning_rate": 9.69943528027111e-06,
      "loss": 0.5150532722473145,
      "memory(GiB)": 67.44,
      "step": 8330,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.253573
    },
    {
      "epoch": 0.7774461337561794,
      "grad_norm": 6.9693922996521,
      "learning_rate": 9.698908385483449e-06,
      "loss": 0.4786041259765625,
      "memory(GiB)": 67.44,
      "step": 8335,
      "train_speed(iter/s)": 0.253572
    },
    {
      "epoch": 0.7779125081615521,
      "grad_norm": 5.508355617523193,
      "learning_rate": 9.69838104360913e-06,
      "loss": 0.5557065963745117,
      "memory(GiB)": 67.44,
      "step": 8340,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.253581
    },
    {
      "epoch": 0.7783788825669248,
      "grad_norm": 4.507212162017822,
      "learning_rate": 9.69785325469833e-06,
      "loss": 0.4924465179443359,
      "memory(GiB)": 67.44,
      "step": 8345,
      "token_acc": 0.5957446808510638,
      "train_speed(iter/s)": 0.253581
    },
    {
      "epoch": 0.7788452569722973,
      "grad_norm": 5.196742057800293,
      "learning_rate": 9.697325018801265e-06,
      "loss": 0.47751951217651367,
      "memory(GiB)": 67.44,
      "step": 8350,
      "train_speed(iter/s)": 0.253578
    },
    {
      "epoch": 0.77931163137767,
      "grad_norm": 4.781151294708252,
      "learning_rate": 9.696796335968194e-06,
      "loss": 0.5264728546142579,
      "memory(GiB)": 67.44,
      "step": 8355,
      "token_acc": 0.8673469387755102,
      "train_speed(iter/s)": 0.253572
    },
    {
      "epoch": 0.7797780057830426,
      "grad_norm": 5.490938186645508,
      "learning_rate": 9.696267206249421e-06,
      "loss": 0.4771676540374756,
      "memory(GiB)": 67.44,
      "step": 8360,
      "train_speed(iter/s)": 0.25358
    },
    {
      "epoch": 0.7802443801884152,
      "grad_norm": 5.1587114334106445,
      "learning_rate": 9.695737629695291e-06,
      "loss": 0.4996958255767822,
      "memory(GiB)": 67.44,
      "step": 8365,
      "token_acc": 0.5737704918032787,
      "train_speed(iter/s)": 0.25358
    },
    {
      "epoch": 0.7807107545937879,
      "grad_norm": 4.410301208496094,
      "learning_rate": 9.695207606356192e-06,
      "loss": 0.5417310237884522,
      "memory(GiB)": 67.44,
      "step": 8370,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.25358
    },
    {
      "epoch": 0.7811771289991605,
      "grad_norm": 5.959232807159424,
      "learning_rate": 9.69467713628255e-06,
      "loss": 0.4778414726257324,
      "memory(GiB)": 67.44,
      "step": 8375,
      "train_speed(iter/s)": 0.253565
    },
    {
      "epoch": 0.7816435034045331,
      "grad_norm": 9.55937671661377,
      "learning_rate": 9.694146219524843e-06,
      "loss": 0.5202206611633301,
      "memory(GiB)": 67.44,
      "step": 8380,
      "train_speed(iter/s)": 0.253569
    },
    {
      "epoch": 0.7821098778099058,
      "grad_norm": 5.979936599731445,
      "learning_rate": 9.693614856133584e-06,
      "loss": 0.49849872589111327,
      "memory(GiB)": 67.44,
      "step": 8385,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.253565
    },
    {
      "epoch": 0.7825762522152784,
      "grad_norm": 5.727031230926514,
      "learning_rate": 9.69308304615933e-06,
      "loss": 0.48804426193237305,
      "memory(GiB)": 67.44,
      "step": 8390,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253563
    },
    {
      "epoch": 0.783042626620651,
      "grad_norm": 5.375875473022461,
      "learning_rate": 9.692550789652682e-06,
      "loss": 0.5054209709167481,
      "memory(GiB)": 67.44,
      "step": 8395,
      "train_speed(iter/s)": 0.253562
    },
    {
      "epoch": 0.7835090010260237,
      "grad_norm": 4.2230119705200195,
      "learning_rate": 9.692018086664282e-06,
      "loss": 0.5316634178161621,
      "memory(GiB)": 67.44,
      "step": 8400,
      "train_speed(iter/s)": 0.253561
    },
    {
      "epoch": 0.7839753754313963,
      "grad_norm": 6.093780040740967,
      "learning_rate": 9.691484937244814e-06,
      "loss": 0.5093668937683106,
      "memory(GiB)": 67.44,
      "step": 8405,
      "train_speed(iter/s)": 0.253565
    },
    {
      "epoch": 0.784441749836769,
      "grad_norm": 4.725615978240967,
      "learning_rate": 9.690951341445007e-06,
      "loss": 0.47461824417114257,
      "memory(GiB)": 67.44,
      "step": 8410,
      "token_acc": 0.8053691275167785,
      "train_speed(iter/s)": 0.253564
    },
    {
      "epoch": 0.7849081242421416,
      "grad_norm": 5.570045471191406,
      "learning_rate": 9.69041729931563e-06,
      "loss": 0.5253726959228515,
      "memory(GiB)": 67.44,
      "step": 8415,
      "train_speed(iter/s)": 0.253561
    },
    {
      "epoch": 0.7853744986475142,
      "grad_norm": 5.8782758712768555,
      "learning_rate": 9.689882810907498e-06,
      "loss": 0.4744431495666504,
      "memory(GiB)": 67.44,
      "step": 8420,
      "train_speed(iter/s)": 0.253361
    },
    {
      "epoch": 0.7858408730528869,
      "grad_norm": 3.888254404067993,
      "learning_rate": 9.689347876271465e-06,
      "loss": 0.4999236106872559,
      "memory(GiB)": 67.44,
      "step": 8425,
      "token_acc": 0.546875,
      "train_speed(iter/s)": 0.253354
    },
    {
      "epoch": 0.7863072474582595,
      "grad_norm": 6.101819038391113,
      "learning_rate": 9.688812495458427e-06,
      "loss": 0.48816471099853515,
      "memory(GiB)": 67.44,
      "step": 8430,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.253362
    },
    {
      "epoch": 0.7867736218636321,
      "grad_norm": 5.2009148597717285,
      "learning_rate": 9.688276668519322e-06,
      "loss": 0.5279853820800782,
      "memory(GiB)": 67.44,
      "step": 8435,
      "token_acc": 0.49122807017543857,
      "train_speed(iter/s)": 0.253358
    },
    {
      "epoch": 0.7872399962690048,
      "grad_norm": 4.9706902503967285,
      "learning_rate": 9.687740395505135e-06,
      "loss": 0.4787726402282715,
      "memory(GiB)": 67.44,
      "step": 8440,
      "token_acc": 0.631578947368421,
      "train_speed(iter/s)": 0.253359
    },
    {
      "epoch": 0.7877063706743774,
      "grad_norm": 5.08637809753418,
      "learning_rate": 9.687203676466893e-06,
      "loss": 0.5261897087097168,
      "memory(GiB)": 67.44,
      "step": 8445,
      "train_speed(iter/s)": 0.253352
    },
    {
      "epoch": 0.78817274507975,
      "grad_norm": 4.807915210723877,
      "learning_rate": 9.686666511455658e-06,
      "loss": 0.5088712692260742,
      "memory(GiB)": 67.44,
      "step": 8450,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.253349
    },
    {
      "epoch": 0.7886391194851227,
      "grad_norm": 2.8950107097625732,
      "learning_rate": 9.686128900522543e-06,
      "loss": 0.4818610191345215,
      "memory(GiB)": 67.44,
      "step": 8455,
      "train_speed(iter/s)": 0.253349
    },
    {
      "epoch": 0.7891054938904953,
      "grad_norm": 6.668105125427246,
      "learning_rate": 9.685590843718697e-06,
      "loss": 0.5233240127563477,
      "memory(GiB)": 67.44,
      "step": 8460,
      "train_speed(iter/s)": 0.253356
    },
    {
      "epoch": 0.7895718682958679,
      "grad_norm": 3.8629367351531982,
      "learning_rate": 9.68505234109532e-06,
      "loss": 0.5063562870025635,
      "memory(GiB)": 67.44,
      "step": 8465,
      "token_acc": 0.8053097345132744,
      "train_speed(iter/s)": 0.253358
    },
    {
      "epoch": 0.7900382427012406,
      "grad_norm": 15.91946792602539,
      "learning_rate": 9.684513392703643e-06,
      "loss": 0.49958181381225586,
      "memory(GiB)": 67.44,
      "step": 8470,
      "token_acc": 0.3582089552238806,
      "train_speed(iter/s)": 0.25336
    },
    {
      "epoch": 0.7905046171066132,
      "grad_norm": 8.861089706420898,
      "learning_rate": 9.683973998594948e-06,
      "loss": 0.5281661033630372,
      "memory(GiB)": 67.44,
      "step": 8475,
      "token_acc": 0.3484848484848485,
      "train_speed(iter/s)": 0.253347
    },
    {
      "epoch": 0.7909709915119858,
      "grad_norm": 3.444866895675659,
      "learning_rate": 9.683434158820557e-06,
      "loss": 0.5184846878051758,
      "memory(GiB)": 67.44,
      "step": 8480,
      "train_speed(iter/s)": 0.253353
    },
    {
      "epoch": 0.7914373659173585,
      "grad_norm": 5.747501373291016,
      "learning_rate": 9.682893873431833e-06,
      "loss": 0.5465421199798584,
      "memory(GiB)": 67.44,
      "step": 8485,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253354
    },
    {
      "epoch": 0.7919037403227311,
      "grad_norm": 5.719590187072754,
      "learning_rate": 9.682353142480183e-06,
      "loss": 0.5090926170349122,
      "memory(GiB)": 67.44,
      "step": 8490,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.253355
    },
    {
      "epoch": 0.7923701147281037,
      "grad_norm": 7.410871982574463,
      "learning_rate": 9.681811966017056e-06,
      "loss": 0.477200984954834,
      "memory(GiB)": 67.44,
      "step": 8495,
      "token_acc": 0.46551724137931033,
      "train_speed(iter/s)": 0.253348
    },
    {
      "epoch": 0.7928364891334764,
      "grad_norm": 4.769709587097168,
      "learning_rate": 9.681270344093943e-06,
      "loss": 0.5378439903259278,
      "memory(GiB)": 67.44,
      "step": 8500,
      "train_speed(iter/s)": 0.253348
    },
    {
      "epoch": 0.7933028635388489,
      "grad_norm": 3.9819397926330566,
      "learning_rate": 9.68072827676238e-06,
      "loss": 0.487677001953125,
      "memory(GiB)": 67.44,
      "step": 8505,
      "train_speed(iter/s)": 0.253351
    },
    {
      "epoch": 0.7937692379442216,
      "grad_norm": 2.885897397994995,
      "learning_rate": 9.680185764073937e-06,
      "loss": 0.45331974029541017,
      "memory(GiB)": 67.44,
      "step": 8510,
      "token_acc": 0.410958904109589,
      "train_speed(iter/s)": 0.253341
    },
    {
      "epoch": 0.7942356123495943,
      "grad_norm": 3.9347727298736572,
      "learning_rate": 9.679642806080239e-06,
      "loss": 0.5312259674072266,
      "memory(GiB)": 67.44,
      "step": 8515,
      "train_speed(iter/s)": 0.253353
    },
    {
      "epoch": 0.7947019867549668,
      "grad_norm": 3.8037710189819336,
      "learning_rate": 9.679099402832941e-06,
      "loss": 0.5231997013092041,
      "memory(GiB)": 67.44,
      "step": 8520,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.25336
    },
    {
      "epoch": 0.7951683611603395,
      "grad_norm": 5.757062911987305,
      "learning_rate": 9.678555554383751e-06,
      "loss": 0.514549970626831,
      "memory(GiB)": 67.44,
      "step": 8525,
      "train_speed(iter/s)": 0.253366
    },
    {
      "epoch": 0.7956347355657122,
      "grad_norm": 5.578664779663086,
      "learning_rate": 9.678011260784414e-06,
      "loss": 0.5445764541625977,
      "memory(GiB)": 67.44,
      "step": 8530,
      "train_speed(iter/s)": 0.253376
    },
    {
      "epoch": 0.7961011099710847,
      "grad_norm": 3.8819355964660645,
      "learning_rate": 9.677466522086715e-06,
      "loss": 0.5169895172119141,
      "memory(GiB)": 67.44,
      "step": 8535,
      "train_speed(iter/s)": 0.253385
    },
    {
      "epoch": 0.7965674843764574,
      "grad_norm": 4.232466697692871,
      "learning_rate": 9.676921338342486e-06,
      "loss": 0.4721211433410645,
      "memory(GiB)": 67.44,
      "step": 8540,
      "train_speed(iter/s)": 0.253401
    },
    {
      "epoch": 0.7970338587818301,
      "grad_norm": 7.2605299949646,
      "learning_rate": 9.676375709603597e-06,
      "loss": 0.5683111190795899,
      "memory(GiB)": 67.44,
      "step": 8545,
      "token_acc": 0.9473684210526315,
      "train_speed(iter/s)": 0.253403
    },
    {
      "epoch": 0.7975002331872026,
      "grad_norm": 7.158373832702637,
      "learning_rate": 9.67582963592197e-06,
      "loss": 0.55561842918396,
      "memory(GiB)": 67.44,
      "step": 8550,
      "token_acc": 0.90625,
      "train_speed(iter/s)": 0.253394
    },
    {
      "epoch": 0.7979666075925753,
      "grad_norm": 9.705489158630371,
      "learning_rate": 9.675283117349554e-06,
      "loss": 0.5063759803771972,
      "memory(GiB)": 67.44,
      "step": 8555,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.253412
    },
    {
      "epoch": 0.798432981997948,
      "grad_norm": 5.409040451049805,
      "learning_rate": 9.674736153938352e-06,
      "loss": 0.5132983207702637,
      "memory(GiB)": 67.44,
      "step": 8560,
      "train_speed(iter/s)": 0.253407
    },
    {
      "epoch": 0.7988993564033205,
      "grad_norm": 4.286170959472656,
      "learning_rate": 9.674188745740407e-06,
      "loss": 0.5084319114685059,
      "memory(GiB)": 67.44,
      "step": 8565,
      "train_speed(iter/s)": 0.253401
    },
    {
      "epoch": 0.7993657308086932,
      "grad_norm": 5.260423183441162,
      "learning_rate": 9.673640892807801e-06,
      "loss": 0.5097436428070068,
      "memory(GiB)": 67.44,
      "step": 8570,
      "train_speed(iter/s)": 0.253406
    },
    {
      "epoch": 0.7998321052140659,
      "grad_norm": 7.194436550140381,
      "learning_rate": 9.673092595192663e-06,
      "loss": 0.515444564819336,
      "memory(GiB)": 67.44,
      "step": 8575,
      "token_acc": 0.5897435897435898,
      "train_speed(iter/s)": 0.253405
    },
    {
      "epoch": 0.8002984796194385,
      "grad_norm": 3.983161211013794,
      "learning_rate": 9.672543852947159e-06,
      "loss": 0.5143641471862793,
      "memory(GiB)": 67.44,
      "step": 8580,
      "token_acc": 0.3684210526315789,
      "train_speed(iter/s)": 0.253417
    },
    {
      "epoch": 0.8007648540248111,
      "grad_norm": 4.442848205566406,
      "learning_rate": 9.671994666123501e-06,
      "loss": 0.4915131092071533,
      "memory(GiB)": 67.44,
      "step": 8585,
      "train_speed(iter/s)": 0.253417
    },
    {
      "epoch": 0.8012312284301838,
      "grad_norm": 4.550954818725586,
      "learning_rate": 9.671445034773945e-06,
      "loss": 0.47194671630859375,
      "memory(GiB)": 67.44,
      "step": 8590,
      "train_speed(iter/s)": 0.253423
    },
    {
      "epoch": 0.8016976028355564,
      "grad_norm": 2.9729537963867188,
      "learning_rate": 9.670894958950783e-06,
      "loss": 0.4628561496734619,
      "memory(GiB)": 67.44,
      "step": 8595,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.253427
    },
    {
      "epoch": 0.802163977240929,
      "grad_norm": 4.234355926513672,
      "learning_rate": 9.670344438706356e-06,
      "loss": 0.4907505989074707,
      "memory(GiB)": 67.44,
      "step": 8600,
      "token_acc": 0.36065573770491804,
      "train_speed(iter/s)": 0.253423
    },
    {
      "epoch": 0.8026303516463017,
      "grad_norm": 4.642180442810059,
      "learning_rate": 9.669793474093044e-06,
      "loss": 0.5264536380767822,
      "memory(GiB)": 67.44,
      "step": 8605,
      "train_speed(iter/s)": 0.25343
    },
    {
      "epoch": 0.8030967260516743,
      "grad_norm": 5.117538928985596,
      "learning_rate": 9.669242065163265e-06,
      "loss": 0.4942955017089844,
      "memory(GiB)": 67.44,
      "step": 8610,
      "token_acc": 0.40476190476190477,
      "train_speed(iter/s)": 0.253441
    },
    {
      "epoch": 0.8035631004570469,
      "grad_norm": 4.040913105010986,
      "learning_rate": 9.66869021196949e-06,
      "loss": 0.5107475280761719,
      "memory(GiB)": 67.44,
      "step": 8615,
      "train_speed(iter/s)": 0.25344
    },
    {
      "epoch": 0.8040294748624196,
      "grad_norm": 5.525641441345215,
      "learning_rate": 9.668137914564222e-06,
      "loss": 0.4922398567199707,
      "memory(GiB)": 67.44,
      "step": 8620,
      "token_acc": 0.9145299145299145,
      "train_speed(iter/s)": 0.253435
    },
    {
      "epoch": 0.8044958492677922,
      "grad_norm": 4.000021457672119,
      "learning_rate": 9.667585173000014e-06,
      "loss": 0.47647686004638673,
      "memory(GiB)": 67.44,
      "step": 8625,
      "token_acc": 0.4657534246575342,
      "train_speed(iter/s)": 0.253433
    },
    {
      "epoch": 0.8049622236731648,
      "grad_norm": 4.389257907867432,
      "learning_rate": 9.667031987329454e-06,
      "loss": 0.4933601379394531,
      "memory(GiB)": 67.44,
      "step": 8630,
      "token_acc": 0.6621621621621622,
      "train_speed(iter/s)": 0.253439
    },
    {
      "epoch": 0.8054285980785374,
      "grad_norm": 4.87441873550415,
      "learning_rate": 9.666478357605179e-06,
      "loss": 0.47074131965637206,
      "memory(GiB)": 67.44,
      "step": 8635,
      "token_acc": 0.6336633663366337,
      "train_speed(iter/s)": 0.253448
    },
    {
      "epoch": 0.8058949724839101,
      "grad_norm": 4.382126331329346,
      "learning_rate": 9.665924283879862e-06,
      "loss": 0.4802866458892822,
      "memory(GiB)": 67.44,
      "step": 8640,
      "token_acc": 0.898876404494382,
      "train_speed(iter/s)": 0.253448
    },
    {
      "epoch": 0.8063613468892827,
      "grad_norm": 4.261673450469971,
      "learning_rate": 9.665369766206225e-06,
      "loss": 0.4912725448608398,
      "memory(GiB)": 67.44,
      "step": 8645,
      "token_acc": 0.7954545454545454,
      "train_speed(iter/s)": 0.253458
    },
    {
      "epoch": 0.8068277212946553,
      "grad_norm": 7.841752529144287,
      "learning_rate": 9.664814804637026e-06,
      "loss": 0.5513838768005371,
      "memory(GiB)": 67.44,
      "step": 8650,
      "train_speed(iter/s)": 0.253466
    },
    {
      "epoch": 0.807294095700028,
      "grad_norm": 3.50166916847229,
      "learning_rate": 9.664259399225069e-06,
      "loss": 0.528313684463501,
      "memory(GiB)": 67.44,
      "step": 8655,
      "train_speed(iter/s)": 0.253469
    },
    {
      "epoch": 0.8077604701054006,
      "grad_norm": 4.837986946105957,
      "learning_rate": 9.663703550023198e-06,
      "loss": 0.5051993370056153,
      "memory(GiB)": 67.44,
      "step": 8660,
      "train_speed(iter/s)": 0.253479
    },
    {
      "epoch": 0.8082268445107732,
      "grad_norm": 2.7932024002075195,
      "learning_rate": 9.6631472570843e-06,
      "loss": 0.5040431022644043,
      "memory(GiB)": 67.44,
      "step": 8665,
      "token_acc": 0.6844660194174758,
      "train_speed(iter/s)": 0.25348
    },
    {
      "epoch": 0.8086932189161459,
      "grad_norm": 6.8123698234558105,
      "learning_rate": 9.662590520461308e-06,
      "loss": 0.4673356056213379,
      "memory(GiB)": 67.44,
      "step": 8670,
      "train_speed(iter/s)": 0.253483
    },
    {
      "epoch": 0.8091595933215185,
      "grad_norm": 5.3660359382629395,
      "learning_rate": 9.66203334020719e-06,
      "loss": 0.48559961318969724,
      "memory(GiB)": 67.44,
      "step": 8675,
      "token_acc": 0.8155339805825242,
      "train_speed(iter/s)": 0.253486
    },
    {
      "epoch": 0.8096259677268911,
      "grad_norm": 3.432537078857422,
      "learning_rate": 9.661475716374961e-06,
      "loss": 0.5235420227050781,
      "memory(GiB)": 67.44,
      "step": 8680,
      "train_speed(iter/s)": 0.253483
    },
    {
      "epoch": 0.8100923421322638,
      "grad_norm": 8.896681785583496,
      "learning_rate": 9.660917649017679e-06,
      "loss": 0.47048110961914064,
      "memory(GiB)": 67.44,
      "step": 8685,
      "train_speed(iter/s)": 0.253485
    },
    {
      "epoch": 0.8105587165376364,
      "grad_norm": 5.285147666931152,
      "learning_rate": 9.66035913818844e-06,
      "loss": 0.5176362037658692,
      "memory(GiB)": 67.44,
      "step": 8690,
      "train_speed(iter/s)": 0.253485
    },
    {
      "epoch": 0.811025090943009,
      "grad_norm": 6.819659233093262,
      "learning_rate": 9.659800183940386e-06,
      "loss": 0.5077186584472656,
      "memory(GiB)": 67.44,
      "step": 8695,
      "token_acc": 0.47244094488188976,
      "train_speed(iter/s)": 0.253492
    },
    {
      "epoch": 0.8114914653483817,
      "grad_norm": 4.6349029541015625,
      "learning_rate": 9.6592407863267e-06,
      "loss": 0.5022440433502198,
      "memory(GiB)": 67.44,
      "step": 8700,
      "train_speed(iter/s)": 0.253497
    },
    {
      "epoch": 0.8119578397537544,
      "grad_norm": 4.582718849182129,
      "learning_rate": 9.658680945400608e-06,
      "loss": 0.4956171989440918,
      "memory(GiB)": 67.44,
      "step": 8705,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.8124242141591269,
      "grad_norm": 7.063054084777832,
      "learning_rate": 9.658120661215372e-06,
      "loss": 0.5139860153198242,
      "memory(GiB)": 67.44,
      "step": 8710,
      "token_acc": 0.46808510638297873,
      "train_speed(iter/s)": 0.253489
    },
    {
      "epoch": 0.8128905885644996,
      "grad_norm": 5.348999500274658,
      "learning_rate": 9.657559933824305e-06,
      "loss": 0.48798327445983886,
      "memory(GiB)": 67.44,
      "step": 8715,
      "train_speed(iter/s)": 0.253487
    },
    {
      "epoch": 0.8133569629698723,
      "grad_norm": 18.3762149810791,
      "learning_rate": 9.65699876328076e-06,
      "loss": 0.45094985961914064,
      "memory(GiB)": 67.44,
      "step": 8720,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.25349
    },
    {
      "epoch": 0.8138233373752448,
      "grad_norm": 5.798618793487549,
      "learning_rate": 9.656437149638129e-06,
      "loss": 0.47940654754638673,
      "memory(GiB)": 67.44,
      "step": 8725,
      "train_speed(iter/s)": 0.253487
    },
    {
      "epoch": 0.8142897117806175,
      "grad_norm": 5.460284233093262,
      "learning_rate": 9.655875092949845e-06,
      "loss": 0.48363170623779295,
      "memory(GiB)": 67.44,
      "step": 8730,
      "token_acc": 0.4827586206896552,
      "train_speed(iter/s)": 0.25349
    },
    {
      "epoch": 0.8147560861859902,
      "grad_norm": 4.236598968505859,
      "learning_rate": 9.655312593269391e-06,
      "loss": 0.5309081554412842,
      "memory(GiB)": 67.44,
      "step": 8735,
      "train_speed(iter/s)": 0.253497
    },
    {
      "epoch": 0.8152224605913627,
      "grad_norm": 4.891384124755859,
      "learning_rate": 9.654749650650285e-06,
      "loss": 0.4872734546661377,
      "memory(GiB)": 67.44,
      "step": 8740,
      "train_speed(iter/s)": 0.253502
    },
    {
      "epoch": 0.8156888349967354,
      "grad_norm": 4.474985122680664,
      "learning_rate": 9.654186265146088e-06,
      "loss": 0.5035918712615967,
      "memory(GiB)": 67.44,
      "step": 8745,
      "token_acc": 0.6041666666666666,
      "train_speed(iter/s)": 0.253501
    },
    {
      "epoch": 0.8161552094021081,
      "grad_norm": 8.78014087677002,
      "learning_rate": 9.653622436810405e-06,
      "loss": 0.5309269905090332,
      "memory(GiB)": 67.44,
      "step": 8750,
      "token_acc": 0.8902439024390244,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.8166215838074806,
      "grad_norm": 4.664052486419678,
      "learning_rate": 9.653058165696884e-06,
      "loss": 0.49280872344970705,
      "memory(GiB)": 67.44,
      "step": 8755,
      "train_speed(iter/s)": 0.253494
    },
    {
      "epoch": 0.8170879582128533,
      "grad_norm": 4.773697853088379,
      "learning_rate": 9.652493451859215e-06,
      "loss": 0.5222699165344238,
      "memory(GiB)": 67.44,
      "step": 8760,
      "token_acc": 0.43902439024390244,
      "train_speed(iter/s)": 0.253496
    },
    {
      "epoch": 0.817554332618226,
      "grad_norm": 4.307128429412842,
      "learning_rate": 9.651928295351124e-06,
      "loss": 0.4874595642089844,
      "memory(GiB)": 67.44,
      "step": 8765,
      "token_acc": 0.9090909090909091,
      "train_speed(iter/s)": 0.253496
    },
    {
      "epoch": 0.8180207070235985,
      "grad_norm": 4.18894624710083,
      "learning_rate": 9.651362696226385e-06,
      "loss": 0.5428021907806396,
      "memory(GiB)": 67.44,
      "step": 8770,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.253499
    },
    {
      "epoch": 0.8184870814289712,
      "grad_norm": 3.5819196701049805,
      "learning_rate": 9.650796654538816e-06,
      "loss": 0.5489694595336914,
      "memory(GiB)": 67.44,
      "step": 8775,
      "token_acc": 0.4230769230769231,
      "train_speed(iter/s)": 0.253505
    },
    {
      "epoch": 0.8189534558343438,
      "grad_norm": 3.68039870262146,
      "learning_rate": 9.650230170342271e-06,
      "loss": 0.5034084320068359,
      "memory(GiB)": 67.44,
      "step": 8780,
      "token_acc": 0.509090909090909,
      "train_speed(iter/s)": 0.253511
    },
    {
      "epoch": 0.8194198302397164,
      "grad_norm": 3.708249807357788,
      "learning_rate": 9.649663243690653e-06,
      "loss": 0.5060811996459961,
      "memory(GiB)": 67.44,
      "step": 8785,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.253515
    },
    {
      "epoch": 0.8198862046450891,
      "grad_norm": 6.163581371307373,
      "learning_rate": 9.649095874637899e-06,
      "loss": 0.48505358695983886,
      "memory(GiB)": 67.44,
      "step": 8790,
      "token_acc": 0.9166666666666666,
      "train_speed(iter/s)": 0.253521
    },
    {
      "epoch": 0.8203525790504617,
      "grad_norm": 2.544672966003418,
      "learning_rate": 9.648528063237995e-06,
      "loss": 0.5083672046661377,
      "memory(GiB)": 67.44,
      "step": 8795,
      "train_speed(iter/s)": 0.253526
    },
    {
      "epoch": 0.8208189534558343,
      "grad_norm": 5.9089460372924805,
      "learning_rate": 9.647959809544967e-06,
      "loss": 0.49416589736938477,
      "memory(GiB)": 67.44,
      "step": 8800,
      "train_speed(iter/s)": 0.253515
    },
    {
      "epoch": 0.821285327861207,
      "grad_norm": 5.999527931213379,
      "learning_rate": 9.647391113612879e-06,
      "loss": 0.48081340789794924,
      "memory(GiB)": 67.44,
      "step": 8805,
      "token_acc": 0.5675675675675675,
      "train_speed(iter/s)": 0.253517
    },
    {
      "epoch": 0.8217517022665796,
      "grad_norm": 3.835285186767578,
      "learning_rate": 9.646821975495846e-06,
      "loss": 0.5001148700714111,
      "memory(GiB)": 67.44,
      "step": 8810,
      "token_acc": 0.5967741935483871,
      "train_speed(iter/s)": 0.253525
    },
    {
      "epoch": 0.8222180766719522,
      "grad_norm": 4.113040447235107,
      "learning_rate": 9.646252395248014e-06,
      "loss": 0.545820951461792,
      "memory(GiB)": 67.44,
      "step": 8815,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.253527
    },
    {
      "epoch": 0.8226844510773249,
      "grad_norm": 3.651508331298828,
      "learning_rate": 9.645682372923583e-06,
      "loss": 0.5153267860412598,
      "memory(GiB)": 67.44,
      "step": 8820,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.253524
    },
    {
      "epoch": 0.8231508254826975,
      "grad_norm": 6.049116611480713,
      "learning_rate": 9.645111908576783e-06,
      "loss": 0.4964897155761719,
      "memory(GiB)": 67.44,
      "step": 8825,
      "train_speed(iter/s)": 0.253518
    },
    {
      "epoch": 0.8236171998880701,
      "grad_norm": 6.232046127319336,
      "learning_rate": 9.644541002261896e-06,
      "loss": 0.48439784049987794,
      "memory(GiB)": 67.44,
      "step": 8830,
      "train_speed(iter/s)": 0.253522
    },
    {
      "epoch": 0.8240835742934428,
      "grad_norm": 5.525269508361816,
      "learning_rate": 9.64396965403324e-06,
      "loss": 0.4620979309082031,
      "memory(GiB)": 67.44,
      "step": 8835,
      "train_speed(iter/s)": 0.253528
    },
    {
      "epoch": 0.8245499486988154,
      "grad_norm": 5.254124641418457,
      "learning_rate": 9.643397863945178e-06,
      "loss": 0.5048796653747558,
      "memory(GiB)": 67.44,
      "step": 8840,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.253533
    },
    {
      "epoch": 0.825016323104188,
      "grad_norm": 5.522476673126221,
      "learning_rate": 9.642825632052113e-06,
      "loss": 0.49691095352172854,
      "memory(GiB)": 67.44,
      "step": 8845,
      "train_speed(iter/s)": 0.253529
    },
    {
      "epoch": 0.8254826975095607,
      "grad_norm": 6.47759485244751,
      "learning_rate": 9.64225295840849e-06,
      "loss": 0.5059350967407227,
      "memory(GiB)": 67.44,
      "step": 8850,
      "train_speed(iter/s)": 0.253526
    },
    {
      "epoch": 0.8259490719149333,
      "grad_norm": 6.019756317138672,
      "learning_rate": 9.641679843068801e-06,
      "loss": 0.5106636047363281,
      "memory(GiB)": 67.44,
      "step": 8855,
      "token_acc": 0.897196261682243,
      "train_speed(iter/s)": 0.253523
    },
    {
      "epoch": 0.826415446320306,
      "grad_norm": 5.122153282165527,
      "learning_rate": 9.641106286087575e-06,
      "loss": 0.4334815502166748,
      "memory(GiB)": 67.44,
      "step": 8860,
      "train_speed(iter/s)": 0.253522
    },
    {
      "epoch": 0.8268818207256786,
      "grad_norm": 6.284817695617676,
      "learning_rate": 9.640532287519382e-06,
      "loss": 0.5157001972198486,
      "memory(GiB)": 67.44,
      "step": 8865,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.253523
    },
    {
      "epoch": 0.8273481951310512,
      "grad_norm": 8.290534019470215,
      "learning_rate": 9.639957847418837e-06,
      "loss": 0.5090363979339599,
      "memory(GiB)": 67.44,
      "step": 8870,
      "train_speed(iter/s)": 0.253521
    },
    {
      "epoch": 0.8278145695364238,
      "grad_norm": 2.988781452178955,
      "learning_rate": 9.639382965840596e-06,
      "loss": 0.5114452362060546,
      "memory(GiB)": 67.44,
      "step": 8875,
      "token_acc": 0.5340909090909091,
      "train_speed(iter/s)": 0.253519
    },
    {
      "epoch": 0.8282809439417965,
      "grad_norm": 3.398493766784668,
      "learning_rate": 9.63880764283936e-06,
      "loss": 0.5336394309997559,
      "memory(GiB)": 67.44,
      "step": 8880,
      "train_speed(iter/s)": 0.253522
    },
    {
      "epoch": 0.8287473183471691,
      "grad_norm": 3.733553409576416,
      "learning_rate": 9.638231878469864e-06,
      "loss": 0.4937028408050537,
      "memory(GiB)": 67.44,
      "step": 8885,
      "train_speed(iter/s)": 0.253527
    },
    {
      "epoch": 0.8292136927525418,
      "grad_norm": 5.447298526763916,
      "learning_rate": 9.637655672786894e-06,
      "loss": 0.5183464527130127,
      "memory(GiB)": 67.44,
      "step": 8890,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.253532
    },
    {
      "epoch": 0.8296800671579144,
      "grad_norm": 5.5951128005981445,
      "learning_rate": 9.637079025845275e-06,
      "loss": 0.5483346462249756,
      "memory(GiB)": 67.44,
      "step": 8895,
      "train_speed(iter/s)": 0.25353
    },
    {
      "epoch": 0.830146441563287,
      "grad_norm": 4.213175296783447,
      "learning_rate": 9.63650193769987e-06,
      "loss": 0.5088875770568848,
      "memory(GiB)": 67.44,
      "step": 8900,
      "train_speed(iter/s)": 0.253531
    },
    {
      "epoch": 0.8306128159686597,
      "grad_norm": 4.504436016082764,
      "learning_rate": 9.63592440840559e-06,
      "loss": 0.4861905097961426,
      "memory(GiB)": 67.44,
      "step": 8905,
      "train_speed(iter/s)": 0.253526
    },
    {
      "epoch": 0.8310791903740323,
      "grad_norm": 4.815211296081543,
      "learning_rate": 9.635346438017383e-06,
      "loss": 0.5084785461425781,
      "memory(GiB)": 67.44,
      "step": 8910,
      "token_acc": 0.4772727272727273,
      "train_speed(iter/s)": 0.253526
    },
    {
      "epoch": 0.8315455647794049,
      "grad_norm": 7.771849632263184,
      "learning_rate": 9.634768026590242e-06,
      "loss": 0.5088491439819336,
      "memory(GiB)": 67.44,
      "step": 8915,
      "token_acc": 0.43137254901960786,
      "train_speed(iter/s)": 0.253525
    },
    {
      "epoch": 0.8320119391847776,
      "grad_norm": 3.660632371902466,
      "learning_rate": 9.6341891741792e-06,
      "loss": 0.4901125907897949,
      "memory(GiB)": 67.44,
      "step": 8920,
      "token_acc": 0.34146341463414637,
      "train_speed(iter/s)": 0.253528
    },
    {
      "epoch": 0.8324783135901501,
      "grad_norm": 5.17942476272583,
      "learning_rate": 9.633609880839337e-06,
      "loss": 0.5189850330352783,
      "memory(GiB)": 67.44,
      "step": 8925,
      "token_acc": 0.6553398058252428,
      "train_speed(iter/s)": 0.253535
    },
    {
      "epoch": 0.8329446879955228,
      "grad_norm": 3.597271680831909,
      "learning_rate": 9.633030146625767e-06,
      "loss": 0.457917308807373,
      "memory(GiB)": 67.44,
      "step": 8930,
      "token_acc": 0.36666666666666664,
      "train_speed(iter/s)": 0.253529
    },
    {
      "epoch": 0.8334110624008955,
      "grad_norm": 4.039499282836914,
      "learning_rate": 9.632449971593649e-06,
      "loss": 0.4928291320800781,
      "memory(GiB)": 67.44,
      "step": 8935,
      "train_speed(iter/s)": 0.253532
    },
    {
      "epoch": 0.833877436806268,
      "grad_norm": 3.051661968231201,
      "learning_rate": 9.631869355798187e-06,
      "loss": 0.4831756591796875,
      "memory(GiB)": 67.44,
      "step": 8940,
      "train_speed(iter/s)": 0.253535
    },
    {
      "epoch": 0.8343438112116407,
      "grad_norm": 4.6897687911987305,
      "learning_rate": 9.631288299294626e-06,
      "loss": 0.4927760124206543,
      "memory(GiB)": 67.44,
      "step": 8945,
      "train_speed(iter/s)": 0.253537
    },
    {
      "epoch": 0.8348101856170134,
      "grad_norm": 4.96986198425293,
      "learning_rate": 9.63070680213825e-06,
      "loss": 0.5160708427429199,
      "memory(GiB)": 67.44,
      "step": 8950,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.253532
    },
    {
      "epoch": 0.8352765600223859,
      "grad_norm": 4.981680870056152,
      "learning_rate": 9.630124864384387e-06,
      "loss": 0.5458628177642822,
      "memory(GiB)": 67.44,
      "step": 8955,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.253535
    },
    {
      "epoch": 0.8357429344277586,
      "grad_norm": 3.911954164505005,
      "learning_rate": 9.629542486088407e-06,
      "loss": 0.5222501277923584,
      "memory(GiB)": 67.44,
      "step": 8960,
      "train_speed(iter/s)": 0.253545
    },
    {
      "epoch": 0.8362093088331313,
      "grad_norm": 3.5382986068725586,
      "learning_rate": 9.62895966730572e-06,
      "loss": 0.475748348236084,
      "memory(GiB)": 67.44,
      "step": 8965,
      "token_acc": 0.9540229885057471,
      "train_speed(iter/s)": 0.253548
    },
    {
      "epoch": 0.8366756832385038,
      "grad_norm": 5.00235652923584,
      "learning_rate": 9.628376408091782e-06,
      "loss": 0.48653435707092285,
      "memory(GiB)": 67.44,
      "step": 8970,
      "train_speed(iter/s)": 0.253555
    },
    {
      "epoch": 0.8371420576438765,
      "grad_norm": 4.030304431915283,
      "learning_rate": 9.627792708502085e-06,
      "loss": 0.5522650718688965,
      "memory(GiB)": 67.44,
      "step": 8975,
      "token_acc": 0.8159509202453987,
      "train_speed(iter/s)": 0.253554
    },
    {
      "epoch": 0.8376084320492492,
      "grad_norm": 9.105169296264648,
      "learning_rate": 9.62720856859217e-06,
      "loss": 0.529330062866211,
      "memory(GiB)": 67.44,
      "step": 8980,
      "train_speed(iter/s)": 0.253548
    },
    {
      "epoch": 0.8380748064546217,
      "grad_norm": 5.12136697769165,
      "learning_rate": 9.626623988417613e-06,
      "loss": 0.5232389450073243,
      "memory(GiB)": 67.44,
      "step": 8985,
      "token_acc": 0.6296296296296297,
      "train_speed(iter/s)": 0.253551
    },
    {
      "epoch": 0.8385411808599944,
      "grad_norm": 4.61501932144165,
      "learning_rate": 9.626038968034038e-06,
      "loss": 0.5113958358764649,
      "memory(GiB)": 67.44,
      "step": 8990,
      "train_speed(iter/s)": 0.25336
    },
    {
      "epoch": 0.8390075552653671,
      "grad_norm": 10.638749122619629,
      "learning_rate": 9.625453507497103e-06,
      "loss": 0.4779379844665527,
      "memory(GiB)": 67.44,
      "step": 8995,
      "train_speed(iter/s)": 0.253361
    },
    {
      "epoch": 0.8394739296707396,
      "grad_norm": 4.103051662445068,
      "learning_rate": 9.624867606862518e-06,
      "loss": 0.48182039260864257,
      "memory(GiB)": 67.44,
      "step": 9000,
      "token_acc": 0.6530612244897959,
      "train_speed(iter/s)": 0.253368
    },
    {
      "epoch": 0.8399403040761123,
      "grad_norm": 3.4554340839385986,
      "learning_rate": 9.624281266186026e-06,
      "loss": 0.4828617095947266,
      "memory(GiB)": 67.44,
      "step": 9005,
      "token_acc": 0.8947368421052632,
      "train_speed(iter/s)": 0.25337
    },
    {
      "epoch": 0.840406678481485,
      "grad_norm": 3.6780426502227783,
      "learning_rate": 9.623694485523418e-06,
      "loss": 0.5119866847991943,
      "memory(GiB)": 67.44,
      "step": 9010,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.253372
    },
    {
      "epoch": 0.8408730528868575,
      "grad_norm": 4.5572123527526855,
      "learning_rate": 9.623107264930522e-06,
      "loss": 0.49117631912231446,
      "memory(GiB)": 72.72,
      "step": 9015,
      "token_acc": 0.875,
      "train_speed(iter/s)": 0.253371
    },
    {
      "epoch": 0.8413394272922302,
      "grad_norm": 3.1090381145477295,
      "learning_rate": 9.622519604463215e-06,
      "loss": 0.4908725738525391,
      "memory(GiB)": 72.72,
      "step": 9020,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.253377
    },
    {
      "epoch": 0.8418058016976029,
      "grad_norm": 4.361937522888184,
      "learning_rate": 9.621931504177404e-06,
      "loss": 0.47698464393615725,
      "memory(GiB)": 72.72,
      "step": 9025,
      "token_acc": 0.759493670886076,
      "train_speed(iter/s)": 0.253368
    },
    {
      "epoch": 0.8422721761029754,
      "grad_norm": 5.556940078735352,
      "learning_rate": 9.62134296412905e-06,
      "loss": 0.5018954753875733,
      "memory(GiB)": 72.72,
      "step": 9030,
      "token_acc": 0.9316239316239316,
      "train_speed(iter/s)": 0.253374
    },
    {
      "epoch": 0.8427385505083481,
      "grad_norm": 7.6739373207092285,
      "learning_rate": 9.62075398437415e-06,
      "loss": 0.526758861541748,
      "memory(GiB)": 72.72,
      "step": 9035,
      "token_acc": 0.5145631067961165,
      "train_speed(iter/s)": 0.253378
    },
    {
      "epoch": 0.8432049249137208,
      "grad_norm": 3.3268871307373047,
      "learning_rate": 9.620164564968741e-06,
      "loss": 0.5039175987243653,
      "memory(GiB)": 72.72,
      "step": 9040,
      "token_acc": 0.48484848484848486,
      "train_speed(iter/s)": 0.253385
    },
    {
      "epoch": 0.8436712993190933,
      "grad_norm": 5.437780380249023,
      "learning_rate": 9.619574705968908e-06,
      "loss": 0.48818240165710447,
      "memory(GiB)": 72.72,
      "step": 9045,
      "train_speed(iter/s)": 0.253386
    },
    {
      "epoch": 0.844137673724466,
      "grad_norm": 3.4527151584625244,
      "learning_rate": 9.618984407430773e-06,
      "loss": 0.553386116027832,
      "memory(GiB)": 72.72,
      "step": 9050,
      "token_acc": 0.39655172413793105,
      "train_speed(iter/s)": 0.253393
    },
    {
      "epoch": 0.8446040481298386,
      "grad_norm": 3.0445332527160645,
      "learning_rate": 9.6183936694105e-06,
      "loss": 0.5032154083251953,
      "memory(GiB)": 72.72,
      "step": 9055,
      "token_acc": 0.8877551020408163,
      "train_speed(iter/s)": 0.253391
    },
    {
      "epoch": 0.8450704225352113,
      "grad_norm": 3.0416440963745117,
      "learning_rate": 9.617802491964296e-06,
      "loss": 0.5147241592407227,
      "memory(GiB)": 72.72,
      "step": 9060,
      "train_speed(iter/s)": 0.253401
    },
    {
      "epoch": 0.8455367969405839,
      "grad_norm": 3.765390157699585,
      "learning_rate": 9.617210875148411e-06,
      "loss": 0.5045023918151855,
      "memory(GiB)": 72.72,
      "step": 9065,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.253402
    },
    {
      "epoch": 0.8460031713459565,
      "grad_norm": 2.604841470718384,
      "learning_rate": 9.616618819019136e-06,
      "loss": 0.4476360321044922,
      "memory(GiB)": 72.72,
      "step": 9070,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.253399
    },
    {
      "epoch": 0.8464695457513292,
      "grad_norm": 3.5123448371887207,
      "learning_rate": 9.6160263236328e-06,
      "loss": 0.533180046081543,
      "memory(GiB)": 72.72,
      "step": 9075,
      "token_acc": 0.45614035087719296,
      "train_speed(iter/s)": 0.253407
    },
    {
      "epoch": 0.8469359201567018,
      "grad_norm": 3.3373093605041504,
      "learning_rate": 9.615433389045781e-06,
      "loss": 0.5197512626647949,
      "memory(GiB)": 72.72,
      "step": 9080,
      "train_speed(iter/s)": 0.253411
    },
    {
      "epoch": 0.8474022945620744,
      "grad_norm": 5.237983703613281,
      "learning_rate": 9.614840015314492e-06,
      "loss": 0.5230479717254639,
      "memory(GiB)": 72.72,
      "step": 9085,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.253409
    },
    {
      "epoch": 0.8478686689674471,
      "grad_norm": 5.170866966247559,
      "learning_rate": 9.614246202495394e-06,
      "loss": 0.5069532871246338,
      "memory(GiB)": 72.72,
      "step": 9090,
      "train_speed(iter/s)": 0.253412
    },
    {
      "epoch": 0.8483350433728197,
      "grad_norm": 4.586601257324219,
      "learning_rate": 9.613651950644984e-06,
      "loss": 0.5102607727050781,
      "memory(GiB)": 72.72,
      "step": 9095,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.253409
    },
    {
      "epoch": 0.8488014177781923,
      "grad_norm": 4.0361857414245605,
      "learning_rate": 9.613057259819803e-06,
      "loss": 0.5254071235656739,
      "memory(GiB)": 72.72,
      "step": 9100,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.253408
    },
    {
      "epoch": 0.849267792183565,
      "grad_norm": 4.623508930206299,
      "learning_rate": 9.612462130076435e-06,
      "loss": 0.4673317909240723,
      "memory(GiB)": 72.72,
      "step": 9105,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.253407
    },
    {
      "epoch": 0.8497341665889376,
      "grad_norm": 4.8370161056518555,
      "learning_rate": 9.611866561471502e-06,
      "loss": 0.5298686027526855,
      "memory(GiB)": 72.72,
      "step": 9110,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.253402
    },
    {
      "epoch": 0.8502005409943102,
      "grad_norm": 3.9258952140808105,
      "learning_rate": 9.611270554061674e-06,
      "loss": 0.5164459228515625,
      "memory(GiB)": 72.72,
      "step": 9115,
      "train_speed(iter/s)": 0.253396
    },
    {
      "epoch": 0.8506669153996829,
      "grad_norm": 7.652462005615234,
      "learning_rate": 9.610674107903659e-06,
      "loss": 0.5062395095825195,
      "memory(GiB)": 72.72,
      "step": 9120,
      "train_speed(iter/s)": 0.253399
    },
    {
      "epoch": 0.8511332898050555,
      "grad_norm": 6.899469375610352,
      "learning_rate": 9.610077223054206e-06,
      "loss": 0.52540283203125,
      "memory(GiB)": 72.72,
      "step": 9125,
      "train_speed(iter/s)": 0.253396
    },
    {
      "epoch": 0.8515996642104281,
      "grad_norm": 4.904873847961426,
      "learning_rate": 9.609479899570106e-06,
      "loss": 0.4971346855163574,
      "memory(GiB)": 72.72,
      "step": 9130,
      "train_speed(iter/s)": 0.253391
    },
    {
      "epoch": 0.8520660386158008,
      "grad_norm": 4.600336074829102,
      "learning_rate": 9.608882137508196e-06,
      "loss": 0.4946186065673828,
      "memory(GiB)": 72.72,
      "step": 9135,
      "train_speed(iter/s)": 0.253385
    },
    {
      "epoch": 0.8525324130211734,
      "grad_norm": 4.424781322479248,
      "learning_rate": 9.608283936925346e-06,
      "loss": 0.47344284057617186,
      "memory(GiB)": 72.72,
      "step": 9140,
      "train_speed(iter/s)": 0.253387
    },
    {
      "epoch": 0.852998787426546,
      "grad_norm": 3.1837639808654785,
      "learning_rate": 9.607685297878476e-06,
      "loss": 0.5151008605957031,
      "memory(GiB)": 72.72,
      "step": 9145,
      "train_speed(iter/s)": 0.253386
    },
    {
      "epoch": 0.8534651618319187,
      "grad_norm": 4.084068298339844,
      "learning_rate": 9.607086220424546e-06,
      "loss": 0.5156369209289551,
      "memory(GiB)": 72.72,
      "step": 9150,
      "token_acc": 0.5434782608695652,
      "train_speed(iter/s)": 0.253382
    },
    {
      "epoch": 0.8539315362372913,
      "grad_norm": 3.826333999633789,
      "learning_rate": 9.606486704620553e-06,
      "loss": 0.47677021026611327,
      "memory(GiB)": 72.72,
      "step": 9155,
      "train_speed(iter/s)": 0.253388
    },
    {
      "epoch": 0.8543979106426639,
      "grad_norm": 3.3858909606933594,
      "learning_rate": 9.60588675052354e-06,
      "loss": 0.5022297382354737,
      "memory(GiB)": 72.72,
      "step": 9160,
      "token_acc": 0.5517241379310345,
      "train_speed(iter/s)": 0.25339
    },
    {
      "epoch": 0.8548642850480366,
      "grad_norm": 7.722385883331299,
      "learning_rate": 9.605286358190593e-06,
      "loss": 0.4576442718505859,
      "memory(GiB)": 72.72,
      "step": 9165,
      "train_speed(iter/s)": 0.25339
    },
    {
      "epoch": 0.8553306594534092,
      "grad_norm": 8.432865142822266,
      "learning_rate": 9.604685527678834e-06,
      "loss": 0.5501507759094239,
      "memory(GiB)": 72.72,
      "step": 9170,
      "train_speed(iter/s)": 0.25339
    },
    {
      "epoch": 0.8557970338587818,
      "grad_norm": 9.085105895996094,
      "learning_rate": 9.604084259045435e-06,
      "loss": 0.5319607734680176,
      "memory(GiB)": 72.72,
      "step": 9175,
      "train_speed(iter/s)": 0.253385
    },
    {
      "epoch": 0.8562634082641545,
      "grad_norm": 6.767471790313721,
      "learning_rate": 9.603482552347601e-06,
      "loss": 0.5217260837554931,
      "memory(GiB)": 72.72,
      "step": 9180,
      "train_speed(iter/s)": 0.25339
    },
    {
      "epoch": 0.8567297826695272,
      "grad_norm": 5.356941223144531,
      "learning_rate": 9.602880407642583e-06,
      "loss": 0.49861750602722166,
      "memory(GiB)": 72.72,
      "step": 9185,
      "token_acc": 0.8717948717948718,
      "train_speed(iter/s)": 0.253395
    },
    {
      "epoch": 0.8571961570748997,
      "grad_norm": 6.258128643035889,
      "learning_rate": 9.602277824987673e-06,
      "loss": 0.47075328826904295,
      "memory(GiB)": 72.72,
      "step": 9190,
      "token_acc": 0.4107142857142857,
      "train_speed(iter/s)": 0.253394
    },
    {
      "epoch": 0.8576625314802724,
      "grad_norm": 4.847031593322754,
      "learning_rate": 9.601674804440206e-06,
      "loss": 0.5037572383880615,
      "memory(GiB)": 72.72,
      "step": 9195,
      "token_acc": 0.6744186046511628,
      "train_speed(iter/s)": 0.253388
    },
    {
      "epoch": 0.8581289058856449,
      "grad_norm": 4.691412925720215,
      "learning_rate": 9.601071346057558e-06,
      "loss": 0.5321971416473389,
      "memory(GiB)": 72.72,
      "step": 9200,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.253397
    },
    {
      "epoch": 0.8585952802910176,
      "grad_norm": 2.6292262077331543,
      "learning_rate": 9.600467449897144e-06,
      "loss": 0.4976658344268799,
      "memory(GiB)": 72.72,
      "step": 9205,
      "token_acc": 0.8488372093023255,
      "train_speed(iter/s)": 0.253403
    },
    {
      "epoch": 0.8590616546963903,
      "grad_norm": 5.340016841888428,
      "learning_rate": 9.599863116016425e-06,
      "loss": 0.472551965713501,
      "memory(GiB)": 72.72,
      "step": 9210,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.253409
    },
    {
      "epoch": 0.8595280291017628,
      "grad_norm": 6.765635967254639,
      "learning_rate": 9.599258344472902e-06,
      "loss": 0.5314139366149903,
      "memory(GiB)": 72.72,
      "step": 9215,
      "train_speed(iter/s)": 0.253407
    },
    {
      "epoch": 0.8599944035071355,
      "grad_norm": 6.496398448944092,
      "learning_rate": 9.598653135324115e-06,
      "loss": 0.5074526786804199,
      "memory(GiB)": 72.72,
      "step": 9220,
      "train_speed(iter/s)": 0.253402
    },
    {
      "epoch": 0.8604607779125082,
      "grad_norm": 6.414966583251953,
      "learning_rate": 9.598047488627648e-06,
      "loss": 0.4977117538452148,
      "memory(GiB)": 72.72,
      "step": 9225,
      "train_speed(iter/s)": 0.253401
    },
    {
      "epoch": 0.8609271523178808,
      "grad_norm": 4.445841312408447,
      "learning_rate": 9.597441404441128e-06,
      "loss": 0.5085483074188233,
      "memory(GiB)": 72.72,
      "step": 9230,
      "train_speed(iter/s)": 0.253394
    },
    {
      "epoch": 0.8613935267232534,
      "grad_norm": 4.964288234710693,
      "learning_rate": 9.59683488282222e-06,
      "loss": 0.49162745475769043,
      "memory(GiB)": 72.72,
      "step": 9235,
      "train_speed(iter/s)": 0.253381
    },
    {
      "epoch": 0.8618599011286261,
      "grad_norm": 73.64921569824219,
      "learning_rate": 9.596227923828634e-06,
      "loss": 0.545293140411377,
      "memory(GiB)": 72.72,
      "step": 9240,
      "train_speed(iter/s)": 0.25337
    },
    {
      "epoch": 0.8623262755339987,
      "grad_norm": 5.455593109130859,
      "learning_rate": 9.595620527518121e-06,
      "loss": 0.48314242362976073,
      "memory(GiB)": 72.72,
      "step": 9245,
      "train_speed(iter/s)": 0.25338
    },
    {
      "epoch": 0.8627926499393713,
      "grad_norm": 5.007823467254639,
      "learning_rate": 9.595012693948471e-06,
      "loss": 0.4927692890167236,
      "memory(GiB)": 72.72,
      "step": 9250,
      "train_speed(iter/s)": 0.253387
    },
    {
      "epoch": 0.863259024344744,
      "grad_norm": 3.514012575149536,
      "learning_rate": 9.594404423177518e-06,
      "loss": 0.5032992362976074,
      "memory(GiB)": 72.72,
      "step": 9255,
      "token_acc": 0.4827586206896552,
      "train_speed(iter/s)": 0.253378
    },
    {
      "epoch": 0.8637253987501166,
      "grad_norm": 5.7470245361328125,
      "learning_rate": 9.59379571526314e-06,
      "loss": 0.43570938110351565,
      "memory(GiB)": 72.72,
      "step": 9260,
      "train_speed(iter/s)": 0.253214
    },
    {
      "epoch": 0.8641917731554892,
      "grad_norm": 6.258077621459961,
      "learning_rate": 9.59318657026325e-06,
      "loss": 0.5370323181152343,
      "memory(GiB)": 72.72,
      "step": 9265,
      "train_speed(iter/s)": 0.253205
    },
    {
      "epoch": 0.8646581475608619,
      "grad_norm": 2.9205620288848877,
      "learning_rate": 9.592576988235807e-06,
      "loss": 0.48269128799438477,
      "memory(GiB)": 72.72,
      "step": 9270,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.253209
    },
    {
      "epoch": 0.8651245219662345,
      "grad_norm": 3.400392770767212,
      "learning_rate": 9.591966969238811e-06,
      "loss": 0.47384076118469237,
      "memory(GiB)": 72.72,
      "step": 9275,
      "token_acc": 0.8488372093023255,
      "train_speed(iter/s)": 0.253212
    },
    {
      "epoch": 0.8655908963716071,
      "grad_norm": 13.090048789978027,
      "learning_rate": 9.591356513330305e-06,
      "loss": 0.5254084587097168,
      "memory(GiB)": 72.72,
      "step": 9280,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.253218
    },
    {
      "epoch": 0.8660572707769798,
      "grad_norm": 4.187959671020508,
      "learning_rate": 9.59074562056837e-06,
      "loss": 0.43554840087890623,
      "memory(GiB)": 72.72,
      "step": 9285,
      "train_speed(iter/s)": 0.253217
    },
    {
      "epoch": 0.8665236451823524,
      "grad_norm": 3.9901645183563232,
      "learning_rate": 9.59013429101113e-06,
      "loss": 0.5095625877380371,
      "memory(GiB)": 72.72,
      "step": 9290,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.253217
    },
    {
      "epoch": 0.866990019587725,
      "grad_norm": 5.518648147583008,
      "learning_rate": 9.589522524716755e-06,
      "loss": 0.5094717025756836,
      "memory(GiB)": 72.72,
      "step": 9295,
      "train_speed(iter/s)": 0.253212
    },
    {
      "epoch": 0.8674563939930977,
      "grad_norm": 5.158836364746094,
      "learning_rate": 9.58891032174345e-06,
      "loss": 0.5185569763183594,
      "memory(GiB)": 72.72,
      "step": 9300,
      "train_speed(iter/s)": 0.253211
    },
    {
      "epoch": 0.8679227683984703,
      "grad_norm": 6.281627655029297,
      "learning_rate": 9.588297682149464e-06,
      "loss": 0.5046442985534668,
      "memory(GiB)": 72.72,
      "step": 9305,
      "token_acc": 0.697986577181208,
      "train_speed(iter/s)": 0.253211
    },
    {
      "epoch": 0.8683891428038429,
      "grad_norm": 4.228614807128906,
      "learning_rate": 9.587684605993086e-06,
      "loss": 0.5136807441711426,
      "memory(GiB)": 72.72,
      "step": 9310,
      "token_acc": 0.38,
      "train_speed(iter/s)": 0.253213
    },
    {
      "epoch": 0.8688555172092156,
      "grad_norm": 8.349066734313965,
      "learning_rate": 9.587071093332652e-06,
      "loss": 0.5233351230621338,
      "memory(GiB)": 72.72,
      "step": 9315,
      "train_speed(iter/s)": 0.253224
    },
    {
      "epoch": 0.8693218916145882,
      "grad_norm": 4.534889221191406,
      "learning_rate": 9.586457144226536e-06,
      "loss": 0.4889109134674072,
      "memory(GiB)": 72.72,
      "step": 9320,
      "token_acc": 0.9204545454545454,
      "train_speed(iter/s)": 0.253224
    },
    {
      "epoch": 0.8697882660199608,
      "grad_norm": 8.102484703063965,
      "learning_rate": 9.585842758733148e-06,
      "loss": 0.47646007537841795,
      "memory(GiB)": 72.72,
      "step": 9325,
      "train_speed(iter/s)": 0.253217
    },
    {
      "epoch": 0.8702546404253334,
      "grad_norm": 4.542932033538818,
      "learning_rate": 9.58522793691095e-06,
      "loss": 0.4958655834197998,
      "memory(GiB)": 72.72,
      "step": 9330,
      "train_speed(iter/s)": 0.253223
    },
    {
      "epoch": 0.8707210148307061,
      "grad_norm": 4.203245639801025,
      "learning_rate": 9.58461267881844e-06,
      "loss": 0.5110823631286621,
      "memory(GiB)": 72.72,
      "step": 9335,
      "token_acc": 0.4880952380952381,
      "train_speed(iter/s)": 0.253221
    },
    {
      "epoch": 0.8711873892360787,
      "grad_norm": 6.454883575439453,
      "learning_rate": 9.583996984514156e-06,
      "loss": 0.5036648273468017,
      "memory(GiB)": 72.72,
      "step": 9340,
      "train_speed(iter/s)": 0.253212
    },
    {
      "epoch": 0.8716537636414513,
      "grad_norm": 6.149125099182129,
      "learning_rate": 9.583380854056682e-06,
      "loss": 0.5014023780822754,
      "memory(GiB)": 72.72,
      "step": 9345,
      "train_speed(iter/s)": 0.253214
    },
    {
      "epoch": 0.872120138046824,
      "grad_norm": 4.82581901550293,
      "learning_rate": 9.582764287504638e-06,
      "loss": 0.4985860824584961,
      "memory(GiB)": 72.72,
      "step": 9350,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.253212
    },
    {
      "epoch": 0.8725865124521966,
      "grad_norm": 4.490650177001953,
      "learning_rate": 9.582147284916689e-06,
      "loss": 0.5035985946655274,
      "memory(GiB)": 72.72,
      "step": 9355,
      "train_speed(iter/s)": 0.253207
    },
    {
      "epoch": 0.8730528868575692,
      "grad_norm": 4.059875011444092,
      "learning_rate": 9.581529846351542e-06,
      "loss": 0.49697537422180177,
      "memory(GiB)": 72.72,
      "step": 9360,
      "token_acc": 0.9130434782608695,
      "train_speed(iter/s)": 0.253202
    },
    {
      "epoch": 0.8735192612629419,
      "grad_norm": 3.022268533706665,
      "learning_rate": 9.580911971867943e-06,
      "loss": 0.49212207794189455,
      "memory(GiB)": 72.72,
      "step": 9365,
      "train_speed(iter/s)": 0.2532
    },
    {
      "epoch": 0.8739856356683146,
      "grad_norm": 3.0955541133880615,
      "learning_rate": 9.580293661524683e-06,
      "loss": 0.551426887512207,
      "memory(GiB)": 72.72,
      "step": 9370,
      "token_acc": 0.9263157894736842,
      "train_speed(iter/s)": 0.253197
    },
    {
      "epoch": 0.8744520100736871,
      "grad_norm": 5.612813949584961,
      "learning_rate": 9.57967491538059e-06,
      "loss": 0.48514389991760254,
      "memory(GiB)": 72.72,
      "step": 9375,
      "token_acc": 0.4392523364485981,
      "train_speed(iter/s)": 0.253199
    },
    {
      "epoch": 0.8749183844790598,
      "grad_norm": 8.156386375427246,
      "learning_rate": 9.579055733494538e-06,
      "loss": 0.4809275150299072,
      "memory(GiB)": 72.72,
      "step": 9380,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.253198
    },
    {
      "epoch": 0.8753847588844325,
      "grad_norm": 8.858295440673828,
      "learning_rate": 9.578436115925439e-06,
      "loss": 0.5315121650695801,
      "memory(GiB)": 72.72,
      "step": 9385,
      "token_acc": 0.4827586206896552,
      "train_speed(iter/s)": 0.253191
    },
    {
      "epoch": 0.875851133289805,
      "grad_norm": 5.233649253845215,
      "learning_rate": 9.577816062732246e-06,
      "loss": 0.5150359630584717,
      "memory(GiB)": 72.72,
      "step": 9390,
      "token_acc": 0.6521739130434783,
      "train_speed(iter/s)": 0.253192
    },
    {
      "epoch": 0.8763175076951777,
      "grad_norm": 4.999918460845947,
      "learning_rate": 9.577195573973959e-06,
      "loss": 0.4782843112945557,
      "memory(GiB)": 72.72,
      "step": 9395,
      "train_speed(iter/s)": 0.253188
    },
    {
      "epoch": 0.8767838821005504,
      "grad_norm": 4.317760944366455,
      "learning_rate": 9.576574649709613e-06,
      "loss": 0.48097825050354004,
      "memory(GiB)": 72.72,
      "step": 9400,
      "train_speed(iter/s)": 0.253187
    },
    {
      "epoch": 0.8772502565059229,
      "grad_norm": 6.889215469360352,
      "learning_rate": 9.575953289998288e-06,
      "loss": 0.4622486114501953,
      "memory(GiB)": 72.72,
      "step": 9405,
      "token_acc": 0.6176470588235294,
      "train_speed(iter/s)": 0.253184
    },
    {
      "epoch": 0.8777166309112956,
      "grad_norm": 3.936765432357788,
      "learning_rate": 9.575331494899102e-06,
      "loss": 0.5312833786010742,
      "memory(GiB)": 72.72,
      "step": 9410,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.253199
    },
    {
      "epoch": 0.8781830053166683,
      "grad_norm": 23.262540817260742,
      "learning_rate": 9.574709264471221e-06,
      "loss": 0.4785030364990234,
      "memory(GiB)": 72.72,
      "step": 9415,
      "train_speed(iter/s)": 0.253206
    },
    {
      "epoch": 0.8786493797220408,
      "grad_norm": 4.995047569274902,
      "learning_rate": 9.574086598773847e-06,
      "loss": 0.49817538261413574,
      "memory(GiB)": 72.72,
      "step": 9420,
      "train_speed(iter/s)": 0.25321
    },
    {
      "epoch": 0.8791157541274135,
      "grad_norm": 3.3125879764556885,
      "learning_rate": 9.573463497866222e-06,
      "loss": 0.4864450454711914,
      "memory(GiB)": 72.72,
      "step": 9425,
      "train_speed(iter/s)": 0.253209
    },
    {
      "epoch": 0.8795821285327862,
      "grad_norm": 6.721943378448486,
      "learning_rate": 9.572839961807634e-06,
      "loss": 0.48740310668945314,
      "memory(GiB)": 72.72,
      "step": 9430,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.253202
    },
    {
      "epoch": 0.8800485029381587,
      "grad_norm": 4.6545186042785645,
      "learning_rate": 9.572215990657411e-06,
      "loss": 0.495751953125,
      "memory(GiB)": 72.72,
      "step": 9435,
      "token_acc": 0.6046511627906976,
      "train_speed(iter/s)": 0.253206
    },
    {
      "epoch": 0.8805148773435314,
      "grad_norm": 4.9498748779296875,
      "learning_rate": 9.571591584474921e-06,
      "loss": 0.48177380561828614,
      "memory(GiB)": 72.72,
      "step": 9440,
      "train_speed(iter/s)": 0.253202
    },
    {
      "epoch": 0.8809812517489041,
      "grad_norm": 4.436631679534912,
      "learning_rate": 9.570966743319576e-06,
      "loss": 0.4894412994384766,
      "memory(GiB)": 72.72,
      "step": 9445,
      "train_speed(iter/s)": 0.253208
    },
    {
      "epoch": 0.8814476261542766,
      "grad_norm": 7.040274620056152,
      "learning_rate": 9.570341467250825e-06,
      "loss": 0.4865746021270752,
      "memory(GiB)": 72.72,
      "step": 9450,
      "train_speed(iter/s)": 0.253209
    },
    {
      "epoch": 0.8819140005596493,
      "grad_norm": 4.975728988647461,
      "learning_rate": 9.569715756328163e-06,
      "loss": 0.435853910446167,
      "memory(GiB)": 72.72,
      "step": 9455,
      "train_speed(iter/s)": 0.253209
    },
    {
      "epoch": 0.882380374965022,
      "grad_norm": 5.990451335906982,
      "learning_rate": 9.569089610611126e-06,
      "loss": 0.466290283203125,
      "memory(GiB)": 72.72,
      "step": 9460,
      "train_speed(iter/s)": 0.253208
    },
    {
      "epoch": 0.8828467493703945,
      "grad_norm": 4.5206732749938965,
      "learning_rate": 9.568463030159288e-06,
      "loss": 0.47459869384765624,
      "memory(GiB)": 72.72,
      "step": 9465,
      "token_acc": 0.875,
      "train_speed(iter/s)": 0.253218
    },
    {
      "epoch": 0.8833131237757672,
      "grad_norm": 4.02912712097168,
      "learning_rate": 9.567836015032265e-06,
      "loss": 0.5358747482299805,
      "memory(GiB)": 72.72,
      "step": 9470,
      "token_acc": 0.5362318840579711,
      "train_speed(iter/s)": 0.253224
    },
    {
      "epoch": 0.8837794981811398,
      "grad_norm": 5.162577152252197,
      "learning_rate": 9.567208565289717e-06,
      "loss": 0.48051228523254397,
      "memory(GiB)": 72.72,
      "step": 9475,
      "train_speed(iter/s)": 0.253222
    },
    {
      "epoch": 0.8842458725865124,
      "grad_norm": 3.798966407775879,
      "learning_rate": 9.566580680991343e-06,
      "loss": 0.5149246692657471,
      "memory(GiB)": 72.72,
      "step": 9480,
      "token_acc": 0.475,
      "train_speed(iter/s)": 0.253228
    },
    {
      "epoch": 0.8847122469918851,
      "grad_norm": 4.013277530670166,
      "learning_rate": 9.565952362196885e-06,
      "loss": 0.5089013576507568,
      "memory(GiB)": 72.72,
      "step": 9485,
      "token_acc": 0.9066666666666666,
      "train_speed(iter/s)": 0.253231
    },
    {
      "epoch": 0.8851786213972577,
      "grad_norm": 3.0657918453216553,
      "learning_rate": 9.565323608966126e-06,
      "loss": 0.4602031230926514,
      "memory(GiB)": 72.72,
      "step": 9490,
      "train_speed(iter/s)": 0.25324
    },
    {
      "epoch": 0.8856449958026303,
      "grad_norm": 3.1408722400665283,
      "learning_rate": 9.56469442135889e-06,
      "loss": 0.5342215538024903,
      "memory(GiB)": 72.72,
      "step": 9495,
      "token_acc": 0.6037735849056604,
      "train_speed(iter/s)": 0.253235
    },
    {
      "epoch": 0.886111370208003,
      "grad_norm": 5.9763689041137695,
      "learning_rate": 9.56406479943504e-06,
      "loss": 0.48466014862060547,
      "memory(GiB)": 72.72,
      "step": 9500,
      "train_speed(iter/s)": 0.253243
    },
    {
      "epoch": 0.8865777446133756,
      "grad_norm": 5.702966690063477,
      "learning_rate": 9.563434743254486e-06,
      "loss": 0.48994293212890627,
      "memory(GiB)": 72.72,
      "step": 9505,
      "token_acc": 0.3888888888888889,
      "train_speed(iter/s)": 0.253249
    },
    {
      "epoch": 0.8870441190187482,
      "grad_norm": 5.019900798797607,
      "learning_rate": 9.562804252877174e-06,
      "loss": 0.493509578704834,
      "memory(GiB)": 72.72,
      "step": 9510,
      "token_acc": 0.46774193548387094,
      "train_speed(iter/s)": 0.25325
    },
    {
      "epoch": 0.8875104934241209,
      "grad_norm": 3.109816074371338,
      "learning_rate": 9.562173328363092e-06,
      "loss": 0.4720609664916992,
      "memory(GiB)": 72.72,
      "step": 9515,
      "train_speed(iter/s)": 0.253247
    },
    {
      "epoch": 0.8879768678294935,
      "grad_norm": 2.889599323272705,
      "learning_rate": 9.561541969772274e-06,
      "loss": 0.49753389358520506,
      "memory(GiB)": 72.72,
      "step": 9520,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.253253
    },
    {
      "epoch": 0.8884432422348661,
      "grad_norm": 4.726217746734619,
      "learning_rate": 9.560910177164789e-06,
      "loss": 0.4665792465209961,
      "memory(GiB)": 72.72,
      "step": 9525,
      "token_acc": 0.4423076923076923,
      "train_speed(iter/s)": 0.253256
    },
    {
      "epoch": 0.8889096166402388,
      "grad_norm": 4.907077789306641,
      "learning_rate": 9.56027795060075e-06,
      "loss": 0.5511886596679687,
      "memory(GiB)": 72.72,
      "step": 9530,
      "token_acc": 0.512396694214876,
      "train_speed(iter/s)": 0.253255
    },
    {
      "epoch": 0.8893759910456114,
      "grad_norm": 3.6970767974853516,
      "learning_rate": 9.559645290140312e-06,
      "loss": 0.4717216491699219,
      "memory(GiB)": 72.72,
      "step": 9535,
      "train_speed(iter/s)": 0.253254
    },
    {
      "epoch": 0.889842365450984,
      "grad_norm": 3.1428310871124268,
      "learning_rate": 9.55901219584367e-06,
      "loss": 0.5071080207824707,
      "memory(GiB)": 72.72,
      "step": 9540,
      "train_speed(iter/s)": 0.253262
    },
    {
      "epoch": 0.8903087398563567,
      "grad_norm": 32.20878601074219,
      "learning_rate": 9.558378667771065e-06,
      "loss": 0.5143341541290283,
      "memory(GiB)": 72.72,
      "step": 9545,
      "train_speed(iter/s)": 0.253262
    },
    {
      "epoch": 0.8907751142617293,
      "grad_norm": 4.2625298500061035,
      "learning_rate": 9.557744705982772e-06,
      "loss": 0.5249893665313721,
      "memory(GiB)": 72.72,
      "step": 9550,
      "token_acc": 0.391304347826087,
      "train_speed(iter/s)": 0.253264
    },
    {
      "epoch": 0.891241488667102,
      "grad_norm": 5.284437656402588,
      "learning_rate": 9.557110310539108e-06,
      "loss": 0.5046751022338867,
      "memory(GiB)": 72.72,
      "step": 9555,
      "token_acc": 0.8205128205128205,
      "train_speed(iter/s)": 0.253263
    },
    {
      "epoch": 0.8917078630724746,
      "grad_norm": 4.905439853668213,
      "learning_rate": 9.556475481500438e-06,
      "loss": 0.5245625495910644,
      "memory(GiB)": 72.72,
      "step": 9560,
      "train_speed(iter/s)": 0.253262
    },
    {
      "epoch": 0.8921742374778472,
      "grad_norm": 3.021395206451416,
      "learning_rate": 9.555840218927163e-06,
      "loss": 0.49530510902404784,
      "memory(GiB)": 72.72,
      "step": 9565,
      "train_speed(iter/s)": 0.253256
    },
    {
      "epoch": 0.8926406118832199,
      "grad_norm": 5.019222736358643,
      "learning_rate": 9.555204522879726e-06,
      "loss": 0.5179584980010986,
      "memory(GiB)": 72.72,
      "step": 9570,
      "train_speed(iter/s)": 0.25326
    },
    {
      "epoch": 0.8931069862885925,
      "grad_norm": 4.3565778732299805,
      "learning_rate": 9.55456839341861e-06,
      "loss": 0.48818225860595704,
      "memory(GiB)": 72.72,
      "step": 9575,
      "train_speed(iter/s)": 0.253261
    },
    {
      "epoch": 0.8935733606939651,
      "grad_norm": 5.432460308074951,
      "learning_rate": 9.553931830604343e-06,
      "loss": 0.4684408187866211,
      "memory(GiB)": 72.72,
      "step": 9580,
      "train_speed(iter/s)": 0.253265
    },
    {
      "epoch": 0.8940397350993378,
      "grad_norm": 4.000884532928467,
      "learning_rate": 9.55329483449749e-06,
      "loss": 0.5388882637023926,
      "memory(GiB)": 72.72,
      "step": 9585,
      "train_speed(iter/s)": 0.253259
    },
    {
      "epoch": 0.8945061095047104,
      "grad_norm": 4.535231113433838,
      "learning_rate": 9.552657405158662e-06,
      "loss": 0.5107650279998779,
      "memory(GiB)": 72.72,
      "step": 9590,
      "train_speed(iter/s)": 0.253261
    },
    {
      "epoch": 0.894972483910083,
      "grad_norm": 7.3670783042907715,
      "learning_rate": 9.552019542648505e-06,
      "loss": 0.521049690246582,
      "memory(GiB)": 72.72,
      "step": 9595,
      "train_speed(iter/s)": 0.253266
    },
    {
      "epoch": 0.8954388583154557,
      "grad_norm": 6.095773696899414,
      "learning_rate": 9.551381247027714e-06,
      "loss": 0.49352359771728516,
      "memory(GiB)": 72.72,
      "step": 9600,
      "train_speed(iter/s)": 0.253266
    },
    {
      "epoch": 0.8959052327208282,
      "grad_norm": 5.832357406616211,
      "learning_rate": 9.550742518357014e-06,
      "loss": 0.49977693557739256,
      "memory(GiB)": 72.72,
      "step": 9605,
      "train_speed(iter/s)": 0.253274
    },
    {
      "epoch": 0.8963716071262009,
      "grad_norm": 5.159787654876709,
      "learning_rate": 9.550103356697185e-06,
      "loss": 0.5282088279724121,
      "memory(GiB)": 72.72,
      "step": 9610,
      "token_acc": 0.5245901639344263,
      "train_speed(iter/s)": 0.253274
    },
    {
      "epoch": 0.8968379815315736,
      "grad_norm": 4.771136283874512,
      "learning_rate": 9.549463762109039e-06,
      "loss": 0.49431381225585935,
      "memory(GiB)": 72.72,
      "step": 9615,
      "token_acc": 0.6818181818181818,
      "train_speed(iter/s)": 0.25327
    },
    {
      "epoch": 0.8973043559369461,
      "grad_norm": 4.463113307952881,
      "learning_rate": 9.548823734653429e-06,
      "loss": 0.5159491539001465,
      "memory(GiB)": 72.72,
      "step": 9620,
      "train_speed(iter/s)": 0.253272
    },
    {
      "epoch": 0.8977707303423188,
      "grad_norm": 5.286480903625488,
      "learning_rate": 9.548183274391256e-06,
      "loss": 0.5297520160675049,
      "memory(GiB)": 72.72,
      "step": 9625,
      "train_speed(iter/s)": 0.253266
    },
    {
      "epoch": 0.8982371047476915,
      "grad_norm": 7.606424331665039,
      "learning_rate": 9.547542381383455e-06,
      "loss": 0.4676054954528809,
      "memory(GiB)": 72.72,
      "step": 9630,
      "token_acc": 0.47,
      "train_speed(iter/s)": 0.253275
    },
    {
      "epoch": 0.898703479153064,
      "grad_norm": 4.274720191955566,
      "learning_rate": 9.546901055691003e-06,
      "loss": 0.5280047416687011,
      "memory(GiB)": 72.72,
      "step": 9635,
      "train_speed(iter/s)": 0.253272
    },
    {
      "epoch": 0.8991698535584367,
      "grad_norm": 3.684516191482544,
      "learning_rate": 9.546259297374924e-06,
      "loss": 0.45790395736694334,
      "memory(GiB)": 72.72,
      "step": 9640,
      "train_speed(iter/s)": 0.253272
    },
    {
      "epoch": 0.8996362279638094,
      "grad_norm": 3.626535415649414,
      "learning_rate": 9.545617106496279e-06,
      "loss": 0.5226557731628418,
      "memory(GiB)": 72.72,
      "step": 9645,
      "train_speed(iter/s)": 0.253273
    },
    {
      "epoch": 0.9001026023691819,
      "grad_norm": 3.5798068046569824,
      "learning_rate": 9.54497448311617e-06,
      "loss": 0.47086563110351565,
      "memory(GiB)": 72.72,
      "step": 9650,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.253275
    },
    {
      "epoch": 0.9005689767745546,
      "grad_norm": 3.4670417308807373,
      "learning_rate": 9.544331427295739e-06,
      "loss": 0.5060482978820801,
      "memory(GiB)": 72.72,
      "step": 9655,
      "train_speed(iter/s)": 0.253277
    },
    {
      "epoch": 0.9010353511799273,
      "grad_norm": 6.597428321838379,
      "learning_rate": 9.543687939096171e-06,
      "loss": 0.5109128952026367,
      "memory(GiB)": 72.72,
      "step": 9660,
      "train_speed(iter/s)": 0.253276
    },
    {
      "epoch": 0.9015017255852998,
      "grad_norm": 6.8573713302612305,
      "learning_rate": 9.543044018578694e-06,
      "loss": 0.49287052154541017,
      "memory(GiB)": 72.72,
      "step": 9665,
      "train_speed(iter/s)": 0.25327
    },
    {
      "epoch": 0.9019680999906725,
      "grad_norm": 4.814738750457764,
      "learning_rate": 9.542399665804572e-06,
      "loss": 0.4640956878662109,
      "memory(GiB)": 72.72,
      "step": 9670,
      "train_speed(iter/s)": 0.253265
    },
    {
      "epoch": 0.9024344743960452,
      "grad_norm": 3.783937931060791,
      "learning_rate": 9.541754880835117e-06,
      "loss": 0.4707059860229492,
      "memory(GiB)": 72.72,
      "step": 9675,
      "train_speed(iter/s)": 0.253264
    },
    {
      "epoch": 0.9029008488014177,
      "grad_norm": 6.745643138885498,
      "learning_rate": 9.541109663731676e-06,
      "loss": 0.5109501838684082,
      "memory(GiB)": 72.72,
      "step": 9680,
      "train_speed(iter/s)": 0.253257
    },
    {
      "epoch": 0.9033672232067904,
      "grad_norm": 3.3353774547576904,
      "learning_rate": 9.540464014555639e-06,
      "loss": 0.515962553024292,
      "memory(GiB)": 72.72,
      "step": 9685,
      "train_speed(iter/s)": 0.253265
    },
    {
      "epoch": 0.9038335976121631,
      "grad_norm": 6.019783020019531,
      "learning_rate": 9.539817933368438e-06,
      "loss": 0.4655726909637451,
      "memory(GiB)": 72.72,
      "step": 9690,
      "token_acc": 0.39285714285714285,
      "train_speed(iter/s)": 0.253264
    },
    {
      "epoch": 0.9042999720175356,
      "grad_norm": 4.910508155822754,
      "learning_rate": 9.539171420231547e-06,
      "loss": 0.5000959873199463,
      "memory(GiB)": 72.72,
      "step": 9695,
      "token_acc": 0.8594594594594595,
      "train_speed(iter/s)": 0.253262
    },
    {
      "epoch": 0.9047663464229083,
      "grad_norm": 2.965853214263916,
      "learning_rate": 9.538524475206477e-06,
      "loss": 0.48615398406982424,
      "memory(GiB)": 72.72,
      "step": 9700,
      "token_acc": 0.3617021276595745,
      "train_speed(iter/s)": 0.253261
    },
    {
      "epoch": 0.905232720828281,
      "grad_norm": 3.7019975185394287,
      "learning_rate": 9.537877098354787e-06,
      "loss": 0.4699080944061279,
      "memory(GiB)": 72.72,
      "step": 9705,
      "token_acc": 0.5346534653465347,
      "train_speed(iter/s)": 0.253265
    },
    {
      "epoch": 0.9056990952336536,
      "grad_norm": 4.517653465270996,
      "learning_rate": 9.537229289738069e-06,
      "loss": 0.5301083564758301,
      "memory(GiB)": 72.72,
      "step": 9710,
      "token_acc": 0.891566265060241,
      "train_speed(iter/s)": 0.253268
    },
    {
      "epoch": 0.9061654696390262,
      "grad_norm": 6.055946350097656,
      "learning_rate": 9.53658104941796e-06,
      "loss": 0.4554446220397949,
      "memory(GiB)": 72.72,
      "step": 9715,
      "token_acc": 0.4473684210526316,
      "train_speed(iter/s)": 0.25327
    },
    {
      "epoch": 0.9066318440443989,
      "grad_norm": 3.106529474258423,
      "learning_rate": 9.53593237745614e-06,
      "loss": 0.49701991081237795,
      "memory(GiB)": 72.72,
      "step": 9720,
      "token_acc": 0.7480916030534351,
      "train_speed(iter/s)": 0.253266
    },
    {
      "epoch": 0.9070982184497715,
      "grad_norm": 7.075149059295654,
      "learning_rate": 9.535283273914328e-06,
      "loss": 0.5197658538818359,
      "memory(GiB)": 72.72,
      "step": 9725,
      "train_speed(iter/s)": 0.253082
    },
    {
      "epoch": 0.9075645928551441,
      "grad_norm": 9.358800888061523,
      "learning_rate": 9.534633738854286e-06,
      "loss": 0.5063522338867188,
      "memory(GiB)": 72.72,
      "step": 9730,
      "train_speed(iter/s)": 0.253081
    },
    {
      "epoch": 0.9080309672605168,
      "grad_norm": 3.8480002880096436,
      "learning_rate": 9.53398377233781e-06,
      "loss": 0.517193078994751,
      "memory(GiB)": 72.72,
      "step": 9735,
      "train_speed(iter/s)": 0.253079
    },
    {
      "epoch": 0.9084973416658894,
      "grad_norm": 4.784961700439453,
      "learning_rate": 9.533333374426748e-06,
      "loss": 0.48981943130493166,
      "memory(GiB)": 72.72,
      "step": 9740,
      "train_speed(iter/s)": 0.253085
    },
    {
      "epoch": 0.908963716071262,
      "grad_norm": 4.001845836639404,
      "learning_rate": 9.532682545182979e-06,
      "loss": 0.4943864822387695,
      "memory(GiB)": 72.72,
      "step": 9745,
      "token_acc": 0.358974358974359,
      "train_speed(iter/s)": 0.253098
    },
    {
      "epoch": 0.9094300904766346,
      "grad_norm": 5.007861614227295,
      "learning_rate": 9.532031284668428e-06,
      "loss": 0.46909894943237307,
      "memory(GiB)": 72.72,
      "step": 9750,
      "train_speed(iter/s)": 0.253092
    },
    {
      "epoch": 0.9098964648820073,
      "grad_norm": 3.474043369293213,
      "learning_rate": 9.531379592945063e-06,
      "loss": 0.5185323238372803,
      "memory(GiB)": 72.72,
      "step": 9755,
      "token_acc": 0.6296296296296297,
      "train_speed(iter/s)": 0.253097
    },
    {
      "epoch": 0.9103628392873799,
      "grad_norm": 2.9828898906707764,
      "learning_rate": 9.530727470074889e-06,
      "loss": 0.4995090484619141,
      "memory(GiB)": 72.72,
      "step": 9760,
      "token_acc": 0.46236559139784944,
      "train_speed(iter/s)": 0.253103
    },
    {
      "epoch": 0.9108292136927525,
      "grad_norm": 2.979375123977661,
      "learning_rate": 9.530074916119954e-06,
      "loss": 0.5254053592681884,
      "memory(GiB)": 72.72,
      "step": 9765,
      "train_speed(iter/s)": 0.253105
    },
    {
      "epoch": 0.9112955880981252,
      "grad_norm": 3.6015145778656006,
      "learning_rate": 9.529421931142345e-06,
      "loss": 0.41909112930297854,
      "memory(GiB)": 72.72,
      "step": 9770,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.253108
    },
    {
      "epoch": 0.9117619625034978,
      "grad_norm": 3.8981847763061523,
      "learning_rate": 9.528768515204192e-06,
      "loss": 0.5254857063293457,
      "memory(GiB)": 72.72,
      "step": 9775,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.253109
    },
    {
      "epoch": 0.9122283369088704,
      "grad_norm": 4.73543643951416,
      "learning_rate": 9.528114668367665e-06,
      "loss": 0.5222939491271973,
      "memory(GiB)": 72.72,
      "step": 9780,
      "token_acc": 0.71900826446281,
      "train_speed(iter/s)": 0.253114
    },
    {
      "epoch": 0.9126947113142431,
      "grad_norm": 4.4322991371154785,
      "learning_rate": 9.527460390694979e-06,
      "loss": 0.5302388668060303,
      "memory(GiB)": 72.72,
      "step": 9785,
      "token_acc": 0.9263157894736842,
      "train_speed(iter/s)": 0.253115
    },
    {
      "epoch": 0.9131610857196157,
      "grad_norm": 4.044455528259277,
      "learning_rate": 9.526805682248383e-06,
      "loss": 0.48546619415283204,
      "memory(GiB)": 72.72,
      "step": 9790,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.253112
    },
    {
      "epoch": 0.9136274601249883,
      "grad_norm": 5.823277950286865,
      "learning_rate": 9.526150543090172e-06,
      "loss": 0.5741979598999023,
      "memory(GiB)": 72.72,
      "step": 9795,
      "train_speed(iter/s)": 0.253121
    },
    {
      "epoch": 0.914093834530361,
      "grad_norm": 5.490528583526611,
      "learning_rate": 9.52549497328268e-06,
      "loss": 0.47919702529907227,
      "memory(GiB)": 72.72,
      "step": 9800,
      "token_acc": 0.6904761904761905,
      "train_speed(iter/s)": 0.253111
    },
    {
      "epoch": 0.9145602089357336,
      "grad_norm": 5.340947151184082,
      "learning_rate": 9.524838972888282e-06,
      "loss": 0.4612292766571045,
      "memory(GiB)": 72.72,
      "step": 9805,
      "token_acc": 0.22448979591836735,
      "train_speed(iter/s)": 0.253106
    },
    {
      "epoch": 0.9150265833411062,
      "grad_norm": 9.603939056396484,
      "learning_rate": 9.524182541969395e-06,
      "loss": 0.46565942764282225,
      "memory(GiB)": 72.72,
      "step": 9810,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.253107
    },
    {
      "epoch": 0.9154929577464789,
      "grad_norm": 3.9637460708618164,
      "learning_rate": 9.523525680588477e-06,
      "loss": 0.5083579063415528,
      "memory(GiB)": 72.72,
      "step": 9815,
      "train_speed(iter/s)": 0.253098
    },
    {
      "epoch": 0.9159593321518515,
      "grad_norm": 5.315596580505371,
      "learning_rate": 9.522868388808024e-06,
      "loss": 0.491497802734375,
      "memory(GiB)": 72.72,
      "step": 9820,
      "train_speed(iter/s)": 0.253099
    },
    {
      "epoch": 0.9164257065572241,
      "grad_norm": 4.143324851989746,
      "learning_rate": 9.522210666690577e-06,
      "loss": 0.5065659999847412,
      "memory(GiB)": 72.72,
      "step": 9825,
      "token_acc": 0.4626865671641791,
      "train_speed(iter/s)": 0.253108
    },
    {
      "epoch": 0.9168920809625968,
      "grad_norm": 8.185393333435059,
      "learning_rate": 9.521552514298718e-06,
      "loss": 0.4551513195037842,
      "memory(GiB)": 72.72,
      "step": 9830,
      "train_speed(iter/s)": 0.253101
    },
    {
      "epoch": 0.9173584553679694,
      "grad_norm": 6.186286926269531,
      "learning_rate": 9.520893931695064e-06,
      "loss": 0.4684898376464844,
      "memory(GiB)": 72.72,
      "step": 9835,
      "train_speed(iter/s)": 0.2531
    },
    {
      "epoch": 0.917824829773342,
      "grad_norm": 5.519681930541992,
      "learning_rate": 9.520234918942279e-06,
      "loss": 0.5072741508483887,
      "memory(GiB)": 72.72,
      "step": 9840,
      "train_speed(iter/s)": 0.253105
    },
    {
      "epoch": 0.9182912041787147,
      "grad_norm": 7.047616004943848,
      "learning_rate": 9.519575476103069e-06,
      "loss": 0.5335044384002685,
      "memory(GiB)": 72.72,
      "step": 9845,
      "train_speed(iter/s)": 0.2531
    },
    {
      "epoch": 0.9187575785840874,
      "grad_norm": 2.891695022583008,
      "learning_rate": 9.518915603240172e-06,
      "loss": 0.4699705123901367,
      "memory(GiB)": 72.72,
      "step": 9850,
      "token_acc": 0.8617021276595744,
      "train_speed(iter/s)": 0.253099
    },
    {
      "epoch": 0.9192239529894599,
      "grad_norm": 4.220324993133545,
      "learning_rate": 9.51825530041638e-06,
      "loss": 0.4660954475402832,
      "memory(GiB)": 72.72,
      "step": 9855,
      "token_acc": 0.5324675324675324,
      "train_speed(iter/s)": 0.253102
    },
    {
      "epoch": 0.9196903273948326,
      "grad_norm": 3.8166580200195312,
      "learning_rate": 9.517594567694512e-06,
      "loss": 0.506617259979248,
      "memory(GiB)": 72.72,
      "step": 9860,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.253103
    },
    {
      "epoch": 0.9201567018002053,
      "grad_norm": 3.28825044631958,
      "learning_rate": 9.51693340513744e-06,
      "loss": 0.47050843238830564,
      "memory(GiB)": 72.72,
      "step": 9865,
      "train_speed(iter/s)": 0.253102
    },
    {
      "epoch": 0.9206230762055778,
      "grad_norm": 6.255667209625244,
      "learning_rate": 9.516271812808067e-06,
      "loss": 0.4747047424316406,
      "memory(GiB)": 72.72,
      "step": 9870,
      "token_acc": 0.6065573770491803,
      "train_speed(iter/s)": 0.253111
    },
    {
      "epoch": 0.9210894506109505,
      "grad_norm": 4.387948036193848,
      "learning_rate": 9.515609790769345e-06,
      "loss": 0.43682336807250977,
      "memory(GiB)": 72.72,
      "step": 9875,
      "token_acc": 0.47619047619047616,
      "train_speed(iter/s)": 0.253111
    },
    {
      "epoch": 0.921555825016323,
      "grad_norm": 3.8710594177246094,
      "learning_rate": 9.514947339084263e-06,
      "loss": 0.5164857864379883,
      "memory(GiB)": 72.72,
      "step": 9880,
      "train_speed(iter/s)": 0.25311
    },
    {
      "epoch": 0.9220221994216957,
      "grad_norm": 4.573050022125244,
      "learning_rate": 9.514284457815849e-06,
      "loss": 0.5110296249389649,
      "memory(GiB)": 72.72,
      "step": 9885,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.253111
    },
    {
      "epoch": 0.9224885738270684,
      "grad_norm": 3.8373031616210938,
      "learning_rate": 9.513621147027175e-06,
      "loss": 0.4689361572265625,
      "memory(GiB)": 72.72,
      "step": 9890,
      "train_speed(iter/s)": 0.253101
    },
    {
      "epoch": 0.922954948232441,
      "grad_norm": 3.6199581623077393,
      "learning_rate": 9.512957406781355e-06,
      "loss": 0.48932828903198244,
      "memory(GiB)": 72.72,
      "step": 9895,
      "train_speed(iter/s)": 0.253098
    },
    {
      "epoch": 0.9234213226378136,
      "grad_norm": 3.515361785888672,
      "learning_rate": 9.512293237141539e-06,
      "loss": 0.475830602645874,
      "memory(GiB)": 72.72,
      "step": 9900,
      "train_speed(iter/s)": 0.253104
    },
    {
      "epoch": 0.9238876970431863,
      "grad_norm": 4.072590351104736,
      "learning_rate": 9.511628638170922e-06,
      "loss": 0.5027549743652344,
      "memory(GiB)": 72.72,
      "step": 9905,
      "train_speed(iter/s)": 0.253111
    },
    {
      "epoch": 0.9243540714485589,
      "grad_norm": 4.273362159729004,
      "learning_rate": 9.51096360993274e-06,
      "loss": 0.5632660865783692,
      "memory(GiB)": 72.72,
      "step": 9910,
      "token_acc": 0.6612021857923497,
      "train_speed(iter/s)": 0.253124
    },
    {
      "epoch": 0.9248204458539315,
      "grad_norm": 3.7344796657562256,
      "learning_rate": 9.510298152490265e-06,
      "loss": 0.5212709903717041,
      "memory(GiB)": 72.72,
      "step": 9915,
      "token_acc": 0.7073170731707317,
      "train_speed(iter/s)": 0.253129
    },
    {
      "epoch": 0.9252868202593042,
      "grad_norm": 5.322630882263184,
      "learning_rate": 9.509632265906816e-06,
      "loss": 0.46987299919128417,
      "memory(GiB)": 72.72,
      "step": 9920,
      "train_speed(iter/s)": 0.253128
    },
    {
      "epoch": 0.9257531946646768,
      "grad_norm": 4.104078769683838,
      "learning_rate": 9.508965950245749e-06,
      "loss": 0.4958007335662842,
      "memory(GiB)": 72.72,
      "step": 9925,
      "train_speed(iter/s)": 0.253127
    },
    {
      "epoch": 0.9262195690700494,
      "grad_norm": 9.012412071228027,
      "learning_rate": 9.508299205570462e-06,
      "loss": 0.49976887702941897,
      "memory(GiB)": 72.72,
      "step": 9930,
      "train_speed(iter/s)": 0.25312
    },
    {
      "epoch": 0.9266859434754221,
      "grad_norm": 5.36350679397583,
      "learning_rate": 9.507632031944394e-06,
      "loss": 0.5327420234680176,
      "memory(GiB)": 72.72,
      "step": 9935,
      "train_speed(iter/s)": 0.253127
    },
    {
      "epoch": 0.9271523178807947,
      "grad_norm": 11.502549171447754,
      "learning_rate": 9.506964429431022e-06,
      "loss": 0.48599586486816404,
      "memory(GiB)": 72.72,
      "step": 9940,
      "train_speed(iter/s)": 0.25312
    },
    {
      "epoch": 0.9276186922861673,
      "grad_norm": 4.943576335906982,
      "learning_rate": 9.506296398093872e-06,
      "loss": 0.513521671295166,
      "memory(GiB)": 72.72,
      "step": 9945,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.25312
    },
    {
      "epoch": 0.92808506669154,
      "grad_norm": 6.964096546173096,
      "learning_rate": 9.5056279379965e-06,
      "loss": 0.4933623313903809,
      "memory(GiB)": 72.72,
      "step": 9950,
      "train_speed(iter/s)": 0.253123
    },
    {
      "epoch": 0.9285514410969126,
      "grad_norm": 5.785112380981445,
      "learning_rate": 9.50495904920251e-06,
      "loss": 0.5025979518890381,
      "memory(GiB)": 72.72,
      "step": 9955,
      "train_speed(iter/s)": 0.253129
    },
    {
      "epoch": 0.9290178155022852,
      "grad_norm": 2.7311558723449707,
      "learning_rate": 9.504289731775544e-06,
      "loss": 0.479872465133667,
      "memory(GiB)": 72.72,
      "step": 9960,
      "train_speed(iter/s)": 0.253129
    },
    {
      "epoch": 0.9294841899076579,
      "grad_norm": 4.907383918762207,
      "learning_rate": 9.503619985779287e-06,
      "loss": 0.5012479782104492,
      "memory(GiB)": 72.72,
      "step": 9965,
      "token_acc": 0.5166666666666667,
      "train_speed(iter/s)": 0.253127
    },
    {
      "epoch": 0.9299505643130305,
      "grad_norm": 4.387529373168945,
      "learning_rate": 9.502949811277461e-06,
      "loss": 0.5031252861022949,
      "memory(GiB)": 72.72,
      "step": 9970,
      "train_speed(iter/s)": 0.253136
    },
    {
      "epoch": 0.9304169387184031,
      "grad_norm": 4.810307502746582,
      "learning_rate": 9.502279208333831e-06,
      "loss": 0.49441871643066404,
      "memory(GiB)": 72.72,
      "step": 9975,
      "train_speed(iter/s)": 0.253142
    },
    {
      "epoch": 0.9308833131237758,
      "grad_norm": 7.300417423248291,
      "learning_rate": 9.501608177012206e-06,
      "loss": 0.4927727222442627,
      "memory(GiB)": 72.72,
      "step": 9980,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.25315
    },
    {
      "epoch": 0.9313496875291484,
      "grad_norm": 9.081428527832031,
      "learning_rate": 9.50093671737643e-06,
      "loss": 0.46918411254882814,
      "memory(GiB)": 72.72,
      "step": 9985,
      "train_speed(iter/s)": 0.253154
    },
    {
      "epoch": 0.931816061934521,
      "grad_norm": 6.9116106033325195,
      "learning_rate": 9.500264829490391e-06,
      "loss": 0.5366175651550293,
      "memory(GiB)": 72.72,
      "step": 9990,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.253156
    },
    {
      "epoch": 0.9322824363398937,
      "grad_norm": 4.2875871658325195,
      "learning_rate": 9.499592513418017e-06,
      "loss": 0.5376858234405517,
      "memory(GiB)": 72.72,
      "step": 9995,
      "train_speed(iter/s)": 0.253157
    },
    {
      "epoch": 0.9327488107452663,
      "grad_norm": 7.69437313079834,
      "learning_rate": 9.498919769223276e-06,
      "loss": 0.4878851413726807,
      "memory(GiB)": 72.72,
      "step": 10000,
      "token_acc": 0.6161616161616161,
      "train_speed(iter/s)": 0.253158
    },
    {
      "epoch": 0.933215185150639,
      "grad_norm": 4.247557163238525,
      "learning_rate": 9.498246596970177e-06,
      "loss": 0.5131396293640137,
      "memory(GiB)": 72.72,
      "step": 10005,
      "token_acc": 0.4418604651162791,
      "train_speed(iter/s)": 0.252991
    },
    {
      "epoch": 0.9336815595560116,
      "grad_norm": 5.204320907592773,
      "learning_rate": 9.497572996722773e-06,
      "loss": 0.5185598373413086,
      "memory(GiB)": 72.72,
      "step": 10010,
      "token_acc": 0.3877551020408163,
      "train_speed(iter/s)": 0.252982
    },
    {
      "epoch": 0.9341479339613842,
      "grad_norm": 5.856358528137207,
      "learning_rate": 9.496898968545155e-06,
      "loss": 0.4781545639038086,
      "memory(GiB)": 72.72,
      "step": 10015,
      "token_acc": 0.46938775510204084,
      "train_speed(iter/s)": 0.252989
    },
    {
      "epoch": 0.9346143083667569,
      "grad_norm": 4.273624420166016,
      "learning_rate": 9.49622451250145e-06,
      "loss": 0.5351330280303955,
      "memory(GiB)": 72.72,
      "step": 10020,
      "train_speed(iter/s)": 0.252992
    },
    {
      "epoch": 0.9350806827721294,
      "grad_norm": 4.272395133972168,
      "learning_rate": 9.495549628655836e-06,
      "loss": 0.5524588584899902,
      "memory(GiB)": 72.72,
      "step": 10025,
      "token_acc": 0.900990099009901,
      "train_speed(iter/s)": 0.252996
    },
    {
      "epoch": 0.9355470571775021,
      "grad_norm": 6.915829181671143,
      "learning_rate": 9.494874317072522e-06,
      "loss": 0.526700210571289,
      "memory(GiB)": 72.72,
      "step": 10030,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252999
    },
    {
      "epoch": 0.9360134315828748,
      "grad_norm": 4.404219150543213,
      "learning_rate": 9.494198577815765e-06,
      "loss": 0.44848856925964353,
      "memory(GiB)": 72.72,
      "step": 10035,
      "train_speed(iter/s)": 0.253001
    },
    {
      "epoch": 0.9364798059882473,
      "grad_norm": 3.576505184173584,
      "learning_rate": 9.493522410949857e-06,
      "loss": 0.46812148094177247,
      "memory(GiB)": 72.72,
      "step": 10040,
      "token_acc": 0.8640776699029126,
      "train_speed(iter/s)": 0.253
    },
    {
      "epoch": 0.93694618039362,
      "grad_norm": 3.3404428958892822,
      "learning_rate": 9.492845816539134e-06,
      "loss": 0.4975799560546875,
      "memory(GiB)": 72.72,
      "step": 10045,
      "token_acc": 0.8876404494382022,
      "train_speed(iter/s)": 0.252993
    },
    {
      "epoch": 0.9374125547989927,
      "grad_norm": 5.7294769287109375,
      "learning_rate": 9.492168794647974e-06,
      "loss": 0.4799649238586426,
      "memory(GiB)": 72.72,
      "step": 10050,
      "train_speed(iter/s)": 0.252989
    },
    {
      "epoch": 0.9378789292043652,
      "grad_norm": 3.0552563667297363,
      "learning_rate": 9.49149134534079e-06,
      "loss": 0.5321311950683594,
      "memory(GiB)": 72.72,
      "step": 10055,
      "train_speed(iter/s)": 0.252988
    },
    {
      "epoch": 0.9383453036097379,
      "grad_norm": 4.447495460510254,
      "learning_rate": 9.49081346868204e-06,
      "loss": 0.495758581161499,
      "memory(GiB)": 72.72,
      "step": 10060,
      "train_speed(iter/s)": 0.25299
    },
    {
      "epoch": 0.9388116780151106,
      "grad_norm": 6.87040901184082,
      "learning_rate": 9.490135164736224e-06,
      "loss": 0.5098135948181153,
      "memory(GiB)": 72.72,
      "step": 10065,
      "token_acc": 0.4032258064516129,
      "train_speed(iter/s)": 0.25299
    },
    {
      "epoch": 0.9392780524204831,
      "grad_norm": 4.983246326446533,
      "learning_rate": 9.48945643356788e-06,
      "loss": 0.4947032928466797,
      "memory(GiB)": 72.72,
      "step": 10070,
      "train_speed(iter/s)": 0.252984
    },
    {
      "epoch": 0.9397444268258558,
      "grad_norm": 4.886124610900879,
      "learning_rate": 9.488777275241586e-06,
      "loss": 0.48228769302368163,
      "memory(GiB)": 72.72,
      "step": 10075,
      "token_acc": 0.6323529411764706,
      "train_speed(iter/s)": 0.252977
    },
    {
      "epoch": 0.9402108012312285,
      "grad_norm": 4.2274699211120605,
      "learning_rate": 9.488097689821962e-06,
      "loss": 0.504356050491333,
      "memory(GiB)": 72.72,
      "step": 10080,
      "token_acc": 0.90625,
      "train_speed(iter/s)": 0.252981
    },
    {
      "epoch": 0.940677175636601,
      "grad_norm": 6.117544651031494,
      "learning_rate": 9.487417677373669e-06,
      "loss": 0.4748093605041504,
      "memory(GiB)": 72.72,
      "step": 10085,
      "train_speed(iter/s)": 0.252978
    },
    {
      "epoch": 0.9411435500419737,
      "grad_norm": 4.499878406524658,
      "learning_rate": 9.486737237961407e-06,
      "loss": 0.5088289260864258,
      "memory(GiB)": 72.72,
      "step": 10090,
      "token_acc": 0.35,
      "train_speed(iter/s)": 0.252859
    },
    {
      "epoch": 0.9416099244473464,
      "grad_norm": 6.108701705932617,
      "learning_rate": 9.48605637164992e-06,
      "loss": 0.4882561683654785,
      "memory(GiB)": 72.72,
      "step": 10095,
      "train_speed(iter/s)": 0.252841
    },
    {
      "epoch": 0.9420762988527189,
      "grad_norm": 10.994322776794434,
      "learning_rate": 9.485375078503988e-06,
      "loss": 0.506333303451538,
      "memory(GiB)": 72.72,
      "step": 10100,
      "train_speed(iter/s)": 0.252842
    },
    {
      "epoch": 0.9425426732580916,
      "grad_norm": 5.687809467315674,
      "learning_rate": 9.484693358588435e-06,
      "loss": 0.45690302848815917,
      "memory(GiB)": 72.72,
      "step": 10105,
      "train_speed(iter/s)": 0.252847
    },
    {
      "epoch": 0.9430090476634643,
      "grad_norm": 5.848581314086914,
      "learning_rate": 9.484011211968124e-06,
      "loss": 0.5094836235046387,
      "memory(GiB)": 72.72,
      "step": 10110,
      "token_acc": 0.9058823529411765,
      "train_speed(iter/s)": 0.252844
    },
    {
      "epoch": 0.9434754220688368,
      "grad_norm": 3.5060179233551025,
      "learning_rate": 9.48332863870796e-06,
      "loss": 0.5153739929199219,
      "memory(GiB)": 72.72,
      "step": 10115,
      "token_acc": 0.39705882352941174,
      "train_speed(iter/s)": 0.252849
    },
    {
      "epoch": 0.9439417964742095,
      "grad_norm": 5.862536430358887,
      "learning_rate": 9.482645638872887e-06,
      "loss": 0.5027047157287597,
      "memory(GiB)": 72.72,
      "step": 10120,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.252859
    },
    {
      "epoch": 0.9444081708795822,
      "grad_norm": 4.791991710662842,
      "learning_rate": 9.481962212527891e-06,
      "loss": 0.5032730579376221,
      "memory(GiB)": 72.72,
      "step": 10125,
      "token_acc": 0.3617021276595745,
      "train_speed(iter/s)": 0.252859
    },
    {
      "epoch": 0.9448745452849547,
      "grad_norm": 5.321353435516357,
      "learning_rate": 9.481278359737998e-06,
      "loss": 0.49433412551879885,
      "memory(GiB)": 72.72,
      "step": 10130,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.252856
    },
    {
      "epoch": 0.9453409196903274,
      "grad_norm": 6.191636562347412,
      "learning_rate": 9.480594080568272e-06,
      "loss": 0.5087347030639648,
      "memory(GiB)": 72.72,
      "step": 10135,
      "token_acc": 0.4117647058823529,
      "train_speed(iter/s)": 0.252861
    },
    {
      "epoch": 0.9458072940957001,
      "grad_norm": 4.023504257202148,
      "learning_rate": 9.479909375083823e-06,
      "loss": 0.5124464988708496,
      "memory(GiB)": 72.72,
      "step": 10140,
      "token_acc": 0.5172413793103449,
      "train_speed(iter/s)": 0.252867
    },
    {
      "epoch": 0.9462736685010726,
      "grad_norm": 4.912346839904785,
      "learning_rate": 9.479224243349799e-06,
      "loss": 0.4650670051574707,
      "memory(GiB)": 72.72,
      "step": 10145,
      "train_speed(iter/s)": 0.252869
    },
    {
      "epoch": 0.9467400429064453,
      "grad_norm": 3.692850351333618,
      "learning_rate": 9.478538685431385e-06,
      "loss": 0.49892492294311525,
      "memory(GiB)": 72.72,
      "step": 10150,
      "train_speed(iter/s)": 0.252868
    },
    {
      "epoch": 0.9472064173118179,
      "grad_norm": 5.575364589691162,
      "learning_rate": 9.47785270139381e-06,
      "loss": 0.44713754653930665,
      "memory(GiB)": 72.72,
      "step": 10155,
      "train_speed(iter/s)": 0.252871
    },
    {
      "epoch": 0.9476727917171905,
      "grad_norm": 3.1456501483917236,
      "learning_rate": 9.477166291302349e-06,
      "loss": 0.5185912132263184,
      "memory(GiB)": 72.72,
      "step": 10160,
      "train_speed(iter/s)": 0.252878
    },
    {
      "epoch": 0.9481391661225632,
      "grad_norm": 5.349161624908447,
      "learning_rate": 9.476479455222305e-06,
      "loss": 0.4805779933929443,
      "memory(GiB)": 72.72,
      "step": 10165,
      "train_speed(iter/s)": 0.252879
    },
    {
      "epoch": 0.9486055405279358,
      "grad_norm": 6.317634105682373,
      "learning_rate": 9.475792193219032e-06,
      "loss": 0.48353161811828616,
      "memory(GiB)": 72.72,
      "step": 10170,
      "token_acc": 0.7786259541984732,
      "train_speed(iter/s)": 0.252868
    },
    {
      "epoch": 0.9490719149333084,
      "grad_norm": 3.9864492416381836,
      "learning_rate": 9.47510450535792e-06,
      "loss": 0.48166046142578123,
      "memory(GiB)": 72.72,
      "step": 10175,
      "token_acc": 0.38461538461538464,
      "train_speed(iter/s)": 0.252866
    },
    {
      "epoch": 0.9495382893386811,
      "grad_norm": 3.8448567390441895,
      "learning_rate": 9.4744163917044e-06,
      "loss": 0.47522716522216796,
      "memory(GiB)": 72.72,
      "step": 10180,
      "train_speed(iter/s)": 0.252875
    },
    {
      "epoch": 0.9500046637440537,
      "grad_norm": 2.4777960777282715,
      "learning_rate": 9.473727852323943e-06,
      "loss": 0.4330145835876465,
      "memory(GiB)": 72.72,
      "step": 10185,
      "train_speed(iter/s)": 0.252871
    },
    {
      "epoch": 0.9504710381494264,
      "grad_norm": 3.9059231281280518,
      "learning_rate": 9.473038887282064e-06,
      "loss": 0.4418786525726318,
      "memory(GiB)": 72.72,
      "step": 10190,
      "train_speed(iter/s)": 0.25287
    },
    {
      "epoch": 0.950937412554799,
      "grad_norm": 8.257072448730469,
      "learning_rate": 9.472349496644312e-06,
      "loss": 0.491487455368042,
      "memory(GiB)": 72.72,
      "step": 10195,
      "token_acc": 0.5692307692307692,
      "train_speed(iter/s)": 0.252864
    },
    {
      "epoch": 0.9514037869601716,
      "grad_norm": 3.214402675628662,
      "learning_rate": 9.471659680476286e-06,
      "loss": 0.47873334884643554,
      "memory(GiB)": 72.72,
      "step": 10200,
      "train_speed(iter/s)": 0.252864
    },
    {
      "epoch": 0.9518701613655443,
      "grad_norm": 6.86126184463501,
      "learning_rate": 9.470969438843614e-06,
      "loss": 0.5112410545349121,
      "memory(GiB)": 72.72,
      "step": 10205,
      "train_speed(iter/s)": 0.252861
    },
    {
      "epoch": 0.9523365357709169,
      "grad_norm": 10.460923194885254,
      "learning_rate": 9.470278771811974e-06,
      "loss": 0.5126847267150879,
      "memory(GiB)": 72.72,
      "step": 10210,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.252864
    },
    {
      "epoch": 0.9528029101762895,
      "grad_norm": 3.1219849586486816,
      "learning_rate": 9.469587679447082e-06,
      "loss": 0.49008989334106445,
      "memory(GiB)": 72.72,
      "step": 10215,
      "train_speed(iter/s)": 0.252864
    },
    {
      "epoch": 0.9532692845816622,
      "grad_norm": 4.261831760406494,
      "learning_rate": 9.46889616181469e-06,
      "loss": 0.49810400009155276,
      "memory(GiB)": 72.72,
      "step": 10220,
      "token_acc": 0.4672897196261682,
      "train_speed(iter/s)": 0.252867
    },
    {
      "epoch": 0.9537356589870348,
      "grad_norm": 3.8763160705566406,
      "learning_rate": 9.468204218980593e-06,
      "loss": 0.4847679138183594,
      "memory(GiB)": 72.72,
      "step": 10225,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.25286
    },
    {
      "epoch": 0.9542020333924074,
      "grad_norm": 7.20074462890625,
      "learning_rate": 9.467511851010631e-06,
      "loss": 0.48015422821044923,
      "memory(GiB)": 72.72,
      "step": 10230,
      "train_speed(iter/s)": 0.252864
    },
    {
      "epoch": 0.9546684077977801,
      "grad_norm": 4.516950607299805,
      "learning_rate": 9.466819057970678e-06,
      "loss": 0.4851388931274414,
      "memory(GiB)": 72.72,
      "step": 10235,
      "token_acc": 0.44144144144144143,
      "train_speed(iter/s)": 0.252874
    },
    {
      "epoch": 0.9551347822031527,
      "grad_norm": 5.717864513397217,
      "learning_rate": 9.466125839926652e-06,
      "loss": 0.5351272583007812,
      "memory(GiB)": 72.72,
      "step": 10240,
      "token_acc": 0.4418604651162791,
      "train_speed(iter/s)": 0.252878
    },
    {
      "epoch": 0.9556011566085253,
      "grad_norm": 7.736853122711182,
      "learning_rate": 9.46543219694451e-06,
      "loss": 0.5037515163421631,
      "memory(GiB)": 72.72,
      "step": 10245,
      "train_speed(iter/s)": 0.252877
    },
    {
      "epoch": 0.956067531013898,
      "grad_norm": 4.722580432891846,
      "learning_rate": 9.464738129090252e-06,
      "loss": 0.48323888778686525,
      "memory(GiB)": 72.72,
      "step": 10250,
      "train_speed(iter/s)": 0.252875
    },
    {
      "epoch": 0.9565339054192706,
      "grad_norm": 4.993422031402588,
      "learning_rate": 9.464043636429916e-06,
      "loss": 0.49517431259155276,
      "memory(GiB)": 72.72,
      "step": 10255,
      "train_speed(iter/s)": 0.252875
    },
    {
      "epoch": 0.9570002798246432,
      "grad_norm": 5.0357184410095215,
      "learning_rate": 9.463348719029578e-06,
      "loss": 0.46503677368164065,
      "memory(GiB)": 72.72,
      "step": 10260,
      "token_acc": 0.90625,
      "train_speed(iter/s)": 0.252882
    },
    {
      "epoch": 0.9574666542300159,
      "grad_norm": 5.325992107391357,
      "learning_rate": 9.46265337695536e-06,
      "loss": 0.4981851577758789,
      "memory(GiB)": 72.72,
      "step": 10265,
      "train_speed(iter/s)": 0.252884
    },
    {
      "epoch": 0.9579330286353885,
      "grad_norm": 2.759551525115967,
      "learning_rate": 9.46195761027342e-06,
      "loss": 0.4927379608154297,
      "memory(GiB)": 72.72,
      "step": 10270,
      "token_acc": 0.5116279069767442,
      "train_speed(iter/s)": 0.252877
    },
    {
      "epoch": 0.9583994030407611,
      "grad_norm": 3.624513864517212,
      "learning_rate": 9.461261419049959e-06,
      "loss": 0.5135167121887207,
      "memory(GiB)": 72.72,
      "step": 10275,
      "token_acc": 0.6216216216216216,
      "train_speed(iter/s)": 0.252882
    },
    {
      "epoch": 0.9588657774461338,
      "grad_norm": 11.176315307617188,
      "learning_rate": 9.460564803351218e-06,
      "loss": 0.5424305915832519,
      "memory(GiB)": 72.72,
      "step": 10280,
      "train_speed(iter/s)": 0.252878
    },
    {
      "epoch": 0.9593321518515064,
      "grad_norm": 3.6989448070526123,
      "learning_rate": 9.459867763243476e-06,
      "loss": 0.519432544708252,
      "memory(GiB)": 72.72,
      "step": 10285,
      "token_acc": 0.425,
      "train_speed(iter/s)": 0.252874
    },
    {
      "epoch": 0.959798526256879,
      "grad_norm": 4.9088029861450195,
      "learning_rate": 9.459170298793055e-06,
      "loss": 0.5080752372741699,
      "memory(GiB)": 72.72,
      "step": 10290,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.25288
    },
    {
      "epoch": 0.9602649006622517,
      "grad_norm": 3.9972100257873535,
      "learning_rate": 9.458472410066317e-06,
      "loss": 0.478641414642334,
      "memory(GiB)": 72.72,
      "step": 10295,
      "token_acc": 0.4461538461538462,
      "train_speed(iter/s)": 0.252878
    },
    {
      "epoch": 0.9607312750676242,
      "grad_norm": 4.271994590759277,
      "learning_rate": 9.457774097129664e-06,
      "loss": 0.5118362426757812,
      "memory(GiB)": 72.72,
      "step": 10300,
      "token_acc": 0.7602739726027398,
      "train_speed(iter/s)": 0.252884
    },
    {
      "epoch": 0.9611976494729969,
      "grad_norm": 3.71490740776062,
      "learning_rate": 9.45707536004954e-06,
      "loss": 0.5067375183105469,
      "memory(GiB)": 72.72,
      "step": 10305,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252882
    },
    {
      "epoch": 0.9616640238783696,
      "grad_norm": 3.93052339553833,
      "learning_rate": 9.456376198892424e-06,
      "loss": 0.4779075622558594,
      "memory(GiB)": 72.72,
      "step": 10310,
      "token_acc": 0.6944444444444444,
      "train_speed(iter/s)": 0.252879
    },
    {
      "epoch": 0.9621303982837421,
      "grad_norm": 4.055060386657715,
      "learning_rate": 9.45567661372484e-06,
      "loss": 0.4693275451660156,
      "memory(GiB)": 72.72,
      "step": 10315,
      "token_acc": 0.4642857142857143,
      "train_speed(iter/s)": 0.25288
    },
    {
      "epoch": 0.9625967726891148,
      "grad_norm": 4.458215236663818,
      "learning_rate": 9.454976604613354e-06,
      "loss": 0.4905398368835449,
      "memory(GiB)": 72.72,
      "step": 10320,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.252874
    },
    {
      "epoch": 0.9630631470944875,
      "grad_norm": 5.229441165924072,
      "learning_rate": 9.454276171624569e-06,
      "loss": 0.469655704498291,
      "memory(GiB)": 72.72,
      "step": 10325,
      "train_speed(iter/s)": 0.252873
    },
    {
      "epoch": 0.96352952149986,
      "grad_norm": 4.415408611297607,
      "learning_rate": 9.453575314825125e-06,
      "loss": 0.5261632919311523,
      "memory(GiB)": 72.72,
      "step": 10330,
      "train_speed(iter/s)": 0.252874
    },
    {
      "epoch": 0.9639958959052327,
      "grad_norm": 7.447026252746582,
      "learning_rate": 9.45287403428171e-06,
      "loss": 0.46891469955444337,
      "memory(GiB)": 72.72,
      "step": 10335,
      "train_speed(iter/s)": 0.252867
    },
    {
      "epoch": 0.9644622703106054,
      "grad_norm": 3.5545923709869385,
      "learning_rate": 9.45217233006105e-06,
      "loss": 0.5299123764038086,
      "memory(GiB)": 72.72,
      "step": 10340,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.252862
    },
    {
      "epoch": 0.964928644715978,
      "grad_norm": 3.7154273986816406,
      "learning_rate": 9.451470202229906e-06,
      "loss": 0.5042786598205566,
      "memory(GiB)": 72.72,
      "step": 10345,
      "train_speed(iter/s)": 0.252866
    },
    {
      "epoch": 0.9653950191213506,
      "grad_norm": 5.649686813354492,
      "learning_rate": 9.450767650855086e-06,
      "loss": 0.5217296123504639,
      "memory(GiB)": 72.72,
      "step": 10350,
      "train_speed(iter/s)": 0.252869
    },
    {
      "epoch": 0.9658613935267233,
      "grad_norm": 2.6299335956573486,
      "learning_rate": 9.450064676003437e-06,
      "loss": 0.4433696746826172,
      "memory(GiB)": 72.72,
      "step": 10355,
      "token_acc": 0.9042553191489362,
      "train_speed(iter/s)": 0.252879
    },
    {
      "epoch": 0.9663277679320958,
      "grad_norm": 3.3236498832702637,
      "learning_rate": 9.44936127774184e-06,
      "loss": 0.477874755859375,
      "memory(GiB)": 72.72,
      "step": 10360,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.252889
    },
    {
      "epoch": 0.9667941423374685,
      "grad_norm": 3.4957261085510254,
      "learning_rate": 9.448657456137224e-06,
      "loss": 0.4909788131713867,
      "memory(GiB)": 72.72,
      "step": 10365,
      "token_acc": 0.39344262295081966,
      "train_speed(iter/s)": 0.252882
    },
    {
      "epoch": 0.9672605167428412,
      "grad_norm": 3.7103536128997803,
      "learning_rate": 9.447953211256558e-06,
      "loss": 0.5249120712280273,
      "memory(GiB)": 72.72,
      "step": 10370,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.252886
    },
    {
      "epoch": 0.9677268911482138,
      "grad_norm": 2.2342116832733154,
      "learning_rate": 9.447248543166845e-06,
      "loss": 0.47502660751342773,
      "memory(GiB)": 72.72,
      "step": 10375,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.252884
    },
    {
      "epoch": 0.9681932655535864,
      "grad_norm": 2.764967203140259,
      "learning_rate": 9.446543451935131e-06,
      "loss": 0.4954807758331299,
      "memory(GiB)": 72.72,
      "step": 10380,
      "train_speed(iter/s)": 0.252883
    },
    {
      "epoch": 0.9686596399589591,
      "grad_norm": 4.39583683013916,
      "learning_rate": 9.445837937628508e-06,
      "loss": 0.4605837345123291,
      "memory(GiB)": 72.72,
      "step": 10385,
      "train_speed(iter/s)": 0.252892
    },
    {
      "epoch": 0.9691260143643317,
      "grad_norm": 3.092268228530884,
      "learning_rate": 9.445132000314101e-06,
      "loss": 0.49588451385498045,
      "memory(GiB)": 72.72,
      "step": 10390,
      "token_acc": 0.9191919191919192,
      "train_speed(iter/s)": 0.252891
    },
    {
      "epoch": 0.9695923887697043,
      "grad_norm": 5.219704627990723,
      "learning_rate": 9.444425640059077e-06,
      "loss": 0.493795108795166,
      "memory(GiB)": 72.72,
      "step": 10395,
      "token_acc": 0.9565217391304348,
      "train_speed(iter/s)": 0.252889
    },
    {
      "epoch": 0.970058763175077,
      "grad_norm": 6.023041248321533,
      "learning_rate": 9.443718856930644e-06,
      "loss": 0.5039906978607178,
      "memory(GiB)": 72.72,
      "step": 10400,
      "train_speed(iter/s)": 0.25289
    },
    {
      "epoch": 0.9705251375804496,
      "grad_norm": 2.915983200073242,
      "learning_rate": 9.443011650996053e-06,
      "loss": 0.4719088554382324,
      "memory(GiB)": 72.72,
      "step": 10405,
      "token_acc": 0.9358974358974359,
      "train_speed(iter/s)": 0.252891
    },
    {
      "epoch": 0.9709915119858222,
      "grad_norm": 2.4676053524017334,
      "learning_rate": 9.44230402232259e-06,
      "loss": 0.5143324851989746,
      "memory(GiB)": 72.72,
      "step": 10410,
      "token_acc": 0.4027777777777778,
      "train_speed(iter/s)": 0.252891
    },
    {
      "epoch": 0.9714578863911949,
      "grad_norm": 6.855316638946533,
      "learning_rate": 9.441595970977582e-06,
      "loss": 0.48894343376159666,
      "memory(GiB)": 72.72,
      "step": 10415,
      "train_speed(iter/s)": 0.252884
    },
    {
      "epoch": 0.9719242607965675,
      "grad_norm": 2.8342933654785156,
      "learning_rate": 9.440887497028402e-06,
      "loss": 0.5145789623260498,
      "memory(GiB)": 72.72,
      "step": 10420,
      "train_speed(iter/s)": 0.252887
    },
    {
      "epoch": 0.9723906352019401,
      "grad_norm": 10.221166610717773,
      "learning_rate": 9.440178600542456e-06,
      "loss": 0.4971358299255371,
      "memory(GiB)": 72.72,
      "step": 10425,
      "token_acc": 0.9444444444444444,
      "train_speed(iter/s)": 0.25288
    },
    {
      "epoch": 0.9728570096073128,
      "grad_norm": 6.285142421722412,
      "learning_rate": 9.439469281587196e-06,
      "loss": 0.48232202529907225,
      "memory(GiB)": 72.72,
      "step": 10430,
      "train_speed(iter/s)": 0.252885
    },
    {
      "epoch": 0.9733233840126854,
      "grad_norm": 2.9718029499053955,
      "learning_rate": 9.438759540230109e-06,
      "loss": 0.4710841655731201,
      "memory(GiB)": 72.72,
      "step": 10435,
      "train_speed(iter/s)": 0.252879
    },
    {
      "epoch": 0.973789758418058,
      "grad_norm": 4.0856757164001465,
      "learning_rate": 9.438049376538724e-06,
      "loss": 0.5227571487426758,
      "memory(GiB)": 72.72,
      "step": 10440,
      "token_acc": 0.37254901960784315,
      "train_speed(iter/s)": 0.252879
    },
    {
      "epoch": 0.9742561328234306,
      "grad_norm": 4.428748607635498,
      "learning_rate": 9.437338790580616e-06,
      "loss": 0.4755383491516113,
      "memory(GiB)": 72.72,
      "step": 10445,
      "train_speed(iter/s)": 0.252882
    },
    {
      "epoch": 0.9747225072288033,
      "grad_norm": 5.025140285491943,
      "learning_rate": 9.43662778242339e-06,
      "loss": 0.5013771057128906,
      "memory(GiB)": 72.72,
      "step": 10450,
      "token_acc": 0.45348837209302323,
      "train_speed(iter/s)": 0.252883
    },
    {
      "epoch": 0.9751888816341759,
      "grad_norm": 5.381463050842285,
      "learning_rate": 9.435916352134697e-06,
      "loss": 0.495839786529541,
      "memory(GiB)": 72.72,
      "step": 10455,
      "token_acc": 0.3877551020408163,
      "train_speed(iter/s)": 0.25272
    },
    {
      "epoch": 0.9756552560395485,
      "grad_norm": 5.226085186004639,
      "learning_rate": 9.43520449978223e-06,
      "loss": 0.5157916069030761,
      "memory(GiB)": 72.72,
      "step": 10460,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.252714
    },
    {
      "epoch": 0.9761216304449212,
      "grad_norm": 4.456711769104004,
      "learning_rate": 9.434492225433715e-06,
      "loss": 0.4891035079956055,
      "memory(GiB)": 72.72,
      "step": 10465,
      "train_speed(iter/s)": 0.252722
    },
    {
      "epoch": 0.9765880048502938,
      "grad_norm": 3.085885763168335,
      "learning_rate": 9.433779529156929e-06,
      "loss": 0.4838663101196289,
      "memory(GiB)": 72.72,
      "step": 10470,
      "token_acc": 0.5254237288135594,
      "train_speed(iter/s)": 0.252733
    },
    {
      "epoch": 0.9770543792556664,
      "grad_norm": 2.7565224170684814,
      "learning_rate": 9.433066411019678e-06,
      "loss": 0.5137156963348388,
      "memory(GiB)": 72.72,
      "step": 10475,
      "token_acc": 0.8439716312056738,
      "train_speed(iter/s)": 0.252732
    },
    {
      "epoch": 0.9775207536610391,
      "grad_norm": 4.776716709136963,
      "learning_rate": 9.432352871089813e-06,
      "loss": 0.466050910949707,
      "memory(GiB)": 72.72,
      "step": 10480,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.252736
    },
    {
      "epoch": 0.9779871280664117,
      "grad_norm": 3.6223814487457275,
      "learning_rate": 9.431638909435228e-06,
      "loss": 0.4658687591552734,
      "memory(GiB)": 72.72,
      "step": 10485,
      "train_speed(iter/s)": 0.252742
    },
    {
      "epoch": 0.9784535024717843,
      "grad_norm": 4.687164783477783,
      "learning_rate": 9.430924526123853e-06,
      "loss": 0.49831523895263674,
      "memory(GiB)": 72.72,
      "step": 10490,
      "token_acc": 0.9183673469387755,
      "train_speed(iter/s)": 0.252741
    },
    {
      "epoch": 0.978919876877157,
      "grad_norm": 5.232397556304932,
      "learning_rate": 9.430209721223658e-06,
      "loss": 0.541442584991455,
      "memory(GiB)": 72.72,
      "step": 10495,
      "train_speed(iter/s)": 0.252739
    },
    {
      "epoch": 0.9793862512825297,
      "grad_norm": 3.640376091003418,
      "learning_rate": 9.429494494802658e-06,
      "loss": 0.47709083557128906,
      "memory(GiB)": 72.72,
      "step": 10500,
      "train_speed(iter/s)": 0.252736
    },
    {
      "epoch": 0.9798526256879022,
      "grad_norm": 3.5181803703308105,
      "learning_rate": 9.4287788469289e-06,
      "loss": 0.49363884925842283,
      "memory(GiB)": 72.72,
      "step": 10505,
      "train_speed(iter/s)": 0.252738
    },
    {
      "epoch": 0.9803190000932749,
      "grad_norm": 8.869702339172363,
      "learning_rate": 9.428062777670478e-06,
      "loss": 0.4922389030456543,
      "memory(GiB)": 72.72,
      "step": 10510,
      "train_speed(iter/s)": 0.252737
    },
    {
      "epoch": 0.9807853744986476,
      "grad_norm": 4.829468727111816,
      "learning_rate": 9.427346287095525e-06,
      "loss": 0.5114301204681396,
      "memory(GiB)": 72.72,
      "step": 10515,
      "train_speed(iter/s)": 0.252729
    },
    {
      "epoch": 0.9812517489040201,
      "grad_norm": 6.770732879638672,
      "learning_rate": 9.42662937527221e-06,
      "loss": 0.48882598876953126,
      "memory(GiB)": 72.72,
      "step": 10520,
      "train_speed(iter/s)": 0.252728
    },
    {
      "epoch": 0.9817181233093928,
      "grad_norm": 4.193080902099609,
      "learning_rate": 9.425912042268748e-06,
      "loss": 0.47397599220275877,
      "memory(GiB)": 72.72,
      "step": 10525,
      "token_acc": 0.5042735042735043,
      "train_speed(iter/s)": 0.252726
    },
    {
      "epoch": 0.9821844977147655,
      "grad_norm": 5.27590274810791,
      "learning_rate": 9.425194288153388e-06,
      "loss": 0.49032912254333494,
      "memory(GiB)": 72.72,
      "step": 10530,
      "train_speed(iter/s)": 0.252734
    },
    {
      "epoch": 0.982650872120138,
      "grad_norm": 5.926595687866211,
      "learning_rate": 9.424476112994424e-06,
      "loss": 0.4797951698303223,
      "memory(GiB)": 72.72,
      "step": 10535,
      "token_acc": 0.6172839506172839,
      "train_speed(iter/s)": 0.252739
    },
    {
      "epoch": 0.9831172465255107,
      "grad_norm": 3.9865353107452393,
      "learning_rate": 9.423757516860187e-06,
      "loss": 0.44416232109069825,
      "memory(GiB)": 72.72,
      "step": 10540,
      "train_speed(iter/s)": 0.252733
    },
    {
      "epoch": 0.9835836209308834,
      "grad_norm": 3.9190354347229004,
      "learning_rate": 9.423038499819053e-06,
      "loss": 0.5126550674438477,
      "memory(GiB)": 72.72,
      "step": 10545,
      "train_speed(iter/s)": 0.252741
    },
    {
      "epoch": 0.9840499953362559,
      "grad_norm": 3.9680936336517334,
      "learning_rate": 9.422319061939428e-06,
      "loss": 0.5019420623779297,
      "memory(GiB)": 72.72,
      "step": 10550,
      "token_acc": 0.4423076923076923,
      "train_speed(iter/s)": 0.252733
    },
    {
      "epoch": 0.9845163697416286,
      "grad_norm": 4.283494472503662,
      "learning_rate": 9.42159920328977e-06,
      "loss": 0.48810291290283203,
      "memory(GiB)": 72.72,
      "step": 10555,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.252735
    },
    {
      "epoch": 0.9849827441470013,
      "grad_norm": 2.851137161254883,
      "learning_rate": 9.420878923938568e-06,
      "loss": 0.5109333038330078,
      "memory(GiB)": 72.72,
      "step": 10560,
      "train_speed(iter/s)": 0.252733
    },
    {
      "epoch": 0.9854491185523738,
      "grad_norm": 4.058520793914795,
      "learning_rate": 9.420158223954354e-06,
      "loss": 0.4373133182525635,
      "memory(GiB)": 72.72,
      "step": 10565,
      "train_speed(iter/s)": 0.252736
    },
    {
      "epoch": 0.9859154929577465,
      "grad_norm": 3.703721284866333,
      "learning_rate": 9.419437103405704e-06,
      "loss": 0.4681530952453613,
      "memory(GiB)": 72.72,
      "step": 10570,
      "token_acc": 0.5163934426229508,
      "train_speed(iter/s)": 0.252731
    },
    {
      "epoch": 0.9863818673631191,
      "grad_norm": 3.337388753890991,
      "learning_rate": 9.418715562361226e-06,
      "loss": 0.511848258972168,
      "memory(GiB)": 72.72,
      "step": 10575,
      "token_acc": 0.9107142857142857,
      "train_speed(iter/s)": 0.25273
    },
    {
      "epoch": 0.9868482417684917,
      "grad_norm": 4.10490608215332,
      "learning_rate": 9.417993600889575e-06,
      "loss": 0.4667035102844238,
      "memory(GiB)": 72.72,
      "step": 10580,
      "train_speed(iter/s)": 0.252738
    },
    {
      "epoch": 0.9873146161738644,
      "grad_norm": 3.3422789573669434,
      "learning_rate": 9.417271219059443e-06,
      "loss": 0.4771724700927734,
      "memory(GiB)": 72.72,
      "step": 10585,
      "token_acc": 0.4888888888888889,
      "train_speed(iter/s)": 0.252753
    },
    {
      "epoch": 0.987780990579237,
      "grad_norm": 4.9120707511901855,
      "learning_rate": 9.416548416939561e-06,
      "loss": 0.4787265777587891,
      "memory(GiB)": 72.72,
      "step": 10590,
      "train_speed(iter/s)": 0.252753
    },
    {
      "epoch": 0.9882473649846096,
      "grad_norm": 3.6302342414855957,
      "learning_rate": 9.415825194598705e-06,
      "loss": 0.4807268619537354,
      "memory(GiB)": 72.72,
      "step": 10595,
      "token_acc": 0.36538461538461536,
      "train_speed(iter/s)": 0.252756
    },
    {
      "epoch": 0.9887137393899823,
      "grad_norm": 3.748032569885254,
      "learning_rate": 9.415101552105684e-06,
      "loss": 0.4779475212097168,
      "memory(GiB)": 72.72,
      "step": 10600,
      "token_acc": 0.5045045045045045,
      "train_speed(iter/s)": 0.252761
    },
    {
      "epoch": 0.9891801137953549,
      "grad_norm": 3.294567108154297,
      "learning_rate": 9.414377489529352e-06,
      "loss": 0.45647516250610354,
      "memory(GiB)": 72.72,
      "step": 10605,
      "train_speed(iter/s)": 0.252766
    },
    {
      "epoch": 0.9896464882007275,
      "grad_norm": 4.401468753814697,
      "learning_rate": 9.413653006938598e-06,
      "loss": 0.5005618095397949,
      "memory(GiB)": 72.72,
      "step": 10610,
      "train_speed(iter/s)": 0.252777
    },
    {
      "epoch": 0.9901128626061002,
      "grad_norm": 3.48429012298584,
      "learning_rate": 9.41292810440236e-06,
      "loss": 0.49881181716918943,
      "memory(GiB)": 72.72,
      "step": 10615,
      "token_acc": 0.3698630136986301,
      "train_speed(iter/s)": 0.252784
    },
    {
      "epoch": 0.9905792370114728,
      "grad_norm": 4.804433822631836,
      "learning_rate": 9.412202781989606e-06,
      "loss": 0.4974973678588867,
      "memory(GiB)": 72.72,
      "step": 10620,
      "token_acc": 0.5245901639344263,
      "train_speed(iter/s)": 0.252777
    },
    {
      "epoch": 0.9910456114168454,
      "grad_norm": 3.6148934364318848,
      "learning_rate": 9.41147703976935e-06,
      "loss": 0.5293529987335205,
      "memory(GiB)": 72.72,
      "step": 10625,
      "token_acc": 0.5692307692307692,
      "train_speed(iter/s)": 0.25278
    },
    {
      "epoch": 0.9915119858222181,
      "grad_norm": 6.040942192077637,
      "learning_rate": 9.410750877810643e-06,
      "loss": 0.45597333908081056,
      "memory(GiB)": 72.72,
      "step": 10630,
      "train_speed(iter/s)": 0.252782
    },
    {
      "epoch": 0.9919783602275907,
      "grad_norm": 4.662199974060059,
      "learning_rate": 9.410024296182577e-06,
      "loss": 0.5192622184753418,
      "memory(GiB)": 72.72,
      "step": 10635,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.252784
    },
    {
      "epoch": 0.9924447346329633,
      "grad_norm": 3.597123384475708,
      "learning_rate": 9.409297294954286e-06,
      "loss": 0.47737703323364256,
      "memory(GiB)": 72.72,
      "step": 10640,
      "train_speed(iter/s)": 0.252786
    },
    {
      "epoch": 0.992911109038336,
      "grad_norm": 3.7667884826660156,
      "learning_rate": 9.40856987419494e-06,
      "loss": 0.5022273063659668,
      "memory(GiB)": 72.72,
      "step": 10645,
      "token_acc": 0.6285714285714286,
      "train_speed(iter/s)": 0.252788
    },
    {
      "epoch": 0.9933774834437086,
      "grad_norm": 3.6157429218292236,
      "learning_rate": 9.407842033973751e-06,
      "loss": 0.5034950733184814,
      "memory(GiB)": 72.72,
      "step": 10650,
      "token_acc": 0.7445255474452555,
      "train_speed(iter/s)": 0.25279
    },
    {
      "epoch": 0.9938438578490812,
      "grad_norm": 3.0902066230773926,
      "learning_rate": 9.407113774359972e-06,
      "loss": 0.5105122566223145,
      "memory(GiB)": 72.72,
      "step": 10655,
      "token_acc": 0.8691588785046729,
      "train_speed(iter/s)": 0.252796
    },
    {
      "epoch": 0.9943102322544539,
      "grad_norm": 2.4822535514831543,
      "learning_rate": 9.406385095422892e-06,
      "loss": 0.463291072845459,
      "memory(GiB)": 72.72,
      "step": 10660,
      "train_speed(iter/s)": 0.252793
    },
    {
      "epoch": 0.9947766066598265,
      "grad_norm": 4.310408592224121,
      "learning_rate": 9.405655997231846e-06,
      "loss": 0.478117561340332,
      "memory(GiB)": 72.72,
      "step": 10665,
      "train_speed(iter/s)": 0.252797
    },
    {
      "epoch": 0.9952429810651992,
      "grad_norm": 3.7259817123413086,
      "learning_rate": 9.404926479856204e-06,
      "loss": 0.49936480522155763,
      "memory(GiB)": 72.72,
      "step": 10670,
      "token_acc": 0.5370370370370371,
      "train_speed(iter/s)": 0.252801
    },
    {
      "epoch": 0.9957093554705718,
      "grad_norm": 5.165253639221191,
      "learning_rate": 9.404196543365377e-06,
      "loss": 0.47849125862121583,
      "memory(GiB)": 72.72,
      "step": 10675,
      "token_acc": 0.7671232876712328,
      "train_speed(iter/s)": 0.25281
    },
    {
      "epoch": 0.9961757298759444,
      "grad_norm": 5.3889594078063965,
      "learning_rate": 9.403466187828815e-06,
      "loss": 0.5309074401855469,
      "memory(GiB)": 72.72,
      "step": 10680,
      "train_speed(iter/s)": 0.252813
    },
    {
      "epoch": 0.996642104281317,
      "grad_norm": 4.976256370544434,
      "learning_rate": 9.402735413316011e-06,
      "loss": 0.49319067001342776,
      "memory(GiB)": 72.72,
      "step": 10685,
      "token_acc": 0.4358974358974359,
      "train_speed(iter/s)": 0.252814
    },
    {
      "epoch": 0.9971084786866897,
      "grad_norm": 8.829815864562988,
      "learning_rate": 9.402004219896497e-06,
      "loss": 0.45968971252441404,
      "memory(GiB)": 72.72,
      "step": 10690,
      "train_speed(iter/s)": 0.25281
    },
    {
      "epoch": 0.9975748530920623,
      "grad_norm": 5.0426225662231445,
      "learning_rate": 9.401272607639841e-06,
      "loss": 0.509820032119751,
      "memory(GiB)": 72.72,
      "step": 10695,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.252821
    },
    {
      "epoch": 0.998041227497435,
      "grad_norm": 6.264036655426025,
      "learning_rate": 9.400540576615655e-06,
      "loss": 0.4849215030670166,
      "memory(GiB)": 72.72,
      "step": 10700,
      "token_acc": 0.5178571428571429,
      "train_speed(iter/s)": 0.252824
    },
    {
      "epoch": 0.9985076019028076,
      "grad_norm": 2.9209647178649902,
      "learning_rate": 9.399808126893589e-06,
      "loss": 0.5298950672149658,
      "memory(GiB)": 72.72,
      "step": 10705,
      "train_speed(iter/s)": 0.252824
    },
    {
      "epoch": 0.9989739763081802,
      "grad_norm": 3.7690799236297607,
      "learning_rate": 9.399075258543334e-06,
      "loss": 0.48169918060302735,
      "memory(GiB)": 72.72,
      "step": 10710,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.25282
    },
    {
      "epoch": 0.9994403507135529,
      "grad_norm": 4.8981804847717285,
      "learning_rate": 9.39834197163462e-06,
      "loss": 0.46326847076416017,
      "memory(GiB)": 72.72,
      "step": 10715,
      "train_speed(iter/s)": 0.252815
    },
    {
      "epoch": 0.9999067251189254,
      "grad_norm": 3.676269054412842,
      "learning_rate": 9.397608266237217e-06,
      "loss": 0.5163899421691894,
      "memory(GiB)": 72.72,
      "step": 10720,
      "train_speed(iter/s)": 0.25281
    },
    {
      "epoch": 1.000373099524298,
      "grad_norm": 3.9815728664398193,
      "learning_rate": 9.396874142420933e-06,
      "loss": 0.4703394889831543,
      "memory(GiB)": 72.72,
      "step": 10725,
      "train_speed(iter/s)": 0.252677
    },
    {
      "epoch": 1.0008394739296707,
      "grad_norm": 3.4181926250457764,
      "learning_rate": 9.39613960025562e-06,
      "loss": 0.4484079360961914,
      "memory(GiB)": 72.72,
      "step": 10730,
      "token_acc": 0.9361702127659575,
      "train_speed(iter/s)": 0.252671
    },
    {
      "epoch": 1.0013058483350434,
      "grad_norm": 4.7470784187316895,
      "learning_rate": 9.395404639811167e-06,
      "loss": 0.48819780349731445,
      "memory(GiB)": 72.72,
      "step": 10735,
      "train_speed(iter/s)": 0.25267
    },
    {
      "epoch": 1.001772222740416,
      "grad_norm": 4.662201404571533,
      "learning_rate": 9.394669261157503e-06,
      "loss": 0.49915733337402346,
      "memory(GiB)": 72.72,
      "step": 10740,
      "train_speed(iter/s)": 0.252671
    },
    {
      "epoch": 1.0022385971457886,
      "grad_norm": 6.537106990814209,
      "learning_rate": 9.393933464364597e-06,
      "loss": 0.5247767448425293,
      "memory(GiB)": 72.72,
      "step": 10745,
      "train_speed(iter/s)": 0.252666
    },
    {
      "epoch": 1.0027049715511613,
      "grad_norm": 7.34660005569458,
      "learning_rate": 9.393197249502459e-06,
      "loss": 0.452738618850708,
      "memory(GiB)": 72.72,
      "step": 10750,
      "token_acc": 0.9404761904761905,
      "train_speed(iter/s)": 0.25266
    },
    {
      "epoch": 1.003171345956534,
      "grad_norm": 6.283707618713379,
      "learning_rate": 9.392460616641135e-06,
      "loss": 0.47826695442199707,
      "memory(GiB)": 72.72,
      "step": 10755,
      "train_speed(iter/s)": 0.252657
    },
    {
      "epoch": 1.0036377203619065,
      "grad_norm": 6.741560935974121,
      "learning_rate": 9.391723565850714e-06,
      "loss": 0.46450958251953123,
      "memory(GiB)": 72.72,
      "step": 10760,
      "train_speed(iter/s)": 0.252656
    },
    {
      "epoch": 1.0041040947672792,
      "grad_norm": 8.881372451782227,
      "learning_rate": 9.390986097201326e-06,
      "loss": 0.5213593482971192,
      "memory(GiB)": 72.72,
      "step": 10765,
      "train_speed(iter/s)": 0.252651
    },
    {
      "epoch": 1.0045704691726518,
      "grad_norm": 3.511488914489746,
      "learning_rate": 9.390248210763136e-06,
      "loss": 0.5394691944122314,
      "memory(GiB)": 72.72,
      "step": 10770,
      "token_acc": 0.43548387096774194,
      "train_speed(iter/s)": 0.252649
    },
    {
      "epoch": 1.0050368435780244,
      "grad_norm": 3.15669846534729,
      "learning_rate": 9.389509906606355e-06,
      "loss": 0.5433249950408936,
      "memory(GiB)": 72.72,
      "step": 10775,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.252644
    },
    {
      "epoch": 1.0055032179833971,
      "grad_norm": 3.047823667526245,
      "learning_rate": 9.388771184801228e-06,
      "loss": 0.48357839584350587,
      "memory(GiB)": 72.72,
      "step": 10780,
      "token_acc": 0.47619047619047616,
      "train_speed(iter/s)": 0.252652
    },
    {
      "epoch": 1.0059695923887697,
      "grad_norm": 3.2147347927093506,
      "learning_rate": 9.388032045418042e-06,
      "loss": 0.4951133728027344,
      "memory(GiB)": 72.72,
      "step": 10785,
      "train_speed(iter/s)": 0.252651
    },
    {
      "epoch": 1.0064359667941423,
      "grad_norm": 4.905163288116455,
      "learning_rate": 9.387292488527124e-06,
      "loss": 0.5113409519195556,
      "memory(GiB)": 72.72,
      "step": 10790,
      "token_acc": 0.2641509433962264,
      "train_speed(iter/s)": 0.252645
    },
    {
      "epoch": 1.006902341199515,
      "grad_norm": 3.778041362762451,
      "learning_rate": 9.386552514198843e-06,
      "loss": 0.4697913646697998,
      "memory(GiB)": 72.72,
      "step": 10795,
      "token_acc": 0.8529411764705882,
      "train_speed(iter/s)": 0.252649
    },
    {
      "epoch": 1.0073687156048876,
      "grad_norm": 3.5446360111236572,
      "learning_rate": 9.385812122503602e-06,
      "loss": 0.479032039642334,
      "memory(GiB)": 72.72,
      "step": 10800,
      "train_speed(iter/s)": 0.252653
    },
    {
      "epoch": 1.0078350900102602,
      "grad_norm": 4.243770122528076,
      "learning_rate": 9.385071313511849e-06,
      "loss": 0.4892555236816406,
      "memory(GiB)": 72.72,
      "step": 10805,
      "train_speed(iter/s)": 0.252655
    },
    {
      "epoch": 1.008301464415633,
      "grad_norm": 3.607954740524292,
      "learning_rate": 9.384330087294068e-06,
      "loss": 0.4685223579406738,
      "memory(GiB)": 72.72,
      "step": 10810,
      "train_speed(iter/s)": 0.252656
    },
    {
      "epoch": 1.0087678388210055,
      "grad_norm": 18.23710060119629,
      "learning_rate": 9.383588443920787e-06,
      "loss": 0.47893190383911133,
      "memory(GiB)": 72.72,
      "step": 10815,
      "train_speed(iter/s)": 0.252662
    },
    {
      "epoch": 1.009234213226378,
      "grad_norm": 4.870079040527344,
      "learning_rate": 9.38284638346257e-06,
      "loss": 0.5082334518432617,
      "memory(GiB)": 72.72,
      "step": 10820,
      "token_acc": 0.68,
      "train_speed(iter/s)": 0.252662
    },
    {
      "epoch": 1.0097005876317509,
      "grad_norm": 3.377293586730957,
      "learning_rate": 9.38210390599002e-06,
      "loss": 0.5154808521270752,
      "memory(GiB)": 72.72,
      "step": 10825,
      "train_speed(iter/s)": 0.252656
    },
    {
      "epoch": 1.0101669620371234,
      "grad_norm": 6.060185432434082,
      "learning_rate": 9.381361011573783e-06,
      "loss": 0.5324771881103516,
      "memory(GiB)": 72.72,
      "step": 10830,
      "train_speed(iter/s)": 0.252652
    },
    {
      "epoch": 1.010633336442496,
      "grad_norm": 5.248744964599609,
      "learning_rate": 9.380617700284543e-06,
      "loss": 0.4713465213775635,
      "memory(GiB)": 72.72,
      "step": 10835,
      "train_speed(iter/s)": 0.252651
    },
    {
      "epoch": 1.0110997108478688,
      "grad_norm": 4.65245246887207,
      "learning_rate": 9.379873972193023e-06,
      "loss": 0.5089298248291015,
      "memory(GiB)": 72.72,
      "step": 10840,
      "train_speed(iter/s)": 0.252653
    },
    {
      "epoch": 1.0115660852532413,
      "grad_norm": 4.445253372192383,
      "learning_rate": 9.379129827369988e-06,
      "loss": 0.4937159061431885,
      "memory(GiB)": 72.72,
      "step": 10845,
      "token_acc": 0.65,
      "train_speed(iter/s)": 0.252656
    },
    {
      "epoch": 1.0120324596586139,
      "grad_norm": 6.020232677459717,
      "learning_rate": 9.378385265886241e-06,
      "loss": 0.507308053970337,
      "memory(GiB)": 72.72,
      "step": 10850,
      "train_speed(iter/s)": 0.252658
    },
    {
      "epoch": 1.0124988340639867,
      "grad_norm": 5.080036163330078,
      "learning_rate": 9.377640287812621e-06,
      "loss": 0.4728262424468994,
      "memory(GiB)": 72.72,
      "step": 10855,
      "train_speed(iter/s)": 0.252659
    },
    {
      "epoch": 1.0129652084693592,
      "grad_norm": 3.9980123043060303,
      "learning_rate": 9.376894893220016e-06,
      "loss": 0.5105472564697265,
      "memory(GiB)": 72.72,
      "step": 10860,
      "train_speed(iter/s)": 0.252666
    },
    {
      "epoch": 1.0134315828747318,
      "grad_norm": 5.31500768661499,
      "learning_rate": 9.376149082179344e-06,
      "loss": 0.5022428512573243,
      "memory(GiB)": 72.72,
      "step": 10865,
      "train_speed(iter/s)": 0.252662
    },
    {
      "epoch": 1.0138979572801046,
      "grad_norm": 5.872913837432861,
      "learning_rate": 9.375402854761568e-06,
      "loss": 0.4647200584411621,
      "memory(GiB)": 72.72,
      "step": 10870,
      "train_speed(iter/s)": 0.252664
    },
    {
      "epoch": 1.0143643316854771,
      "grad_norm": 5.805971145629883,
      "learning_rate": 9.37465621103769e-06,
      "loss": 0.5051013469696045,
      "memory(GiB)": 72.72,
      "step": 10875,
      "token_acc": 0.5057471264367817,
      "train_speed(iter/s)": 0.252667
    },
    {
      "epoch": 1.0148307060908497,
      "grad_norm": 6.3819451332092285,
      "learning_rate": 9.373909151078748e-06,
      "loss": 0.5288155555725098,
      "memory(GiB)": 72.72,
      "step": 10880,
      "train_speed(iter/s)": 0.252667
    },
    {
      "epoch": 1.0152970804962225,
      "grad_norm": 3.983611583709717,
      "learning_rate": 9.373161674955826e-06,
      "loss": 0.4762401103973389,
      "memory(GiB)": 72.72,
      "step": 10885,
      "token_acc": 0.3333333333333333,
      "train_speed(iter/s)": 0.252666
    },
    {
      "epoch": 1.015763454901595,
      "grad_norm": 4.459420204162598,
      "learning_rate": 9.372413782740042e-06,
      "loss": 0.47367262840270996,
      "memory(GiB)": 72.72,
      "step": 10890,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.252671
    },
    {
      "epoch": 1.0162298293069676,
      "grad_norm": 3.551522731781006,
      "learning_rate": 9.371665474502556e-06,
      "loss": 0.4484713077545166,
      "memory(GiB)": 72.72,
      "step": 10895,
      "token_acc": 0.9484536082474226,
      "train_speed(iter/s)": 0.252676
    },
    {
      "epoch": 1.0166962037123404,
      "grad_norm": 4.347694396972656,
      "learning_rate": 9.370916750314567e-06,
      "loss": 0.4524775505065918,
      "memory(GiB)": 72.72,
      "step": 10900,
      "train_speed(iter/s)": 0.252677
    },
    {
      "epoch": 1.017162578117713,
      "grad_norm": 2.9782731533050537,
      "learning_rate": 9.370167610247316e-06,
      "loss": 0.4818459987640381,
      "memory(GiB)": 72.72,
      "step": 10905,
      "train_speed(iter/s)": 0.252686
    },
    {
      "epoch": 1.0176289525230855,
      "grad_norm": 4.9776177406311035,
      "learning_rate": 9.369418054372078e-06,
      "loss": 0.44496593475341795,
      "memory(GiB)": 72.72,
      "step": 10910,
      "train_speed(iter/s)": 0.252687
    },
    {
      "epoch": 1.0180953269284583,
      "grad_norm": 3.9743385314941406,
      "learning_rate": 9.368668082760172e-06,
      "loss": 0.4816006660461426,
      "memory(GiB)": 72.72,
      "step": 10915,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.252687
    },
    {
      "epoch": 1.0185617013338308,
      "grad_norm": 5.4635820388793945,
      "learning_rate": 9.367917695482958e-06,
      "loss": 0.48605990409851074,
      "memory(GiB)": 72.72,
      "step": 10920,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.252692
    },
    {
      "epoch": 1.0190280757392034,
      "grad_norm": 7.571970462799072,
      "learning_rate": 9.367166892611828e-06,
      "loss": 0.49187483787536623,
      "memory(GiB)": 72.72,
      "step": 10925,
      "token_acc": 0.5076923076923077,
      "train_speed(iter/s)": 0.252562
    },
    {
      "epoch": 1.019494450144576,
      "grad_norm": 4.178193092346191,
      "learning_rate": 9.366415674218222e-06,
      "loss": 0.5106652259826661,
      "memory(GiB)": 72.72,
      "step": 10930,
      "token_acc": 0.46987951807228917,
      "train_speed(iter/s)": 0.25255
    },
    {
      "epoch": 1.0199608245499487,
      "grad_norm": 3.36783766746521,
      "learning_rate": 9.36566404037362e-06,
      "loss": 0.5444244384765625,
      "memory(GiB)": 72.72,
      "step": 10935,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.252552
    },
    {
      "epoch": 1.0204271989553213,
      "grad_norm": 3.0067291259765625,
      "learning_rate": 9.364911991149529e-06,
      "loss": 0.4700972080230713,
      "memory(GiB)": 72.72,
      "step": 10940,
      "token_acc": 0.5178571428571429,
      "train_speed(iter/s)": 0.252552
    },
    {
      "epoch": 1.0208935733606939,
      "grad_norm": 2.984827756881714,
      "learning_rate": 9.364159526617509e-06,
      "loss": 0.5183888912200928,
      "memory(GiB)": 72.72,
      "step": 10945,
      "token_acc": 0.8648648648648649,
      "train_speed(iter/s)": 0.252552
    },
    {
      "epoch": 1.0213599477660666,
      "grad_norm": 4.214197635650635,
      "learning_rate": 9.363406646849155e-06,
      "loss": 0.5462267875671387,
      "memory(GiB)": 72.72,
      "step": 10950,
      "token_acc": 0.872093023255814,
      "train_speed(iter/s)": 0.252545
    },
    {
      "epoch": 1.0218263221714392,
      "grad_norm": 4.219388008117676,
      "learning_rate": 9.3626533519161e-06,
      "loss": 0.4726101398468018,
      "memory(GiB)": 72.72,
      "step": 10955,
      "train_speed(iter/s)": 0.252544
    },
    {
      "epoch": 1.0222926965768118,
      "grad_norm": 4.321829319000244,
      "learning_rate": 9.361899641890019e-06,
      "loss": 0.5001177310943603,
      "memory(GiB)": 72.72,
      "step": 10960,
      "token_acc": 0.7843137254901961,
      "train_speed(iter/s)": 0.252542
    },
    {
      "epoch": 1.0227590709821845,
      "grad_norm": 3.8250629901885986,
      "learning_rate": 9.361145516842624e-06,
      "loss": 0.4643280506134033,
      "memory(GiB)": 72.72,
      "step": 10965,
      "token_acc": 0.6976744186046512,
      "train_speed(iter/s)": 0.252542
    },
    {
      "epoch": 1.023225445387557,
      "grad_norm": 3.5856006145477295,
      "learning_rate": 9.360390976845666e-06,
      "loss": 0.5003537178039551,
      "memory(GiB)": 72.72,
      "step": 10970,
      "train_speed(iter/s)": 0.252546
    },
    {
      "epoch": 1.0236918197929297,
      "grad_norm": 8.419742584228516,
      "learning_rate": 9.359636021970941e-06,
      "loss": 0.48595490455627444,
      "memory(GiB)": 72.72,
      "step": 10975,
      "token_acc": 0.3392857142857143,
      "train_speed(iter/s)": 0.252554
    },
    {
      "epoch": 1.0241581941983025,
      "grad_norm": 7.182618618011475,
      "learning_rate": 9.358880652290279e-06,
      "loss": 0.4681715488433838,
      "memory(GiB)": 72.72,
      "step": 10980,
      "train_speed(iter/s)": 0.252564
    },
    {
      "epoch": 1.024624568603675,
      "grad_norm": 3.0538315773010254,
      "learning_rate": 9.358124867875548e-06,
      "loss": 0.4856096267700195,
      "memory(GiB)": 72.72,
      "step": 10985,
      "token_acc": 0.8114754098360656,
      "train_speed(iter/s)": 0.252567
    },
    {
      "epoch": 1.0250909430090476,
      "grad_norm": 6.01450777053833,
      "learning_rate": 9.357368668798665e-06,
      "loss": 0.4768360137939453,
      "memory(GiB)": 72.72,
      "step": 10990,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.252561
    },
    {
      "epoch": 1.0255573174144204,
      "grad_norm": 6.352632522583008,
      "learning_rate": 9.356612055131574e-06,
      "loss": 0.5118564605712891,
      "memory(GiB)": 72.72,
      "step": 10995,
      "train_speed(iter/s)": 0.25257
    },
    {
      "epoch": 1.026023691819793,
      "grad_norm": 8.526544570922852,
      "learning_rate": 9.355855026946268e-06,
      "loss": 0.520053482055664,
      "memory(GiB)": 72.72,
      "step": 11000,
      "train_speed(iter/s)": 0.252571
    },
    {
      "epoch": 1.0264900662251655,
      "grad_norm": 3.5692636966705322,
      "learning_rate": 9.355097584314774e-06,
      "loss": 0.4537664890289307,
      "memory(GiB)": 72.72,
      "step": 11005,
      "train_speed(iter/s)": 0.252568
    },
    {
      "epoch": 1.0269564406305383,
      "grad_norm": 4.225433826446533,
      "learning_rate": 9.354339727309161e-06,
      "loss": 0.48136272430419924,
      "memory(GiB)": 72.72,
      "step": 11010,
      "token_acc": 0.922077922077922,
      "train_speed(iter/s)": 0.252569
    },
    {
      "epoch": 1.0274228150359108,
      "grad_norm": 4.6098551750183105,
      "learning_rate": 9.353581456001537e-06,
      "loss": 0.4867703914642334,
      "memory(GiB)": 72.72,
      "step": 11015,
      "train_speed(iter/s)": 0.252564
    },
    {
      "epoch": 1.0278891894412834,
      "grad_norm": 4.20515775680542,
      "learning_rate": 9.35282277046405e-06,
      "loss": 0.47055587768554685,
      "memory(GiB)": 72.72,
      "step": 11020,
      "token_acc": 0.88,
      "train_speed(iter/s)": 0.252566
    },
    {
      "epoch": 1.0283555638466562,
      "grad_norm": 4.937305450439453,
      "learning_rate": 9.352063670768884e-06,
      "loss": 0.4672818183898926,
      "memory(GiB)": 72.72,
      "step": 11025,
      "train_speed(iter/s)": 0.252558
    },
    {
      "epoch": 1.0288219382520287,
      "grad_norm": 7.091905117034912,
      "learning_rate": 9.351304156988267e-06,
      "loss": 0.5314371585845947,
      "memory(GiB)": 72.72,
      "step": 11030,
      "train_speed(iter/s)": 0.252561
    },
    {
      "epoch": 1.0292883126574013,
      "grad_norm": 5.502107620239258,
      "learning_rate": 9.350544229194464e-06,
      "loss": 0.48201909065246584,
      "memory(GiB)": 72.72,
      "step": 11035,
      "token_acc": 0.4339622641509434,
      "train_speed(iter/s)": 0.252566
    },
    {
      "epoch": 1.029754687062774,
      "grad_norm": 3.931755304336548,
      "learning_rate": 9.34978388745978e-06,
      "loss": 0.5099156379699707,
      "memory(GiB)": 72.72,
      "step": 11040,
      "train_speed(iter/s)": 0.252565
    },
    {
      "epoch": 1.0302210614681466,
      "grad_norm": 3.8748738765716553,
      "learning_rate": 9.349023131856561e-06,
      "loss": 0.47303047180175783,
      "memory(GiB)": 72.72,
      "step": 11045,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.252562
    },
    {
      "epoch": 1.0306874358735192,
      "grad_norm": 3.4689924716949463,
      "learning_rate": 9.348261962457185e-06,
      "loss": 0.4893978118896484,
      "memory(GiB)": 72.72,
      "step": 11050,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252566
    },
    {
      "epoch": 1.031153810278892,
      "grad_norm": 4.473036289215088,
      "learning_rate": 9.34750037933408e-06,
      "loss": 0.49015369415283205,
      "memory(GiB)": 72.72,
      "step": 11055,
      "token_acc": 0.5434782608695652,
      "train_speed(iter/s)": 0.252568
    },
    {
      "epoch": 1.0316201846842645,
      "grad_norm": 21.579233169555664,
      "learning_rate": 9.346738382559709e-06,
      "loss": 0.5021422386169434,
      "memory(GiB)": 72.72,
      "step": 11060,
      "token_acc": 0.9058823529411765,
      "train_speed(iter/s)": 0.252571
    },
    {
      "epoch": 1.032086559089637,
      "grad_norm": 6.679362773895264,
      "learning_rate": 9.345975972206566e-06,
      "loss": 0.523685073852539,
      "memory(GiB)": 72.72,
      "step": 11065,
      "token_acc": 0.9532710280373832,
      "train_speed(iter/s)": 0.25257
    },
    {
      "epoch": 1.0325529334950099,
      "grad_norm": 5.9799652099609375,
      "learning_rate": 9.345213148347201e-06,
      "loss": 0.5097801208496093,
      "memory(GiB)": 72.72,
      "step": 11070,
      "token_acc": 0.9298245614035088,
      "train_speed(iter/s)": 0.252569
    },
    {
      "epoch": 1.0330193079003824,
      "grad_norm": 3.396679401397705,
      "learning_rate": 9.344449911054192e-06,
      "loss": 0.5051643371582031,
      "memory(GiB)": 72.72,
      "step": 11075,
      "token_acc": 0.45217391304347826,
      "train_speed(iter/s)": 0.252564
    },
    {
      "epoch": 1.033485682305755,
      "grad_norm": 3.8667750358581543,
      "learning_rate": 9.343686260400154e-06,
      "loss": 0.510794734954834,
      "memory(GiB)": 72.72,
      "step": 11080,
      "token_acc": 0.5113636363636364,
      "train_speed(iter/s)": 0.252561
    },
    {
      "epoch": 1.0339520567111278,
      "grad_norm": 5.216953277587891,
      "learning_rate": 9.34292219645775e-06,
      "loss": 0.49587211608886717,
      "memory(GiB)": 72.72,
      "step": 11085,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.252557
    },
    {
      "epoch": 1.0344184311165003,
      "grad_norm": 5.789780616760254,
      "learning_rate": 9.34215771929968e-06,
      "loss": 0.49991436004638673,
      "memory(GiB)": 72.72,
      "step": 11090,
      "token_acc": 0.9252336448598131,
      "train_speed(iter/s)": 0.25255
    },
    {
      "epoch": 1.034884805521873,
      "grad_norm": 4.769079685211182,
      "learning_rate": 9.341392828998677e-06,
      "loss": 0.5044514179229737,
      "memory(GiB)": 72.72,
      "step": 11095,
      "train_speed(iter/s)": 0.252549
    },
    {
      "epoch": 1.0353511799272457,
      "grad_norm": 4.694522857666016,
      "learning_rate": 9.34062752562752e-06,
      "loss": 0.47875585556030276,
      "memory(GiB)": 72.72,
      "step": 11100,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.252561
    },
    {
      "epoch": 1.0358175543326182,
      "grad_norm": 3.933591365814209,
      "learning_rate": 9.339861809259027e-06,
      "loss": 0.4909862995147705,
      "memory(GiB)": 72.72,
      "step": 11105,
      "token_acc": 0.5166666666666667,
      "train_speed(iter/s)": 0.252559
    },
    {
      "epoch": 1.0362839287379908,
      "grad_norm": 3.297804355621338,
      "learning_rate": 9.339095679966052e-06,
      "loss": 0.4783347129821777,
      "memory(GiB)": 72.72,
      "step": 11110,
      "train_speed(iter/s)": 0.252562
    },
    {
      "epoch": 1.0367503031433636,
      "grad_norm": 3.619157314300537,
      "learning_rate": 9.33832913782149e-06,
      "loss": 0.4604511260986328,
      "memory(GiB)": 72.72,
      "step": 11115,
      "token_acc": 0.5338983050847458,
      "train_speed(iter/s)": 0.252567
    },
    {
      "epoch": 1.0372166775487361,
      "grad_norm": 2.7237889766693115,
      "learning_rate": 9.337562182898277e-06,
      "loss": 0.45734472274780275,
      "memory(GiB)": 72.72,
      "step": 11120,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.252567
    },
    {
      "epoch": 1.0376830519541087,
      "grad_norm": 3.143442392349243,
      "learning_rate": 9.336794815269382e-06,
      "loss": 0.45818190574645995,
      "memory(GiB)": 72.72,
      "step": 11125,
      "train_speed(iter/s)": 0.252565
    },
    {
      "epoch": 1.0381494263594815,
      "grad_norm": 3.4578497409820557,
      "learning_rate": 9.33602703500782e-06,
      "loss": 0.5308080673217773,
      "memory(GiB)": 72.72,
      "step": 11130,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.252566
    },
    {
      "epoch": 1.038615800764854,
      "grad_norm": 3.4573330879211426,
      "learning_rate": 9.335258842186643e-06,
      "loss": 0.48825826644897463,
      "memory(GiB)": 72.72,
      "step": 11135,
      "token_acc": 0.4520547945205479,
      "train_speed(iter/s)": 0.252563
    },
    {
      "epoch": 1.0390821751702266,
      "grad_norm": 2.765559196472168,
      "learning_rate": 9.334490236878943e-06,
      "loss": 0.447042179107666,
      "memory(GiB)": 72.72,
      "step": 11140,
      "train_speed(iter/s)": 0.252561
    },
    {
      "epoch": 1.0395485495755994,
      "grad_norm": 3.1411187648773193,
      "learning_rate": 9.33372121915785e-06,
      "loss": 0.4806227684020996,
      "memory(GiB)": 72.72,
      "step": 11145,
      "train_speed(iter/s)": 0.252559
    },
    {
      "epoch": 1.040014923980972,
      "grad_norm": 6.094019412994385,
      "learning_rate": 9.332951789096534e-06,
      "loss": 0.487135124206543,
      "memory(GiB)": 72.72,
      "step": 11150,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.252556
    },
    {
      "epoch": 1.0404812983863445,
      "grad_norm": 3.3775768280029297,
      "learning_rate": 9.332181946768202e-06,
      "loss": 0.48369760513305665,
      "memory(GiB)": 72.72,
      "step": 11155,
      "token_acc": 0.41025641025641024,
      "train_speed(iter/s)": 0.252552
    },
    {
      "epoch": 1.0409476727917173,
      "grad_norm": 7.167657375335693,
      "learning_rate": 9.331411692246103e-06,
      "loss": 0.5178029537200928,
      "memory(GiB)": 72.72,
      "step": 11160,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.252548
    },
    {
      "epoch": 1.0414140471970899,
      "grad_norm": 3.5459580421447754,
      "learning_rate": 9.330641025603525e-06,
      "loss": 0.5369659423828125,
      "memory(GiB)": 72.72,
      "step": 11165,
      "train_speed(iter/s)": 0.252546
    },
    {
      "epoch": 1.0418804216024624,
      "grad_norm": 3.1493141651153564,
      "learning_rate": 9.329869946913794e-06,
      "loss": 0.46663198471069334,
      "memory(GiB)": 72.72,
      "step": 11170,
      "token_acc": 0.6041666666666666,
      "train_speed(iter/s)": 0.252556
    },
    {
      "epoch": 1.0423467960078352,
      "grad_norm": 4.775846004486084,
      "learning_rate": 9.329098456250278e-06,
      "loss": 0.5414365768432617,
      "memory(GiB)": 72.72,
      "step": 11175,
      "token_acc": 0.34,
      "train_speed(iter/s)": 0.252555
    },
    {
      "epoch": 1.0428131704132078,
      "grad_norm": 4.9297194480896,
      "learning_rate": 9.328326553686377e-06,
      "loss": 0.5137839794158936,
      "memory(GiB)": 72.72,
      "step": 11180,
      "train_speed(iter/s)": 0.25256
    },
    {
      "epoch": 1.0432795448185803,
      "grad_norm": 6.153144359588623,
      "learning_rate": 9.327554239295542e-06,
      "loss": 0.5059664249420166,
      "memory(GiB)": 72.72,
      "step": 11185,
      "train_speed(iter/s)": 0.2524
    },
    {
      "epoch": 1.0437459192239529,
      "grad_norm": 4.506737232208252,
      "learning_rate": 9.32678151315125e-06,
      "loss": 0.48706827163696287,
      "memory(GiB)": 72.72,
      "step": 11190,
      "train_speed(iter/s)": 0.25239
    },
    {
      "epoch": 1.0442122936293257,
      "grad_norm": 3.9719951152801514,
      "learning_rate": 9.326008375327026e-06,
      "loss": 0.4317026615142822,
      "memory(GiB)": 72.72,
      "step": 11195,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.252391
    },
    {
      "epoch": 1.0446786680346982,
      "grad_norm": 4.594274044036865,
      "learning_rate": 9.325234825896432e-06,
      "loss": 0.48436698913574217,
      "memory(GiB)": 72.72,
      "step": 11200,
      "train_speed(iter/s)": 0.25239
    },
    {
      "epoch": 1.0451450424400708,
      "grad_norm": 4.754172325134277,
      "learning_rate": 9.324460864933068e-06,
      "loss": 0.4588508605957031,
      "memory(GiB)": 72.72,
      "step": 11205,
      "train_speed(iter/s)": 0.252381
    },
    {
      "epoch": 1.0456114168454436,
      "grad_norm": 7.4166669845581055,
      "learning_rate": 9.323686492510575e-06,
      "loss": 0.4891303062438965,
      "memory(GiB)": 72.72,
      "step": 11210,
      "train_speed(iter/s)": 0.252386
    },
    {
      "epoch": 1.0460777912508161,
      "grad_norm": 5.147338390350342,
      "learning_rate": 9.322911708702631e-06,
      "loss": 0.5126540660858154,
      "memory(GiB)": 72.72,
      "step": 11215,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.252381
    },
    {
      "epoch": 1.0465441656561887,
      "grad_norm": 4.049158096313477,
      "learning_rate": 9.322136513582956e-06,
      "loss": 0.48093400001525877,
      "memory(GiB)": 72.72,
      "step": 11220,
      "token_acc": 0.5666666666666667,
      "train_speed(iter/s)": 0.252377
    },
    {
      "epoch": 1.0470105400615615,
      "grad_norm": 5.569662094116211,
      "learning_rate": 9.321360907225308e-06,
      "loss": 0.4943559646606445,
      "memory(GiB)": 72.72,
      "step": 11225,
      "token_acc": 0.6129032258064516,
      "train_speed(iter/s)": 0.252376
    },
    {
      "epoch": 1.047476914466934,
      "grad_norm": 4.384220600128174,
      "learning_rate": 9.320584889703479e-06,
      "loss": 0.4747594356536865,
      "memory(GiB)": 72.72,
      "step": 11230,
      "train_speed(iter/s)": 0.252376
    },
    {
      "epoch": 1.0479432888723066,
      "grad_norm": 3.061927318572998,
      "learning_rate": 9.319808461091308e-06,
      "loss": 0.4715325355529785,
      "memory(GiB)": 72.72,
      "step": 11235,
      "train_speed(iter/s)": 0.252376
    },
    {
      "epoch": 1.0484096632776794,
      "grad_norm": 3.5651776790618896,
      "learning_rate": 9.319031621462671e-06,
      "loss": 0.4675463676452637,
      "memory(GiB)": 72.72,
      "step": 11240,
      "train_speed(iter/s)": 0.252378
    },
    {
      "epoch": 1.048876037683052,
      "grad_norm": 4.041360378265381,
      "learning_rate": 9.31825437089148e-06,
      "loss": 0.5239046573638916,
      "memory(GiB)": 72.72,
      "step": 11245,
      "token_acc": 0.9058823529411765,
      "train_speed(iter/s)": 0.252376
    },
    {
      "epoch": 1.0493424120884245,
      "grad_norm": 5.5279011726379395,
      "learning_rate": 9.317476709451687e-06,
      "loss": 0.4785356044769287,
      "memory(GiB)": 72.72,
      "step": 11250,
      "train_speed(iter/s)": 0.252376
    },
    {
      "epoch": 1.0498087864937973,
      "grad_norm": 3.5864226818084717,
      "learning_rate": 9.316698637217287e-06,
      "loss": 0.5047550201416016,
      "memory(GiB)": 72.72,
      "step": 11255,
      "train_speed(iter/s)": 0.252377
    },
    {
      "epoch": 1.0502751608991698,
      "grad_norm": 2.7455461025238037,
      "learning_rate": 9.315920154262308e-06,
      "loss": 0.4666720390319824,
      "memory(GiB)": 72.72,
      "step": 11260,
      "token_acc": 0.34615384615384615,
      "train_speed(iter/s)": 0.252371
    },
    {
      "epoch": 1.0507415353045424,
      "grad_norm": 5.305250644683838,
      "learning_rate": 9.315141260660822e-06,
      "loss": 0.47878365516662597,
      "memory(GiB)": 72.72,
      "step": 11265,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.25237
    },
    {
      "epoch": 1.0512079097099152,
      "grad_norm": 3.3845345973968506,
      "learning_rate": 9.31436195648694e-06,
      "loss": 0.43676185607910156,
      "memory(GiB)": 72.72,
      "step": 11270,
      "token_acc": 0.4594594594594595,
      "train_speed(iter/s)": 0.252373
    },
    {
      "epoch": 1.0516742841152877,
      "grad_norm": 13.50632095336914,
      "learning_rate": 9.313582241814807e-06,
      "loss": 0.4450520515441895,
      "memory(GiB)": 72.72,
      "step": 11275,
      "train_speed(iter/s)": 0.25237
    },
    {
      "epoch": 1.0521406585206603,
      "grad_norm": 6.147711277008057,
      "learning_rate": 9.312802116718613e-06,
      "loss": 0.4782132148742676,
      "memory(GiB)": 72.72,
      "step": 11280,
      "token_acc": 0.9120879120879121,
      "train_speed(iter/s)": 0.252364
    },
    {
      "epoch": 1.052607032926033,
      "grad_norm": 3.5255324840545654,
      "learning_rate": 9.312021581272583e-06,
      "loss": 0.46793208122253416,
      "memory(GiB)": 72.72,
      "step": 11285,
      "train_speed(iter/s)": 0.252353
    },
    {
      "epoch": 1.0530734073314056,
      "grad_norm": 3.4041030406951904,
      "learning_rate": 9.311240635550981e-06,
      "loss": 0.4494914531707764,
      "memory(GiB)": 72.72,
      "step": 11290,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.252354
    },
    {
      "epoch": 1.0535397817367782,
      "grad_norm": 3.886347532272339,
      "learning_rate": 9.310459279628117e-06,
      "loss": 0.49600634574890134,
      "memory(GiB)": 72.72,
      "step": 11295,
      "train_speed(iter/s)": 0.252352
    },
    {
      "epoch": 1.054006156142151,
      "grad_norm": 4.737429618835449,
      "learning_rate": 9.30967751357833e-06,
      "loss": 0.5011245727539062,
      "memory(GiB)": 72.72,
      "step": 11300,
      "train_speed(iter/s)": 0.252354
    },
    {
      "epoch": 1.0544725305475235,
      "grad_norm": 17.6368408203125,
      "learning_rate": 9.308895337476003e-06,
      "loss": 0.4748247146606445,
      "memory(GiB)": 72.72,
      "step": 11305,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.252347
    },
    {
      "epoch": 1.054938904952896,
      "grad_norm": 3.324636220932007,
      "learning_rate": 9.30811275139556e-06,
      "loss": 0.4755234718322754,
      "memory(GiB)": 72.72,
      "step": 11310,
      "train_speed(iter/s)": 0.252344
    },
    {
      "epoch": 1.0554052793582689,
      "grad_norm": 11.492521286010742,
      "learning_rate": 9.307329755411458e-06,
      "loss": 0.4982153415679932,
      "memory(GiB)": 72.72,
      "step": 11315,
      "train_speed(iter/s)": 0.252356
    },
    {
      "epoch": 1.0558716537636414,
      "grad_norm": 4.4892048835754395,
      "learning_rate": 9.3065463495982e-06,
      "loss": 0.49242663383483887,
      "memory(GiB)": 72.72,
      "step": 11320,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.252353
    },
    {
      "epoch": 1.056338028169014,
      "grad_norm": 3.2955739498138428,
      "learning_rate": 9.305762534030325e-06,
      "loss": 0.5419334411621094,
      "memory(GiB)": 72.72,
      "step": 11325,
      "token_acc": 0.851063829787234,
      "train_speed(iter/s)": 0.25236
    },
    {
      "epoch": 1.0568044025743868,
      "grad_norm": 4.095477104187012,
      "learning_rate": 9.304978308782406e-06,
      "loss": 0.5268814563751221,
      "memory(GiB)": 72.72,
      "step": 11330,
      "token_acc": 0.5698924731182796,
      "train_speed(iter/s)": 0.252363
    },
    {
      "epoch": 1.0572707769797594,
      "grad_norm": 3.0515966415405273,
      "learning_rate": 9.304193673929065e-06,
      "loss": 0.47408666610717776,
      "memory(GiB)": 72.72,
      "step": 11335,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.252368
    },
    {
      "epoch": 1.057737151385132,
      "grad_norm": 5.501046180725098,
      "learning_rate": 9.303408629544956e-06,
      "loss": 0.4669026374816895,
      "memory(GiB)": 72.72,
      "step": 11340,
      "train_speed(iter/s)": 0.25237
    },
    {
      "epoch": 1.0582035257905047,
      "grad_norm": 4.543590545654297,
      "learning_rate": 9.302623175704772e-06,
      "loss": 0.4820741653442383,
      "memory(GiB)": 72.72,
      "step": 11345,
      "train_speed(iter/s)": 0.252364
    },
    {
      "epoch": 1.0586699001958773,
      "grad_norm": 3.857856273651123,
      "learning_rate": 9.301837312483247e-06,
      "loss": 0.4397120475769043,
      "memory(GiB)": 72.72,
      "step": 11350,
      "token_acc": 0.727810650887574,
      "train_speed(iter/s)": 0.252361
    },
    {
      "epoch": 1.0591362746012498,
      "grad_norm": 4.097889423370361,
      "learning_rate": 9.301051039955153e-06,
      "loss": 0.49091534614562987,
      "memory(GiB)": 72.72,
      "step": 11355,
      "train_speed(iter/s)": 0.252362
    },
    {
      "epoch": 1.0596026490066226,
      "grad_norm": 5.1614580154418945,
      "learning_rate": 9.300264358195303e-06,
      "loss": 0.4744081497192383,
      "memory(GiB)": 72.72,
      "step": 11360,
      "train_speed(iter/s)": 0.252365
    },
    {
      "epoch": 1.0600690234119952,
      "grad_norm": 5.857138633728027,
      "learning_rate": 9.299477267278548e-06,
      "loss": 0.48746500015258787,
      "memory(GiB)": 72.72,
      "step": 11365,
      "train_speed(iter/s)": 0.252368
    },
    {
      "epoch": 1.0605353978173677,
      "grad_norm": 4.258580207824707,
      "learning_rate": 9.298689767279774e-06,
      "loss": 0.5171939849853515,
      "memory(GiB)": 72.72,
      "step": 11370,
      "train_speed(iter/s)": 0.25237
    },
    {
      "epoch": 1.0610017722227405,
      "grad_norm": 4.978996753692627,
      "learning_rate": 9.297901858273912e-06,
      "loss": 0.47759408950805665,
      "memory(GiB)": 72.72,
      "step": 11375,
      "train_speed(iter/s)": 0.252371
    },
    {
      "epoch": 1.061468146628113,
      "grad_norm": 4.5165886878967285,
      "learning_rate": 9.297113540335927e-06,
      "loss": 0.5123228073120117,
      "memory(GiB)": 72.72,
      "step": 11380,
      "token_acc": 0.5576923076923077,
      "train_speed(iter/s)": 0.252376
    },
    {
      "epoch": 1.0619345210334856,
      "grad_norm": 5.729588031768799,
      "learning_rate": 9.29632481354083e-06,
      "loss": 0.5012932777404785,
      "memory(GiB)": 72.72,
      "step": 11385,
      "train_speed(iter/s)": 0.252373
    },
    {
      "epoch": 1.0624008954388584,
      "grad_norm": 12.36932373046875,
      "learning_rate": 9.295535677963657e-06,
      "loss": 0.5016368389129638,
      "memory(GiB)": 72.72,
      "step": 11390,
      "token_acc": 0.5636363636363636,
      "train_speed(iter/s)": 0.252377
    },
    {
      "epoch": 1.062867269844231,
      "grad_norm": 5.538472652435303,
      "learning_rate": 9.2947461336795e-06,
      "loss": 0.4604611396789551,
      "memory(GiB)": 72.72,
      "step": 11395,
      "train_speed(iter/s)": 0.25238
    },
    {
      "epoch": 1.0633336442496035,
      "grad_norm": 6.876278877258301,
      "learning_rate": 9.293956180763478e-06,
      "loss": 0.4804710865020752,
      "memory(GiB)": 72.72,
      "step": 11400,
      "token_acc": 0.5208333333333334,
      "train_speed(iter/s)": 0.252382
    },
    {
      "epoch": 1.0638000186549763,
      "grad_norm": 3.778705358505249,
      "learning_rate": 9.293165819290753e-06,
      "loss": 0.5392836093902588,
      "memory(GiB)": 72.72,
      "step": 11405,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.252391
    },
    {
      "epoch": 1.0642663930603489,
      "grad_norm": 5.581661224365234,
      "learning_rate": 9.292375049336526e-06,
      "loss": 0.48600006103515625,
      "memory(GiB)": 72.72,
      "step": 11410,
      "token_acc": 0.1935483870967742,
      "train_speed(iter/s)": 0.252387
    },
    {
      "epoch": 1.0647327674657214,
      "grad_norm": 3.2564985752105713,
      "learning_rate": 9.291583870976035e-06,
      "loss": 0.4810882568359375,
      "memory(GiB)": 72.72,
      "step": 11415,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.252388
    },
    {
      "epoch": 1.0651991418710942,
      "grad_norm": 4.609519004821777,
      "learning_rate": 9.290792284284563e-06,
      "loss": 0.45052061080932615,
      "memory(GiB)": 72.72,
      "step": 11420,
      "token_acc": 0.9117647058823529,
      "train_speed(iter/s)": 0.252386
    },
    {
      "epoch": 1.0656655162764668,
      "grad_norm": 4.446811676025391,
      "learning_rate": 9.29000028933742e-06,
      "loss": 0.4539656639099121,
      "memory(GiB)": 72.72,
      "step": 11425,
      "train_speed(iter/s)": 0.252385
    },
    {
      "epoch": 1.0661318906818393,
      "grad_norm": 6.02708101272583,
      "learning_rate": 9.289207886209964e-06,
      "loss": 0.50733642578125,
      "memory(GiB)": 72.72,
      "step": 11430,
      "token_acc": 0.9380530973451328,
      "train_speed(iter/s)": 0.252388
    },
    {
      "epoch": 1.0665982650872121,
      "grad_norm": 3.943275213241577,
      "learning_rate": 9.288415074977593e-06,
      "loss": 0.5240999698638916,
      "memory(GiB)": 72.72,
      "step": 11435,
      "token_acc": 0.5074626865671642,
      "train_speed(iter/s)": 0.252388
    },
    {
      "epoch": 1.0670646394925847,
      "grad_norm": 2.792872190475464,
      "learning_rate": 9.287621855715738e-06,
      "loss": 0.481220006942749,
      "memory(GiB)": 72.72,
      "step": 11440,
      "token_acc": 0.7151162790697675,
      "train_speed(iter/s)": 0.252392
    },
    {
      "epoch": 1.0675310138979572,
      "grad_norm": 4.844168186187744,
      "learning_rate": 9.28682822849987e-06,
      "loss": 0.4619605541229248,
      "memory(GiB)": 72.72,
      "step": 11445,
      "train_speed(iter/s)": 0.252387
    },
    {
      "epoch": 1.06799738830333,
      "grad_norm": 3.5163516998291016,
      "learning_rate": 9.286034193405505e-06,
      "loss": 0.4905247688293457,
      "memory(GiB)": 72.72,
      "step": 11450,
      "train_speed(iter/s)": 0.252384
    },
    {
      "epoch": 1.0684637627087026,
      "grad_norm": 4.0200958251953125,
      "learning_rate": 9.285239750508188e-06,
      "loss": 0.502453088760376,
      "memory(GiB)": 72.72,
      "step": 11455,
      "token_acc": 0.3783783783783784,
      "train_speed(iter/s)": 0.252383
    },
    {
      "epoch": 1.0689301371140751,
      "grad_norm": 4.271146297454834,
      "learning_rate": 9.284444899883511e-06,
      "loss": 0.4662785530090332,
      "memory(GiB)": 72.72,
      "step": 11460,
      "train_speed(iter/s)": 0.252394
    },
    {
      "epoch": 1.069396511519448,
      "grad_norm": 4.420360088348389,
      "learning_rate": 9.2836496416071e-06,
      "loss": 0.5089473724365234,
      "memory(GiB)": 72.72,
      "step": 11465,
      "token_acc": 0.44285714285714284,
      "train_speed(iter/s)": 0.252392
    },
    {
      "epoch": 1.0698628859248205,
      "grad_norm": 3.7132723331451416,
      "learning_rate": 9.282853975754622e-06,
      "loss": 0.5108551502227783,
      "memory(GiB)": 72.72,
      "step": 11470,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.252395
    },
    {
      "epoch": 1.070329260330193,
      "grad_norm": 5.340545177459717,
      "learning_rate": 9.282057902401781e-06,
      "loss": 0.40673389434814455,
      "memory(GiB)": 72.72,
      "step": 11475,
      "token_acc": 0.8111888111888111,
      "train_speed(iter/s)": 0.252399
    },
    {
      "epoch": 1.0707956347355658,
      "grad_norm": 5.486789226531982,
      "learning_rate": 9.281261421624321e-06,
      "loss": 0.46552696228027346,
      "memory(GiB)": 72.72,
      "step": 11480,
      "token_acc": 0.4805194805194805,
      "train_speed(iter/s)": 0.252406
    },
    {
      "epoch": 1.0712620091409384,
      "grad_norm": 2.5110623836517334,
      "learning_rate": 9.280464533498029e-06,
      "loss": 0.4587803840637207,
      "memory(GiB)": 72.72,
      "step": 11485,
      "train_speed(iter/s)": 0.252407
    },
    {
      "epoch": 1.071728383546311,
      "grad_norm": 3.816019058227539,
      "learning_rate": 9.279667238098719e-06,
      "loss": 0.5255656242370605,
      "memory(GiB)": 72.72,
      "step": 11490,
      "train_speed(iter/s)": 0.252412
    },
    {
      "epoch": 1.0721947579516835,
      "grad_norm": 3.8729677200317383,
      "learning_rate": 9.278869535502258e-06,
      "loss": 0.4993560314178467,
      "memory(GiB)": 72.72,
      "step": 11495,
      "token_acc": 0.8846153846153846,
      "train_speed(iter/s)": 0.252412
    },
    {
      "epoch": 1.0726611323570563,
      "grad_norm": 4.182174205780029,
      "learning_rate": 9.278071425784539e-06,
      "loss": 0.4490175247192383,
      "memory(GiB)": 72.72,
      "step": 11500,
      "token_acc": 0.5350877192982456,
      "train_speed(iter/s)": 0.252415
    },
    {
      "epoch": 1.0731275067624289,
      "grad_norm": 4.071686267852783,
      "learning_rate": 9.277272909021504e-06,
      "loss": 0.4698606491088867,
      "memory(GiB)": 72.72,
      "step": 11505,
      "train_speed(iter/s)": 0.252412
    },
    {
      "epoch": 1.0735938811678014,
      "grad_norm": 5.495085716247559,
      "learning_rate": 9.276473985289129e-06,
      "loss": 0.49762649536132814,
      "memory(GiB)": 72.72,
      "step": 11510,
      "train_speed(iter/s)": 0.252415
    },
    {
      "epoch": 1.0740602555731742,
      "grad_norm": 3.5564799308776855,
      "learning_rate": 9.275674654663427e-06,
      "loss": 0.44273786544799804,
      "memory(GiB)": 72.72,
      "step": 11515,
      "token_acc": 0.7414965986394558,
      "train_speed(iter/s)": 0.252412
    },
    {
      "epoch": 1.0745266299785468,
      "grad_norm": 5.707476615905762,
      "learning_rate": 9.274874917220456e-06,
      "loss": 0.5159183025360108,
      "memory(GiB)": 72.72,
      "step": 11520,
      "train_speed(iter/s)": 0.252418
    },
    {
      "epoch": 1.0749930043839193,
      "grad_norm": 3.619480848312378,
      "learning_rate": 9.274074773036304e-06,
      "loss": 0.46288042068481444,
      "memory(GiB)": 72.72,
      "step": 11525,
      "train_speed(iter/s)": 0.252423
    },
    {
      "epoch": 1.075459378789292,
      "grad_norm": 4.62129020690918,
      "learning_rate": 9.273274222187103e-06,
      "loss": 0.4445232391357422,
      "memory(GiB)": 72.72,
      "step": 11530,
      "train_speed(iter/s)": 0.25242
    },
    {
      "epoch": 1.0759257531946647,
      "grad_norm": 6.05052375793457,
      "learning_rate": 9.272473264749024e-06,
      "loss": 0.5005070686340332,
      "memory(GiB)": 72.72,
      "step": 11535,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.25242
    },
    {
      "epoch": 1.0763921276000372,
      "grad_norm": 7.166414260864258,
      "learning_rate": 9.271671900798276e-06,
      "loss": 0.502523136138916,
      "memory(GiB)": 72.72,
      "step": 11540,
      "token_acc": 0.4153846153846154,
      "train_speed(iter/s)": 0.25242
    },
    {
      "epoch": 1.07685850200541,
      "grad_norm": 17.974111557006836,
      "learning_rate": 9.270870130411108e-06,
      "loss": 0.5121668338775635,
      "memory(GiB)": 72.72,
      "step": 11545,
      "token_acc": 0.42,
      "train_speed(iter/s)": 0.252426
    },
    {
      "epoch": 1.0773248764107826,
      "grad_norm": 3.919957399368286,
      "learning_rate": 9.2700679536638e-06,
      "loss": 0.4937275886535645,
      "memory(GiB)": 72.72,
      "step": 11550,
      "train_speed(iter/s)": 0.252434
    },
    {
      "epoch": 1.0777912508161551,
      "grad_norm": 4.572386741638184,
      "learning_rate": 9.269265370632684e-06,
      "loss": 0.499920654296875,
      "memory(GiB)": 72.72,
      "step": 11555,
      "train_speed(iter/s)": 0.252428
    },
    {
      "epoch": 1.078257625221528,
      "grad_norm": 5.41632080078125,
      "learning_rate": 9.268462381394117e-06,
      "loss": 0.507548713684082,
      "memory(GiB)": 72.72,
      "step": 11560,
      "train_speed(iter/s)": 0.252431
    },
    {
      "epoch": 1.0787239996269005,
      "grad_norm": 3.838003635406494,
      "learning_rate": 9.267658986024504e-06,
      "loss": 0.5153545379638672,
      "memory(GiB)": 72.72,
      "step": 11565,
      "train_speed(iter/s)": 0.252429
    },
    {
      "epoch": 1.079190374032273,
      "grad_norm": 3.6318767070770264,
      "learning_rate": 9.266855184600288e-06,
      "loss": 0.5010408401489258,
      "memory(GiB)": 72.72,
      "step": 11570,
      "token_acc": 0.9587628865979382,
      "train_speed(iter/s)": 0.252432
    },
    {
      "epoch": 1.0796567484376458,
      "grad_norm": 5.9187445640563965,
      "learning_rate": 9.266050977197943e-06,
      "loss": 0.4712925910949707,
      "memory(GiB)": 72.72,
      "step": 11575,
      "train_speed(iter/s)": 0.252441
    },
    {
      "epoch": 1.0801231228430184,
      "grad_norm": 4.635472297668457,
      "learning_rate": 9.265246363893989e-06,
      "loss": 0.4950098037719727,
      "memory(GiB)": 72.72,
      "step": 11580,
      "train_speed(iter/s)": 0.252445
    },
    {
      "epoch": 1.080589497248391,
      "grad_norm": 6.513526439666748,
      "learning_rate": 9.264441344764986e-06,
      "loss": 0.5210801124572754,
      "memory(GiB)": 72.72,
      "step": 11585,
      "train_speed(iter/s)": 0.252449
    },
    {
      "epoch": 1.0810558716537637,
      "grad_norm": 3.6202597618103027,
      "learning_rate": 9.263635919887523e-06,
      "loss": 0.4704732894897461,
      "memory(GiB)": 72.72,
      "step": 11590,
      "train_speed(iter/s)": 0.252431
    },
    {
      "epoch": 1.0815222460591363,
      "grad_norm": 3.9454050064086914,
      "learning_rate": 9.262830089338238e-06,
      "loss": 0.48638219833374025,
      "memory(GiB)": 72.72,
      "step": 11595,
      "train_speed(iter/s)": 0.252431
    },
    {
      "epoch": 1.0819886204645088,
      "grad_norm": 3.878207206726074,
      "learning_rate": 9.2620238531938e-06,
      "loss": 0.4745308876037598,
      "memory(GiB)": 72.72,
      "step": 11600,
      "train_speed(iter/s)": 0.252426
    },
    {
      "epoch": 1.0824549948698816,
      "grad_norm": 3.730325937271118,
      "learning_rate": 9.261217211530924e-06,
      "loss": 0.47719736099243165,
      "memory(GiB)": 72.72,
      "step": 11605,
      "train_speed(iter/s)": 0.252426
    },
    {
      "epoch": 1.0829213692752542,
      "grad_norm": 5.052452564239502,
      "learning_rate": 9.260410164426359e-06,
      "loss": 0.5111827850341797,
      "memory(GiB)": 72.72,
      "step": 11610,
      "train_speed(iter/s)": 0.25243
    },
    {
      "epoch": 1.0833877436806267,
      "grad_norm": 5.854225158691406,
      "learning_rate": 9.259602711956888e-06,
      "loss": 0.47011518478393555,
      "memory(GiB)": 72.72,
      "step": 11615,
      "token_acc": 0.4222222222222222,
      "train_speed(iter/s)": 0.25243
    },
    {
      "epoch": 1.0838541180859995,
      "grad_norm": 4.6984076499938965,
      "learning_rate": 9.258794854199343e-06,
      "loss": 0.44003710746765134,
      "memory(GiB)": 72.72,
      "step": 11620,
      "train_speed(iter/s)": 0.252428
    },
    {
      "epoch": 1.084320492491372,
      "grad_norm": 4.068098545074463,
      "learning_rate": 9.257986591230585e-06,
      "loss": 0.49387969970703127,
      "memory(GiB)": 72.72,
      "step": 11625,
      "train_speed(iter/s)": 0.252433
    },
    {
      "epoch": 1.0847868668967446,
      "grad_norm": 6.434357166290283,
      "learning_rate": 9.257177923127521e-06,
      "loss": 0.4963058948516846,
      "memory(GiB)": 72.72,
      "step": 11630,
      "train_speed(iter/s)": 0.252431
    },
    {
      "epoch": 1.0852532413021174,
      "grad_norm": 6.202848434448242,
      "learning_rate": 9.256368849967094e-06,
      "loss": 0.48076457977294923,
      "memory(GiB)": 72.72,
      "step": 11635,
      "token_acc": 0.49230769230769234,
      "train_speed(iter/s)": 0.252425
    },
    {
      "epoch": 1.08571961570749,
      "grad_norm": 4.340244770050049,
      "learning_rate": 9.25555937182628e-06,
      "loss": 0.5150303840637207,
      "memory(GiB)": 72.72,
      "step": 11640,
      "token_acc": 0.3695652173913043,
      "train_speed(iter/s)": 0.252428
    },
    {
      "epoch": 1.0861859901128625,
      "grad_norm": 2.9208760261535645,
      "learning_rate": 9.254749488782104e-06,
      "loss": 0.4366010189056396,
      "memory(GiB)": 72.72,
      "step": 11645,
      "train_speed(iter/s)": 0.252421
    },
    {
      "epoch": 1.0866523645182353,
      "grad_norm": 4.152618885040283,
      "learning_rate": 9.253939200911619e-06,
      "loss": 0.47719945907592776,
      "memory(GiB)": 72.72,
      "step": 11650,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252425
    },
    {
      "epoch": 1.0871187389236079,
      "grad_norm": 4.007569789886475,
      "learning_rate": 9.253128508291925e-06,
      "loss": 0.47565016746520994,
      "memory(GiB)": 72.72,
      "step": 11655,
      "train_speed(iter/s)": 0.252431
    },
    {
      "epoch": 1.0875851133289804,
      "grad_norm": 4.618380069732666,
      "learning_rate": 9.252317411000155e-06,
      "loss": 0.5244827270507812,
      "memory(GiB)": 72.72,
      "step": 11660,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.252429
    },
    {
      "epoch": 1.0880514877343532,
      "grad_norm": 5.437721252441406,
      "learning_rate": 9.251505909113483e-06,
      "loss": 0.49637494087219236,
      "memory(GiB)": 72.72,
      "step": 11665,
      "train_speed(iter/s)": 0.252427
    },
    {
      "epoch": 1.0885178621397258,
      "grad_norm": 4.309306621551514,
      "learning_rate": 9.250694002709123e-06,
      "loss": 0.4869267463684082,
      "memory(GiB)": 72.72,
      "step": 11670,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252426
    },
    {
      "epoch": 1.0889842365450983,
      "grad_norm": 4.992131233215332,
      "learning_rate": 9.24988169186432e-06,
      "loss": 0.502784252166748,
      "memory(GiB)": 72.72,
      "step": 11675,
      "train_speed(iter/s)": 0.252429
    },
    {
      "epoch": 1.0894506109504711,
      "grad_norm": 2.85878324508667,
      "learning_rate": 9.249068976656366e-06,
      "loss": 0.49782447814941405,
      "memory(GiB)": 72.72,
      "step": 11680,
      "token_acc": 0.37777777777777777,
      "train_speed(iter/s)": 0.252432
    },
    {
      "epoch": 1.0899169853558437,
      "grad_norm": 4.159656524658203,
      "learning_rate": 9.24825585716259e-06,
      "loss": 0.4531411170959473,
      "memory(GiB)": 72.72,
      "step": 11685,
      "train_speed(iter/s)": 0.252439
    },
    {
      "epoch": 1.0903833597612163,
      "grad_norm": 5.10300350189209,
      "learning_rate": 9.247442333460356e-06,
      "loss": 0.4829914093017578,
      "memory(GiB)": 72.72,
      "step": 11690,
      "token_acc": 0.9318181818181818,
      "train_speed(iter/s)": 0.252444
    },
    {
      "epoch": 1.090849734166589,
      "grad_norm": 6.62031888961792,
      "learning_rate": 9.246628405627069e-06,
      "loss": 0.48468446731567383,
      "memory(GiB)": 72.72,
      "step": 11695,
      "train_speed(iter/s)": 0.252444
    },
    {
      "epoch": 1.0913161085719616,
      "grad_norm": 6.6860737800598145,
      "learning_rate": 9.245814073740171e-06,
      "loss": 0.514399242401123,
      "memory(GiB)": 72.72,
      "step": 11700,
      "train_speed(iter/s)": 0.252453
    },
    {
      "epoch": 1.0917824829773342,
      "grad_norm": 4.786190032958984,
      "learning_rate": 9.244999337877142e-06,
      "loss": 0.5059984207153321,
      "memory(GiB)": 72.72,
      "step": 11705,
      "train_speed(iter/s)": 0.25245
    },
    {
      "epoch": 1.092248857382707,
      "grad_norm": 4.189786434173584,
      "learning_rate": 9.244184198115504e-06,
      "loss": 0.46819257736206055,
      "memory(GiB)": 72.72,
      "step": 11710,
      "train_speed(iter/s)": 0.252453
    },
    {
      "epoch": 1.0927152317880795,
      "grad_norm": 4.3249969482421875,
      "learning_rate": 9.243368654532815e-06,
      "loss": 0.4774302959442139,
      "memory(GiB)": 72.72,
      "step": 11715,
      "token_acc": 0.4810126582278481,
      "train_speed(iter/s)": 0.252456
    },
    {
      "epoch": 1.093181606193452,
      "grad_norm": 4.276087284088135,
      "learning_rate": 9.242552707206672e-06,
      "loss": 0.4455564975738525,
      "memory(GiB)": 72.72,
      "step": 11720,
      "train_speed(iter/s)": 0.252457
    },
    {
      "epoch": 1.0936479805988246,
      "grad_norm": 4.402551651000977,
      "learning_rate": 9.241736356214705e-06,
      "loss": 0.4760024070739746,
      "memory(GiB)": 72.72,
      "step": 11725,
      "train_speed(iter/s)": 0.252449
    },
    {
      "epoch": 1.0941143550041974,
      "grad_norm": 5.468425273895264,
      "learning_rate": 9.240919601634592e-06,
      "loss": 0.5076356410980225,
      "memory(GiB)": 72.72,
      "step": 11730,
      "train_speed(iter/s)": 0.252445
    },
    {
      "epoch": 1.09458072940957,
      "grad_norm": 4.126128196716309,
      "learning_rate": 9.240102443544043e-06,
      "loss": 0.473402214050293,
      "memory(GiB)": 72.72,
      "step": 11735,
      "train_speed(iter/s)": 0.252442
    },
    {
      "epoch": 1.0950471038149425,
      "grad_norm": 4.298964500427246,
      "learning_rate": 9.23928488202081e-06,
      "loss": 0.5331465244293213,
      "memory(GiB)": 72.72,
      "step": 11740,
      "token_acc": 0.4318181818181818,
      "train_speed(iter/s)": 0.252444
    },
    {
      "epoch": 1.0955134782203153,
      "grad_norm": 3.550049304962158,
      "learning_rate": 9.238466917142678e-06,
      "loss": 0.4985082149505615,
      "memory(GiB)": 72.72,
      "step": 11745,
      "token_acc": 0.5930232558139535,
      "train_speed(iter/s)": 0.25244
    },
    {
      "epoch": 1.0959798526256879,
      "grad_norm": 4.038517475128174,
      "learning_rate": 9.237648548987477e-06,
      "loss": 0.4586195945739746,
      "memory(GiB)": 72.72,
      "step": 11750,
      "train_speed(iter/s)": 0.252434
    },
    {
      "epoch": 1.0964462270310604,
      "grad_norm": 4.723361492156982,
      "learning_rate": 9.23682977763307e-06,
      "loss": 0.4843896389007568,
      "memory(GiB)": 72.72,
      "step": 11755,
      "token_acc": 0.40476190476190477,
      "train_speed(iter/s)": 0.252312
    },
    {
      "epoch": 1.0969126014364332,
      "grad_norm": 5.26627254486084,
      "learning_rate": 9.23601060315736e-06,
      "loss": 0.49778118133544924,
      "memory(GiB)": 72.72,
      "step": 11760,
      "token_acc": 0.5045045045045045,
      "train_speed(iter/s)": 0.252293
    },
    {
      "epoch": 1.0973789758418058,
      "grad_norm": 4.870262622833252,
      "learning_rate": 9.235191025638294e-06,
      "loss": 0.4889871597290039,
      "memory(GiB)": 72.72,
      "step": 11765,
      "token_acc": 0.5660377358490566,
      "train_speed(iter/s)": 0.252294
    },
    {
      "epoch": 1.0978453502471783,
      "grad_norm": 3.613321304321289,
      "learning_rate": 9.234371045153847e-06,
      "loss": 0.47158217430114746,
      "memory(GiB)": 72.72,
      "step": 11770,
      "token_acc": 0.945054945054945,
      "train_speed(iter/s)": 0.252291
    },
    {
      "epoch": 1.0983117246525511,
      "grad_norm": 3.5194246768951416,
      "learning_rate": 9.23355066178204e-06,
      "loss": 0.4718462467193604,
      "memory(GiB)": 72.72,
      "step": 11775,
      "train_speed(iter/s)": 0.252291
    },
    {
      "epoch": 1.0987780990579237,
      "grad_norm": 4.110642910003662,
      "learning_rate": 9.232729875600929e-06,
      "loss": 0.4479378700256348,
      "memory(GiB)": 72.72,
      "step": 11780,
      "train_speed(iter/s)": 0.252288
    },
    {
      "epoch": 1.0992444734632962,
      "grad_norm": 4.217340469360352,
      "learning_rate": 9.231908686688608e-06,
      "loss": 0.4978757381439209,
      "memory(GiB)": 72.72,
      "step": 11785,
      "train_speed(iter/s)": 0.252291
    },
    {
      "epoch": 1.099710847868669,
      "grad_norm": 4.669806957244873,
      "learning_rate": 9.231087095123214e-06,
      "loss": 0.5193934440612793,
      "memory(GiB)": 72.72,
      "step": 11790,
      "token_acc": 0.45,
      "train_speed(iter/s)": 0.252296
    },
    {
      "epoch": 1.1001772222740416,
      "grad_norm": 3.431621789932251,
      "learning_rate": 9.230265100982919e-06,
      "loss": 0.519873046875,
      "memory(GiB)": 72.72,
      "step": 11795,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252296
    },
    {
      "epoch": 1.1006435966794141,
      "grad_norm": 2.971416711807251,
      "learning_rate": 9.229442704345927e-06,
      "loss": 0.44885101318359377,
      "memory(GiB)": 72.72,
      "step": 11800,
      "train_speed(iter/s)": 0.252294
    },
    {
      "epoch": 1.101109971084787,
      "grad_norm": 4.406233787536621,
      "learning_rate": 9.228619905290493e-06,
      "loss": 0.47612848281860354,
      "memory(GiB)": 72.72,
      "step": 11805,
      "token_acc": 0.8817204301075269,
      "train_speed(iter/s)": 0.25229
    },
    {
      "epoch": 1.1015763454901595,
      "grad_norm": 5.068690299987793,
      "learning_rate": 9.227796703894902e-06,
      "loss": 0.46643896102905275,
      "memory(GiB)": 72.72,
      "step": 11810,
      "token_acc": 0.37037037037037035,
      "train_speed(iter/s)": 0.252286
    },
    {
      "epoch": 1.102042719895532,
      "grad_norm": 3.6587257385253906,
      "learning_rate": 9.226973100237477e-06,
      "loss": 0.4409649848937988,
      "memory(GiB)": 72.72,
      "step": 11815,
      "train_speed(iter/s)": 0.252288
    },
    {
      "epoch": 1.1025090943009048,
      "grad_norm": 3.5573670864105225,
      "learning_rate": 9.226149094396584e-06,
      "loss": 0.4616091251373291,
      "memory(GiB)": 72.72,
      "step": 11820,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.252286
    },
    {
      "epoch": 1.1029754687062774,
      "grad_norm": 5.480475425720215,
      "learning_rate": 9.225324686450625e-06,
      "loss": 0.41631484031677246,
      "memory(GiB)": 72.72,
      "step": 11825,
      "token_acc": 0.4473684210526316,
      "train_speed(iter/s)": 0.252292
    },
    {
      "epoch": 1.10344184311165,
      "grad_norm": 11.23770523071289,
      "learning_rate": 9.224499876478037e-06,
      "loss": 0.49308366775512696,
      "memory(GiB)": 72.72,
      "step": 11830,
      "token_acc": 0.7333333333333333,
      "train_speed(iter/s)": 0.252301
    },
    {
      "epoch": 1.1039082175170227,
      "grad_norm": 3.179586172103882,
      "learning_rate": 9.2236746645573e-06,
      "loss": 0.5199997425079346,
      "memory(GiB)": 72.72,
      "step": 11835,
      "train_speed(iter/s)": 0.25231
    },
    {
      "epoch": 1.1043745919223953,
      "grad_norm": 4.757388114929199,
      "learning_rate": 9.222849050766928e-06,
      "loss": 0.5160681724548339,
      "memory(GiB)": 72.72,
      "step": 11840,
      "token_acc": 0.6289308176100629,
      "train_speed(iter/s)": 0.252317
    },
    {
      "epoch": 1.1048409663277678,
      "grad_norm": 5.48874044418335,
      "learning_rate": 9.222023035185481e-06,
      "loss": 0.47708520889282224,
      "memory(GiB)": 72.72,
      "step": 11845,
      "train_speed(iter/s)": 0.252318
    },
    {
      "epoch": 1.1053073407331406,
      "grad_norm": 3.4922618865966797,
      "learning_rate": 9.221196617891548e-06,
      "loss": 0.46794557571411133,
      "memory(GiB)": 72.72,
      "step": 11850,
      "token_acc": 0.4861111111111111,
      "train_speed(iter/s)": 0.252323
    },
    {
      "epoch": 1.1057737151385132,
      "grad_norm": 7.193774223327637,
      "learning_rate": 9.220369798963759e-06,
      "loss": 0.4876557350158691,
      "memory(GiB)": 72.72,
      "step": 11855,
      "token_acc": 0.525,
      "train_speed(iter/s)": 0.252327
    },
    {
      "epoch": 1.1062400895438858,
      "grad_norm": 4.048266887664795,
      "learning_rate": 9.219542578480784e-06,
      "loss": 0.49335179328918455,
      "memory(GiB)": 72.72,
      "step": 11860,
      "token_acc": 0.898989898989899,
      "train_speed(iter/s)": 0.252335
    },
    {
      "epoch": 1.1067064639492585,
      "grad_norm": 5.075954914093018,
      "learning_rate": 9.218714956521333e-06,
      "loss": 0.47535409927368166,
      "memory(GiB)": 72.72,
      "step": 11865,
      "token_acc": 0.49122807017543857,
      "train_speed(iter/s)": 0.252338
    },
    {
      "epoch": 1.107172838354631,
      "grad_norm": 18.29054069519043,
      "learning_rate": 9.21788693316415e-06,
      "loss": 0.5061153411865235,
      "memory(GiB)": 72.72,
      "step": 11870,
      "token_acc": 0.4567901234567901,
      "train_speed(iter/s)": 0.252338
    },
    {
      "epoch": 1.1076392127600037,
      "grad_norm": 4.96495246887207,
      "learning_rate": 9.217058508488019e-06,
      "loss": 0.4960309982299805,
      "memory(GiB)": 72.72,
      "step": 11875,
      "train_speed(iter/s)": 0.252339
    },
    {
      "epoch": 1.1081055871653764,
      "grad_norm": 4.634296417236328,
      "learning_rate": 9.21622968257176e-06,
      "loss": 0.5247438430786133,
      "memory(GiB)": 72.72,
      "step": 11880,
      "train_speed(iter/s)": 0.252344
    },
    {
      "epoch": 1.108571961570749,
      "grad_norm": 5.028749942779541,
      "learning_rate": 9.215400455494237e-06,
      "loss": 0.5118432998657226,
      "memory(GiB)": 72.72,
      "step": 11885,
      "train_speed(iter/s)": 0.252348
    },
    {
      "epoch": 1.1090383359761216,
      "grad_norm": 5.482846260070801,
      "learning_rate": 9.214570827334347e-06,
      "loss": 0.47599101066589355,
      "memory(GiB)": 72.72,
      "step": 11890,
      "token_acc": 0.43103448275862066,
      "train_speed(iter/s)": 0.25235
    },
    {
      "epoch": 1.1095047103814943,
      "grad_norm": 4.278813362121582,
      "learning_rate": 9.213740798171024e-06,
      "loss": 0.4806692600250244,
      "memory(GiB)": 72.72,
      "step": 11895,
      "train_speed(iter/s)": 0.252346
    },
    {
      "epoch": 1.109971084786867,
      "grad_norm": 10.89599609375,
      "learning_rate": 9.212910368083246e-06,
      "loss": 0.4880340099334717,
      "memory(GiB)": 72.72,
      "step": 11900,
      "token_acc": 0.9130434782608695,
      "train_speed(iter/s)": 0.252344
    },
    {
      "epoch": 1.1104374591922395,
      "grad_norm": 4.826589584350586,
      "learning_rate": 9.212079537150025e-06,
      "loss": 0.5009446620941163,
      "memory(GiB)": 72.72,
      "step": 11905,
      "train_speed(iter/s)": 0.25234
    },
    {
      "epoch": 1.1109038335976122,
      "grad_norm": 7.727148532867432,
      "learning_rate": 9.211248305450412e-06,
      "loss": 0.4835676193237305,
      "memory(GiB)": 72.72,
      "step": 11910,
      "token_acc": 0.525,
      "train_speed(iter/s)": 0.252344
    },
    {
      "epoch": 1.1113702080029848,
      "grad_norm": 4.6135358810424805,
      "learning_rate": 9.210416673063494e-06,
      "loss": 0.5009848594665527,
      "memory(GiB)": 72.72,
      "step": 11915,
      "train_speed(iter/s)": 0.25222
    },
    {
      "epoch": 1.1118365824083574,
      "grad_norm": 6.389049530029297,
      "learning_rate": 9.2095846400684e-06,
      "loss": 0.4727468490600586,
      "memory(GiB)": 72.72,
      "step": 11920,
      "token_acc": 0.32857142857142857,
      "train_speed(iter/s)": 0.252214
    },
    {
      "epoch": 1.1123029568137301,
      "grad_norm": 7.623230934143066,
      "learning_rate": 9.208752206544298e-06,
      "loss": 0.46906461715698244,
      "memory(GiB)": 72.72,
      "step": 11925,
      "token_acc": 0.42592592592592593,
      "train_speed(iter/s)": 0.25222
    },
    {
      "epoch": 1.1127693312191027,
      "grad_norm": 3.093736410140991,
      "learning_rate": 9.207919372570387e-06,
      "loss": 0.4685373783111572,
      "memory(GiB)": 72.72,
      "step": 11930,
      "token_acc": 0.9178082191780822,
      "train_speed(iter/s)": 0.252211
    },
    {
      "epoch": 1.1132357056244753,
      "grad_norm": 3.7791202068328857,
      "learning_rate": 9.207086138225911e-06,
      "loss": 0.5173296451568603,
      "memory(GiB)": 72.72,
      "step": 11935,
      "train_speed(iter/s)": 0.252212
    },
    {
      "epoch": 1.113702080029848,
      "grad_norm": 3.5406692028045654,
      "learning_rate": 9.20625250359015e-06,
      "loss": 0.48176064491271975,
      "memory(GiB)": 72.72,
      "step": 11940,
      "token_acc": 0.8189655172413793,
      "train_speed(iter/s)": 0.252217
    },
    {
      "epoch": 1.1141684544352206,
      "grad_norm": 3.160982608795166,
      "learning_rate": 9.20541846874242e-06,
      "loss": 0.46677818298339846,
      "memory(GiB)": 72.72,
      "step": 11945,
      "token_acc": 0.36764705882352944,
      "train_speed(iter/s)": 0.252222
    },
    {
      "epoch": 1.1146348288405932,
      "grad_norm": 4.316140174865723,
      "learning_rate": 9.204584033762075e-06,
      "loss": 0.45162506103515626,
      "memory(GiB)": 72.72,
      "step": 11950,
      "train_speed(iter/s)": 0.252233
    },
    {
      "epoch": 1.115101203245966,
      "grad_norm": 6.37150764465332,
      "learning_rate": 9.203749198728517e-06,
      "loss": 0.491514778137207,
      "memory(GiB)": 72.72,
      "step": 11955,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.252231
    },
    {
      "epoch": 1.1155675776513385,
      "grad_norm": 6.402353763580322,
      "learning_rate": 9.20291396372117e-06,
      "loss": 0.48114657402038574,
      "memory(GiB)": 72.72,
      "step": 11960,
      "train_speed(iter/s)": 0.252227
    },
    {
      "epoch": 1.116033952056711,
      "grad_norm": 2.696929454803467,
      "learning_rate": 9.202078328819507e-06,
      "loss": 0.4520364761352539,
      "memory(GiB)": 72.72,
      "step": 11965,
      "token_acc": 0.8217054263565892,
      "train_speed(iter/s)": 0.252222
    },
    {
      "epoch": 1.1165003264620839,
      "grad_norm": 5.442291736602783,
      "learning_rate": 9.201242294103037e-06,
      "loss": 0.48838467597961427,
      "memory(GiB)": 72.72,
      "step": 11970,
      "train_speed(iter/s)": 0.25222
    },
    {
      "epoch": 1.1169667008674564,
      "grad_norm": 5.793906211853027,
      "learning_rate": 9.200405859651302e-06,
      "loss": 0.499815845489502,
      "memory(GiB)": 72.72,
      "step": 11975,
      "token_acc": 0.8910891089108911,
      "train_speed(iter/s)": 0.252216
    },
    {
      "epoch": 1.117433075272829,
      "grad_norm": 6.177689075469971,
      "learning_rate": 9.199569025543892e-06,
      "loss": 0.466845703125,
      "memory(GiB)": 72.72,
      "step": 11980,
      "token_acc": 0.43137254901960786,
      "train_speed(iter/s)": 0.252218
    },
    {
      "epoch": 1.1178994496782018,
      "grad_norm": 6.566096782684326,
      "learning_rate": 9.198731791860425e-06,
      "loss": 0.5154887676239014,
      "memory(GiB)": 72.72,
      "step": 11985,
      "train_speed(iter/s)": 0.252212
    },
    {
      "epoch": 1.1183658240835743,
      "grad_norm": 4.94225549697876,
      "learning_rate": 9.197894158680563e-06,
      "loss": 0.4975284576416016,
      "memory(GiB)": 72.72,
      "step": 11990,
      "token_acc": 0.8709677419354839,
      "train_speed(iter/s)": 0.252211
    },
    {
      "epoch": 1.1188321984889469,
      "grad_norm": 6.1899237632751465,
      "learning_rate": 9.197056126084004e-06,
      "loss": 0.46433100700378416,
      "memory(GiB)": 72.72,
      "step": 11995,
      "train_speed(iter/s)": 0.252212
    },
    {
      "epoch": 1.1192985728943197,
      "grad_norm": 3.7786242961883545,
      "learning_rate": 9.196217694150481e-06,
      "loss": 0.49748659133911133,
      "memory(GiB)": 72.72,
      "step": 12000,
      "train_speed(iter/s)": 0.252217
    },
    {
      "epoch": 1.1197649472996922,
      "grad_norm": 4.8278045654296875,
      "learning_rate": 9.195378862959775e-06,
      "loss": 0.4899428367614746,
      "memory(GiB)": 72.72,
      "step": 12005,
      "train_speed(iter/s)": 0.252074
    },
    {
      "epoch": 1.1202313217050648,
      "grad_norm": 4.5397467613220215,
      "learning_rate": 9.194539632591693e-06,
      "loss": 0.4652432441711426,
      "memory(GiB)": 72.72,
      "step": 12010,
      "token_acc": 0.5277777777777778,
      "train_speed(iter/s)": 0.252076
    },
    {
      "epoch": 1.1206976961104376,
      "grad_norm": 3.8214263916015625,
      "learning_rate": 9.193700003126087e-06,
      "loss": 0.48488726615905764,
      "memory(GiB)": 72.72,
      "step": 12015,
      "token_acc": 0.5480769230769231,
      "train_speed(iter/s)": 0.252068
    },
    {
      "epoch": 1.1211640705158101,
      "grad_norm": 5.176693439483643,
      "learning_rate": 9.192859974642844e-06,
      "loss": 0.4945465087890625,
      "memory(GiB)": 72.72,
      "step": 12020,
      "train_speed(iter/s)": 0.25207
    },
    {
      "epoch": 1.1216304449211827,
      "grad_norm": 5.421703338623047,
      "learning_rate": 9.192019547221891e-06,
      "loss": 0.4765427589416504,
      "memory(GiB)": 72.72,
      "step": 12025,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.1220968193265555,
      "grad_norm": 4.065618515014648,
      "learning_rate": 9.191178720943193e-06,
      "loss": 0.4679088592529297,
      "memory(GiB)": 72.72,
      "step": 12030,
      "train_speed(iter/s)": 0.252072
    },
    {
      "epoch": 1.122563193731928,
      "grad_norm": 3.3261749744415283,
      "learning_rate": 9.19033749588675e-06,
      "loss": 0.4397914886474609,
      "memory(GiB)": 72.72,
      "step": 12035,
      "train_speed(iter/s)": 0.252077
    },
    {
      "epoch": 1.1230295681373006,
      "grad_norm": 4.639028549194336,
      "learning_rate": 9.189495872132604e-06,
      "loss": 0.5145702362060547,
      "memory(GiB)": 72.72,
      "step": 12040,
      "train_speed(iter/s)": 0.252081
    },
    {
      "epoch": 1.1234959425426734,
      "grad_norm": 5.048539161682129,
      "learning_rate": 9.18865384976083e-06,
      "loss": 0.4268989562988281,
      "memory(GiB)": 72.72,
      "step": 12045,
      "token_acc": 0.7635135135135135,
      "train_speed(iter/s)": 0.252083
    },
    {
      "epoch": 1.123962316948046,
      "grad_norm": 4.322826385498047,
      "learning_rate": 9.187811428851547e-06,
      "loss": 0.5334076881408691,
      "memory(GiB)": 72.72,
      "step": 12050,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.1244286913534185,
      "grad_norm": 3.014395236968994,
      "learning_rate": 9.186968609484906e-06,
      "loss": 0.45146679878234863,
      "memory(GiB)": 72.72,
      "step": 12055,
      "token_acc": 0.36,
      "train_speed(iter/s)": 0.252084
    },
    {
      "epoch": 1.124895065758791,
      "grad_norm": 2.7674765586853027,
      "learning_rate": 9.186125391741102e-06,
      "loss": 0.4831727981567383,
      "memory(GiB)": 72.72,
      "step": 12060,
      "token_acc": 0.8270676691729323,
      "train_speed(iter/s)": 0.252084
    },
    {
      "epoch": 1.1253614401641638,
      "grad_norm": 4.777889251708984,
      "learning_rate": 9.18528177570036e-06,
      "loss": 0.4967322826385498,
      "memory(GiB)": 72.72,
      "step": 12065,
      "train_speed(iter/s)": 0.252084
    },
    {
      "epoch": 1.1258278145695364,
      "grad_norm": 6.392601490020752,
      "learning_rate": 9.184437761442952e-06,
      "loss": 0.46593666076660156,
      "memory(GiB)": 72.72,
      "step": 12070,
      "token_acc": 0.37735849056603776,
      "train_speed(iter/s)": 0.252087
    },
    {
      "epoch": 1.126294188974909,
      "grad_norm": 3.5700836181640625,
      "learning_rate": 9.183593349049181e-06,
      "loss": 0.40665359497070314,
      "memory(GiB)": 72.72,
      "step": 12075,
      "train_speed(iter/s)": 0.252087
    },
    {
      "epoch": 1.1267605633802817,
      "grad_norm": 6.4326982498168945,
      "learning_rate": 9.182748538599392e-06,
      "loss": 0.4894435882568359,
      "memory(GiB)": 72.72,
      "step": 12080,
      "token_acc": 0.41935483870967744,
      "train_speed(iter/s)": 0.25209
    },
    {
      "epoch": 1.1272269377856543,
      "grad_norm": 4.598477363586426,
      "learning_rate": 9.181903330173962e-06,
      "loss": 0.46830215454101565,
      "memory(GiB)": 72.72,
      "step": 12085,
      "token_acc": 0.6595744680851063,
      "train_speed(iter/s)": 0.252092
    },
    {
      "epoch": 1.1276933121910269,
      "grad_norm": 4.053119659423828,
      "learning_rate": 9.181057723853316e-06,
      "loss": 0.49718585014343264,
      "memory(GiB)": 72.72,
      "step": 12090,
      "train_speed(iter/s)": 0.252094
    },
    {
      "epoch": 1.1281596865963996,
      "grad_norm": 5.134341716766357,
      "learning_rate": 9.180211719717906e-06,
      "loss": 0.459903621673584,
      "memory(GiB)": 72.72,
      "step": 12095,
      "train_speed(iter/s)": 0.252097
    },
    {
      "epoch": 1.1286260610017722,
      "grad_norm": 5.119998455047607,
      "learning_rate": 9.179365317848227e-06,
      "loss": 0.48807806968688966,
      "memory(GiB)": 72.72,
      "step": 12100,
      "token_acc": 0.5535714285714286,
      "train_speed(iter/s)": 0.252098
    },
    {
      "epoch": 1.1290924354071448,
      "grad_norm": 3.2725818157196045,
      "learning_rate": 9.178518518324817e-06,
      "loss": 0.44601783752441404,
      "memory(GiB)": 72.72,
      "step": 12105,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.252099
    },
    {
      "epoch": 1.1295588098125176,
      "grad_norm": 29.985441207885742,
      "learning_rate": 9.177671321228239e-06,
      "loss": 0.4730043411254883,
      "memory(GiB)": 72.72,
      "step": 12110,
      "train_speed(iter/s)": 0.252099
    },
    {
      "epoch": 1.13002518421789,
      "grad_norm": 4.726504802703857,
      "learning_rate": 9.176823726639104e-06,
      "loss": 0.47146029472351075,
      "memory(GiB)": 72.72,
      "step": 12115,
      "token_acc": 0.4716981132075472,
      "train_speed(iter/s)": 0.252099
    },
    {
      "epoch": 1.1304915586232627,
      "grad_norm": 11.979568481445312,
      "learning_rate": 9.17597573463806e-06,
      "loss": 0.5088554859161377,
      "memory(GiB)": 72.72,
      "step": 12120,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.252097
    },
    {
      "epoch": 1.1309579330286355,
      "grad_norm": 5.2845354080200195,
      "learning_rate": 9.175127345305788e-06,
      "loss": 0.4319854736328125,
      "memory(GiB)": 72.72,
      "step": 12125,
      "token_acc": 0.8924731182795699,
      "train_speed(iter/s)": 0.252096
    },
    {
      "epoch": 1.131424307434008,
      "grad_norm": 12.0837984085083,
      "learning_rate": 9.174278558723013e-06,
      "loss": 0.4634410858154297,
      "memory(GiB)": 72.72,
      "step": 12130,
      "token_acc": 0.9195402298850575,
      "train_speed(iter/s)": 0.252093
    },
    {
      "epoch": 1.1318906818393806,
      "grad_norm": 3.386761426925659,
      "learning_rate": 9.17342937497049e-06,
      "loss": 0.45467357635498046,
      "memory(GiB)": 72.72,
      "step": 12135,
      "train_speed(iter/s)": 0.252097
    },
    {
      "epoch": 1.1323570562447534,
      "grad_norm": 4.038676738739014,
      "learning_rate": 9.17257979412902e-06,
      "loss": 0.4994205474853516,
      "memory(GiB)": 72.72,
      "step": 12140,
      "train_speed(iter/s)": 0.252101
    },
    {
      "epoch": 1.132823430650126,
      "grad_norm": 8.21194076538086,
      "learning_rate": 9.171729816279436e-06,
      "loss": 0.4932264804840088,
      "memory(GiB)": 72.72,
      "step": 12145,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.252095
    },
    {
      "epoch": 1.1332898050554985,
      "grad_norm": 5.202970504760742,
      "learning_rate": 9.170879441502612e-06,
      "loss": 0.46668062210083006,
      "memory(GiB)": 72.72,
      "step": 12150,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.252095
    },
    {
      "epoch": 1.1337561794608713,
      "grad_norm": 5.574527263641357,
      "learning_rate": 9.170028669879456e-06,
      "loss": 0.4478460788726807,
      "memory(GiB)": 72.72,
      "step": 12155,
      "train_speed(iter/s)": 0.252098
    },
    {
      "epoch": 1.1342225538662438,
      "grad_norm": 4.582705974578857,
      "learning_rate": 9.16917750149092e-06,
      "loss": 0.45944700241088865,
      "memory(GiB)": 72.72,
      "step": 12160,
      "token_acc": 0.2962962962962963,
      "train_speed(iter/s)": 0.252095
    },
    {
      "epoch": 1.1346889282716164,
      "grad_norm": 4.645167827606201,
      "learning_rate": 9.168325936417988e-06,
      "loss": 0.5328883171081543,
      "memory(GiB)": 72.72,
      "step": 12165,
      "train_speed(iter/s)": 0.252098
    },
    {
      "epoch": 1.1351553026769892,
      "grad_norm": 9.250205039978027,
      "learning_rate": 9.167473974741683e-06,
      "loss": 0.5178755760192871,
      "memory(GiB)": 72.72,
      "step": 12170,
      "train_speed(iter/s)": 0.252104
    },
    {
      "epoch": 1.1356216770823617,
      "grad_norm": 5.808943271636963,
      "learning_rate": 9.166621616543068e-06,
      "loss": 0.4813538551330566,
      "memory(GiB)": 72.72,
      "step": 12175,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.1360880514877343,
      "grad_norm": 5.1509809494018555,
      "learning_rate": 9.165768861903241e-06,
      "loss": 0.5053946495056152,
      "memory(GiB)": 72.72,
      "step": 12180,
      "train_speed(iter/s)": 0.252114
    },
    {
      "epoch": 1.136554425893107,
      "grad_norm": 5.476696014404297,
      "learning_rate": 9.164915710903342e-06,
      "loss": 0.5211228847503662,
      "memory(GiB)": 72.72,
      "step": 12185,
      "token_acc": 0.7074829931972789,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.1370208002984796,
      "grad_norm": 5.280938625335693,
      "learning_rate": 9.164062163624541e-06,
      "loss": 0.4841176986694336,
      "memory(GiB)": 72.72,
      "step": 12190,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.1374871747038522,
      "grad_norm": 6.985288619995117,
      "learning_rate": 9.163208220148055e-06,
      "loss": 0.4912540912628174,
      "memory(GiB)": 72.72,
      "step": 12195,
      "token_acc": 0.4473684210526316,
      "train_speed(iter/s)": 0.252117
    },
    {
      "epoch": 1.137953549109225,
      "grad_norm": 5.174715995788574,
      "learning_rate": 9.16235388055513e-06,
      "loss": 0.49390430450439454,
      "memory(GiB)": 72.72,
      "step": 12200,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.1384199235145975,
      "grad_norm": 6.3780717849731445,
      "learning_rate": 9.161499144927057e-06,
      "loss": 0.46567859649658205,
      "memory(GiB)": 72.72,
      "step": 12205,
      "token_acc": 0.45614035087719296,
      "train_speed(iter/s)": 0.252117
    },
    {
      "epoch": 1.13888629791997,
      "grad_norm": 7.219780445098877,
      "learning_rate": 9.160644013345159e-06,
      "loss": 0.5240338802337646,
      "memory(GiB)": 72.72,
      "step": 12210,
      "token_acc": 0.449438202247191,
      "train_speed(iter/s)": 0.252123
    },
    {
      "epoch": 1.1393526723253429,
      "grad_norm": 6.235720157623291,
      "learning_rate": 9.159788485890801e-06,
      "loss": 0.5168781757354737,
      "memory(GiB)": 72.72,
      "step": 12215,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252128
    },
    {
      "epoch": 1.1398190467307154,
      "grad_norm": 8.285730361938477,
      "learning_rate": 9.158932562645383e-06,
      "loss": 0.476016902923584,
      "memory(GiB)": 72.72,
      "step": 12220,
      "train_speed(iter/s)": 0.252138
    },
    {
      "epoch": 1.140285421136088,
      "grad_norm": 4.150331020355225,
      "learning_rate": 9.158076243690344e-06,
      "loss": 0.4981797218322754,
      "memory(GiB)": 72.72,
      "step": 12225,
      "train_speed(iter/s)": 0.252136
    },
    {
      "epoch": 1.1407517955414608,
      "grad_norm": 20.118730545043945,
      "learning_rate": 9.15721952910716e-06,
      "loss": 0.48205032348632815,
      "memory(GiB)": 72.72,
      "step": 12230,
      "token_acc": 0.4807692307692308,
      "train_speed(iter/s)": 0.252129
    },
    {
      "epoch": 1.1412181699468333,
      "grad_norm": 6.285783290863037,
      "learning_rate": 9.156362418977343e-06,
      "loss": 0.49472389221191404,
      "memory(GiB)": 72.72,
      "step": 12235,
      "token_acc": 0.9047619047619048,
      "train_speed(iter/s)": 0.252132
    },
    {
      "epoch": 1.141684544352206,
      "grad_norm": 4.638771057128906,
      "learning_rate": 9.155504913382447e-06,
      "loss": 0.45946393013000486,
      "memory(GiB)": 72.72,
      "step": 12240,
      "train_speed(iter/s)": 0.252135
    },
    {
      "epoch": 1.1421509187575785,
      "grad_norm": 6.0115790367126465,
      "learning_rate": 9.15464701240406e-06,
      "loss": 0.4597781181335449,
      "memory(GiB)": 72.72,
      "step": 12245,
      "token_acc": 0.5041322314049587,
      "train_speed(iter/s)": 0.252137
    },
    {
      "epoch": 1.1426172931629512,
      "grad_norm": 4.190394401550293,
      "learning_rate": 9.153788716123806e-06,
      "loss": 0.5000401496887207,
      "memory(GiB)": 72.72,
      "step": 12250,
      "token_acc": 0.37254901960784315,
      "train_speed(iter/s)": 0.252137
    },
    {
      "epoch": 1.1430836675683238,
      "grad_norm": 6.335011959075928,
      "learning_rate": 9.152930024623355e-06,
      "loss": 0.5338742733001709,
      "memory(GiB)": 72.72,
      "step": 12255,
      "train_speed(iter/s)": 0.252143
    },
    {
      "epoch": 1.1435500419736964,
      "grad_norm": 6.687150955200195,
      "learning_rate": 9.152070937984404e-06,
      "loss": 0.5134847640991211,
      "memory(GiB)": 72.72,
      "step": 12260,
      "train_speed(iter/s)": 0.252143
    },
    {
      "epoch": 1.1440164163790691,
      "grad_norm": 10.42967700958252,
      "learning_rate": 9.151211456288693e-06,
      "loss": 0.47600507736206055,
      "memory(GiB)": 72.72,
      "step": 12265,
      "token_acc": 0.8695652173913043,
      "train_speed(iter/s)": 0.252142
    },
    {
      "epoch": 1.1444827907844417,
      "grad_norm": 6.397422790527344,
      "learning_rate": 9.150351579618002e-06,
      "loss": 0.5005438327789307,
      "memory(GiB)": 72.72,
      "step": 12270,
      "token_acc": 0.4090909090909091,
      "train_speed(iter/s)": 0.252142
    },
    {
      "epoch": 1.1449491651898143,
      "grad_norm": 8.230619430541992,
      "learning_rate": 9.149491308054143e-06,
      "loss": 0.467901611328125,
      "memory(GiB)": 72.72,
      "step": 12275,
      "train_speed(iter/s)": 0.252143
    },
    {
      "epoch": 1.145415539595187,
      "grad_norm": 5.969954490661621,
      "learning_rate": 9.14863064167897e-06,
      "loss": 0.49685091972351075,
      "memory(GiB)": 72.72,
      "step": 12280,
      "token_acc": 0.9240506329113924,
      "train_speed(iter/s)": 0.25214
    },
    {
      "epoch": 1.1458819140005596,
      "grad_norm": 3.484699010848999,
      "learning_rate": 9.14776958057437e-06,
      "loss": 0.452833366394043,
      "memory(GiB)": 72.72,
      "step": 12285,
      "train_speed(iter/s)": 0.252143
    },
    {
      "epoch": 1.1463482884059322,
      "grad_norm": 5.148325443267822,
      "learning_rate": 9.14690812482227e-06,
      "loss": 0.4748873710632324,
      "memory(GiB)": 72.72,
      "step": 12290,
      "train_speed(iter/s)": 0.252151
    },
    {
      "epoch": 1.146814662811305,
      "grad_norm": 6.650595188140869,
      "learning_rate": 9.146046274504641e-06,
      "loss": 0.42753281593322756,
      "memory(GiB)": 72.72,
      "step": 12295,
      "token_acc": 0.776,
      "train_speed(iter/s)": 0.252154
    },
    {
      "epoch": 1.1472810372166775,
      "grad_norm": 5.895500659942627,
      "learning_rate": 9.14518402970348e-06,
      "loss": 0.45153393745422366,
      "memory(GiB)": 72.72,
      "step": 12300,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25216
    },
    {
      "epoch": 1.14774741162205,
      "grad_norm": 5.92448091506958,
      "learning_rate": 9.144321390500827e-06,
      "loss": 0.47138113975524903,
      "memory(GiB)": 72.72,
      "step": 12305,
      "train_speed(iter/s)": 0.252159
    },
    {
      "epoch": 1.1482137860274229,
      "grad_norm": 5.441867828369141,
      "learning_rate": 9.143458356978761e-06,
      "loss": 0.4495199203491211,
      "memory(GiB)": 72.72,
      "step": 12310,
      "train_speed(iter/s)": 0.25216
    },
    {
      "epoch": 1.1486801604327954,
      "grad_norm": 5.2380805015563965,
      "learning_rate": 9.142594929219397e-06,
      "loss": 0.48418092727661133,
      "memory(GiB)": 72.72,
      "step": 12315,
      "token_acc": 0.7326732673267327,
      "train_speed(iter/s)": 0.252156
    },
    {
      "epoch": 1.149146534838168,
      "grad_norm": 4.903923988342285,
      "learning_rate": 9.141731107304886e-06,
      "loss": 0.46860218048095703,
      "memory(GiB)": 72.72,
      "step": 12320,
      "train_speed(iter/s)": 0.252151
    },
    {
      "epoch": 1.1496129092435408,
      "grad_norm": 6.765446662902832,
      "learning_rate": 9.14086689131742e-06,
      "loss": 0.4558697700500488,
      "memory(GiB)": 72.72,
      "step": 12325,
      "train_speed(iter/s)": 0.252155
    },
    {
      "epoch": 1.1500792836489133,
      "grad_norm": 5.798537254333496,
      "learning_rate": 9.140002281339226e-06,
      "loss": 0.5078028202056885,
      "memory(GiB)": 72.72,
      "step": 12330,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.252158
    },
    {
      "epoch": 1.1505456580542859,
      "grad_norm": 7.527783393859863,
      "learning_rate": 9.139137277452567e-06,
      "loss": 0.46948394775390623,
      "memory(GiB)": 72.72,
      "step": 12335,
      "train_speed(iter/s)": 0.252158
    },
    {
      "epoch": 1.1510120324596587,
      "grad_norm": 5.768637180328369,
      "learning_rate": 9.138271879739748e-06,
      "loss": 0.49724550247192384,
      "memory(GiB)": 72.72,
      "step": 12340,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 1.1514784068650312,
      "grad_norm": 4.795790195465088,
      "learning_rate": 9.137406088283108e-06,
      "loss": 0.48963079452514646,
      "memory(GiB)": 72.72,
      "step": 12345,
      "token_acc": 0.6764705882352942,
      "train_speed(iter/s)": 0.252163
    },
    {
      "epoch": 1.1519447812704038,
      "grad_norm": 4.9352521896362305,
      "learning_rate": 9.136539903165024e-06,
      "loss": 0.47108283042907717,
      "memory(GiB)": 72.72,
      "step": 12350,
      "train_speed(iter/s)": 0.252163
    },
    {
      "epoch": 1.1524111556757766,
      "grad_norm": 6.568763732910156,
      "learning_rate": 9.135673324467911e-06,
      "loss": 0.4390267848968506,
      "memory(GiB)": 72.72,
      "step": 12355,
      "train_speed(iter/s)": 0.25217
    },
    {
      "epoch": 1.1528775300811491,
      "grad_norm": 7.8954901695251465,
      "learning_rate": 9.134806352274222e-06,
      "loss": 0.4747403621673584,
      "memory(GiB)": 72.72,
      "step": 12360,
      "train_speed(iter/s)": 0.252174
    },
    {
      "epoch": 1.1533439044865217,
      "grad_norm": 4.730012893676758,
      "learning_rate": 9.133938986666447e-06,
      "loss": 0.5087749481201171,
      "memory(GiB)": 72.72,
      "step": 12365,
      "token_acc": 0.9146341463414634,
      "train_speed(iter/s)": 0.252173
    },
    {
      "epoch": 1.1538102788918945,
      "grad_norm": 5.017539978027344,
      "learning_rate": 9.13307122772711e-06,
      "loss": 0.49677062034606934,
      "memory(GiB)": 72.72,
      "step": 12370,
      "train_speed(iter/s)": 0.252175
    },
    {
      "epoch": 1.154276653297267,
      "grad_norm": 3.888068914413452,
      "learning_rate": 9.13220307553878e-06,
      "loss": 0.46689629554748535,
      "memory(GiB)": 72.72,
      "step": 12375,
      "token_acc": 0.5405405405405406,
      "train_speed(iter/s)": 0.252174
    },
    {
      "epoch": 1.1547430277026396,
      "grad_norm": 4.720405101776123,
      "learning_rate": 9.131334530184056e-06,
      "loss": 0.4660797119140625,
      "memory(GiB)": 72.72,
      "step": 12380,
      "train_speed(iter/s)": 0.25217
    },
    {
      "epoch": 1.1552094021080124,
      "grad_norm": 4.891905784606934,
      "learning_rate": 9.130465591745578e-06,
      "loss": 0.4363423824310303,
      "memory(GiB)": 72.72,
      "step": 12385,
      "token_acc": 0.712,
      "train_speed(iter/s)": 0.252173
    },
    {
      "epoch": 1.155675776513385,
      "grad_norm": 4.817016124725342,
      "learning_rate": 9.129596260306022e-06,
      "loss": 0.4742763519287109,
      "memory(GiB)": 72.72,
      "step": 12390,
      "train_speed(iter/s)": 0.252172
    },
    {
      "epoch": 1.1561421509187575,
      "grad_norm": 4.294769287109375,
      "learning_rate": 9.128726535948106e-06,
      "loss": 0.49645051956176756,
      "memory(GiB)": 72.72,
      "step": 12395,
      "token_acc": 0.4875,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.1566085253241303,
      "grad_norm": 4.756147861480713,
      "learning_rate": 9.127856418754577e-06,
      "loss": 0.4628588676452637,
      "memory(GiB)": 72.72,
      "step": 12400,
      "train_speed(iter/s)": 0.25218
    },
    {
      "epoch": 1.1570748997295028,
      "grad_norm": 5.328631401062012,
      "learning_rate": 9.126985908808229e-06,
      "loss": 0.5025993347167969,
      "memory(GiB)": 72.72,
      "step": 12405,
      "train_speed(iter/s)": 0.25218
    },
    {
      "epoch": 1.1575412741348754,
      "grad_norm": 3.718977451324463,
      "learning_rate": 9.126115006191882e-06,
      "loss": 0.44021925926208494,
      "memory(GiB)": 72.72,
      "step": 12410,
      "token_acc": 0.9680851063829787,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.1580076485402482,
      "grad_norm": 5.572921276092529,
      "learning_rate": 9.125243710988403e-06,
      "loss": 0.461984920501709,
      "memory(GiB)": 72.72,
      "step": 12415,
      "token_acc": 0.6875,
      "train_speed(iter/s)": 0.252179
    },
    {
      "epoch": 1.1584740229456207,
      "grad_norm": 4.192714214324951,
      "learning_rate": 9.124372023280694e-06,
      "loss": 0.49312553405761717,
      "memory(GiB)": 72.72,
      "step": 12420,
      "train_speed(iter/s)": 0.252177
    },
    {
      "epoch": 1.1589403973509933,
      "grad_norm": 3.4549310207366943,
      "learning_rate": 9.123499943151692e-06,
      "loss": 0.4518378734588623,
      "memory(GiB)": 72.72,
      "step": 12425,
      "token_acc": 0.7894736842105263,
      "train_speed(iter/s)": 0.252184
    },
    {
      "epoch": 1.159406771756366,
      "grad_norm": 11.922508239746094,
      "learning_rate": 9.122627470684374e-06,
      "loss": 0.49355335235595704,
      "memory(GiB)": 72.72,
      "step": 12430,
      "train_speed(iter/s)": 0.252189
    },
    {
      "epoch": 1.1598731461617386,
      "grad_norm": 6.6754889488220215,
      "learning_rate": 9.121754605961752e-06,
      "loss": 0.4742000102996826,
      "memory(GiB)": 72.72,
      "step": 12435,
      "train_speed(iter/s)": 0.252192
    },
    {
      "epoch": 1.1603395205671112,
      "grad_norm": 3.739877939224243,
      "learning_rate": 9.120881349066876e-06,
      "loss": 0.4829902648925781,
      "memory(GiB)": 72.72,
      "step": 12440,
      "train_speed(iter/s)": 0.252189
    },
    {
      "epoch": 1.160805894972484,
      "grad_norm": 4.170417308807373,
      "learning_rate": 9.120007700082836e-06,
      "loss": 0.4826235771179199,
      "memory(GiB)": 72.72,
      "step": 12445,
      "token_acc": 0.5096153846153846,
      "train_speed(iter/s)": 0.252186
    },
    {
      "epoch": 1.1612722693778565,
      "grad_norm": 3.9906857013702393,
      "learning_rate": 9.119133659092754e-06,
      "loss": 0.46949024200439454,
      "memory(GiB)": 72.72,
      "step": 12450,
      "token_acc": 0.4188034188034188,
      "train_speed(iter/s)": 0.252188
    },
    {
      "epoch": 1.161738643783229,
      "grad_norm": 5.687594413757324,
      "learning_rate": 9.118259226179793e-06,
      "loss": 0.43806705474853513,
      "memory(GiB)": 72.72,
      "step": 12455,
      "train_speed(iter/s)": 0.252188
    },
    {
      "epoch": 1.162205018188602,
      "grad_norm": 4.082341194152832,
      "learning_rate": 9.117384401427153e-06,
      "loss": 0.45545039176940916,
      "memory(GiB)": 72.72,
      "step": 12460,
      "token_acc": 0.9125,
      "train_speed(iter/s)": 0.252185
    },
    {
      "epoch": 1.1626713925939745,
      "grad_norm": 4.427742004394531,
      "learning_rate": 9.116509184918073e-06,
      "loss": 0.4426872730255127,
      "memory(GiB)": 72.72,
      "step": 12465,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.252186
    },
    {
      "epoch": 1.163137766999347,
      "grad_norm": 23.01995277404785,
      "learning_rate": 9.115633576735825e-06,
      "loss": 0.45186309814453124,
      "memory(GiB)": 72.72,
      "step": 12470,
      "train_speed(iter/s)": 0.252185
    },
    {
      "epoch": 1.1636041414047198,
      "grad_norm": 4.276556968688965,
      "learning_rate": 9.11475757696372e-06,
      "loss": 0.4940960884094238,
      "memory(GiB)": 72.72,
      "step": 12475,
      "train_speed(iter/s)": 0.252192
    },
    {
      "epoch": 1.1640705158100924,
      "grad_norm": 4.359984874725342,
      "learning_rate": 9.113881185685106e-06,
      "loss": 0.4754384994506836,
      "memory(GiB)": 72.72,
      "step": 12480,
      "train_speed(iter/s)": 0.252194
    },
    {
      "epoch": 1.164536890215465,
      "grad_norm": 15.719438552856445,
      "learning_rate": 9.113004402983372e-06,
      "loss": 0.4786555290222168,
      "memory(GiB)": 72.72,
      "step": 12485,
      "train_speed(iter/s)": 0.252194
    },
    {
      "epoch": 1.1650032646208377,
      "grad_norm": 7.599315643310547,
      "learning_rate": 9.112127228941941e-06,
      "loss": 0.5183520317077637,
      "memory(GiB)": 72.72,
      "step": 12490,
      "train_speed(iter/s)": 0.252193
    },
    {
      "epoch": 1.1654696390262103,
      "grad_norm": 4.4987993240356445,
      "learning_rate": 9.111249663644269e-06,
      "loss": 0.4847513198852539,
      "memory(GiB)": 72.72,
      "step": 12495,
      "train_speed(iter/s)": 0.252197
    },
    {
      "epoch": 1.1659360134315828,
      "grad_norm": 4.929627418518066,
      "learning_rate": 9.110371707173858e-06,
      "loss": 0.4415288925170898,
      "memory(GiB)": 72.72,
      "step": 12500,
      "token_acc": 0.35714285714285715,
      "train_speed(iter/s)": 0.252194
    },
    {
      "epoch": 1.1664023878369556,
      "grad_norm": 4.936983585357666,
      "learning_rate": 9.10949335961424e-06,
      "loss": 0.4688127517700195,
      "memory(GiB)": 72.72,
      "step": 12505,
      "train_speed(iter/s)": 0.252193
    },
    {
      "epoch": 1.1668687622423282,
      "grad_norm": 3.508697271347046,
      "learning_rate": 9.10861462104899e-06,
      "loss": 0.49138975143432617,
      "memory(GiB)": 72.72,
      "step": 12510,
      "token_acc": 0.4727272727272727,
      "train_speed(iter/s)": 0.252197
    },
    {
      "epoch": 1.1673351366477007,
      "grad_norm": 4.866327285766602,
      "learning_rate": 9.107735491561715e-06,
      "loss": 0.4561323165893555,
      "memory(GiB)": 72.72,
      "step": 12515,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.252202
    },
    {
      "epoch": 1.1678015110530735,
      "grad_norm": 4.223543643951416,
      "learning_rate": 9.106855971236063e-06,
      "loss": 0.4876094818115234,
      "memory(GiB)": 72.72,
      "step": 12520,
      "token_acc": 0.5869565217391305,
      "train_speed(iter/s)": 0.252201
    },
    {
      "epoch": 1.168267885458446,
      "grad_norm": 11.647130012512207,
      "learning_rate": 9.105976060155716e-06,
      "loss": 0.47519726753234864,
      "memory(GiB)": 72.72,
      "step": 12525,
      "train_speed(iter/s)": 0.252202
    },
    {
      "epoch": 1.1687342598638186,
      "grad_norm": 4.899012565612793,
      "learning_rate": 9.105095758404397e-06,
      "loss": 0.4357820987701416,
      "memory(GiB)": 72.72,
      "step": 12530,
      "train_speed(iter/s)": 0.25221
    },
    {
      "epoch": 1.1692006342691914,
      "grad_norm": 7.289492130279541,
      "learning_rate": 9.10421506606586e-06,
      "loss": 0.4730052947998047,
      "memory(GiB)": 72.72,
      "step": 12535,
      "train_speed(iter/s)": 0.25221
    },
    {
      "epoch": 1.169667008674564,
      "grad_norm": 6.1393022537231445,
      "learning_rate": 9.103333983223904e-06,
      "loss": 0.4729606628417969,
      "memory(GiB)": 72.72,
      "step": 12540,
      "train_speed(iter/s)": 0.252204
    },
    {
      "epoch": 1.1701333830799365,
      "grad_norm": 4.054754734039307,
      "learning_rate": 9.10245250996236e-06,
      "loss": 0.493101167678833,
      "memory(GiB)": 72.72,
      "step": 12545,
      "token_acc": 0.44166666666666665,
      "train_speed(iter/s)": 0.252205
    },
    {
      "epoch": 1.1705997574853093,
      "grad_norm": 7.7686638832092285,
      "learning_rate": 9.101570646365098e-06,
      "loss": 0.4931004524230957,
      "memory(GiB)": 72.72,
      "step": 12550,
      "token_acc": 0.9770114942528736,
      "train_speed(iter/s)": 0.252204
    },
    {
      "epoch": 1.1710661318906819,
      "grad_norm": 8.140082359313965,
      "learning_rate": 9.100688392516025e-06,
      "loss": 0.5136814117431641,
      "memory(GiB)": 72.72,
      "step": 12555,
      "token_acc": 0.4262295081967213,
      "train_speed(iter/s)": 0.252207
    },
    {
      "epoch": 1.1715325062960544,
      "grad_norm": 7.14290189743042,
      "learning_rate": 9.099805748499083e-06,
      "loss": 0.4980146408081055,
      "memory(GiB)": 72.72,
      "step": 12560,
      "train_speed(iter/s)": 0.25221
    },
    {
      "epoch": 1.1719988807014272,
      "grad_norm": 6.683047294616699,
      "learning_rate": 9.098922714398254e-06,
      "loss": 0.4681044101715088,
      "memory(GiB)": 72.72,
      "step": 12565,
      "token_acc": 0.9302325581395349,
      "train_speed(iter/s)": 0.252217
    },
    {
      "epoch": 1.1724652551067998,
      "grad_norm": 4.704394817352295,
      "learning_rate": 9.098039290297556e-06,
      "loss": 0.47226524353027344,
      "memory(GiB)": 72.72,
      "step": 12570,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252222
    },
    {
      "epoch": 1.1729316295121723,
      "grad_norm": 4.88532829284668,
      "learning_rate": 9.097155476281043e-06,
      "loss": 0.5015095233917236,
      "memory(GiB)": 72.72,
      "step": 12575,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.252216
    },
    {
      "epoch": 1.1733980039175451,
      "grad_norm": 3.4391438961029053,
      "learning_rate": 9.096271272432808e-06,
      "loss": 0.4780888557434082,
      "memory(GiB)": 72.72,
      "step": 12580,
      "train_speed(iter/s)": 0.252219
    },
    {
      "epoch": 1.1738643783229177,
      "grad_norm": 4.18488883972168,
      "learning_rate": 9.09538667883698e-06,
      "loss": 0.4771442413330078,
      "memory(GiB)": 72.72,
      "step": 12585,
      "train_speed(iter/s)": 0.25223
    },
    {
      "epoch": 1.1743307527282902,
      "grad_norm": 3.1309282779693604,
      "learning_rate": 9.094501695577729e-06,
      "loss": 0.46665000915527344,
      "memory(GiB)": 72.72,
      "step": 12590,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.252106
    },
    {
      "epoch": 1.174797127133663,
      "grad_norm": 3.5320870876312256,
      "learning_rate": 9.09361632273925e-06,
      "loss": 0.4965946674346924,
      "memory(GiB)": 72.72,
      "step": 12595,
      "token_acc": 0.35384615384615387,
      "train_speed(iter/s)": 0.252096
    },
    {
      "epoch": 1.1752635015390356,
      "grad_norm": 6.08038330078125,
      "learning_rate": 9.092730560405792e-06,
      "loss": 0.5166188240051269,
      "memory(GiB)": 72.72,
      "step": 12600,
      "token_acc": 0.5497076023391813,
      "train_speed(iter/s)": 0.252092
    },
    {
      "epoch": 1.1757298759444081,
      "grad_norm": 3.7510321140289307,
      "learning_rate": 9.09184440866163e-06,
      "loss": 0.4361849784851074,
      "memory(GiB)": 72.72,
      "step": 12605,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.252091
    },
    {
      "epoch": 1.176196250349781,
      "grad_norm": 2.916888475418091,
      "learning_rate": 9.090957867591074e-06,
      "loss": 0.45197458267211915,
      "memory(GiB)": 72.72,
      "step": 12610,
      "token_acc": 0.3829787234042553,
      "train_speed(iter/s)": 0.252094
    },
    {
      "epoch": 1.1766626247551535,
      "grad_norm": 3.685749053955078,
      "learning_rate": 9.090070937278483e-06,
      "loss": 0.5037635803222656,
      "memory(GiB)": 72.72,
      "step": 12615,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.252099
    },
    {
      "epoch": 1.177128999160526,
      "grad_norm": 4.90069055557251,
      "learning_rate": 9.08918361780824e-06,
      "loss": 0.4547084331512451,
      "memory(GiB)": 72.72,
      "step": 12620,
      "token_acc": 0.4927536231884058,
      "train_speed(iter/s)": 0.252105
    },
    {
      "epoch": 1.1775953735658986,
      "grad_norm": 3.9983673095703125,
      "learning_rate": 9.088295909264773e-06,
      "loss": 0.4965664863586426,
      "memory(GiB)": 72.72,
      "step": 12625,
      "token_acc": 0.631578947368421,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.1780617479712714,
      "grad_norm": 4.556135654449463,
      "learning_rate": 9.087407811732546e-06,
      "loss": 0.45430936813354494,
      "memory(GiB)": 72.72,
      "step": 12630,
      "train_speed(iter/s)": 0.252107
    },
    {
      "epoch": 1.178528122376644,
      "grad_norm": 3.3968427181243896,
      "learning_rate": 9.086519325296057e-06,
      "loss": 0.45945205688476565,
      "memory(GiB)": 72.72,
      "step": 12635,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.1789944967820165,
      "grad_norm": 3.2630395889282227,
      "learning_rate": 9.085630450039842e-06,
      "loss": 0.46369566917419436,
      "memory(GiB)": 72.72,
      "step": 12640,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.252108
    },
    {
      "epoch": 1.1794608711873893,
      "grad_norm": 8.240194320678711,
      "learning_rate": 9.084741186048476e-06,
      "loss": 0.43745107650756837,
      "memory(GiB)": 72.72,
      "step": 12645,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.1799272455927619,
      "grad_norm": 3.9613709449768066,
      "learning_rate": 9.08385153340657e-06,
      "loss": 0.49261837005615233,
      "memory(GiB)": 72.72,
      "step": 12650,
      "train_speed(iter/s)": 0.252005
    },
    {
      "epoch": 1.1803936199981344,
      "grad_norm": 2.969376802444458,
      "learning_rate": 9.08296149219877e-06,
      "loss": 0.47763910293579104,
      "memory(GiB)": 72.72,
      "step": 12655,
      "token_acc": 0.66,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.1808599944035072,
      "grad_norm": 5.504786491394043,
      "learning_rate": 9.082071062509762e-06,
      "loss": 0.44562516212463377,
      "memory(GiB)": 72.72,
      "step": 12660,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.1813263688088798,
      "grad_norm": 6.371425628662109,
      "learning_rate": 9.081180244424268e-06,
      "loss": 0.48592076301574705,
      "memory(GiB)": 72.72,
      "step": 12665,
      "token_acc": 0.4262295081967213,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.1817927432142523,
      "grad_norm": 4.299795627593994,
      "learning_rate": 9.080289038027046e-06,
      "loss": 0.46579704284667967,
      "memory(GiB)": 72.72,
      "step": 12670,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.182259117619625,
      "grad_norm": 5.676342010498047,
      "learning_rate": 9.079397443402893e-06,
      "loss": 0.5085681915283203,
      "memory(GiB)": 72.72,
      "step": 12675,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.1827254920249977,
      "grad_norm": 4.7215704917907715,
      "learning_rate": 9.07850546063664e-06,
      "loss": 0.49084815979003904,
      "memory(GiB)": 72.72,
      "step": 12680,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.1831918664303702,
      "grad_norm": 5.388446807861328,
      "learning_rate": 9.077613089813155e-06,
      "loss": 0.46271839141845705,
      "memory(GiB)": 72.72,
      "step": 12685,
      "train_speed(iter/s)": 0.251997
    },
    {
      "epoch": 1.183658240835743,
      "grad_norm": 3.562920093536377,
      "learning_rate": 9.076720331017346e-06,
      "loss": 0.4375462532043457,
      "memory(GiB)": 72.72,
      "step": 12690,
      "token_acc": 0.5903614457831325,
      "train_speed(iter/s)": 0.252001
    },
    {
      "epoch": 1.1841246152411156,
      "grad_norm": 4.864859104156494,
      "learning_rate": 9.075827184334155e-06,
      "loss": 0.46027798652648927,
      "memory(GiB)": 72.72,
      "step": 12695,
      "token_acc": 0.4642857142857143,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.1845909896464881,
      "grad_norm": 3.375629425048828,
      "learning_rate": 9.074933649848567e-06,
      "loss": 0.4993553161621094,
      "memory(GiB)": 72.72,
      "step": 12700,
      "token_acc": 0.45652173913043476,
      "train_speed(iter/s)": 0.252005
    },
    {
      "epoch": 1.185057364051861,
      "grad_norm": 5.605872631072998,
      "learning_rate": 9.074039727645595e-06,
      "loss": 0.46643457412719724,
      "memory(GiB)": 72.72,
      "step": 12705,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.1855237384572335,
      "grad_norm": 5.574757099151611,
      "learning_rate": 9.07314541781029e-06,
      "loss": 0.5007200717926026,
      "memory(GiB)": 72.72,
      "step": 12710,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.185990112862606,
      "grad_norm": 4.7564544677734375,
      "learning_rate": 9.072250720427749e-06,
      "loss": 0.4833235740661621,
      "memory(GiB)": 72.72,
      "step": 12715,
      "token_acc": 0.3333333333333333,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.1864564872679788,
      "grad_norm": 5.706604480743408,
      "learning_rate": 9.071355635583094e-06,
      "loss": 0.4631446361541748,
      "memory(GiB)": 72.72,
      "step": 12720,
      "token_acc": 0.64,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.1869228616733514,
      "grad_norm": 6.313394546508789,
      "learning_rate": 9.070460163361494e-06,
      "loss": 0.45084576606750487,
      "memory(GiB)": 72.72,
      "step": 12725,
      "train_speed(iter/s)": 0.252011
    },
    {
      "epoch": 1.187389236078724,
      "grad_norm": 3.2255327701568604,
      "learning_rate": 9.06956430384815e-06,
      "loss": 0.4173150062561035,
      "memory(GiB)": 72.72,
      "step": 12730,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.1878556104840967,
      "grad_norm": 5.867602825164795,
      "learning_rate": 9.068668057128297e-06,
      "loss": 0.44838695526123046,
      "memory(GiB)": 72.72,
      "step": 12735,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.25202
    },
    {
      "epoch": 1.1883219848894693,
      "grad_norm": 3.055471897125244,
      "learning_rate": 9.067771423287214e-06,
      "loss": 0.48482694625854494,
      "memory(GiB)": 72.72,
      "step": 12740,
      "token_acc": 0.4715447154471545,
      "train_speed(iter/s)": 0.252024
    },
    {
      "epoch": 1.1887883592948418,
      "grad_norm": 3.8007657527923584,
      "learning_rate": 9.06687440241021e-06,
      "loss": 0.4815239429473877,
      "memory(GiB)": 72.72,
      "step": 12745,
      "train_speed(iter/s)": 0.252021
    },
    {
      "epoch": 1.1892547337002146,
      "grad_norm": 5.625994682312012,
      "learning_rate": 9.065976994582634e-06,
      "loss": 0.4719886302947998,
      "memory(GiB)": 72.72,
      "step": 12750,
      "train_speed(iter/s)": 0.252019
    },
    {
      "epoch": 1.1897211081055872,
      "grad_norm": 3.052253484725952,
      "learning_rate": 9.065079199889875e-06,
      "loss": 0.4928410530090332,
      "memory(GiB)": 72.72,
      "step": 12755,
      "token_acc": 0.49019607843137253,
      "train_speed(iter/s)": 0.252024
    },
    {
      "epoch": 1.1901874825109597,
      "grad_norm": 2.8396708965301514,
      "learning_rate": 9.064181018417353e-06,
      "loss": 0.45805835723876953,
      "memory(GiB)": 72.72,
      "step": 12760,
      "train_speed(iter/s)": 0.252019
    },
    {
      "epoch": 1.1906538569163325,
      "grad_norm": 7.508086681365967,
      "learning_rate": 9.063282450250525e-06,
      "loss": 0.4168851852416992,
      "memory(GiB)": 72.72,
      "step": 12765,
      "train_speed(iter/s)": 0.25202
    },
    {
      "epoch": 1.191120231321705,
      "grad_norm": 3.8682467937469482,
      "learning_rate": 9.062383495474889e-06,
      "loss": 0.4737697601318359,
      "memory(GiB)": 72.72,
      "step": 12770,
      "train_speed(iter/s)": 0.25201
    },
    {
      "epoch": 1.1915866057270776,
      "grad_norm": 3.802741289138794,
      "learning_rate": 9.061484154175979e-06,
      "loss": 0.47951374053955076,
      "memory(GiB)": 72.72,
      "step": 12775,
      "token_acc": 0.45901639344262296,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.1920529801324504,
      "grad_norm": 10.785127639770508,
      "learning_rate": 9.060584426439363e-06,
      "loss": 0.5189488410949707,
      "memory(GiB)": 72.72,
      "step": 12780,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25201
    },
    {
      "epoch": 1.192519354537823,
      "grad_norm": 4.982512950897217,
      "learning_rate": 9.059684312350648e-06,
      "loss": 0.4978634834289551,
      "memory(GiB)": 72.72,
      "step": 12785,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.1929857289431955,
      "grad_norm": 4.760525226593018,
      "learning_rate": 9.058783811995477e-06,
      "loss": 0.49493932723999023,
      "memory(GiB)": 72.72,
      "step": 12790,
      "token_acc": 0.6585365853658537,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.1934521033485683,
      "grad_norm": 4.598594665527344,
      "learning_rate": 9.057882925459529e-06,
      "loss": 0.4930706977844238,
      "memory(GiB)": 72.72,
      "step": 12795,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.1939184777539409,
      "grad_norm": 4.164862632751465,
      "learning_rate": 9.056981652828523e-06,
      "loss": 0.44988579750061036,
      "memory(GiB)": 72.72,
      "step": 12800,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.1943848521593134,
      "grad_norm": 6.714015483856201,
      "learning_rate": 9.056079994188209e-06,
      "loss": 0.5019582748413086,
      "memory(GiB)": 72.72,
      "step": 12805,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.194851226564686,
      "grad_norm": 4.132083415985107,
      "learning_rate": 9.055177949624378e-06,
      "loss": 0.4794137001037598,
      "memory(GiB)": 72.72,
      "step": 12810,
      "token_acc": 0.5050505050505051,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.1953176009700588,
      "grad_norm": 7.247530937194824,
      "learning_rate": 9.054275519222859e-06,
      "loss": 0.5450748443603516,
      "memory(GiB)": 72.72,
      "step": 12815,
      "token_acc": 0.9101123595505618,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.1957839753754314,
      "grad_norm": 5.849198341369629,
      "learning_rate": 9.053372703069514e-06,
      "loss": 0.5051186561584473,
      "memory(GiB)": 72.72,
      "step": 12820,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.196250349780804,
      "grad_norm": 3.5465152263641357,
      "learning_rate": 9.052469501250241e-06,
      "loss": 0.46941328048706055,
      "memory(GiB)": 72.72,
      "step": 12825,
      "token_acc": 0.6216216216216216,
      "train_speed(iter/s)": 0.252022
    },
    {
      "epoch": 1.1967167241861767,
      "grad_norm": 4.343686103820801,
      "learning_rate": 9.051565913850981e-06,
      "loss": 0.47608366012573244,
      "memory(GiB)": 72.72,
      "step": 12830,
      "train_speed(iter/s)": 0.252024
    },
    {
      "epoch": 1.1971830985915493,
      "grad_norm": 4.175350189208984,
      "learning_rate": 9.050661940957705e-06,
      "loss": 0.4697747230529785,
      "memory(GiB)": 72.72,
      "step": 12835,
      "train_speed(iter/s)": 0.25202
    },
    {
      "epoch": 1.1976494729969218,
      "grad_norm": 3.486445426940918,
      "learning_rate": 9.049757582656422e-06,
      "loss": 0.482145881652832,
      "memory(GiB)": 72.72,
      "step": 12840,
      "token_acc": 0.5576923076923077,
      "train_speed(iter/s)": 0.252022
    },
    {
      "epoch": 1.1981158474022946,
      "grad_norm": 3.9235005378723145,
      "learning_rate": 9.048852839033183e-06,
      "loss": 0.4652093887329102,
      "memory(GiB)": 72.72,
      "step": 12845,
      "train_speed(iter/s)": 0.252021
    },
    {
      "epoch": 1.1985822218076672,
      "grad_norm": 4.849946022033691,
      "learning_rate": 9.047947710174067e-06,
      "loss": 0.4573498725891113,
      "memory(GiB)": 72.72,
      "step": 12850,
      "token_acc": 0.39215686274509803,
      "train_speed(iter/s)": 0.252023
    },
    {
      "epoch": 1.1990485962130397,
      "grad_norm": 4.690520763397217,
      "learning_rate": 9.047042196165199e-06,
      "loss": 0.47225255966186525,
      "memory(GiB)": 72.72,
      "step": 12855,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.1995149706184125,
      "grad_norm": 4.189566135406494,
      "learning_rate": 9.046136297092732e-06,
      "loss": 0.45951051712036134,
      "memory(GiB)": 72.72,
      "step": 12860,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.199981345023785,
      "grad_norm": 3.788688898086548,
      "learning_rate": 9.045230013042859e-06,
      "loss": 0.4889406204223633,
      "memory(GiB)": 72.72,
      "step": 12865,
      "train_speed(iter/s)": 0.252023
    },
    {
      "epoch": 1.2004477194291576,
      "grad_norm": 3.8404810428619385,
      "learning_rate": 9.044323344101814e-06,
      "loss": 0.44770135879516604,
      "memory(GiB)": 72.72,
      "step": 12870,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.2009140938345304,
      "grad_norm": 4.635137557983398,
      "learning_rate": 9.043416290355862e-06,
      "loss": 0.4723832130432129,
      "memory(GiB)": 72.72,
      "step": 12875,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.252028
    },
    {
      "epoch": 1.201380468239903,
      "grad_norm": 4.42555570602417,
      "learning_rate": 9.042508851891303e-06,
      "loss": 0.4474180221557617,
      "memory(GiB)": 72.72,
      "step": 12880,
      "token_acc": 0.8705882352941177,
      "train_speed(iter/s)": 0.252029
    },
    {
      "epoch": 1.2018468426452755,
      "grad_norm": 3.4518182277679443,
      "learning_rate": 9.041601028794483e-06,
      "loss": 0.4521501541137695,
      "memory(GiB)": 72.72,
      "step": 12885,
      "train_speed(iter/s)": 0.252036
    },
    {
      "epoch": 1.2023132170506483,
      "grad_norm": 3.148115873336792,
      "learning_rate": 9.040692821151775e-06,
      "loss": 0.50596923828125,
      "memory(GiB)": 72.72,
      "step": 12890,
      "train_speed(iter/s)": 0.252037
    },
    {
      "epoch": 1.2027795914560209,
      "grad_norm": 3.520429849624634,
      "learning_rate": 9.039784229049592e-06,
      "loss": 0.48664169311523436,
      "memory(GiB)": 72.72,
      "step": 12895,
      "token_acc": 0.45161290322580644,
      "train_speed(iter/s)": 0.252042
    },
    {
      "epoch": 1.2032459658613934,
      "grad_norm": 3.942582368850708,
      "learning_rate": 9.038875252574384e-06,
      "loss": 0.4527834415435791,
      "memory(GiB)": 72.72,
      "step": 12900,
      "train_speed(iter/s)": 0.252044
    },
    {
      "epoch": 1.2037123402667662,
      "grad_norm": 21.61525535583496,
      "learning_rate": 9.03796589181264e-06,
      "loss": 0.47465062141418457,
      "memory(GiB)": 72.72,
      "step": 12905,
      "token_acc": 0.425,
      "train_speed(iter/s)": 0.25205
    },
    {
      "epoch": 1.2041787146721388,
      "grad_norm": 4.104272365570068,
      "learning_rate": 9.037056146850878e-06,
      "loss": 0.5051374435424805,
      "memory(GiB)": 72.72,
      "step": 12910,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.2046450890775113,
      "grad_norm": 4.419119834899902,
      "learning_rate": 9.036146017775663e-06,
      "loss": 0.4453582763671875,
      "memory(GiB)": 72.72,
      "step": 12915,
      "token_acc": 0.54,
      "train_speed(iter/s)": 0.252054
    },
    {
      "epoch": 1.2051114634828841,
      "grad_norm": 7.803255558013916,
      "learning_rate": 9.035235504673586e-06,
      "loss": 0.428632926940918,
      "memory(GiB)": 72.72,
      "step": 12920,
      "token_acc": 0.66,
      "train_speed(iter/s)": 0.252061
    },
    {
      "epoch": 1.2055778378882567,
      "grad_norm": 4.395666599273682,
      "learning_rate": 9.034324607631282e-06,
      "loss": 0.45977120399475097,
      "memory(GiB)": 72.72,
      "step": 12925,
      "train_speed(iter/s)": 0.252066
    },
    {
      "epoch": 1.2060442122936292,
      "grad_norm": 2.500499725341797,
      "learning_rate": 9.033413326735419e-06,
      "loss": 0.4488811492919922,
      "memory(GiB)": 72.72,
      "step": 12930,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.206510586699002,
      "grad_norm": 3.3565304279327393,
      "learning_rate": 9.032501662072703e-06,
      "loss": 0.47579526901245117,
      "memory(GiB)": 72.72,
      "step": 12935,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.25207
    },
    {
      "epoch": 1.2069769611043746,
      "grad_norm": 3.482280731201172,
      "learning_rate": 9.031589613729877e-06,
      "loss": 0.44803733825683595,
      "memory(GiB)": 72.72,
      "step": 12940,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.2074433355097471,
      "grad_norm": 3.088540554046631,
      "learning_rate": 9.030677181793718e-06,
      "loss": 0.46781134605407715,
      "memory(GiB)": 72.72,
      "step": 12945,
      "token_acc": 0.4745762711864407,
      "train_speed(iter/s)": 0.252084
    },
    {
      "epoch": 1.20790970991512,
      "grad_norm": 3.322049856185913,
      "learning_rate": 9.029764366351044e-06,
      "loss": 0.41464986801147463,
      "memory(GiB)": 72.72,
      "step": 12950,
      "train_speed(iter/s)": 0.25208
    },
    {
      "epoch": 1.2083760843204925,
      "grad_norm": 3.0483057498931885,
      "learning_rate": 9.028851167488704e-06,
      "loss": 0.49706058502197265,
      "memory(GiB)": 72.72,
      "step": 12955,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.252084
    },
    {
      "epoch": 1.208842458725865,
      "grad_norm": 3.9599716663360596,
      "learning_rate": 9.027937585293587e-06,
      "loss": 0.47843027114868164,
      "memory(GiB)": 72.72,
      "step": 12960,
      "token_acc": 0.4489795918367347,
      "train_speed(iter/s)": 0.252086
    },
    {
      "epoch": 1.2093088331312378,
      "grad_norm": 19.44066047668457,
      "learning_rate": 9.027023619852615e-06,
      "loss": 0.44841823577880857,
      "memory(GiB)": 72.72,
      "step": 12965,
      "train_speed(iter/s)": 0.252084
    },
    {
      "epoch": 1.2097752075366104,
      "grad_norm": 3.415825128555298,
      "learning_rate": 9.026109271252751e-06,
      "loss": 0.46695551872253416,
      "memory(GiB)": 72.72,
      "step": 12970,
      "token_acc": 0.3829787234042553,
      "train_speed(iter/s)": 0.252086
    },
    {
      "epoch": 1.210241581941983,
      "grad_norm": 7.13338565826416,
      "learning_rate": 9.025194539580995e-06,
      "loss": 0.4522867202758789,
      "memory(GiB)": 72.72,
      "step": 12975,
      "train_speed(iter/s)": 0.252085
    },
    {
      "epoch": 1.2107079563473557,
      "grad_norm": 4.992563247680664,
      "learning_rate": 9.024279424924378e-06,
      "loss": 0.48476195335388184,
      "memory(GiB)": 72.72,
      "step": 12980,
      "token_acc": 0.7333333333333333,
      "train_speed(iter/s)": 0.252093
    },
    {
      "epoch": 1.2111743307527283,
      "grad_norm": 4.942391872406006,
      "learning_rate": 9.02336392736997e-06,
      "loss": 0.44594745635986327,
      "memory(GiB)": 72.72,
      "step": 12985,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.252096
    },
    {
      "epoch": 1.2116407051581009,
      "grad_norm": 3.3900177478790283,
      "learning_rate": 9.022448047004879e-06,
      "loss": 0.4778427600860596,
      "memory(GiB)": 72.72,
      "step": 12990,
      "train_speed(iter/s)": 0.252095
    },
    {
      "epoch": 1.2121070795634736,
      "grad_norm": 4.715540885925293,
      "learning_rate": 9.021531783916246e-06,
      "loss": 0.43961315155029296,
      "memory(GiB)": 72.72,
      "step": 12995,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.2521
    },
    {
      "epoch": 1.2125734539688462,
      "grad_norm": 14.52463150024414,
      "learning_rate": 9.020615138191256e-06,
      "loss": 0.5279118061065674,
      "memory(GiB)": 72.72,
      "step": 13000,
      "train_speed(iter/s)": 0.252101
    },
    {
      "epoch": 1.2130398283742188,
      "grad_norm": 3.6572344303131104,
      "learning_rate": 9.019698109917118e-06,
      "loss": 0.49197826385498045,
      "memory(GiB)": 72.72,
      "step": 13005,
      "train_speed(iter/s)": 0.252103
    },
    {
      "epoch": 1.2135062027795915,
      "grad_norm": 3.1329596042633057,
      "learning_rate": 9.01878069918109e-06,
      "loss": 0.4882031440734863,
      "memory(GiB)": 72.72,
      "step": 13010,
      "train_speed(iter/s)": 0.252107
    },
    {
      "epoch": 1.213972577184964,
      "grad_norm": 3.161792039871216,
      "learning_rate": 9.017862906070457e-06,
      "loss": 0.42269220352172854,
      "memory(GiB)": 72.72,
      "step": 13015,
      "train_speed(iter/s)": 0.252117
    },
    {
      "epoch": 1.2144389515903367,
      "grad_norm": 6.667512893676758,
      "learning_rate": 9.016944730672547e-06,
      "loss": 0.4541186809539795,
      "memory(GiB)": 72.72,
      "step": 13020,
      "token_acc": 0.5681818181818182,
      "train_speed(iter/s)": 0.252121
    },
    {
      "epoch": 1.2149053259957094,
      "grad_norm": 4.285848140716553,
      "learning_rate": 9.016026173074719e-06,
      "loss": 0.48069095611572266,
      "memory(GiB)": 72.72,
      "step": 13025,
      "train_speed(iter/s)": 0.252127
    },
    {
      "epoch": 1.215371700401082,
      "grad_norm": 3.7545721530914307,
      "learning_rate": 9.015107233364374e-06,
      "loss": 0.45309133529663087,
      "memory(GiB)": 72.72,
      "step": 13030,
      "token_acc": 0.7716049382716049,
      "train_speed(iter/s)": 0.252131
    },
    {
      "epoch": 1.2158380748064546,
      "grad_norm": 5.401941299438477,
      "learning_rate": 9.014187911628944e-06,
      "loss": 0.4810193538665771,
      "memory(GiB)": 72.72,
      "step": 13035,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252134
    },
    {
      "epoch": 1.2163044492118273,
      "grad_norm": 5.862877368927002,
      "learning_rate": 9.0132682079559e-06,
      "loss": 0.4767906188964844,
      "memory(GiB)": 72.72,
      "step": 13040,
      "token_acc": 0.3064516129032258,
      "train_speed(iter/s)": 0.252139
    },
    {
      "epoch": 1.2167708236172,
      "grad_norm": 4.6252288818359375,
      "learning_rate": 9.012348122432749e-06,
      "loss": 0.44178028106689454,
      "memory(GiB)": 72.72,
      "step": 13045,
      "token_acc": 0.4098360655737705,
      "train_speed(iter/s)": 0.252136
    },
    {
      "epoch": 1.2172371980225725,
      "grad_norm": 5.541245937347412,
      "learning_rate": 9.011427655147035e-06,
      "loss": 0.4367171287536621,
      "memory(GiB)": 72.72,
      "step": 13050,
      "train_speed(iter/s)": 0.252138
    },
    {
      "epoch": 1.2177035724279452,
      "grad_norm": 3.393066883087158,
      "learning_rate": 9.010506806186336e-06,
      "loss": 0.46112470626831054,
      "memory(GiB)": 72.72,
      "step": 13055,
      "token_acc": 0.4409448818897638,
      "train_speed(iter/s)": 0.252142
    },
    {
      "epoch": 1.2181699468333178,
      "grad_norm": 3.767138957977295,
      "learning_rate": 9.009585575638271e-06,
      "loss": 0.4446086883544922,
      "memory(GiB)": 72.72,
      "step": 13060,
      "train_speed(iter/s)": 0.252147
    },
    {
      "epoch": 1.2186363212386904,
      "grad_norm": 3.847919225692749,
      "learning_rate": 9.00866396359049e-06,
      "loss": 0.44226875305175783,
      "memory(GiB)": 72.72,
      "step": 13065,
      "token_acc": 0.8977272727272727,
      "train_speed(iter/s)": 0.252147
    },
    {
      "epoch": 1.2191026956440632,
      "grad_norm": 4.604024887084961,
      "learning_rate": 9.00774197013068e-06,
      "loss": 0.4510353565216064,
      "memory(GiB)": 72.72,
      "step": 13070,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.252144
    },
    {
      "epoch": 1.2195690700494357,
      "grad_norm": 2.7847900390625,
      "learning_rate": 9.00681959534657e-06,
      "loss": 0.4249542713165283,
      "memory(GiB)": 72.72,
      "step": 13075,
      "train_speed(iter/s)": 0.252151
    },
    {
      "epoch": 1.2200354444548083,
      "grad_norm": 2.527569532394409,
      "learning_rate": 9.005896839325917e-06,
      "loss": 0.45798182487487793,
      "memory(GiB)": 72.72,
      "step": 13080,
      "token_acc": 0.5166666666666667,
      "train_speed(iter/s)": 0.252159
    },
    {
      "epoch": 1.220501818860181,
      "grad_norm": 3.292083263397217,
      "learning_rate": 9.00497370215652e-06,
      "loss": 0.4642971038818359,
      "memory(GiB)": 72.72,
      "step": 13085,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 1.2209681932655536,
      "grad_norm": 8.501914024353027,
      "learning_rate": 9.004050183926214e-06,
      "loss": 0.47755746841430663,
      "memory(GiB)": 72.72,
      "step": 13090,
      "train_speed(iter/s)": 0.252161
    },
    {
      "epoch": 1.2214345676709262,
      "grad_norm": 4.685376167297363,
      "learning_rate": 9.003126284722868e-06,
      "loss": 0.4443825244903564,
      "memory(GiB)": 72.72,
      "step": 13095,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 1.221900942076299,
      "grad_norm": 3.5138680934906006,
      "learning_rate": 9.002202004634389e-06,
      "loss": 0.4105199337005615,
      "memory(GiB)": 72.72,
      "step": 13100,
      "train_speed(iter/s)": 0.252167
    },
    {
      "epoch": 1.2223673164816715,
      "grad_norm": 3.4483203887939453,
      "learning_rate": 9.001277343748716e-06,
      "loss": 0.5019430160522461,
      "memory(GiB)": 72.72,
      "step": 13105,
      "token_acc": 0.527027027027027,
      "train_speed(iter/s)": 0.252161
    },
    {
      "epoch": 1.222833690887044,
      "grad_norm": 5.045104026794434,
      "learning_rate": 9.00035230215383e-06,
      "loss": 0.46776299476623534,
      "memory(GiB)": 72.72,
      "step": 13110,
      "token_acc": 0.31746031746031744,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 1.2233000652924169,
      "grad_norm": 3.6438238620758057,
      "learning_rate": 8.999426879937746e-06,
      "loss": 0.46588926315307616,
      "memory(GiB)": 72.72,
      "step": 13115,
      "token_acc": 0.35555555555555557,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 1.2237664396977894,
      "grad_norm": 5.724114894866943,
      "learning_rate": 8.998501077188516e-06,
      "loss": 0.4797815322875977,
      "memory(GiB)": 72.72,
      "step": 13120,
      "train_speed(iter/s)": 0.252165
    },
    {
      "epoch": 1.224232814103162,
      "grad_norm": 3.5346076488494873,
      "learning_rate": 8.997574893994225e-06,
      "loss": 0.454119873046875,
      "memory(GiB)": 72.72,
      "step": 13125,
      "token_acc": 0.7215189873417721,
      "train_speed(iter/s)": 0.252167
    },
    {
      "epoch": 1.2246991885085348,
      "grad_norm": 5.866003513336182,
      "learning_rate": 8.996648330443e-06,
      "loss": 0.49214396476745603,
      "memory(GiB)": 72.72,
      "step": 13130,
      "token_acc": 0.9012345679012346,
      "train_speed(iter/s)": 0.252166
    },
    {
      "epoch": 1.2251655629139073,
      "grad_norm": 2.8336329460144043,
      "learning_rate": 8.995721386622995e-06,
      "loss": 0.4453281879425049,
      "memory(GiB)": 72.72,
      "step": 13135,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.252159
    },
    {
      "epoch": 1.2256319373192799,
      "grad_norm": 4.670436382293701,
      "learning_rate": 8.994794062622412e-06,
      "loss": 0.44489479064941406,
      "memory(GiB)": 72.72,
      "step": 13140,
      "train_speed(iter/s)": 0.252165
    },
    {
      "epoch": 1.2260983117246527,
      "grad_norm": 8.906989097595215,
      "learning_rate": 8.99386635852948e-06,
      "loss": 0.49491233825683595,
      "memory(GiB)": 72.72,
      "step": 13145,
      "token_acc": 0.5157894736842106,
      "train_speed(iter/s)": 0.252171
    },
    {
      "epoch": 1.2265646861300252,
      "grad_norm": 4.381726264953613,
      "learning_rate": 8.992938274432465e-06,
      "loss": 0.43033971786499026,
      "memory(GiB)": 72.72,
      "step": 13150,
      "train_speed(iter/s)": 0.252169
    },
    {
      "epoch": 1.2270310605353978,
      "grad_norm": 4.525888919830322,
      "learning_rate": 8.992009810419676e-06,
      "loss": 0.5036400318145752,
      "memory(GiB)": 72.72,
      "step": 13155,
      "train_speed(iter/s)": 0.252168
    },
    {
      "epoch": 1.2274974349407706,
      "grad_norm": 3.45076322555542,
      "learning_rate": 8.99108096657945e-06,
      "loss": 0.4395784378051758,
      "memory(GiB)": 72.72,
      "step": 13160,
      "token_acc": 0.927710843373494,
      "train_speed(iter/s)": 0.252169
    },
    {
      "epoch": 1.2279638093461431,
      "grad_norm": 3.4612839221954346,
      "learning_rate": 8.990151743000166e-06,
      "loss": 0.4458251953125,
      "memory(GiB)": 72.72,
      "step": 13165,
      "train_speed(iter/s)": 0.252174
    },
    {
      "epoch": 1.2284301837515157,
      "grad_norm": 3.0334208011627197,
      "learning_rate": 8.989222139770235e-06,
      "loss": 0.47081761360168456,
      "memory(GiB)": 72.72,
      "step": 13170,
      "train_speed(iter/s)": 0.252178
    },
    {
      "epoch": 1.2288965581568885,
      "grad_norm": 5.938080310821533,
      "learning_rate": 8.988292156978107e-06,
      "loss": 0.47255620956420896,
      "memory(GiB)": 72.72,
      "step": 13175,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252173
    },
    {
      "epoch": 1.229362932562261,
      "grad_norm": 3.1419012546539307,
      "learning_rate": 8.987361794712266e-06,
      "loss": 0.4109065055847168,
      "memory(GiB)": 72.72,
      "step": 13180,
      "token_acc": 0.4626865671641791,
      "train_speed(iter/s)": 0.252173
    },
    {
      "epoch": 1.2298293069676336,
      "grad_norm": 3.9581806659698486,
      "learning_rate": 8.986431053061233e-06,
      "loss": 0.47725591659545896,
      "memory(GiB)": 72.72,
      "step": 13185,
      "train_speed(iter/s)": 0.252171
    },
    {
      "epoch": 1.2302956813730062,
      "grad_norm": 4.0475616455078125,
      "learning_rate": 8.985499932113566e-06,
      "loss": 0.44598970413208006,
      "memory(GiB)": 72.72,
      "step": 13190,
      "train_speed(iter/s)": 0.252169
    },
    {
      "epoch": 1.230762055778379,
      "grad_norm": 2.498317003250122,
      "learning_rate": 8.984568431957858e-06,
      "loss": 0.45662784576416016,
      "memory(GiB)": 72.72,
      "step": 13195,
      "token_acc": 0.40860215053763443,
      "train_speed(iter/s)": 0.25217
    },
    {
      "epoch": 1.2312284301837515,
      "grad_norm": 3.740684986114502,
      "learning_rate": 8.98363655268274e-06,
      "loss": 0.4877042770385742,
      "memory(GiB)": 72.72,
      "step": 13200,
      "train_speed(iter/s)": 0.25217
    },
    {
      "epoch": 1.231694804589124,
      "grad_norm": 3.726820468902588,
      "learning_rate": 8.982704294376874e-06,
      "loss": 0.46552562713623047,
      "memory(GiB)": 72.72,
      "step": 13205,
      "train_speed(iter/s)": 0.252166
    },
    {
      "epoch": 1.2321611789944968,
      "grad_norm": 4.2738447189331055,
      "learning_rate": 8.981771657128965e-06,
      "loss": 0.45481290817260744,
      "memory(GiB)": 72.72,
      "step": 13210,
      "token_acc": 0.6785714285714286,
      "train_speed(iter/s)": 0.252168
    },
    {
      "epoch": 1.2326275533998694,
      "grad_norm": 3.911903142929077,
      "learning_rate": 8.980838641027747e-06,
      "loss": 0.4607519626617432,
      "memory(GiB)": 72.72,
      "step": 13215,
      "train_speed(iter/s)": 0.252178
    },
    {
      "epoch": 1.233093927805242,
      "grad_norm": 4.224345684051514,
      "learning_rate": 8.979905246161997e-06,
      "loss": 0.43765554428100584,
      "memory(GiB)": 72.72,
      "step": 13220,
      "train_speed(iter/s)": 0.25218
    },
    {
      "epoch": 1.2335603022106147,
      "grad_norm": 5.917801380157471,
      "learning_rate": 8.978971472620524e-06,
      "loss": 0.4601790428161621,
      "memory(GiB)": 72.72,
      "step": 13225,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.252183
    },
    {
      "epoch": 1.2340266766159873,
      "grad_norm": 9.97541618347168,
      "learning_rate": 8.978037320492172e-06,
      "loss": 0.49794845581054686,
      "memory(GiB)": 72.72,
      "step": 13230,
      "token_acc": 0.37209302325581395,
      "train_speed(iter/s)": 0.252186
    },
    {
      "epoch": 1.2344930510213599,
      "grad_norm": 3.6662144660949707,
      "learning_rate": 8.977102789865824e-06,
      "loss": 0.4407342910766602,
      "memory(GiB)": 72.72,
      "step": 13235,
      "train_speed(iter/s)": 0.25219
    },
    {
      "epoch": 1.2349594254267326,
      "grad_norm": 6.232382774353027,
      "learning_rate": 8.976167880830397e-06,
      "loss": 0.4672098159790039,
      "memory(GiB)": 72.72,
      "step": 13240,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.252187
    },
    {
      "epoch": 1.2354257998321052,
      "grad_norm": 3.0573642253875732,
      "learning_rate": 8.975232593474843e-06,
      "loss": 0.41649975776672366,
      "memory(GiB)": 72.72,
      "step": 13245,
      "token_acc": 0.6320754716981132,
      "train_speed(iter/s)": 0.25219
    },
    {
      "epoch": 1.2358921742374778,
      "grad_norm": 6.754461288452148,
      "learning_rate": 8.974296927888158e-06,
      "loss": 0.42777190208435056,
      "memory(GiB)": 72.72,
      "step": 13250,
      "train_speed(iter/s)": 0.252195
    },
    {
      "epoch": 1.2363585486428506,
      "grad_norm": 2.3938331604003906,
      "learning_rate": 8.97336088415936e-06,
      "loss": 0.4439080238342285,
      "memory(GiB)": 72.72,
      "step": 13255,
      "token_acc": 0.8625,
      "train_speed(iter/s)": 0.252196
    },
    {
      "epoch": 1.2368249230482231,
      "grad_norm": 4.900398254394531,
      "learning_rate": 8.972424462377517e-06,
      "loss": 0.4623075485229492,
      "memory(GiB)": 72.72,
      "step": 13260,
      "train_speed(iter/s)": 0.2522
    },
    {
      "epoch": 1.2372912974535957,
      "grad_norm": 3.6542248725891113,
      "learning_rate": 8.97148766263172e-06,
      "loss": 0.4450861930847168,
      "memory(GiB)": 72.72,
      "step": 13265,
      "train_speed(iter/s)": 0.252207
    },
    {
      "epoch": 1.2377576718589685,
      "grad_norm": 12.467278480529785,
      "learning_rate": 8.970550485011108e-06,
      "loss": 0.48256425857543944,
      "memory(GiB)": 72.72,
      "step": 13270,
      "token_acc": 0.7697368421052632,
      "train_speed(iter/s)": 0.252214
    },
    {
      "epoch": 1.238224046264341,
      "grad_norm": 3.4399197101593018,
      "learning_rate": 8.969612929604849e-06,
      "loss": 0.4902463912963867,
      "memory(GiB)": 72.72,
      "step": 13275,
      "token_acc": 0.46551724137931033,
      "train_speed(iter/s)": 0.252219
    },
    {
      "epoch": 1.2386904206697136,
      "grad_norm": 3.2841944694519043,
      "learning_rate": 8.96867499650215e-06,
      "loss": 0.4607067584991455,
      "memory(GiB)": 72.72,
      "step": 13280,
      "train_speed(iter/s)": 0.25222
    },
    {
      "epoch": 1.2391567950750864,
      "grad_norm": 2.830080986022949,
      "learning_rate": 8.967736685792249e-06,
      "loss": 0.42621560096740724,
      "memory(GiB)": 72.72,
      "step": 13285,
      "token_acc": 0.5656565656565656,
      "train_speed(iter/s)": 0.252219
    },
    {
      "epoch": 1.239623169480459,
      "grad_norm": 3.7474007606506348,
      "learning_rate": 8.966797997564426e-06,
      "loss": 0.46389074325561525,
      "memory(GiB)": 72.72,
      "step": 13290,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.25223
    },
    {
      "epoch": 1.2400895438858315,
      "grad_norm": 4.160800933837891,
      "learning_rate": 8.965858931907993e-06,
      "loss": 0.479232120513916,
      "memory(GiB)": 72.72,
      "step": 13295,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.252234
    },
    {
      "epoch": 1.2405559182912043,
      "grad_norm": 3.9478681087493896,
      "learning_rate": 8.964919488912301e-06,
      "loss": 0.44049835205078125,
      "memory(GiB)": 72.72,
      "step": 13300,
      "token_acc": 0.8456375838926175,
      "train_speed(iter/s)": 0.252236
    },
    {
      "epoch": 1.2410222926965768,
      "grad_norm": 5.344112396240234,
      "learning_rate": 8.963979668666733e-06,
      "loss": 0.44943647384643554,
      "memory(GiB)": 72.72,
      "step": 13305,
      "train_speed(iter/s)": 0.25224
    },
    {
      "epoch": 1.2414886671019494,
      "grad_norm": 3.3290743827819824,
      "learning_rate": 8.963039471260711e-06,
      "loss": 0.41731891632080076,
      "memory(GiB)": 72.72,
      "step": 13310,
      "train_speed(iter/s)": 0.252242
    },
    {
      "epoch": 1.2419550415073222,
      "grad_norm": 3.9439713954925537,
      "learning_rate": 8.962098896783691e-06,
      "loss": 0.49130024909973147,
      "memory(GiB)": 72.72,
      "step": 13315,
      "token_acc": 0.7922077922077922,
      "train_speed(iter/s)": 0.25224
    },
    {
      "epoch": 1.2424214159126947,
      "grad_norm": 5.083515644073486,
      "learning_rate": 8.961157945325167e-06,
      "loss": 0.4354720115661621,
      "memory(GiB)": 72.72,
      "step": 13320,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.252242
    },
    {
      "epoch": 1.2428877903180673,
      "grad_norm": 4.149221420288086,
      "learning_rate": 8.960216616974667e-06,
      "loss": 0.4602669715881348,
      "memory(GiB)": 72.72,
      "step": 13325,
      "train_speed(iter/s)": 0.25224
    },
    {
      "epoch": 1.24335416472344,
      "grad_norm": 3.0373096466064453,
      "learning_rate": 8.959274911821757e-06,
      "loss": 0.4407684803009033,
      "memory(GiB)": 72.72,
      "step": 13330,
      "token_acc": 0.36363636363636365,
      "train_speed(iter/s)": 0.252234
    },
    {
      "epoch": 1.2438205391288126,
      "grad_norm": 3.4099819660186768,
      "learning_rate": 8.958332829956034e-06,
      "loss": 0.47504572868347167,
      "memory(GiB)": 72.72,
      "step": 13335,
      "token_acc": 0.36363636363636365,
      "train_speed(iter/s)": 0.252237
    },
    {
      "epoch": 1.2442869135341852,
      "grad_norm": 4.290187835693359,
      "learning_rate": 8.957390371467137e-06,
      "loss": 0.5103266716003418,
      "memory(GiB)": 72.72,
      "step": 13340,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.252237
    },
    {
      "epoch": 1.244753287939558,
      "grad_norm": 4.337111473083496,
      "learning_rate": 8.956447536444737e-06,
      "loss": 0.4501331806182861,
      "memory(GiB)": 72.72,
      "step": 13345,
      "token_acc": 0.5806451612903226,
      "train_speed(iter/s)": 0.252237
    },
    {
      "epoch": 1.2452196623449305,
      "grad_norm": 4.203765869140625,
      "learning_rate": 8.955504324978544e-06,
      "loss": 0.49271860122680666,
      "memory(GiB)": 72.72,
      "step": 13350,
      "train_speed(iter/s)": 0.252236
    },
    {
      "epoch": 1.245686036750303,
      "grad_norm": 5.0312724113464355,
      "learning_rate": 8.954560737158298e-06,
      "loss": 0.4592737197875977,
      "memory(GiB)": 72.72,
      "step": 13355,
      "train_speed(iter/s)": 0.252237
    },
    {
      "epoch": 1.2461524111556757,
      "grad_norm": 3.9569361209869385,
      "learning_rate": 8.953616773073778e-06,
      "loss": 0.4541201591491699,
      "memory(GiB)": 72.72,
      "step": 13360,
      "train_speed(iter/s)": 0.252239
    },
    {
      "epoch": 1.2466187855610484,
      "grad_norm": 4.162750244140625,
      "learning_rate": 8.952672432814805e-06,
      "loss": 0.4603874206542969,
      "memory(GiB)": 72.72,
      "step": 13365,
      "train_speed(iter/s)": 0.252245
    },
    {
      "epoch": 1.247085159966421,
      "grad_norm": 4.7973103523254395,
      "learning_rate": 8.951727716471226e-06,
      "loss": 0.4547120094299316,
      "memory(GiB)": 72.72,
      "step": 13370,
      "token_acc": 0.8552631578947368,
      "train_speed(iter/s)": 0.252248
    },
    {
      "epoch": 1.2475515343717936,
      "grad_norm": 4.567653656005859,
      "learning_rate": 8.950782624132927e-06,
      "loss": 0.4529869079589844,
      "memory(GiB)": 72.72,
      "step": 13375,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.25225
    },
    {
      "epoch": 1.2480179087771663,
      "grad_norm": 4.627090930938721,
      "learning_rate": 8.949837155889832e-06,
      "loss": 0.4720608711242676,
      "memory(GiB)": 72.72,
      "step": 13380,
      "train_speed(iter/s)": 0.252248
    },
    {
      "epoch": 1.248484283182539,
      "grad_norm": 4.895605087280273,
      "learning_rate": 8.9488913118319e-06,
      "loss": 0.49006853103637693,
      "memory(GiB)": 72.72,
      "step": 13385,
      "token_acc": 0.695364238410596,
      "train_speed(iter/s)": 0.25225
    },
    {
      "epoch": 1.2489506575879115,
      "grad_norm": 3.228802442550659,
      "learning_rate": 8.947945092049125e-06,
      "loss": 0.42083349227905276,
      "memory(GiB)": 72.72,
      "step": 13390,
      "token_acc": 0.97,
      "train_speed(iter/s)": 0.252162
    },
    {
      "epoch": 1.2494170319932842,
      "grad_norm": 4.17619514465332,
      "learning_rate": 8.946998496631536e-06,
      "loss": 0.47347235679626465,
      "memory(GiB)": 72.72,
      "step": 13395,
      "train_speed(iter/s)": 0.252161
    },
    {
      "epoch": 1.2498834063986568,
      "grad_norm": 3.836721897125244,
      "learning_rate": 8.9460515256692e-06,
      "loss": 0.44178619384765627,
      "memory(GiB)": 72.72,
      "step": 13400,
      "token_acc": 0.4067796610169492,
      "train_speed(iter/s)": 0.25217
    },
    {
      "epoch": 1.2503497808040294,
      "grad_norm": 6.059642791748047,
      "learning_rate": 8.945104179252215e-06,
      "loss": 0.4448598861694336,
      "memory(GiB)": 72.72,
      "step": 13405,
      "token_acc": 0.4067796610169492,
      "train_speed(iter/s)": 0.252168
    },
    {
      "epoch": 1.2508161552094021,
      "grad_norm": 5.320610046386719,
      "learning_rate": 8.944156457470722e-06,
      "loss": 0.44193711280822756,
      "memory(GiB)": 72.72,
      "step": 13410,
      "train_speed(iter/s)": 0.252167
    },
    {
      "epoch": 1.2512825296147747,
      "grad_norm": 5.790449619293213,
      "learning_rate": 8.943208360414894e-06,
      "loss": 0.46213741302490235,
      "memory(GiB)": 72.72,
      "step": 13415,
      "train_speed(iter/s)": 0.252166
    },
    {
      "epoch": 1.2517489040201473,
      "grad_norm": 4.261415004730225,
      "learning_rate": 8.942259888174935e-06,
      "loss": 0.43418292999267577,
      "memory(GiB)": 72.72,
      "step": 13420,
      "train_speed(iter/s)": 0.252168
    },
    {
      "epoch": 1.25221527842552,
      "grad_norm": 3.5586905479431152,
      "learning_rate": 8.941311040841095e-06,
      "loss": 0.4866168975830078,
      "memory(GiB)": 72.72,
      "step": 13425,
      "train_speed(iter/s)": 0.252172
    },
    {
      "epoch": 1.2526816528308926,
      "grad_norm": 3.7341175079345703,
      "learning_rate": 8.94036181850365e-06,
      "loss": 0.4898648738861084,
      "memory(GiB)": 72.72,
      "step": 13430,
      "token_acc": 0.9035087719298246,
      "train_speed(iter/s)": 0.252076
    },
    {
      "epoch": 1.2531480272362652,
      "grad_norm": 3.6835238933563232,
      "learning_rate": 8.939412221252914e-06,
      "loss": 0.4454324245452881,
      "memory(GiB)": 72.72,
      "step": 13435,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.252072
    },
    {
      "epoch": 1.253614401641638,
      "grad_norm": 3.1429100036621094,
      "learning_rate": 8.938462249179243e-06,
      "loss": 0.4212244987487793,
      "memory(GiB)": 72.72,
      "step": 13440,
      "train_speed(iter/s)": 0.252076
    },
    {
      "epoch": 1.2540807760470105,
      "grad_norm": 6.719107627868652,
      "learning_rate": 8.937511902373022e-06,
      "loss": 0.4730405330657959,
      "memory(GiB)": 72.72,
      "step": 13445,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252077
    },
    {
      "epoch": 1.254547150452383,
      "grad_norm": 3.1321895122528076,
      "learning_rate": 8.936561180924672e-06,
      "loss": 0.4611659526824951,
      "memory(GiB)": 72.72,
      "step": 13450,
      "train_speed(iter/s)": 0.252078
    },
    {
      "epoch": 1.2550135248577559,
      "grad_norm": 3.7089040279388428,
      "learning_rate": 8.935610084924654e-06,
      "loss": 0.4503913402557373,
      "memory(GiB)": 72.72,
      "step": 13455,
      "token_acc": 0.8651685393258427,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.2554798992631284,
      "grad_norm": 5.181633472442627,
      "learning_rate": 8.934658614463458e-06,
      "loss": 0.42075114250183104,
      "memory(GiB)": 72.72,
      "step": 13460,
      "train_speed(iter/s)": 0.25208
    },
    {
      "epoch": 1.255946273668501,
      "grad_norm": 3.4042325019836426,
      "learning_rate": 8.933706769631619e-06,
      "loss": 0.422044038772583,
      "memory(GiB)": 72.72,
      "step": 13465,
      "train_speed(iter/s)": 0.252081
    },
    {
      "epoch": 1.2564126480738738,
      "grad_norm": 2.684601306915283,
      "learning_rate": 8.932754550519695e-06,
      "loss": 0.4790314197540283,
      "memory(GiB)": 72.72,
      "step": 13470,
      "token_acc": 0.9358974358974359,
      "train_speed(iter/s)": 0.252081
    },
    {
      "epoch": 1.2568790224792463,
      "grad_norm": 3.5292537212371826,
      "learning_rate": 8.931801957218294e-06,
      "loss": 0.4315198421478271,
      "memory(GiB)": 72.72,
      "step": 13475,
      "token_acc": 0.9174311926605505,
      "train_speed(iter/s)": 0.252086
    },
    {
      "epoch": 1.2573453968846189,
      "grad_norm": 3.914425849914551,
      "learning_rate": 8.930848989818049e-06,
      "loss": 0.4199251651763916,
      "memory(GiB)": 72.72,
      "step": 13480,
      "train_speed(iter/s)": 0.252086
    },
    {
      "epoch": 1.2578117712899917,
      "grad_norm": 2.6486306190490723,
      "learning_rate": 8.92989564840963e-06,
      "loss": 0.4430381298065186,
      "memory(GiB)": 72.72,
      "step": 13485,
      "token_acc": 0.5425531914893617,
      "train_speed(iter/s)": 0.252092
    },
    {
      "epoch": 1.2582781456953642,
      "grad_norm": 4.595702648162842,
      "learning_rate": 8.928941933083748e-06,
      "loss": 0.45023293495178224,
      "memory(GiB)": 72.72,
      "step": 13490,
      "token_acc": 0.49019607843137253,
      "train_speed(iter/s)": 0.252093
    },
    {
      "epoch": 1.2587445201007368,
      "grad_norm": 4.824710369110107,
      "learning_rate": 8.927987843931142e-06,
      "loss": 0.43652772903442383,
      "memory(GiB)": 72.72,
      "step": 13495,
      "train_speed(iter/s)": 0.252089
    },
    {
      "epoch": 1.2592108945061096,
      "grad_norm": 2.9592630863189697,
      "learning_rate": 8.927033381042596e-06,
      "loss": 0.462841796875,
      "memory(GiB)": 72.72,
      "step": 13500,
      "token_acc": 0.4067796610169492,
      "train_speed(iter/s)": 0.252093
    },
    {
      "epoch": 1.2596772689114821,
      "grad_norm": 2.2782037258148193,
      "learning_rate": 8.92607854450892e-06,
      "loss": 0.4483345031738281,
      "memory(GiB)": 72.72,
      "step": 13505,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.252091
    },
    {
      "epoch": 1.2601436433168547,
      "grad_norm": 3.1176939010620117,
      "learning_rate": 8.925123334420966e-06,
      "loss": 0.42751388549804686,
      "memory(GiB)": 72.72,
      "step": 13510,
      "train_speed(iter/s)": 0.252091
    },
    {
      "epoch": 1.2606100177222275,
      "grad_norm": 3.773735761642456,
      "learning_rate": 8.924167750869617e-06,
      "loss": 0.45568075180053713,
      "memory(GiB)": 72.72,
      "step": 13515,
      "train_speed(iter/s)": 0.25209
    },
    {
      "epoch": 1.2610763921276,
      "grad_norm": 3.3761167526245117,
      "learning_rate": 8.923211793945796e-06,
      "loss": 0.45899271965026855,
      "memory(GiB)": 72.72,
      "step": 13520,
      "token_acc": 0.9326923076923077,
      "train_speed(iter/s)": 0.252097
    },
    {
      "epoch": 1.2615427665329726,
      "grad_norm": 3.937746524810791,
      "learning_rate": 8.922255463740458e-06,
      "loss": 0.47281084060668943,
      "memory(GiB)": 72.72,
      "step": 13525,
      "train_speed(iter/s)": 0.2521
    },
    {
      "epoch": 1.2620091409383454,
      "grad_norm": 8.0355806350708,
      "learning_rate": 8.921298760344597e-06,
      "loss": 0.4527273178100586,
      "memory(GiB)": 72.72,
      "step": 13530,
      "token_acc": 0.5348837209302325,
      "train_speed(iter/s)": 0.252094
    },
    {
      "epoch": 1.262475515343718,
      "grad_norm": 4.567580223083496,
      "learning_rate": 8.920341683849237e-06,
      "loss": 0.44365854263305665,
      "memory(GiB)": 72.72,
      "step": 13535,
      "train_speed(iter/s)": 0.252094
    },
    {
      "epoch": 1.2629418897490905,
      "grad_norm": 4.694931983947754,
      "learning_rate": 8.919384234345444e-06,
      "loss": 0.5171058654785157,
      "memory(GiB)": 72.72,
      "step": 13540,
      "token_acc": 0.4642857142857143,
      "train_speed(iter/s)": 0.252099
    },
    {
      "epoch": 1.2634082641544633,
      "grad_norm": 4.9751996994018555,
      "learning_rate": 8.918426411924313e-06,
      "loss": 0.45746679306030275,
      "memory(GiB)": 72.72,
      "step": 13545,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.2638746385598358,
      "grad_norm": 4.187623023986816,
      "learning_rate": 8.91746821667698e-06,
      "loss": 0.45616817474365234,
      "memory(GiB)": 72.72,
      "step": 13550,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.2643410129652084,
      "grad_norm": 3.7928626537323,
      "learning_rate": 8.916509648694617e-06,
      "loss": 0.4247809886932373,
      "memory(GiB)": 72.72,
      "step": 13555,
      "token_acc": 0.32075471698113206,
      "train_speed(iter/s)": 0.252119
    },
    {
      "epoch": 1.2648073873705812,
      "grad_norm": 3.2222707271575928,
      "learning_rate": 8.915550708068425e-06,
      "loss": 0.4266561508178711,
      "memory(GiB)": 72.72,
      "step": 13560,
      "token_acc": 0.6724137931034483,
      "train_speed(iter/s)": 0.252117
    },
    {
      "epoch": 1.2652737617759537,
      "grad_norm": 3.6676409244537354,
      "learning_rate": 8.914591394889645e-06,
      "loss": 0.41317238807678225,
      "memory(GiB)": 72.72,
      "step": 13565,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25212
    },
    {
      "epoch": 1.2657401361813263,
      "grad_norm": 6.580312728881836,
      "learning_rate": 8.913631709249552e-06,
      "loss": 0.4765749931335449,
      "memory(GiB)": 72.72,
      "step": 13570,
      "train_speed(iter/s)": 0.252124
    },
    {
      "epoch": 1.266206510586699,
      "grad_norm": 4.642073631286621,
      "learning_rate": 8.91267165123946e-06,
      "loss": 0.4446393013000488,
      "memory(GiB)": 72.72,
      "step": 13575,
      "train_speed(iter/s)": 0.252129
    },
    {
      "epoch": 1.2666728849920716,
      "grad_norm": 3.4702107906341553,
      "learning_rate": 8.911711220950713e-06,
      "loss": 0.4440616607666016,
      "memory(GiB)": 72.72,
      "step": 13580,
      "train_speed(iter/s)": 0.252129
    },
    {
      "epoch": 1.2671392593974442,
      "grad_norm": 5.0747880935668945,
      "learning_rate": 8.910750418474692e-06,
      "loss": 0.4739387035369873,
      "memory(GiB)": 72.72,
      "step": 13585,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.252127
    },
    {
      "epoch": 1.267605633802817,
      "grad_norm": 4.360795974731445,
      "learning_rate": 8.909789243902818e-06,
      "loss": 0.49632840156555175,
      "memory(GiB)": 72.72,
      "step": 13590,
      "train_speed(iter/s)": 0.25213
    },
    {
      "epoch": 1.2680720082081895,
      "grad_norm": 5.431789398193359,
      "learning_rate": 8.90882769732654e-06,
      "loss": 0.457391357421875,
      "memory(GiB)": 72.72,
      "step": 13595,
      "train_speed(iter/s)": 0.25213
    },
    {
      "epoch": 1.268538382613562,
      "grad_norm": 5.607455730438232,
      "learning_rate": 8.90786577883735e-06,
      "loss": 0.4680156230926514,
      "memory(GiB)": 72.72,
      "step": 13600,
      "train_speed(iter/s)": 0.252131
    },
    {
      "epoch": 1.269004757018935,
      "grad_norm": 3.8731133937835693,
      "learning_rate": 8.90690348852677e-06,
      "loss": 0.4782904624938965,
      "memory(GiB)": 72.72,
      "step": 13605,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.252135
    },
    {
      "epoch": 1.2694711314243075,
      "grad_norm": 4.295690536499023,
      "learning_rate": 8.905940826486357e-06,
      "loss": 0.4904186248779297,
      "memory(GiB)": 72.72,
      "step": 13610,
      "train_speed(iter/s)": 0.252137
    },
    {
      "epoch": 1.26993750582968,
      "grad_norm": 3.549778938293457,
      "learning_rate": 8.904977792807708e-06,
      "loss": 0.4200422286987305,
      "memory(GiB)": 72.72,
      "step": 13615,
      "train_speed(iter/s)": 0.252143
    },
    {
      "epoch": 1.2704038802350528,
      "grad_norm": 3.0502007007598877,
      "learning_rate": 8.904014387582449e-06,
      "loss": 0.43894362449645996,
      "memory(GiB)": 72.72,
      "step": 13620,
      "token_acc": 0.9354838709677419,
      "train_speed(iter/s)": 0.252145
    },
    {
      "epoch": 1.2708702546404254,
      "grad_norm": 4.342861175537109,
      "learning_rate": 8.903050610902252e-06,
      "loss": 0.45670576095581056,
      "memory(GiB)": 72.72,
      "step": 13625,
      "train_speed(iter/s)": 0.252149
    },
    {
      "epoch": 1.271336629045798,
      "grad_norm": 6.434442043304443,
      "learning_rate": 8.902086462858808e-06,
      "loss": 0.43764796257019045,
      "memory(GiB)": 72.72,
      "step": 13630,
      "token_acc": 0.7121212121212122,
      "train_speed(iter/s)": 0.252148
    },
    {
      "epoch": 1.2718030034511707,
      "grad_norm": 3.034543037414551,
      "learning_rate": 8.901121943543862e-06,
      "loss": 0.4433603763580322,
      "memory(GiB)": 72.72,
      "step": 13635,
      "token_acc": 0.8137931034482758,
      "train_speed(iter/s)": 0.252152
    },
    {
      "epoch": 1.2722693778565433,
      "grad_norm": 3.5655646324157715,
      "learning_rate": 8.90015705304918e-06,
      "loss": 0.4570327281951904,
      "memory(GiB)": 72.72,
      "step": 13640,
      "train_speed(iter/s)": 0.252155
    },
    {
      "epoch": 1.2727357522619158,
      "grad_norm": 4.477649688720703,
      "learning_rate": 8.899191791466566e-06,
      "loss": 0.45786523818969727,
      "memory(GiB)": 72.72,
      "step": 13645,
      "token_acc": 0.5471698113207547,
      "train_speed(iter/s)": 0.25216
    },
    {
      "epoch": 1.2732021266672886,
      "grad_norm": 3.9420883655548096,
      "learning_rate": 8.898226158887868e-06,
      "loss": 0.4728337287902832,
      "memory(GiB)": 72.72,
      "step": 13650,
      "token_acc": 0.9873417721518988,
      "train_speed(iter/s)": 0.252158
    },
    {
      "epoch": 1.2736685010726612,
      "grad_norm": 4.645881652832031,
      "learning_rate": 8.897260155404958e-06,
      "loss": 0.43355603218078614,
      "memory(GiB)": 72.72,
      "step": 13655,
      "train_speed(iter/s)": 0.252161
    },
    {
      "epoch": 1.2741348754780337,
      "grad_norm": 3.142772674560547,
      "learning_rate": 8.896293781109751e-06,
      "loss": 0.4556549549102783,
      "memory(GiB)": 72.72,
      "step": 13660,
      "train_speed(iter/s)": 0.252159
    },
    {
      "epoch": 1.2746012498834065,
      "grad_norm": 4.480162143707275,
      "learning_rate": 8.895327036094193e-06,
      "loss": 0.40976996421813966,
      "memory(GiB)": 72.72,
      "step": 13665,
      "train_speed(iter/s)": 0.252158
    },
    {
      "epoch": 1.275067624288779,
      "grad_norm": 4.554320335388184,
      "learning_rate": 8.894359920450269e-06,
      "loss": 0.47086734771728517,
      "memory(GiB)": 72.72,
      "step": 13670,
      "token_acc": 0.6875,
      "train_speed(iter/s)": 0.252157
    },
    {
      "epoch": 1.2755339986941516,
      "grad_norm": 3.585012674331665,
      "learning_rate": 8.893392434269994e-06,
      "loss": 0.42244687080383303,
      "memory(GiB)": 72.72,
      "step": 13675,
      "train_speed(iter/s)": 0.252161
    },
    {
      "epoch": 1.2760003730995244,
      "grad_norm": 11.472262382507324,
      "learning_rate": 8.892424577645422e-06,
      "loss": 0.4714221954345703,
      "memory(GiB)": 72.72,
      "step": 13680,
      "train_speed(iter/s)": 0.252165
    },
    {
      "epoch": 1.276466747504897,
      "grad_norm": 6.21179723739624,
      "learning_rate": 8.891456350668644e-06,
      "loss": 0.4461878776550293,
      "memory(GiB)": 72.72,
      "step": 13685,
      "train_speed(iter/s)": 0.252161
    },
    {
      "epoch": 1.2769331219102695,
      "grad_norm": 4.433393955230713,
      "learning_rate": 8.89048775343178e-06,
      "loss": 0.4347087860107422,
      "memory(GiB)": 72.72,
      "step": 13690,
      "train_speed(iter/s)": 0.252165
    },
    {
      "epoch": 1.2773994963156423,
      "grad_norm": 4.024551868438721,
      "learning_rate": 8.889518786026994e-06,
      "loss": 0.4665096282958984,
      "memory(GiB)": 72.72,
      "step": 13695,
      "token_acc": 0.43636363636363634,
      "train_speed(iter/s)": 0.252165
    },
    {
      "epoch": 1.2778658707210149,
      "grad_norm": 5.3175048828125,
      "learning_rate": 8.888549448546475e-06,
      "loss": 0.4416536331176758,
      "memory(GiB)": 72.72,
      "step": 13700,
      "train_speed(iter/s)": 0.252166
    },
    {
      "epoch": 1.2783322451263874,
      "grad_norm": 5.148758888244629,
      "learning_rate": 8.887579741082456e-06,
      "loss": 0.44803605079650877,
      "memory(GiB)": 72.72,
      "step": 13705,
      "train_speed(iter/s)": 0.252166
    },
    {
      "epoch": 1.2787986195317602,
      "grad_norm": 3.0648927688598633,
      "learning_rate": 8.886609663727201e-06,
      "loss": 0.4344635486602783,
      "memory(GiB)": 72.72,
      "step": 13710,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 1.2792649939371328,
      "grad_norm": 3.731323003768921,
      "learning_rate": 8.88563921657301e-06,
      "loss": 0.4172307014465332,
      "memory(GiB)": 72.72,
      "step": 13715,
      "token_acc": 0.8045112781954887,
      "train_speed(iter/s)": 0.252159
    },
    {
      "epoch": 1.2797313683425053,
      "grad_norm": 53.67412567138672,
      "learning_rate": 8.884668399712216e-06,
      "loss": 0.46743011474609375,
      "memory(GiB)": 72.72,
      "step": 13720,
      "train_speed(iter/s)": 0.252156
    },
    {
      "epoch": 1.2801977427478781,
      "grad_norm": 4.813477516174316,
      "learning_rate": 8.883697213237193e-06,
      "loss": 0.4818232536315918,
      "memory(GiB)": 72.72,
      "step": 13725,
      "token_acc": 0.8141592920353983,
      "train_speed(iter/s)": 0.252156
    },
    {
      "epoch": 1.2806641171532507,
      "grad_norm": 3.555384397506714,
      "learning_rate": 8.88272565724034e-06,
      "loss": 0.45299396514892576,
      "memory(GiB)": 72.72,
      "step": 13730,
      "train_speed(iter/s)": 0.252157
    },
    {
      "epoch": 1.2811304915586232,
      "grad_norm": 4.685652732849121,
      "learning_rate": 8.881753731814106e-06,
      "loss": 0.458863639831543,
      "memory(GiB)": 72.72,
      "step": 13735,
      "train_speed(iter/s)": 0.252158
    },
    {
      "epoch": 1.281596865963996,
      "grad_norm": 9.731719017028809,
      "learning_rate": 8.88078143705096e-06,
      "loss": 0.43262972831726076,
      "memory(GiB)": 72.72,
      "step": 13740,
      "train_speed(iter/s)": 0.252167
    },
    {
      "epoch": 1.2820632403693686,
      "grad_norm": 4.066373825073242,
      "learning_rate": 8.879808773043416e-06,
      "loss": 0.40822515487670896,
      "memory(GiB)": 72.72,
      "step": 13745,
      "token_acc": 0.3728813559322034,
      "train_speed(iter/s)": 0.252163
    },
    {
      "epoch": 1.2825296147747411,
      "grad_norm": 5.52878475189209,
      "learning_rate": 8.87883573988402e-06,
      "loss": 0.4599612236022949,
      "memory(GiB)": 72.72,
      "step": 13750,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 1.282995989180114,
      "grad_norm": 8.612102508544922,
      "learning_rate": 8.877862337665352e-06,
      "loss": 0.44801812171936034,
      "memory(GiB)": 72.72,
      "step": 13755,
      "token_acc": 0.9108910891089109,
      "train_speed(iter/s)": 0.25217
    },
    {
      "epoch": 1.2834623635854865,
      "grad_norm": 3.3729217052459717,
      "learning_rate": 8.876888566480028e-06,
      "loss": 0.45873312950134276,
      "memory(GiB)": 72.72,
      "step": 13760,
      "train_speed(iter/s)": 0.252166
    },
    {
      "epoch": 1.283928737990859,
      "grad_norm": 9.314692497253418,
      "learning_rate": 8.875914426420701e-06,
      "loss": 0.43673295974731446,
      "memory(GiB)": 72.72,
      "step": 13765,
      "train_speed(iter/s)": 0.252167
    },
    {
      "epoch": 1.2843951123962318,
      "grad_norm": 4.707247257232666,
      "learning_rate": 8.874939917580057e-06,
      "loss": 0.45762996673583983,
      "memory(GiB)": 72.72,
      "step": 13770,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.25217
    },
    {
      "epoch": 1.2848614868016044,
      "grad_norm": 8.211307525634766,
      "learning_rate": 8.873965040050816e-06,
      "loss": 0.46514062881469725,
      "memory(GiB)": 72.72,
      "step": 13775,
      "train_speed(iter/s)": 0.252175
    },
    {
      "epoch": 1.285327861206977,
      "grad_norm": 3.6482937335968018,
      "learning_rate": 8.872989793925734e-06,
      "loss": 0.4138631343841553,
      "memory(GiB)": 72.72,
      "step": 13780,
      "train_speed(iter/s)": 0.252171
    },
    {
      "epoch": 1.2857942356123495,
      "grad_norm": 15.777560234069824,
      "learning_rate": 8.872014179297606e-06,
      "loss": 0.45934429168701174,
      "memory(GiB)": 72.72,
      "step": 13785,
      "token_acc": 0.8383838383838383,
      "train_speed(iter/s)": 0.252172
    },
    {
      "epoch": 1.2862606100177223,
      "grad_norm": 5.534479141235352,
      "learning_rate": 8.871038196259256e-06,
      "loss": 0.45319738388061526,
      "memory(GiB)": 72.72,
      "step": 13790,
      "train_speed(iter/s)": 0.252172
    },
    {
      "epoch": 1.2867269844230949,
      "grad_norm": 3.245120048522949,
      "learning_rate": 8.870061844903545e-06,
      "loss": 0.42455644607543946,
      "memory(GiB)": 72.72,
      "step": 13795,
      "train_speed(iter/s)": 0.252171
    },
    {
      "epoch": 1.2871933588284674,
      "grad_norm": 4.634543418884277,
      "learning_rate": 8.869085125323375e-06,
      "loss": 0.42465596199035643,
      "memory(GiB)": 72.72,
      "step": 13800,
      "train_speed(iter/s)": 0.252173
    },
    {
      "epoch": 1.2876597332338402,
      "grad_norm": 3.8203506469726562,
      "learning_rate": 8.868108037611672e-06,
      "loss": 0.4416694641113281,
      "memory(GiB)": 72.72,
      "step": 13805,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.2881261076392128,
      "grad_norm": 3.7054874897003174,
      "learning_rate": 8.867130581861408e-06,
      "loss": 0.394282865524292,
      "memory(GiB)": 72.72,
      "step": 13810,
      "train_speed(iter/s)": 0.252179
    },
    {
      "epoch": 1.2885924820445853,
      "grad_norm": 4.912684440612793,
      "learning_rate": 8.866152758165578e-06,
      "loss": 0.44216012954711914,
      "memory(GiB)": 72.72,
      "step": 13815,
      "token_acc": 0.90625,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.289058856449958,
      "grad_norm": 3.9170751571655273,
      "learning_rate": 8.865174566617225e-06,
      "loss": 0.4306144714355469,
      "memory(GiB)": 72.72,
      "step": 13820,
      "token_acc": 0.9239130434782609,
      "train_speed(iter/s)": 0.252177
    },
    {
      "epoch": 1.2895252308553307,
      "grad_norm": 3.7075510025024414,
      "learning_rate": 8.86419600730942e-06,
      "loss": 0.4769586563110352,
      "memory(GiB)": 72.72,
      "step": 13825,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.252181
    },
    {
      "epoch": 1.2899916052607032,
      "grad_norm": 5.233263969421387,
      "learning_rate": 8.863217080335266e-06,
      "loss": 0.4646148681640625,
      "memory(GiB)": 72.72,
      "step": 13830,
      "train_speed(iter/s)": 0.252181
    },
    {
      "epoch": 1.290457979666076,
      "grad_norm": 4.431035995483398,
      "learning_rate": 8.86223778578791e-06,
      "loss": 0.44286742210388186,
      "memory(GiB)": 72.72,
      "step": 13835,
      "train_speed(iter/s)": 0.252189
    },
    {
      "epoch": 1.2909243540714486,
      "grad_norm": 3.447960138320923,
      "learning_rate": 8.861258123760527e-06,
      "loss": 0.4154956340789795,
      "memory(GiB)": 72.72,
      "step": 13840,
      "token_acc": 0.6785714285714286,
      "train_speed(iter/s)": 0.252195
    },
    {
      "epoch": 1.2913907284768211,
      "grad_norm": 3.6038613319396973,
      "learning_rate": 8.860278094346328e-06,
      "loss": 0.43230552673339845,
      "memory(GiB)": 72.72,
      "step": 13845,
      "train_speed(iter/s)": 0.2522
    },
    {
      "epoch": 1.291857102882194,
      "grad_norm": 3.748990774154663,
      "learning_rate": 8.85929769763856e-06,
      "loss": 0.4990374565124512,
      "memory(GiB)": 72.72,
      "step": 13850,
      "token_acc": 0.9619047619047619,
      "train_speed(iter/s)": 0.252199
    },
    {
      "epoch": 1.2923234772875665,
      "grad_norm": 5.228214740753174,
      "learning_rate": 8.858316933730505e-06,
      "loss": 0.4405547618865967,
      "memory(GiB)": 72.72,
      "step": 13855,
      "train_speed(iter/s)": 0.252194
    },
    {
      "epoch": 1.292789851692939,
      "grad_norm": 5.136058330535889,
      "learning_rate": 8.857335802715479e-06,
      "loss": 0.44547033309936523,
      "memory(GiB)": 72.72,
      "step": 13860,
      "train_speed(iter/s)": 0.252203
    },
    {
      "epoch": 1.2932562260983116,
      "grad_norm": 3.868210792541504,
      "learning_rate": 8.856354304686834e-06,
      "loss": 0.467702054977417,
      "memory(GiB)": 72.72,
      "step": 13865,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.252203
    },
    {
      "epoch": 1.2937226005036844,
      "grad_norm": 3.7950360774993896,
      "learning_rate": 8.855372439737958e-06,
      "loss": 0.5157000064849854,
      "memory(GiB)": 72.72,
      "step": 13870,
      "train_speed(iter/s)": 0.252204
    },
    {
      "epoch": 1.294188974909057,
      "grad_norm": 3.45985746383667,
      "learning_rate": 8.85439020796227e-06,
      "loss": 0.4448056221008301,
      "memory(GiB)": 72.72,
      "step": 13875,
      "train_speed(iter/s)": 0.25221
    },
    {
      "epoch": 1.2946553493144295,
      "grad_norm": 3.498570203781128,
      "learning_rate": 8.853407609453228e-06,
      "loss": 0.46691389083862306,
      "memory(GiB)": 72.72,
      "step": 13880,
      "token_acc": 0.7244094488188977,
      "train_speed(iter/s)": 0.252208
    },
    {
      "epoch": 1.2951217237198023,
      "grad_norm": 4.566377639770508,
      "learning_rate": 8.852424644304323e-06,
      "loss": 0.47502832412719725,
      "memory(GiB)": 72.72,
      "step": 13885,
      "token_acc": 0.7593984962406015,
      "train_speed(iter/s)": 0.252208
    },
    {
      "epoch": 1.2955880981251748,
      "grad_norm": 3.577488422393799,
      "learning_rate": 8.85144131260908e-06,
      "loss": 0.45295166969299316,
      "memory(GiB)": 72.72,
      "step": 13890,
      "token_acc": 0.9368421052631579,
      "train_speed(iter/s)": 0.252211
    },
    {
      "epoch": 1.2960544725305474,
      "grad_norm": 3.5899791717529297,
      "learning_rate": 8.850457614461061e-06,
      "loss": 0.44907779693603517,
      "memory(GiB)": 72.72,
      "step": 13895,
      "train_speed(iter/s)": 0.252214
    },
    {
      "epoch": 1.2965208469359202,
      "grad_norm": 3.1336565017700195,
      "learning_rate": 8.849473549953863e-06,
      "loss": 0.454299259185791,
      "memory(GiB)": 72.72,
      "step": 13900,
      "train_speed(iter/s)": 0.252214
    },
    {
      "epoch": 1.2969872213412927,
      "grad_norm": 5.8898234367370605,
      "learning_rate": 8.848489119181112e-06,
      "loss": 0.4342842102050781,
      "memory(GiB)": 72.72,
      "step": 13905,
      "train_speed(iter/s)": 0.252209
    },
    {
      "epoch": 1.2974535957466653,
      "grad_norm": 3.907724618911743,
      "learning_rate": 8.84750432223648e-06,
      "loss": 0.45658226013183595,
      "memory(GiB)": 72.72,
      "step": 13910,
      "token_acc": 0.5416666666666666,
      "train_speed(iter/s)": 0.252213
    },
    {
      "epoch": 1.297919970152038,
      "grad_norm": 9.015769004821777,
      "learning_rate": 8.846519159213662e-06,
      "loss": 0.47161116600036623,
      "memory(GiB)": 72.72,
      "step": 13915,
      "train_speed(iter/s)": 0.252078
    },
    {
      "epoch": 1.2983863445574106,
      "grad_norm": 4.9442548751831055,
      "learning_rate": 8.845533630206396e-06,
      "loss": 0.4444594383239746,
      "memory(GiB)": 72.72,
      "step": 13920,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.2988527189627832,
      "grad_norm": 7.495347023010254,
      "learning_rate": 8.844547735308453e-06,
      "loss": 0.459778356552124,
      "memory(GiB)": 72.72,
      "step": 13925,
      "train_speed(iter/s)": 0.252073
    },
    {
      "epoch": 1.299319093368156,
      "grad_norm": 3.554626226425171,
      "learning_rate": 8.843561474613636e-06,
      "loss": 0.454754114151001,
      "memory(GiB)": 72.72,
      "step": 13930,
      "train_speed(iter/s)": 0.252073
    },
    {
      "epoch": 1.2997854677735285,
      "grad_norm": 3.7957332134246826,
      "learning_rate": 8.842574848215784e-06,
      "loss": 0.44116983413696287,
      "memory(GiB)": 72.72,
      "step": 13935,
      "token_acc": 0.43846153846153846,
      "train_speed(iter/s)": 0.25208
    },
    {
      "epoch": 1.300251842178901,
      "grad_norm": 9.327469825744629,
      "learning_rate": 8.841587856208773e-06,
      "loss": 0.45641512870788575,
      "memory(GiB)": 72.72,
      "step": 13940,
      "train_speed(iter/s)": 0.25208
    },
    {
      "epoch": 1.300718216584274,
      "grad_norm": 4.184938430786133,
      "learning_rate": 8.840600498686512e-06,
      "loss": 0.41734561920166013,
      "memory(GiB)": 72.72,
      "step": 13945,
      "train_speed(iter/s)": 0.252078
    },
    {
      "epoch": 1.3011845909896465,
      "grad_norm": 3.939000129699707,
      "learning_rate": 8.839612775742945e-06,
      "loss": 0.42438631057739257,
      "memory(GiB)": 72.72,
      "step": 13950,
      "train_speed(iter/s)": 0.252077
    },
    {
      "epoch": 1.301650965395019,
      "grad_norm": 3.680103302001953,
      "learning_rate": 8.838624687472051e-06,
      "loss": 0.4423759937286377,
      "memory(GiB)": 72.72,
      "step": 13955,
      "token_acc": 0.45098039215686275,
      "train_speed(iter/s)": 0.252076
    },
    {
      "epoch": 1.3021173398003918,
      "grad_norm": 4.345366954803467,
      "learning_rate": 8.837636233967842e-06,
      "loss": 0.4495208740234375,
      "memory(GiB)": 72.72,
      "step": 13960,
      "token_acc": 0.5531914893617021,
      "train_speed(iter/s)": 0.25208
    },
    {
      "epoch": 1.3025837142057644,
      "grad_norm": 4.021484375,
      "learning_rate": 8.836647415324369e-06,
      "loss": 0.4629502296447754,
      "memory(GiB)": 72.72,
      "step": 13965,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.252078
    },
    {
      "epoch": 1.303050088611137,
      "grad_norm": 4.07791805267334,
      "learning_rate": 8.83565823163571e-06,
      "loss": 0.4421669960021973,
      "memory(GiB)": 72.72,
      "step": 13970,
      "token_acc": 0.8627450980392157,
      "train_speed(iter/s)": 0.252074
    },
    {
      "epoch": 1.3035164630165097,
      "grad_norm": 3.1097798347473145,
      "learning_rate": 8.83466868299599e-06,
      "loss": 0.46253318786621095,
      "memory(GiB)": 72.72,
      "step": 13975,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.252068
    },
    {
      "epoch": 1.3039828374218823,
      "grad_norm": 6.472855567932129,
      "learning_rate": 8.833678769499356e-06,
      "loss": 0.47119894027709963,
      "memory(GiB)": 72.72,
      "step": 13980,
      "token_acc": 0.5584415584415584,
      "train_speed(iter/s)": 0.252068
    },
    {
      "epoch": 1.3044492118272548,
      "grad_norm": 4.348288536071777,
      "learning_rate": 8.832688491239998e-06,
      "loss": 0.5084916591644287,
      "memory(GiB)": 72.72,
      "step": 13985,
      "token_acc": 0.43636363636363634,
      "train_speed(iter/s)": 0.252075
    },
    {
      "epoch": 1.3049155862326276,
      "grad_norm": 3.8630528450012207,
      "learning_rate": 8.831697848312137e-06,
      "loss": 0.5062618255615234,
      "memory(GiB)": 72.72,
      "step": 13990,
      "token_acc": 0.9017857142857143,
      "train_speed(iter/s)": 0.252076
    },
    {
      "epoch": 1.3053819606380002,
      "grad_norm": 7.538697242736816,
      "learning_rate": 8.83070684081003e-06,
      "loss": 0.4569951057434082,
      "memory(GiB)": 72.72,
      "step": 13995,
      "token_acc": 0.896551724137931,
      "train_speed(iter/s)": 0.252085
    },
    {
      "epoch": 1.3058483350433727,
      "grad_norm": 5.53097677230835,
      "learning_rate": 8.829715468827966e-06,
      "loss": 0.4684892654418945,
      "memory(GiB)": 72.72,
      "step": 14000,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.252083
    },
    {
      "epoch": 1.3063147094487455,
      "grad_norm": 4.268861770629883,
      "learning_rate": 8.828723732460274e-06,
      "loss": 0.4669364929199219,
      "memory(GiB)": 72.72,
      "step": 14005,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.306781083854118,
      "grad_norm": 5.354183197021484,
      "learning_rate": 8.827731631801315e-06,
      "loss": 0.4865823268890381,
      "memory(GiB)": 72.72,
      "step": 14010,
      "token_acc": 0.45132743362831856,
      "train_speed(iter/s)": 0.251971
    },
    {
      "epoch": 1.3072474582594906,
      "grad_norm": 3.2557811737060547,
      "learning_rate": 8.82673916694548e-06,
      "loss": 0.4598685264587402,
      "memory(GiB)": 72.72,
      "step": 14015,
      "train_speed(iter/s)": 0.251973
    },
    {
      "epoch": 1.3077138326648634,
      "grad_norm": 2.997992515563965,
      "learning_rate": 8.825746337987205e-06,
      "loss": 0.4186295509338379,
      "memory(GiB)": 72.72,
      "step": 14020,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 1.308180207070236,
      "grad_norm": 4.347104072570801,
      "learning_rate": 8.824753145020948e-06,
      "loss": 0.46402645111083984,
      "memory(GiB)": 72.72,
      "step": 14025,
      "train_speed(iter/s)": 0.251972
    },
    {
      "epoch": 1.3086465814756085,
      "grad_norm": 3.346937894821167,
      "learning_rate": 8.823759588141214e-06,
      "loss": 0.4934290885925293,
      "memory(GiB)": 72.72,
      "step": 14030,
      "train_speed(iter/s)": 0.251975
    },
    {
      "epoch": 1.3091129558809813,
      "grad_norm": 8.155476570129395,
      "learning_rate": 8.822765667442534e-06,
      "loss": 0.4837358474731445,
      "memory(GiB)": 72.72,
      "step": 14035,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251975
    },
    {
      "epoch": 1.3095793302863539,
      "grad_norm": 2.560655355453491,
      "learning_rate": 8.821771383019476e-06,
      "loss": 0.4338886260986328,
      "memory(GiB)": 72.72,
      "step": 14040,
      "token_acc": 0.9157894736842105,
      "train_speed(iter/s)": 0.25198
    },
    {
      "epoch": 1.3100457046917264,
      "grad_norm": 8.239912986755371,
      "learning_rate": 8.820776734966646e-06,
      "loss": 0.40965967178344725,
      "memory(GiB)": 72.72,
      "step": 14045,
      "token_acc": 0.6436781609195402,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.3105120790970992,
      "grad_norm": 7.723210334777832,
      "learning_rate": 8.819781723378678e-06,
      "loss": 0.4881352424621582,
      "memory(GiB)": 72.72,
      "step": 14050,
      "token_acc": 0.3953488372093023,
      "train_speed(iter/s)": 0.251985
    },
    {
      "epoch": 1.3109784535024718,
      "grad_norm": 3.588143825531006,
      "learning_rate": 8.818786348350247e-06,
      "loss": 0.49967250823974607,
      "memory(GiB)": 72.72,
      "step": 14055,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.3114448279078443,
      "grad_norm": 4.053629398345947,
      "learning_rate": 8.81779060997606e-06,
      "loss": 0.4502458095550537,
      "memory(GiB)": 72.72,
      "step": 14060,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.3119112023132171,
      "grad_norm": 4.735558032989502,
      "learning_rate": 8.816794508350857e-06,
      "loss": 0.4387204170227051,
      "memory(GiB)": 72.72,
      "step": 14065,
      "token_acc": 0.42,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.3123775767185897,
      "grad_norm": 3.097682476043701,
      "learning_rate": 8.815798043569412e-06,
      "loss": 0.4571226596832275,
      "memory(GiB)": 72.72,
      "step": 14070,
      "token_acc": 0.42016806722689076,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.3128439511239622,
      "grad_norm": 3.904482364654541,
      "learning_rate": 8.81480121572654e-06,
      "loss": 0.4419894218444824,
      "memory(GiB)": 72.72,
      "step": 14075,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.251995
    },
    {
      "epoch": 1.313310325529335,
      "grad_norm": 3.298203229904175,
      "learning_rate": 8.813804024917085e-06,
      "loss": 0.4575524806976318,
      "memory(GiB)": 72.72,
      "step": 14080,
      "token_acc": 0.4772727272727273,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.3137766999347076,
      "grad_norm": 4.050460338592529,
      "learning_rate": 8.812806471235926e-06,
      "loss": 0.4568942546844482,
      "memory(GiB)": 72.72,
      "step": 14085,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.3142430743400801,
      "grad_norm": 3.461574077606201,
      "learning_rate": 8.811808554777974e-06,
      "loss": 0.4584968566894531,
      "memory(GiB)": 72.72,
      "step": 14090,
      "token_acc": 0.8924731182795699,
      "train_speed(iter/s)": 0.251993
    },
    {
      "epoch": 1.314709448745453,
      "grad_norm": 5.09208345413208,
      "learning_rate": 8.810810275638183e-06,
      "loss": 0.4444094181060791,
      "memory(GiB)": 72.72,
      "step": 14095,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.3151758231508255,
      "grad_norm": 3.75199556350708,
      "learning_rate": 8.809811633911533e-06,
      "loss": 0.45906796455383303,
      "memory(GiB)": 72.72,
      "step": 14100,
      "train_speed(iter/s)": 0.251993
    },
    {
      "epoch": 1.315642197556198,
      "grad_norm": 3.137787103652954,
      "learning_rate": 8.808812629693042e-06,
      "loss": 0.4615579605102539,
      "memory(GiB)": 72.72,
      "step": 14105,
      "token_acc": 0.5419847328244275,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.3161085719615708,
      "grad_norm": 4.446830749511719,
      "learning_rate": 8.807813263077765e-06,
      "loss": 0.46798105239868165,
      "memory(GiB)": 72.72,
      "step": 14110,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.3165749463669434,
      "grad_norm": 3.629546880722046,
      "learning_rate": 8.806813534160783e-06,
      "loss": 0.4303898811340332,
      "memory(GiB)": 72.72,
      "step": 14115,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.251994
    },
    {
      "epoch": 1.317041320772316,
      "grad_norm": 3.2055633068084717,
      "learning_rate": 8.805813443037222e-06,
      "loss": 0.5009160995483398,
      "memory(GiB)": 72.72,
      "step": 14120,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.251886
    },
    {
      "epoch": 1.3175076951776887,
      "grad_norm": 5.73969841003418,
      "learning_rate": 8.804812989802236e-06,
      "loss": 0.3980377674102783,
      "memory(GiB)": 72.72,
      "step": 14125,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.251862
    },
    {
      "epoch": 1.3179740695830613,
      "grad_norm": 3.8454196453094482,
      "learning_rate": 8.803812174551015e-06,
      "loss": 0.4338065624237061,
      "memory(GiB)": 72.72,
      "step": 14130,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.251863
    },
    {
      "epoch": 1.3184404439884339,
      "grad_norm": 13.306619644165039,
      "learning_rate": 8.802810997378784e-06,
      "loss": 0.4338010311126709,
      "memory(GiB)": 72.72,
      "step": 14135,
      "token_acc": 0.7819548872180451,
      "train_speed(iter/s)": 0.251867
    },
    {
      "epoch": 1.3189068183938066,
      "grad_norm": 4.830020427703857,
      "learning_rate": 8.801809458380801e-06,
      "loss": 0.47792692184448243,
      "memory(GiB)": 72.72,
      "step": 14140,
      "train_speed(iter/s)": 0.251864
    },
    {
      "epoch": 1.3193731927991792,
      "grad_norm": 26.929189682006836,
      "learning_rate": 8.80080755765236e-06,
      "loss": 0.4317603588104248,
      "memory(GiB)": 72.72,
      "step": 14145,
      "token_acc": 0.8863636363636364,
      "train_speed(iter/s)": 0.251866
    },
    {
      "epoch": 1.3198395672045518,
      "grad_norm": 4.731070041656494,
      "learning_rate": 8.799805295288788e-06,
      "loss": 0.4400090217590332,
      "memory(GiB)": 72.72,
      "step": 14150,
      "train_speed(iter/s)": 0.251869
    },
    {
      "epoch": 1.3203059416099245,
      "grad_norm": 3.005363702774048,
      "learning_rate": 8.798802671385446e-06,
      "loss": 0.4703374862670898,
      "memory(GiB)": 72.72,
      "step": 14155,
      "token_acc": 0.42424242424242425,
      "train_speed(iter/s)": 0.251879
    },
    {
      "epoch": 1.320772316015297,
      "grad_norm": 3.31173038482666,
      "learning_rate": 8.797799686037735e-06,
      "loss": 0.4725958347320557,
      "memory(GiB)": 72.72,
      "step": 14160,
      "token_acc": 0.2631578947368421,
      "train_speed(iter/s)": 0.251883
    },
    {
      "epoch": 1.3212386904206697,
      "grad_norm": 6.451930046081543,
      "learning_rate": 8.796796339341083e-06,
      "loss": 0.45653462409973145,
      "memory(GiB)": 72.72,
      "step": 14165,
      "token_acc": 0.4857142857142857,
      "train_speed(iter/s)": 0.251889
    },
    {
      "epoch": 1.3217050648260424,
      "grad_norm": 5.538506984710693,
      "learning_rate": 8.795792631390955e-06,
      "loss": 0.412201452255249,
      "memory(GiB)": 72.72,
      "step": 14170,
      "train_speed(iter/s)": 0.251892
    },
    {
      "epoch": 1.322171439231415,
      "grad_norm": 3.668001413345337,
      "learning_rate": 8.794788562282852e-06,
      "loss": 0.4071327209472656,
      "memory(GiB)": 72.72,
      "step": 14175,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251896
    },
    {
      "epoch": 1.3226378136367876,
      "grad_norm": 4.251644611358643,
      "learning_rate": 8.793784132112306e-06,
      "loss": 0.4780468463897705,
      "memory(GiB)": 72.72,
      "step": 14180,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.2519
    },
    {
      "epoch": 1.3231041880421603,
      "grad_norm": 5.714054107666016,
      "learning_rate": 8.792779340974889e-06,
      "loss": 0.44169034957885744,
      "memory(GiB)": 72.72,
      "step": 14185,
      "train_speed(iter/s)": 0.251901
    },
    {
      "epoch": 1.323570562447533,
      "grad_norm": 3.367321252822876,
      "learning_rate": 8.7917741889662e-06,
      "loss": 0.44209952354431153,
      "memory(GiB)": 72.72,
      "step": 14190,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.251906
    },
    {
      "epoch": 1.3240369368529055,
      "grad_norm": 6.159832954406738,
      "learning_rate": 8.790768676181878e-06,
      "loss": 0.432694149017334,
      "memory(GiB)": 72.72,
      "step": 14195,
      "train_speed(iter/s)": 0.251911
    },
    {
      "epoch": 1.3245033112582782,
      "grad_norm": 3.24100399017334,
      "learning_rate": 8.789762802717596e-06,
      "loss": 0.46641979217529295,
      "memory(GiB)": 72.72,
      "step": 14200,
      "token_acc": 0.391304347826087,
      "train_speed(iter/s)": 0.251917
    },
    {
      "epoch": 1.3249696856636508,
      "grad_norm": 4.813294887542725,
      "learning_rate": 8.788756568669055e-06,
      "loss": 0.4494673728942871,
      "memory(GiB)": 72.72,
      "step": 14205,
      "train_speed(iter/s)": 0.25192
    },
    {
      "epoch": 1.3254360600690234,
      "grad_norm": 2.784372568130493,
      "learning_rate": 8.787749974132e-06,
      "loss": 0.434278678894043,
      "memory(GiB)": 72.72,
      "step": 14210,
      "train_speed(iter/s)": 0.251922
    },
    {
      "epoch": 1.3259024344743962,
      "grad_norm": 3.457341194152832,
      "learning_rate": 8.786743019202202e-06,
      "loss": 0.4315042972564697,
      "memory(GiB)": 72.72,
      "step": 14215,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.251926
    },
    {
      "epoch": 1.3263688088797687,
      "grad_norm": 2.697824001312256,
      "learning_rate": 8.785735703975473e-06,
      "loss": 0.4620694160461426,
      "memory(GiB)": 72.72,
      "step": 14220,
      "token_acc": 0.43103448275862066,
      "train_speed(iter/s)": 0.251928
    },
    {
      "epoch": 1.3268351832851413,
      "grad_norm": 10.110294342041016,
      "learning_rate": 8.784728028547654e-06,
      "loss": 0.4383252620697021,
      "memory(GiB)": 72.72,
      "step": 14225,
      "token_acc": 0.5106382978723404,
      "train_speed(iter/s)": 0.251935
    },
    {
      "epoch": 1.327301557690514,
      "grad_norm": 3.848433017730713,
      "learning_rate": 8.78371999301462e-06,
      "loss": 0.4854330539703369,
      "memory(GiB)": 72.72,
      "step": 14230,
      "token_acc": 0.7183098591549296,
      "train_speed(iter/s)": 0.25194
    },
    {
      "epoch": 1.3277679320958866,
      "grad_norm": 4.60857629776001,
      "learning_rate": 8.782711597472287e-06,
      "loss": 0.4512385368347168,
      "memory(GiB)": 72.72,
      "step": 14235,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.3282343065012592,
      "grad_norm": 4.811102390289307,
      "learning_rate": 8.781702842016598e-06,
      "loss": 0.46376819610595704,
      "memory(GiB)": 72.72,
      "step": 14240,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.328700680906632,
      "grad_norm": 3.6824121475219727,
      "learning_rate": 8.780693726743531e-06,
      "loss": 0.4505480766296387,
      "memory(GiB)": 72.72,
      "step": 14245,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.3291670553120045,
      "grad_norm": 4.449491500854492,
      "learning_rate": 8.779684251749105e-06,
      "loss": 0.48519191741943357,
      "memory(GiB)": 72.72,
      "step": 14250,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.329633429717377,
      "grad_norm": 4.362557888031006,
      "learning_rate": 8.778674417129364e-06,
      "loss": 0.41520676612854,
      "memory(GiB)": 72.72,
      "step": 14255,
      "train_speed(iter/s)": 0.25194
    },
    {
      "epoch": 1.3300998041227499,
      "grad_norm": 5.017455577850342,
      "learning_rate": 8.777664222980396e-06,
      "loss": 0.46012344360351565,
      "memory(GiB)": 72.72,
      "step": 14260,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.3305661785281224,
      "grad_norm": 4.598614692687988,
      "learning_rate": 8.776653669398312e-06,
      "loss": 0.4393411636352539,
      "memory(GiB)": 72.72,
      "step": 14265,
      "token_acc": 0.8673469387755102,
      "train_speed(iter/s)": 0.251945
    },
    {
      "epoch": 1.331032552933495,
      "grad_norm": 5.587404727935791,
      "learning_rate": 8.775642756479266e-06,
      "loss": 0.46628785133361816,
      "memory(GiB)": 72.72,
      "step": 14270,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.3314989273388678,
      "grad_norm": 8.240991592407227,
      "learning_rate": 8.774631484319443e-06,
      "loss": 0.4631770133972168,
      "memory(GiB)": 72.72,
      "step": 14275,
      "train_speed(iter/s)": 0.251945
    },
    {
      "epoch": 1.3319653017442403,
      "grad_norm": 13.502903938293457,
      "learning_rate": 8.773619853015064e-06,
      "loss": 0.4364506721496582,
      "memory(GiB)": 72.72,
      "step": 14280,
      "token_acc": 0.4519230769230769,
      "train_speed(iter/s)": 0.251949
    },
    {
      "epoch": 1.3324316761496129,
      "grad_norm": 4.517851829528809,
      "learning_rate": 8.77260786266238e-06,
      "loss": 0.42659788131713866,
      "memory(GiB)": 72.72,
      "step": 14285,
      "train_speed(iter/s)": 0.251948
    },
    {
      "epoch": 1.3328980505549857,
      "grad_norm": 2.856562614440918,
      "learning_rate": 8.771595513357678e-06,
      "loss": 0.4739250659942627,
      "memory(GiB)": 72.72,
      "step": 14290,
      "train_speed(iter/s)": 0.251952
    },
    {
      "epoch": 1.3333644249603582,
      "grad_norm": 5.366915225982666,
      "learning_rate": 8.770582805197283e-06,
      "loss": 0.4208054542541504,
      "memory(GiB)": 72.72,
      "step": 14295,
      "train_speed(iter/s)": 0.251956
    },
    {
      "epoch": 1.3338307993657308,
      "grad_norm": 3.7664430141448975,
      "learning_rate": 8.769569738277547e-06,
      "loss": 0.4201509475708008,
      "memory(GiB)": 72.72,
      "step": 14300,
      "token_acc": 0.5344827586206896,
      "train_speed(iter/s)": 0.251961
    },
    {
      "epoch": 1.3342971737711036,
      "grad_norm": 13.84866714477539,
      "learning_rate": 8.768556312694866e-06,
      "loss": 0.4601130962371826,
      "memory(GiB)": 72.72,
      "step": 14305,
      "train_speed(iter/s)": 0.25196
    },
    {
      "epoch": 1.3347635481764761,
      "grad_norm": 3.721473455429077,
      "learning_rate": 8.767542528545662e-06,
      "loss": 0.4678691864013672,
      "memory(GiB)": 72.72,
      "step": 14310,
      "token_acc": 0.46938775510204084,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.3352299225818487,
      "grad_norm": 5.2017340660095215,
      "learning_rate": 8.76652838592639e-06,
      "loss": 0.44601850509643554,
      "memory(GiB)": 72.72,
      "step": 14315,
      "train_speed(iter/s)": 0.251968
    },
    {
      "epoch": 1.3356962969872215,
      "grad_norm": 5.971735000610352,
      "learning_rate": 8.765513884933548e-06,
      "loss": 0.48613882064819336,
      "memory(GiB)": 72.72,
      "step": 14320,
      "train_speed(iter/s)": 0.251972
    },
    {
      "epoch": 1.336162671392594,
      "grad_norm": 12.037254333496094,
      "learning_rate": 8.764499025663656e-06,
      "loss": 0.46300573348999025,
      "memory(GiB)": 72.72,
      "step": 14325,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.3366290457979666,
      "grad_norm": 3.4298596382141113,
      "learning_rate": 8.763483808213282e-06,
      "loss": 0.4754178524017334,
      "memory(GiB)": 72.72,
      "step": 14330,
      "token_acc": 0.8714285714285714,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 1.3370954202033392,
      "grad_norm": 5.855515480041504,
      "learning_rate": 8.762468232679016e-06,
      "loss": 0.4867271423339844,
      "memory(GiB)": 72.72,
      "step": 14335,
      "train_speed(iter/s)": 0.251973
    },
    {
      "epoch": 1.337561794608712,
      "grad_norm": 4.771939754486084,
      "learning_rate": 8.761452299157486e-06,
      "loss": 0.4629105567932129,
      "memory(GiB)": 72.72,
      "step": 14340,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.251974
    },
    {
      "epoch": 1.3380281690140845,
      "grad_norm": 5.3509931564331055,
      "learning_rate": 8.760436007745361e-06,
      "loss": 0.47102861404418944,
      "memory(GiB)": 72.72,
      "step": 14345,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.251975
    },
    {
      "epoch": 1.338494543419457,
      "grad_norm": 5.128718852996826,
      "learning_rate": 8.759419358539331e-06,
      "loss": 0.5017502307891846,
      "memory(GiB)": 72.72,
      "step": 14350,
      "train_speed(iter/s)": 0.251977
    },
    {
      "epoch": 1.3389609178248298,
      "grad_norm": 10.255633354187012,
      "learning_rate": 8.758402351636132e-06,
      "loss": 0.4651355743408203,
      "memory(GiB)": 72.72,
      "step": 14355,
      "train_speed(iter/s)": 0.25198
    },
    {
      "epoch": 1.3394272922302024,
      "grad_norm": 5.334959983825684,
      "learning_rate": 8.757384987132527e-06,
      "loss": 0.4939451217651367,
      "memory(GiB)": 72.72,
      "step": 14360,
      "token_acc": 0.3090909090909091,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.339893666635575,
      "grad_norm": 6.0074872970581055,
      "learning_rate": 8.756367265125315e-06,
      "loss": 0.4686431407928467,
      "memory(GiB)": 72.72,
      "step": 14365,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.3403600410409477,
      "grad_norm": 6.063814163208008,
      "learning_rate": 8.75534918571133e-06,
      "loss": 0.4369663715362549,
      "memory(GiB)": 72.72,
      "step": 14370,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251983
    },
    {
      "epoch": 1.3408264154463203,
      "grad_norm": 6.245996952056885,
      "learning_rate": 8.75433074898744e-06,
      "loss": 0.4521505355834961,
      "memory(GiB)": 72.72,
      "step": 14375,
      "train_speed(iter/s)": 0.251982
    },
    {
      "epoch": 1.3412927898516929,
      "grad_norm": 5.102839469909668,
      "learning_rate": 8.75331195505054e-06,
      "loss": 0.45028533935546877,
      "memory(GiB)": 72.72,
      "step": 14380,
      "token_acc": 0.9239130434782609,
      "train_speed(iter/s)": 0.251985
    },
    {
      "epoch": 1.3417591642570657,
      "grad_norm": 6.187804222106934,
      "learning_rate": 8.752292803997576e-06,
      "loss": 0.5050066947937012,
      "memory(GiB)": 72.72,
      "step": 14385,
      "train_speed(iter/s)": 0.251982
    },
    {
      "epoch": 1.3422255386624382,
      "grad_norm": 7.889580249786377,
      "learning_rate": 8.751273295925507e-06,
      "loss": 0.46692495346069335,
      "memory(GiB)": 72.72,
      "step": 14390,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.3426919130678108,
      "grad_norm": 5.397613048553467,
      "learning_rate": 8.75025343093134e-06,
      "loss": 0.4366811752319336,
      "memory(GiB)": 72.72,
      "step": 14395,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 1.3431582874731836,
      "grad_norm": 4.780535697937012,
      "learning_rate": 8.749233209112114e-06,
      "loss": 0.4287723064422607,
      "memory(GiB)": 72.72,
      "step": 14400,
      "token_acc": 0.4716981132075472,
      "train_speed(iter/s)": 0.251981
    },
    {
      "epoch": 1.3436246618785561,
      "grad_norm": 5.990455150604248,
      "learning_rate": 8.748212630564895e-06,
      "loss": 0.4777698516845703,
      "memory(GiB)": 72.72,
      "step": 14405,
      "train_speed(iter/s)": 0.25198
    },
    {
      "epoch": 1.3440910362839287,
      "grad_norm": 6.848714351654053,
      "learning_rate": 8.747191695386794e-06,
      "loss": 0.4319900989532471,
      "memory(GiB)": 72.72,
      "step": 14410,
      "token_acc": 0.821656050955414,
      "train_speed(iter/s)": 0.251983
    },
    {
      "epoch": 1.3445574106893012,
      "grad_norm": 5.972900390625,
      "learning_rate": 8.746170403674944e-06,
      "loss": 0.43845596313476565,
      "memory(GiB)": 72.72,
      "step": 14415,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.345023785094674,
      "grad_norm": 6.247974872589111,
      "learning_rate": 8.745148755526523e-06,
      "loss": 0.4490482807159424,
      "memory(GiB)": 72.72,
      "step": 14420,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.3454901595000466,
      "grad_norm": 2.6746745109558105,
      "learning_rate": 8.744126751038733e-06,
      "loss": 0.4546821594238281,
      "memory(GiB)": 72.72,
      "step": 14425,
      "token_acc": 0.5740740740740741,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.3459565339054191,
      "grad_norm": 4.657151222229004,
      "learning_rate": 8.743104390308818e-06,
      "loss": 0.46317329406738283,
      "memory(GiB)": 72.72,
      "step": 14430,
      "token_acc": 0.5403225806451613,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.346422908310792,
      "grad_norm": 4.158682346343994,
      "learning_rate": 8.742081673434051e-06,
      "loss": 0.44402570724487306,
      "memory(GiB)": 72.72,
      "step": 14435,
      "token_acc": 0.4270833333333333,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.3468892827161645,
      "grad_norm": 4.026283264160156,
      "learning_rate": 8.74105860051174e-06,
      "loss": 0.47346038818359376,
      "memory(GiB)": 72.72,
      "step": 14440,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.347355657121537,
      "grad_norm": 4.326377868652344,
      "learning_rate": 8.74003517163923e-06,
      "loss": 0.435669994354248,
      "memory(GiB)": 72.72,
      "step": 14445,
      "train_speed(iter/s)": 0.252005
    },
    {
      "epoch": 1.3478220315269098,
      "grad_norm": 5.435781478881836,
      "learning_rate": 8.739011386913892e-06,
      "loss": 0.4420599937438965,
      "memory(GiB)": 72.72,
      "step": 14450,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.3482884059322824,
      "grad_norm": 4.914929389953613,
      "learning_rate": 8.73798724643314e-06,
      "loss": 0.4459074020385742,
      "memory(GiB)": 72.72,
      "step": 14455,
      "token_acc": 0.9583333333333334,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.348754780337655,
      "grad_norm": 11.311712265014648,
      "learning_rate": 8.736962750294416e-06,
      "loss": 0.4689539909362793,
      "memory(GiB)": 72.72,
      "step": 14460,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.3492211547430277,
      "grad_norm": 3.957526445388794,
      "learning_rate": 8.735937898595199e-06,
      "loss": 0.4266188621520996,
      "memory(GiB)": 72.72,
      "step": 14465,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.3496875291484003,
      "grad_norm": 4.213788032531738,
      "learning_rate": 8.734912691433e-06,
      "loss": 0.47794437408447266,
      "memory(GiB)": 72.72,
      "step": 14470,
      "train_speed(iter/s)": 0.252023
    },
    {
      "epoch": 1.3501539035537728,
      "grad_norm": 3.8822317123413086,
      "learning_rate": 8.733887128905362e-06,
      "loss": 0.47826471328735354,
      "memory(GiB)": 72.72,
      "step": 14475,
      "token_acc": 0.6288659793814433,
      "train_speed(iter/s)": 0.252021
    },
    {
      "epoch": 1.3506202779591456,
      "grad_norm": 4.675646781921387,
      "learning_rate": 8.73286121110987e-06,
      "loss": 0.4607055187225342,
      "memory(GiB)": 72.72,
      "step": 14480,
      "train_speed(iter/s)": 0.25202
    },
    {
      "epoch": 1.3510866523645182,
      "grad_norm": 4.168704032897949,
      "learning_rate": 8.73183493814413e-06,
      "loss": 0.4155853271484375,
      "memory(GiB)": 72.72,
      "step": 14485,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.252026
    },
    {
      "epoch": 1.3515530267698908,
      "grad_norm": 4.528148651123047,
      "learning_rate": 8.730808310105794e-06,
      "loss": 0.41279211044311526,
      "memory(GiB)": 72.72,
      "step": 14490,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.3520194011752635,
      "grad_norm": 14.034388542175293,
      "learning_rate": 8.729781327092539e-06,
      "loss": 0.48247151374816893,
      "memory(GiB)": 72.72,
      "step": 14495,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.352485775580636,
      "grad_norm": 3.2479500770568848,
      "learning_rate": 8.72875398920208e-06,
      "loss": 0.47765407562255857,
      "memory(GiB)": 72.72,
      "step": 14500,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.252033
    },
    {
      "epoch": 1.3529521499860087,
      "grad_norm": 5.721049785614014,
      "learning_rate": 8.727726296532166e-06,
      "loss": 0.4460750579833984,
      "memory(GiB)": 72.72,
      "step": 14505,
      "token_acc": 0.5569620253164557,
      "train_speed(iter/s)": 0.252039
    },
    {
      "epoch": 1.3534185243913814,
      "grad_norm": 12.65484619140625,
      "learning_rate": 8.72669824918058e-06,
      "loss": 0.4396620273590088,
      "memory(GiB)": 72.72,
      "step": 14510,
      "token_acc": 0.5188679245283019,
      "train_speed(iter/s)": 0.252038
    },
    {
      "epoch": 1.353884898796754,
      "grad_norm": 5.891945838928223,
      "learning_rate": 8.725669847245134e-06,
      "loss": 0.4355504512786865,
      "memory(GiB)": 72.72,
      "step": 14515,
      "token_acc": 0.5945945945945946,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.3543512732021266,
      "grad_norm": 5.16562032699585,
      "learning_rate": 8.72464109082368e-06,
      "loss": 0.441435432434082,
      "memory(GiB)": 72.72,
      "step": 14520,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.3548176476074993,
      "grad_norm": 7.290877342224121,
      "learning_rate": 8.7236119800141e-06,
      "loss": 0.44475603103637695,
      "memory(GiB)": 72.72,
      "step": 14525,
      "train_speed(iter/s)": 0.252042
    },
    {
      "epoch": 1.355284022012872,
      "grad_norm": 5.156408309936523,
      "learning_rate": 8.722582514914311e-06,
      "loss": 0.47310352325439453,
      "memory(GiB)": 72.72,
      "step": 14530,
      "token_acc": 0.5092592592592593,
      "train_speed(iter/s)": 0.252046
    },
    {
      "epoch": 1.3557503964182445,
      "grad_norm": 8.962430953979492,
      "learning_rate": 8.721552695622264e-06,
      "loss": 0.44408655166625977,
      "memory(GiB)": 72.72,
      "step": 14535,
      "train_speed(iter/s)": 0.25205
    },
    {
      "epoch": 1.3562167708236172,
      "grad_norm": 5.549302577972412,
      "learning_rate": 8.720522522235944e-06,
      "loss": 0.4468387603759766,
      "memory(GiB)": 72.72,
      "step": 14540,
      "token_acc": 0.8,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.3566831452289898,
      "grad_norm": 10.392152786254883,
      "learning_rate": 8.719491994853363e-06,
      "loss": 0.48255128860473634,
      "memory(GiB)": 72.72,
      "step": 14545,
      "train_speed(iter/s)": 0.252053
    },
    {
      "epoch": 1.3571495196343624,
      "grad_norm": 4.054042816162109,
      "learning_rate": 8.718461113572581e-06,
      "loss": 0.4652578353881836,
      "memory(GiB)": 72.72,
      "step": 14550,
      "train_speed(iter/s)": 0.252053
    },
    {
      "epoch": 1.3576158940397351,
      "grad_norm": 3.1590771675109863,
      "learning_rate": 8.717429878491678e-06,
      "loss": 0.3984766721725464,
      "memory(GiB)": 72.72,
      "step": 14555,
      "token_acc": 0.8901098901098901,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.3580822684451077,
      "grad_norm": 4.370302200317383,
      "learning_rate": 8.716398289708773e-06,
      "loss": 0.4835184097290039,
      "memory(GiB)": 72.72,
      "step": 14560,
      "token_acc": 0.9361702127659575,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.3585486428504803,
      "grad_norm": 4.89297342300415,
      "learning_rate": 8.715366347322021e-06,
      "loss": 0.44450960159301756,
      "memory(GiB)": 72.72,
      "step": 14565,
      "train_speed(iter/s)": 0.252053
    },
    {
      "epoch": 1.359015017255853,
      "grad_norm": 5.030608177185059,
      "learning_rate": 8.714334051429605e-06,
      "loss": 0.4324789047241211,
      "memory(GiB)": 72.72,
      "step": 14570,
      "token_acc": 0.8048780487804879,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.3594813916612256,
      "grad_norm": 9.453575134277344,
      "learning_rate": 8.713301402129745e-06,
      "loss": 0.43892793655395507,
      "memory(GiB)": 72.72,
      "step": 14575,
      "token_acc": 0.5212765957446809,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.3599477660665982,
      "grad_norm": 3.913619041442871,
      "learning_rate": 8.712268399520698e-06,
      "loss": 0.42657032012939455,
      "memory(GiB)": 72.72,
      "step": 14580,
      "token_acc": 0.8991596638655462,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.360414140471971,
      "grad_norm": 10.358261108398438,
      "learning_rate": 8.711235043700747e-06,
      "loss": 0.4933148384094238,
      "memory(GiB)": 72.72,
      "step": 14585,
      "token_acc": 0.5371900826446281,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.3608805148773435,
      "grad_norm": 6.289050579071045,
      "learning_rate": 8.710201334768217e-06,
      "loss": 0.4910137176513672,
      "memory(GiB)": 72.72,
      "step": 14590,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.361346889282716,
      "grad_norm": 15.61091423034668,
      "learning_rate": 8.709167272821458e-06,
      "loss": 0.3921316623687744,
      "memory(GiB)": 72.72,
      "step": 14595,
      "token_acc": 0.4583333333333333,
      "train_speed(iter/s)": 0.252072
    },
    {
      "epoch": 1.3618132636880889,
      "grad_norm": 4.404556751251221,
      "learning_rate": 8.708132857958859e-06,
      "loss": 0.39505610466003416,
      "memory(GiB)": 72.72,
      "step": 14600,
      "token_acc": 0.6206896551724138,
      "train_speed(iter/s)": 0.252075
    },
    {
      "epoch": 1.3622796380934614,
      "grad_norm": 3.4993162155151367,
      "learning_rate": 8.707098090278843e-06,
      "loss": 0.40944294929504393,
      "memory(GiB)": 72.72,
      "step": 14605,
      "token_acc": 0.6326530612244898,
      "train_speed(iter/s)": 0.252072
    },
    {
      "epoch": 1.362746012498834,
      "grad_norm": 3.535743474960327,
      "learning_rate": 8.70606296987986e-06,
      "loss": 0.4188072204589844,
      "memory(GiB)": 72.72,
      "step": 14610,
      "token_acc": 0.9506172839506173,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.3632123869042068,
      "grad_norm": 3.883723258972168,
      "learning_rate": 8.705027496860407e-06,
      "loss": 0.4874983310699463,
      "memory(GiB)": 72.72,
      "step": 14615,
      "token_acc": 0.5111111111111111,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.3636787613095793,
      "grad_norm": 5.3799614906311035,
      "learning_rate": 8.703991671318999e-06,
      "loss": 0.4516605377197266,
      "memory(GiB)": 72.72,
      "step": 14620,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.3641451357149519,
      "grad_norm": 5.098613262176514,
      "learning_rate": 8.702955493354194e-06,
      "loss": 0.47373409271240235,
      "memory(GiB)": 72.72,
      "step": 14625,
      "train_speed(iter/s)": 0.252068
    },
    {
      "epoch": 1.3646115101203247,
      "grad_norm": 4.612958908081055,
      "learning_rate": 8.701918963064582e-06,
      "loss": 0.43613133430480955,
      "memory(GiB)": 72.72,
      "step": 14630,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.3650778845256972,
      "grad_norm": 7.345005989074707,
      "learning_rate": 8.700882080548782e-06,
      "loss": 0.42757186889648435,
      "memory(GiB)": 72.72,
      "step": 14635,
      "train_speed(iter/s)": 0.252061
    },
    {
      "epoch": 1.3655442589310698,
      "grad_norm": 4.565264701843262,
      "learning_rate": 8.699844845905456e-06,
      "loss": 0.4569276809692383,
      "memory(GiB)": 72.72,
      "step": 14640,
      "token_acc": 0.8246753246753247,
      "train_speed(iter/s)": 0.25207
    },
    {
      "epoch": 1.3660106333364426,
      "grad_norm": 4.634481906890869,
      "learning_rate": 8.698807259233288e-06,
      "loss": 0.43176956176757814,
      "memory(GiB)": 72.72,
      "step": 14645,
      "token_acc": 0.4520547945205479,
      "train_speed(iter/s)": 0.252071
    },
    {
      "epoch": 1.3664770077418151,
      "grad_norm": 4.829773426055908,
      "learning_rate": 8.697769320631007e-06,
      "loss": 0.4315041065216064,
      "memory(GiB)": 72.72,
      "step": 14650,
      "token_acc": 0.9252336448598131,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.3669433821471877,
      "grad_norm": 5.666985988616943,
      "learning_rate": 8.696731030197364e-06,
      "loss": 0.4369314193725586,
      "memory(GiB)": 72.72,
      "step": 14655,
      "train_speed(iter/s)": 0.252076
    },
    {
      "epoch": 1.3674097565525605,
      "grad_norm": 5.235589504241943,
      "learning_rate": 8.695692388031152e-06,
      "loss": 0.4741702079772949,
      "memory(GiB)": 72.72,
      "step": 14660,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.25208
    },
    {
      "epoch": 1.367876130957933,
      "grad_norm": 7.5230207443237305,
      "learning_rate": 8.694653394231193e-06,
      "loss": 0.46852693557739256,
      "memory(GiB)": 72.72,
      "step": 14665,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.252081
    },
    {
      "epoch": 1.3683425053633056,
      "grad_norm": 4.415948390960693,
      "learning_rate": 8.693614048896347e-06,
      "loss": 0.46594085693359377,
      "memory(GiB)": 72.72,
      "step": 14670,
      "token_acc": 0.5222222222222223,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.3688088797686784,
      "grad_norm": 3.3954715728759766,
      "learning_rate": 8.692574352125502e-06,
      "loss": 0.43296337127685547,
      "memory(GiB)": 72.72,
      "step": 14675,
      "train_speed(iter/s)": 0.252082
    },
    {
      "epoch": 1.369275254174051,
      "grad_norm": 4.13029146194458,
      "learning_rate": 8.691534304017583e-06,
      "loss": 0.4275721549987793,
      "memory(GiB)": 72.72,
      "step": 14680,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.252089
    },
    {
      "epoch": 1.3697416285794235,
      "grad_norm": 16.49992561340332,
      "learning_rate": 8.690493904671547e-06,
      "loss": 0.4612566947937012,
      "memory(GiB)": 72.72,
      "step": 14685,
      "train_speed(iter/s)": 0.252091
    },
    {
      "epoch": 1.3702080029847963,
      "grad_norm": 10.270035743713379,
      "learning_rate": 8.689453154186385e-06,
      "loss": 0.42136430740356445,
      "memory(GiB)": 72.72,
      "step": 14690,
      "train_speed(iter/s)": 0.252094
    },
    {
      "epoch": 1.3706743773901688,
      "grad_norm": 5.771938800811768,
      "learning_rate": 8.68841205266112e-06,
      "loss": 0.4534632682800293,
      "memory(GiB)": 72.72,
      "step": 14695,
      "token_acc": 0.7310924369747899,
      "train_speed(iter/s)": 0.252089
    },
    {
      "epoch": 1.3711407517955414,
      "grad_norm": 6.614053726196289,
      "learning_rate": 8.687370600194811e-06,
      "loss": 0.43591890335083006,
      "memory(GiB)": 72.72,
      "step": 14700,
      "token_acc": 0.43478260869565216,
      "train_speed(iter/s)": 0.252084
    },
    {
      "epoch": 1.3716071262009142,
      "grad_norm": 2.7607054710388184,
      "learning_rate": 8.686328796886549e-06,
      "loss": 0.4586818695068359,
      "memory(GiB)": 72.72,
      "step": 14705,
      "token_acc": 0.54,
      "train_speed(iter/s)": 0.252087
    },
    {
      "epoch": 1.3720735006062867,
      "grad_norm": 4.713977336883545,
      "learning_rate": 8.685286642835458e-06,
      "loss": 0.4158018589019775,
      "memory(GiB)": 72.72,
      "step": 14710,
      "token_acc": 0.4722222222222222,
      "train_speed(iter/s)": 0.252086
    },
    {
      "epoch": 1.3725398750116593,
      "grad_norm": 3.7760047912597656,
      "learning_rate": 8.684244138140697e-06,
      "loss": 0.4582841873168945,
      "memory(GiB)": 72.72,
      "step": 14715,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.25209
    },
    {
      "epoch": 1.373006249417032,
      "grad_norm": 3.7413063049316406,
      "learning_rate": 8.683201282901452e-06,
      "loss": 0.4439715385437012,
      "memory(GiB)": 72.72,
      "step": 14720,
      "token_acc": 0.9306930693069307,
      "train_speed(iter/s)": 0.252091
    },
    {
      "epoch": 1.3734726238224046,
      "grad_norm": 8.696819305419922,
      "learning_rate": 8.682158077216956e-06,
      "loss": 0.4637901782989502,
      "memory(GiB)": 72.72,
      "step": 14725,
      "train_speed(iter/s)": 0.252092
    },
    {
      "epoch": 1.3739389982277772,
      "grad_norm": 8.680045127868652,
      "learning_rate": 8.68111452118646e-06,
      "loss": 0.45821218490600585,
      "memory(GiB)": 72.72,
      "step": 14730,
      "token_acc": 0.36666666666666664,
      "train_speed(iter/s)": 0.252097
    },
    {
      "epoch": 1.37440537263315,
      "grad_norm": 6.633411884307861,
      "learning_rate": 8.680070614909255e-06,
      "loss": 0.4440913200378418,
      "memory(GiB)": 72.72,
      "step": 14735,
      "train_speed(iter/s)": 0.252098
    },
    {
      "epoch": 1.3748717470385226,
      "grad_norm": 9.530720710754395,
      "learning_rate": 8.679026358484671e-06,
      "loss": 0.44096736907958983,
      "memory(GiB)": 72.72,
      "step": 14740,
      "train_speed(iter/s)": 0.252101
    },
    {
      "epoch": 1.3753381214438951,
      "grad_norm": 6.345427513122559,
      "learning_rate": 8.677981752012061e-06,
      "loss": 0.45159063339233396,
      "memory(GiB)": 72.72,
      "step": 14745,
      "train_speed(iter/s)": 0.2521
    },
    {
      "epoch": 1.375804495849268,
      "grad_norm": 6.133158206939697,
      "learning_rate": 8.676936795590819e-06,
      "loss": 0.44440202713012694,
      "memory(GiB)": 72.72,
      "step": 14750,
      "token_acc": 0.46938775510204084,
      "train_speed(iter/s)": 0.252103
    },
    {
      "epoch": 1.3762708702546405,
      "grad_norm": 28.071331024169922,
      "learning_rate": 8.675891489320366e-06,
      "loss": 0.43469414710998533,
      "memory(GiB)": 72.72,
      "step": 14755,
      "token_acc": 0.7647058823529411,
      "train_speed(iter/s)": 0.252103
    },
    {
      "epoch": 1.376737244660013,
      "grad_norm": 6.087963104248047,
      "learning_rate": 8.674845833300163e-06,
      "loss": 0.5105483055114746,
      "memory(GiB)": 72.72,
      "step": 14760,
      "token_acc": 0.6101694915254238,
      "train_speed(iter/s)": 0.252111
    },
    {
      "epoch": 1.3772036190653858,
      "grad_norm": 5.849907398223877,
      "learning_rate": 8.673799827629698e-06,
      "loss": 0.4277037620544434,
      "memory(GiB)": 72.72,
      "step": 14765,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.3776699934707584,
      "grad_norm": 5.2849440574646,
      "learning_rate": 8.672753472408499e-06,
      "loss": 0.42892656326293943,
      "memory(GiB)": 72.72,
      "step": 14770,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.252111
    },
    {
      "epoch": 1.378136367876131,
      "grad_norm": 6.60438346862793,
      "learning_rate": 8.67170676773612e-06,
      "loss": 0.4459393501281738,
      "memory(GiB)": 72.72,
      "step": 14775,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.252114
    },
    {
      "epoch": 1.3786027422815037,
      "grad_norm": 4.990774154663086,
      "learning_rate": 8.670659713712153e-06,
      "loss": 0.4102262020111084,
      "memory(GiB)": 72.72,
      "step": 14780,
      "token_acc": 0.41379310344827586,
      "train_speed(iter/s)": 0.252115
    },
    {
      "epoch": 1.3790691166868763,
      "grad_norm": 6.123313903808594,
      "learning_rate": 8.669612310436224e-06,
      "loss": 0.45714359283447265,
      "memory(GiB)": 72.72,
      "step": 14785,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.252111
    },
    {
      "epoch": 1.3795354910922488,
      "grad_norm": 9.06674575805664,
      "learning_rate": 8.668564558007984e-06,
      "loss": 0.43999223709106444,
      "memory(GiB)": 72.72,
      "step": 14790,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.3800018654976216,
      "grad_norm": 7.328082084655762,
      "learning_rate": 8.667516456527131e-06,
      "loss": 0.44507737159729005,
      "memory(GiB)": 72.72,
      "step": 14795,
      "token_acc": 0.5223880597014925,
      "train_speed(iter/s)": 0.252113
    },
    {
      "epoch": 1.3804682399029942,
      "grad_norm": 4.450592994689941,
      "learning_rate": 8.666468006093386e-06,
      "loss": 0.4645353317260742,
      "memory(GiB)": 72.72,
      "step": 14800,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.3809346143083667,
      "grad_norm": 5.098845958709717,
      "learning_rate": 8.665419206806503e-06,
      "loss": 0.43736824989318845,
      "memory(GiB)": 72.72,
      "step": 14805,
      "train_speed(iter/s)": 0.252113
    },
    {
      "epoch": 1.3814009887137395,
      "grad_norm": 7.9243950843811035,
      "learning_rate": 8.664370058766274e-06,
      "loss": 0.48932685852050783,
      "memory(GiB)": 72.72,
      "step": 14810,
      "token_acc": 0.47540983606557374,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.381867363119112,
      "grad_norm": 6.775847434997559,
      "learning_rate": 8.66332056207252e-06,
      "loss": 0.44112215042114256,
      "memory(GiB)": 72.72,
      "step": 14815,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.3823337375244846,
      "grad_norm": 12.43275260925293,
      "learning_rate": 8.662270716825106e-06,
      "loss": 0.487703800201416,
      "memory(GiB)": 72.72,
      "step": 14820,
      "token_acc": 0.6170212765957447,
      "train_speed(iter/s)": 0.252117
    },
    {
      "epoch": 1.3828001119298574,
      "grad_norm": 6.146854400634766,
      "learning_rate": 8.66122052312391e-06,
      "loss": 0.4603735446929932,
      "memory(GiB)": 72.72,
      "step": 14825,
      "token_acc": 0.9680851063829787,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.38326648633523,
      "grad_norm": 5.129952430725098,
      "learning_rate": 8.660169981068863e-06,
      "loss": 0.4306673049926758,
      "memory(GiB)": 72.72,
      "step": 14830,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.252119
    },
    {
      "epoch": 1.3837328607406025,
      "grad_norm": 5.780350685119629,
      "learning_rate": 8.659119090759916e-06,
      "loss": 0.4313100814819336,
      "memory(GiB)": 72.72,
      "step": 14835,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.3841992351459753,
      "grad_norm": 3.380667209625244,
      "learning_rate": 8.658067852297058e-06,
      "loss": 0.4439934253692627,
      "memory(GiB)": 72.72,
      "step": 14840,
      "token_acc": 0.9534883720930233,
      "train_speed(iter/s)": 0.252121
    },
    {
      "epoch": 1.3846656095513479,
      "grad_norm": 7.0182390213012695,
      "learning_rate": 8.657016265780315e-06,
      "loss": 0.476700496673584,
      "memory(GiB)": 72.72,
      "step": 14845,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.3851319839567204,
      "grad_norm": 3.3327431678771973,
      "learning_rate": 8.65596433130974e-06,
      "loss": 0.47010087966918945,
      "memory(GiB)": 72.72,
      "step": 14850,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.25212
    },
    {
      "epoch": 1.3855983583620932,
      "grad_norm": 7.475434303283691,
      "learning_rate": 8.654912048985422e-06,
      "loss": 0.43320498466491697,
      "memory(GiB)": 72.72,
      "step": 14855,
      "train_speed(iter/s)": 0.252123
    },
    {
      "epoch": 1.3860647327674658,
      "grad_norm": 6.856359481811523,
      "learning_rate": 8.653859418907479e-06,
      "loss": 0.44116697311401365,
      "memory(GiB)": 72.72,
      "step": 14860,
      "train_speed(iter/s)": 0.252125
    },
    {
      "epoch": 1.3865311071728383,
      "grad_norm": 3.4340405464172363,
      "learning_rate": 8.652806441176071e-06,
      "loss": 0.4715413093566895,
      "memory(GiB)": 72.72,
      "step": 14865,
      "train_speed(iter/s)": 0.252128
    },
    {
      "epoch": 1.3869974815782111,
      "grad_norm": 6.861946105957031,
      "learning_rate": 8.651753115891382e-06,
      "loss": 0.4370603561401367,
      "memory(GiB)": 72.72,
      "step": 14870,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.252042
    },
    {
      "epoch": 1.3874638559835837,
      "grad_norm": 5.432811737060547,
      "learning_rate": 8.650699443153634e-06,
      "loss": 0.4118718147277832,
      "memory(GiB)": 72.72,
      "step": 14875,
      "token_acc": 0.9304347826086956,
      "train_speed(iter/s)": 0.252031
    },
    {
      "epoch": 1.3879302303889562,
      "grad_norm": 3.63559889793396,
      "learning_rate": 8.64964542306308e-06,
      "loss": 0.4084421157836914,
      "memory(GiB)": 72.72,
      "step": 14880,
      "token_acc": 0.5588235294117647,
      "train_speed(iter/s)": 0.252034
    },
    {
      "epoch": 1.388396604794329,
      "grad_norm": 4.092339515686035,
      "learning_rate": 8.648591055720007e-06,
      "loss": 0.434291934967041,
      "memory(GiB)": 72.72,
      "step": 14885,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.3888629791997016,
      "grad_norm": 4.797247409820557,
      "learning_rate": 8.647536341224734e-06,
      "loss": 0.45617475509643557,
      "memory(GiB)": 72.72,
      "step": 14890,
      "token_acc": 0.5342465753424658,
      "train_speed(iter/s)": 0.252029
    },
    {
      "epoch": 1.3893293536050741,
      "grad_norm": 4.198314189910889,
      "learning_rate": 8.646481279677617e-06,
      "loss": 0.43253498077392577,
      "memory(GiB)": 72.72,
      "step": 14895,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 1.3897957280104467,
      "grad_norm": 4.731507301330566,
      "learning_rate": 8.645425871179036e-06,
      "loss": 0.4641002655029297,
      "memory(GiB)": 72.72,
      "step": 14900,
      "token_acc": 0.4868421052631579,
      "train_speed(iter/s)": 0.252037
    },
    {
      "epoch": 1.3902621024158195,
      "grad_norm": 4.79871129989624,
      "learning_rate": 8.644370115829415e-06,
      "loss": 0.4446547985076904,
      "memory(GiB)": 72.72,
      "step": 14905,
      "token_acc": 0.5360824742268041,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.390728476821192,
      "grad_norm": 5.641025066375732,
      "learning_rate": 8.643314013729205e-06,
      "loss": 0.5074734687805176,
      "memory(GiB)": 72.72,
      "step": 14910,
      "train_speed(iter/s)": 0.252038
    },
    {
      "epoch": 1.3911948512265646,
      "grad_norm": 3.696465492248535,
      "learning_rate": 8.642257564978888e-06,
      "loss": 0.44845333099365237,
      "memory(GiB)": 72.72,
      "step": 14915,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.3916612256319374,
      "grad_norm": 5.268784523010254,
      "learning_rate": 8.641200769678988e-06,
      "loss": 0.4697854042053223,
      "memory(GiB)": 72.72,
      "step": 14920,
      "train_speed(iter/s)": 0.252037
    },
    {
      "epoch": 1.39212760003731,
      "grad_norm": 4.260585784912109,
      "learning_rate": 8.640143627930047e-06,
      "loss": 0.47168502807617185,
      "memory(GiB)": 72.72,
      "step": 14925,
      "train_speed(iter/s)": 0.252039
    },
    {
      "epoch": 1.3925939744426825,
      "grad_norm": 5.686498641967773,
      "learning_rate": 8.639086139832658e-06,
      "loss": 0.45444798469543457,
      "memory(GiB)": 72.72,
      "step": 14930,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.3930603488480553,
      "grad_norm": 3.9169843196868896,
      "learning_rate": 8.638028305487429e-06,
      "loss": 0.44382333755493164,
      "memory(GiB)": 72.72,
      "step": 14935,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.3935267232534279,
      "grad_norm": 3.3179256916046143,
      "learning_rate": 8.636970124995017e-06,
      "loss": 0.48438091278076173,
      "memory(GiB)": 72.72,
      "step": 14940,
      "token_acc": 0.5102040816326531,
      "train_speed(iter/s)": 0.252037
    },
    {
      "epoch": 1.3939930976588004,
      "grad_norm": 5.558058261871338,
      "learning_rate": 8.6359115984561e-06,
      "loss": 0.48093395233154296,
      "memory(GiB)": 72.72,
      "step": 14945,
      "train_speed(iter/s)": 0.252039
    },
    {
      "epoch": 1.3944594720641732,
      "grad_norm": 4.6942925453186035,
      "learning_rate": 8.634852725971395e-06,
      "loss": 0.45857868194580076,
      "memory(GiB)": 72.72,
      "step": 14950,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.252039
    },
    {
      "epoch": 1.3949258464695458,
      "grad_norm": 6.286478519439697,
      "learning_rate": 8.633793507641653e-06,
      "loss": 0.4458205223083496,
      "memory(GiB)": 72.72,
      "step": 14955,
      "token_acc": 0.4959349593495935,
      "train_speed(iter/s)": 0.252045
    },
    {
      "epoch": 1.3953922208749183,
      "grad_norm": 11.062159538269043,
      "learning_rate": 8.63273394356765e-06,
      "loss": 0.42492022514343264,
      "memory(GiB)": 72.72,
      "step": 14960,
      "train_speed(iter/s)": 0.252048
    },
    {
      "epoch": 1.3958585952802909,
      "grad_norm": 3.793978214263916,
      "learning_rate": 8.631674033850204e-06,
      "loss": 0.40079426765441895,
      "memory(GiB)": 72.72,
      "step": 14965,
      "token_acc": 0.5181818181818182,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.3963249696856637,
      "grad_norm": 4.837244987487793,
      "learning_rate": 8.630613778590162e-06,
      "loss": 0.47924132347106935,
      "memory(GiB)": 72.72,
      "step": 14970,
      "token_acc": 0.574468085106383,
      "train_speed(iter/s)": 0.252049
    },
    {
      "epoch": 1.3967913440910362,
      "grad_norm": 9.207776069641113,
      "learning_rate": 8.629553177888404e-06,
      "loss": 0.4941319465637207,
      "memory(GiB)": 72.72,
      "step": 14975,
      "token_acc": 0.91,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.3972577184964088,
      "grad_norm": 8.92552375793457,
      "learning_rate": 8.62849223184584e-06,
      "loss": 0.4759033203125,
      "memory(GiB)": 72.72,
      "step": 14980,
      "train_speed(iter/s)": 0.25205
    },
    {
      "epoch": 1.3977240929017816,
      "grad_norm": 7.036706924438477,
      "learning_rate": 8.62743094056342e-06,
      "loss": 0.49900455474853517,
      "memory(GiB)": 72.72,
      "step": 14985,
      "token_acc": 0.36507936507936506,
      "train_speed(iter/s)": 0.25205
    },
    {
      "epoch": 1.3981904673071541,
      "grad_norm": 8.46428394317627,
      "learning_rate": 8.626369304142119e-06,
      "loss": 0.4365082740783691,
      "memory(GiB)": 72.72,
      "step": 14990,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.3986568417125267,
      "grad_norm": 5.403264999389648,
      "learning_rate": 8.625307322682952e-06,
      "loss": 0.48433446884155273,
      "memory(GiB)": 72.72,
      "step": 14995,
      "token_acc": 0.9135802469135802,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.3991232161178995,
      "grad_norm": 5.164309978485107,
      "learning_rate": 8.62424499628696e-06,
      "loss": 0.4600506782531738,
      "memory(GiB)": 72.72,
      "step": 15000,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.399589590523272,
      "grad_norm": 8.927002906799316,
      "learning_rate": 8.623182325055222e-06,
      "loss": 0.45340719223022463,
      "memory(GiB)": 72.72,
      "step": 15005,
      "token_acc": 0.4690265486725664,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.4000559649286446,
      "grad_norm": 4.009505271911621,
      "learning_rate": 8.622119309088845e-06,
      "loss": 0.4567784309387207,
      "memory(GiB)": 72.72,
      "step": 15010,
      "token_acc": 0.49746192893401014,
      "train_speed(iter/s)": 0.252062
    },
    {
      "epoch": 1.4005223393340174,
      "grad_norm": 5.003543376922607,
      "learning_rate": 8.621055948488976e-06,
      "loss": 0.466793155670166,
      "memory(GiB)": 72.72,
      "step": 15015,
      "train_speed(iter/s)": 0.252061
    },
    {
      "epoch": 1.40098871373939,
      "grad_norm": 7.805070877075195,
      "learning_rate": 8.619992243356788e-06,
      "loss": 0.4522817611694336,
      "memory(GiB)": 72.72,
      "step": 15020,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.4014550881447625,
      "grad_norm": 5.868065357208252,
      "learning_rate": 8.61892819379349e-06,
      "loss": 0.4278438091278076,
      "memory(GiB)": 72.72,
      "step": 15025,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.4019214625501353,
      "grad_norm": 3.269895553588867,
      "learning_rate": 8.617863799900324e-06,
      "loss": 0.44141626358032227,
      "memory(GiB)": 72.72,
      "step": 15030,
      "token_acc": 0.5179856115107914,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.4023878369555078,
      "grad_norm": 5.770228862762451,
      "learning_rate": 8.61679906177856e-06,
      "loss": 0.43459558486938477,
      "memory(GiB)": 72.72,
      "step": 15035,
      "token_acc": 0.5344827586206896,
      "train_speed(iter/s)": 0.252064
    },
    {
      "epoch": 1.4028542113608804,
      "grad_norm": 4.3290300369262695,
      "learning_rate": 8.615733979529508e-06,
      "loss": 0.40770320892333983,
      "memory(GiB)": 72.72,
      "step": 15040,
      "token_acc": 0.4794520547945205,
      "train_speed(iter/s)": 0.252061
    },
    {
      "epoch": 1.4033205857662532,
      "grad_norm": 6.159639358520508,
      "learning_rate": 8.614668553254506e-06,
      "loss": 0.42981905937194825,
      "memory(GiB)": 72.72,
      "step": 15045,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.252061
    },
    {
      "epoch": 1.4037869601716257,
      "grad_norm": 8.016373634338379,
      "learning_rate": 8.613602783054928e-06,
      "loss": 0.46752161979675294,
      "memory(GiB)": 72.72,
      "step": 15050,
      "train_speed(iter/s)": 0.25207
    },
    {
      "epoch": 1.4042533345769983,
      "grad_norm": 11.636603355407715,
      "learning_rate": 8.612536669032176e-06,
      "loss": 0.443436861038208,
      "memory(GiB)": 72.72,
      "step": 15055,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.252072
    },
    {
      "epoch": 1.404719708982371,
      "grad_norm": 4.93498420715332,
      "learning_rate": 8.61147021128769e-06,
      "loss": 0.4764529228210449,
      "memory(GiB)": 72.72,
      "step": 15060,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.4051860833877436,
      "grad_norm": 5.167577743530273,
      "learning_rate": 8.610403409922936e-06,
      "loss": 0.4739116668701172,
      "memory(GiB)": 72.72,
      "step": 15065,
      "token_acc": 0.40350877192982454,
      "train_speed(iter/s)": 0.252065
    },
    {
      "epoch": 1.4056524577931162,
      "grad_norm": 6.162209510803223,
      "learning_rate": 8.60933626503942e-06,
      "loss": 0.44799013137817384,
      "memory(GiB)": 72.72,
      "step": 15070,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.406118832198489,
      "grad_norm": 4.178625106811523,
      "learning_rate": 8.60826877673868e-06,
      "loss": 0.45946836471557617,
      "memory(GiB)": 72.72,
      "step": 15075,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.4065852066038615,
      "grad_norm": 4.675682544708252,
      "learning_rate": 8.607200945122281e-06,
      "loss": 0.4188797950744629,
      "memory(GiB)": 72.72,
      "step": 15080,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.407051581009234,
      "grad_norm": 4.1142964363098145,
      "learning_rate": 8.606132770291821e-06,
      "loss": 0.46907339096069334,
      "memory(GiB)": 72.72,
      "step": 15085,
      "token_acc": 0.42696629213483145,
      "train_speed(iter/s)": 0.252075
    },
    {
      "epoch": 1.407517955414607,
      "grad_norm": 7.730342388153076,
      "learning_rate": 8.60506425234894e-06,
      "loss": 0.46888418197631837,
      "memory(GiB)": 72.72,
      "step": 15090,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.4079843298199795,
      "grad_norm": 6.887812614440918,
      "learning_rate": 8.603995391395301e-06,
      "loss": 0.42127137184143065,
      "memory(GiB)": 72.72,
      "step": 15095,
      "token_acc": 0.4461538461538462,
      "train_speed(iter/s)": 0.252082
    },
    {
      "epoch": 1.408450704225352,
      "grad_norm": 5.215999603271484,
      "learning_rate": 8.602926187532601e-06,
      "loss": 0.4494961738586426,
      "memory(GiB)": 72.72,
      "step": 15100,
      "token_acc": 0.576271186440678,
      "train_speed(iter/s)": 0.252086
    },
    {
      "epoch": 1.4089170786307248,
      "grad_norm": 6.295620441436768,
      "learning_rate": 8.601856640862576e-06,
      "loss": 0.43304014205932617,
      "memory(GiB)": 72.72,
      "step": 15105,
      "train_speed(iter/s)": 0.252089
    },
    {
      "epoch": 1.4093834530360974,
      "grad_norm": 4.3972601890563965,
      "learning_rate": 8.600786751486984e-06,
      "loss": 0.43021674156188966,
      "memory(GiB)": 72.72,
      "step": 15110,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.252095
    },
    {
      "epoch": 1.40984982744147,
      "grad_norm": 3.6411921977996826,
      "learning_rate": 8.599716519507628e-06,
      "loss": 0.45493135452270506,
      "memory(GiB)": 72.72,
      "step": 15115,
      "train_speed(iter/s)": 0.252095
    },
    {
      "epoch": 1.4103162018468427,
      "grad_norm": 2.451104164123535,
      "learning_rate": 8.598645945026334e-06,
      "loss": 0.44533615112304686,
      "memory(GiB)": 72.72,
      "step": 15120,
      "token_acc": 0.43478260869565216,
      "train_speed(iter/s)": 0.252094
    },
    {
      "epoch": 1.4107825762522153,
      "grad_norm": 3.5747900009155273,
      "learning_rate": 8.597575028144964e-06,
      "loss": 0.4723196983337402,
      "memory(GiB)": 72.72,
      "step": 15125,
      "token_acc": 0.54,
      "train_speed(iter/s)": 0.252098
    },
    {
      "epoch": 1.4112489506575878,
      "grad_norm": 5.351028919219971,
      "learning_rate": 8.596503768965412e-06,
      "loss": 0.42302713394165037,
      "memory(GiB)": 72.72,
      "step": 15130,
      "train_speed(iter/s)": 0.252097
    },
    {
      "epoch": 1.4117153250629606,
      "grad_norm": 4.33431339263916,
      "learning_rate": 8.595432167589605e-06,
      "loss": 0.46094541549682616,
      "memory(GiB)": 72.72,
      "step": 15135,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.252101
    },
    {
      "epoch": 1.4121816994683332,
      "grad_norm": 8.994546890258789,
      "learning_rate": 8.594360224119504e-06,
      "loss": 0.48081235885620116,
      "memory(GiB)": 72.72,
      "step": 15140,
      "train_speed(iter/s)": 0.252103
    },
    {
      "epoch": 1.4126480738737057,
      "grad_norm": 4.8790717124938965,
      "learning_rate": 8.5932879386571e-06,
      "loss": 0.4379263877868652,
      "memory(GiB)": 72.72,
      "step": 15145,
      "train_speed(iter/s)": 0.252107
    },
    {
      "epoch": 1.4131144482790785,
      "grad_norm": 28.09811782836914,
      "learning_rate": 8.59221531130442e-06,
      "loss": 0.4352621078491211,
      "memory(GiB)": 72.72,
      "step": 15150,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.413580822684451,
      "grad_norm": 3.1481833457946777,
      "learning_rate": 8.591142342163517e-06,
      "loss": 0.42189550399780273,
      "memory(GiB)": 72.72,
      "step": 15155,
      "train_speed(iter/s)": 0.25211
    },
    {
      "epoch": 1.4140471970898236,
      "grad_norm": 3.239920139312744,
      "learning_rate": 8.590069031336485e-06,
      "loss": 0.4421990871429443,
      "memory(GiB)": 72.72,
      "step": 15160,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.4145135714951964,
      "grad_norm": 3.5719075202941895,
      "learning_rate": 8.588995378925442e-06,
      "loss": 0.44118623733520507,
      "memory(GiB)": 72.72,
      "step": 15165,
      "train_speed(iter/s)": 0.25211
    },
    {
      "epoch": 1.414979945900569,
      "grad_norm": 7.169856071472168,
      "learning_rate": 8.587921385032545e-06,
      "loss": 0.4188559055328369,
      "memory(GiB)": 72.72,
      "step": 15170,
      "train_speed(iter/s)": 0.252108
    },
    {
      "epoch": 1.4154463203059415,
      "grad_norm": 3.4281551837921143,
      "learning_rate": 8.586847049759983e-06,
      "loss": 0.46252593994140623,
      "memory(GiB)": 72.72,
      "step": 15175,
      "token_acc": 0.967391304347826,
      "train_speed(iter/s)": 0.252107
    },
    {
      "epoch": 1.4159126947113143,
      "grad_norm": 4.274863243103027,
      "learning_rate": 8.585772373209972e-06,
      "loss": 0.4107905387878418,
      "memory(GiB)": 72.72,
      "step": 15180,
      "token_acc": 0.417910447761194,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.4163790691166869,
      "grad_norm": 2.9626686573028564,
      "learning_rate": 8.584697355484767e-06,
      "loss": 0.4200320243835449,
      "memory(GiB)": 72.72,
      "step": 15185,
      "token_acc": 0.6764705882352942,
      "train_speed(iter/s)": 0.252108
    },
    {
      "epoch": 1.4168454435220594,
      "grad_norm": 5.343235492706299,
      "learning_rate": 8.583621996686652e-06,
      "loss": 0.5256939888000488,
      "memory(GiB)": 72.72,
      "step": 15190,
      "token_acc": 0.4418604651162791,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.4173118179274322,
      "grad_norm": 4.251188278198242,
      "learning_rate": 8.582546296917942e-06,
      "loss": 0.46260967254638674,
      "memory(GiB)": 72.72,
      "step": 15195,
      "train_speed(iter/s)": 0.252115
    },
    {
      "epoch": 1.4177781923328048,
      "grad_norm": 3.8899405002593994,
      "learning_rate": 8.581470256280988e-06,
      "loss": 0.4455542087554932,
      "memory(GiB)": 72.72,
      "step": 15200,
      "token_acc": 0.4174757281553398,
      "train_speed(iter/s)": 0.252117
    },
    {
      "epoch": 1.4182445667381773,
      "grad_norm": 5.98518180847168,
      "learning_rate": 8.580393874878174e-06,
      "loss": 0.44294037818908694,
      "memory(GiB)": 72.72,
      "step": 15205,
      "train_speed(iter/s)": 0.252113
    },
    {
      "epoch": 1.4187109411435501,
      "grad_norm": 2.4456512928009033,
      "learning_rate": 8.57931715281191e-06,
      "loss": 0.4493569850921631,
      "memory(GiB)": 72.72,
      "step": 15210,
      "token_acc": 0.755868544600939,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.4191773155489227,
      "grad_norm": 3.651569128036499,
      "learning_rate": 8.578240090184648e-06,
      "loss": 0.42599191665649416,
      "memory(GiB)": 72.72,
      "step": 15215,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.4196436899542952,
      "grad_norm": 3.4704675674438477,
      "learning_rate": 8.577162687098864e-06,
      "loss": 0.4258847236633301,
      "memory(GiB)": 72.72,
      "step": 15220,
      "train_speed(iter/s)": 0.252119
    },
    {
      "epoch": 1.420110064359668,
      "grad_norm": 2.9201815128326416,
      "learning_rate": 8.576084943657069e-06,
      "loss": 0.4936403751373291,
      "memory(GiB)": 72.72,
      "step": 15225,
      "token_acc": 0.7564102564102564,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.4205764387650406,
      "grad_norm": 3.9277994632720947,
      "learning_rate": 8.575006859961807e-06,
      "loss": 0.4556769847869873,
      "memory(GiB)": 72.72,
      "step": 15230,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.4210428131704131,
      "grad_norm": 4.4582695960998535,
      "learning_rate": 8.573928436115658e-06,
      "loss": 0.429428768157959,
      "memory(GiB)": 72.72,
      "step": 15235,
      "train_speed(iter/s)": 0.252114
    },
    {
      "epoch": 1.421509187575786,
      "grad_norm": 4.1083831787109375,
      "learning_rate": 8.572849672221226e-06,
      "loss": 0.5066763401031494,
      "memory(GiB)": 72.72,
      "step": 15240,
      "token_acc": 0.6764705882352942,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.4219755619811585,
      "grad_norm": 4.262394905090332,
      "learning_rate": 8.571770568381155e-06,
      "loss": 0.42783780097961427,
      "memory(GiB)": 72.72,
      "step": 15245,
      "token_acc": 0.4830508474576271,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.422441936386531,
      "grad_norm": 10.654684066772461,
      "learning_rate": 8.570691124698116e-06,
      "loss": 0.4340367317199707,
      "memory(GiB)": 72.72,
      "step": 15250,
      "train_speed(iter/s)": 0.252122
    },
    {
      "epoch": 1.4229083107919038,
      "grad_norm": 6.945913791656494,
      "learning_rate": 8.569611341274818e-06,
      "loss": 0.4676321029663086,
      "memory(GiB)": 72.72,
      "step": 15255,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.252119
    },
    {
      "epoch": 1.4233746851972764,
      "grad_norm": 7.238779067993164,
      "learning_rate": 8.568531218213998e-06,
      "loss": 0.4688405513763428,
      "memory(GiB)": 72.72,
      "step": 15260,
      "train_speed(iter/s)": 0.252117
    },
    {
      "epoch": 1.423841059602649,
      "grad_norm": 7.691890239715576,
      "learning_rate": 8.567450755618425e-06,
      "loss": 0.4849687099456787,
      "memory(GiB)": 72.72,
      "step": 15265,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.25212
    },
    {
      "epoch": 1.4243074340080217,
      "grad_norm": 12.984837532043457,
      "learning_rate": 8.5663699535909e-06,
      "loss": 0.5143157958984375,
      "memory(GiB)": 72.72,
      "step": 15270,
      "token_acc": 0.9292929292929293,
      "train_speed(iter/s)": 0.252121
    },
    {
      "epoch": 1.4247738084133943,
      "grad_norm": 8.034100532531738,
      "learning_rate": 8.565288812234264e-06,
      "loss": 0.42067298889160154,
      "memory(GiB)": 72.72,
      "step": 15275,
      "train_speed(iter/s)": 0.252122
    },
    {
      "epoch": 1.4252401828187669,
      "grad_norm": 3.3647055625915527,
      "learning_rate": 8.564207331651379e-06,
      "loss": 0.4550173759460449,
      "memory(GiB)": 72.72,
      "step": 15280,
      "token_acc": 0.6756756756756757,
      "train_speed(iter/s)": 0.252121
    },
    {
      "epoch": 1.4257065572241396,
      "grad_norm": 3.3079397678375244,
      "learning_rate": 8.563125511945146e-06,
      "loss": 0.4982332706451416,
      "memory(GiB)": 72.72,
      "step": 15285,
      "token_acc": 0.6511627906976745,
      "train_speed(iter/s)": 0.252124
    },
    {
      "epoch": 1.4261729316295122,
      "grad_norm": 3.879488229751587,
      "learning_rate": 8.562043353218498e-06,
      "loss": 0.4037655830383301,
      "memory(GiB)": 72.72,
      "step": 15290,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.25212
    },
    {
      "epoch": 1.4266393060348848,
      "grad_norm": 6.131350994110107,
      "learning_rate": 8.560960855574396e-06,
      "loss": 0.47894582748413084,
      "memory(GiB)": 72.72,
      "step": 15295,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252122
    },
    {
      "epoch": 1.4271056804402575,
      "grad_norm": 4.463979244232178,
      "learning_rate": 8.55987801911584e-06,
      "loss": 0.4814887523651123,
      "memory(GiB)": 72.72,
      "step": 15300,
      "token_acc": 0.3364485981308411,
      "train_speed(iter/s)": 0.252124
    },
    {
      "epoch": 1.42757205484563,
      "grad_norm": 8.300863265991211,
      "learning_rate": 8.558794843945856e-06,
      "loss": 0.4644777297973633,
      "memory(GiB)": 72.72,
      "step": 15305,
      "train_speed(iter/s)": 0.252121
    },
    {
      "epoch": 1.4280384292510027,
      "grad_norm": 4.54482364654541,
      "learning_rate": 8.557711330167508e-06,
      "loss": 0.4065434455871582,
      "memory(GiB)": 72.72,
      "step": 15310,
      "token_acc": 0.5214723926380368,
      "train_speed(iter/s)": 0.252122
    },
    {
      "epoch": 1.4285048036563754,
      "grad_norm": 4.901571750640869,
      "learning_rate": 8.556627477883886e-06,
      "loss": 0.44657001495361326,
      "memory(GiB)": 72.72,
      "step": 15315,
      "train_speed(iter/s)": 0.252124
    },
    {
      "epoch": 1.428971178061748,
      "grad_norm": 3.585642099380493,
      "learning_rate": 8.555543287198116e-06,
      "loss": 0.42400026321411133,
      "memory(GiB)": 72.72,
      "step": 15320,
      "token_acc": 0.5284552845528455,
      "train_speed(iter/s)": 0.252131
    },
    {
      "epoch": 1.4294375524671206,
      "grad_norm": 3.487732172012329,
      "learning_rate": 8.554458758213353e-06,
      "loss": 0.45598883628845216,
      "memory(GiB)": 72.72,
      "step": 15325,
      "token_acc": 0.5922330097087378,
      "train_speed(iter/s)": 0.252136
    },
    {
      "epoch": 1.4299039268724933,
      "grad_norm": 3.9344141483306885,
      "learning_rate": 8.55337389103279e-06,
      "loss": 0.4483345031738281,
      "memory(GiB)": 72.72,
      "step": 15330,
      "train_speed(iter/s)": 0.252134
    },
    {
      "epoch": 1.430370301277866,
      "grad_norm": 3.7638509273529053,
      "learning_rate": 8.55228868575965e-06,
      "loss": 0.41539487838745115,
      "memory(GiB)": 72.72,
      "step": 15335,
      "train_speed(iter/s)": 0.252136
    },
    {
      "epoch": 1.4308366756832385,
      "grad_norm": 4.273240566253662,
      "learning_rate": 8.551203142497181e-06,
      "loss": 0.4536640167236328,
      "memory(GiB)": 72.72,
      "step": 15340,
      "train_speed(iter/s)": 0.252135
    },
    {
      "epoch": 1.4313030500886113,
      "grad_norm": 3.5631535053253174,
      "learning_rate": 8.550117261348675e-06,
      "loss": 0.4257963180541992,
      "memory(GiB)": 72.72,
      "step": 15345,
      "train_speed(iter/s)": 0.252131
    },
    {
      "epoch": 1.4317694244939838,
      "grad_norm": 5.773996829986572,
      "learning_rate": 8.549031042417447e-06,
      "loss": 0.4469568729400635,
      "memory(GiB)": 72.72,
      "step": 15350,
      "train_speed(iter/s)": 0.25213
    },
    {
      "epoch": 1.4322357988993564,
      "grad_norm": 4.379048824310303,
      "learning_rate": 8.54794448580685e-06,
      "loss": 0.46128273010253906,
      "memory(GiB)": 72.72,
      "step": 15355,
      "train_speed(iter/s)": 0.252131
    },
    {
      "epoch": 1.4327021733047292,
      "grad_norm": 5.085010528564453,
      "learning_rate": 8.546857591620264e-06,
      "loss": 0.431537389755249,
      "memory(GiB)": 72.72,
      "step": 15360,
      "train_speed(iter/s)": 0.252133
    },
    {
      "epoch": 1.4331685477101017,
      "grad_norm": 3.353557586669922,
      "learning_rate": 8.545770359961103e-06,
      "loss": 0.38503460884094237,
      "memory(GiB)": 72.72,
      "step": 15365,
      "train_speed(iter/s)": 0.252138
    },
    {
      "epoch": 1.4336349221154743,
      "grad_norm": 2.655583143234253,
      "learning_rate": 8.544682790932817e-06,
      "loss": 0.4146474838256836,
      "memory(GiB)": 72.72,
      "step": 15370,
      "token_acc": 0.5405405405405406,
      "train_speed(iter/s)": 0.25214
    },
    {
      "epoch": 1.434101296520847,
      "grad_norm": 3.412775754928589,
      "learning_rate": 8.543594884638883e-06,
      "loss": 0.4482569217681885,
      "memory(GiB)": 72.72,
      "step": 15375,
      "train_speed(iter/s)": 0.252143
    },
    {
      "epoch": 1.4345676709262196,
      "grad_norm": 3.2720909118652344,
      "learning_rate": 8.542506641182812e-06,
      "loss": 0.42720561027526854,
      "memory(GiB)": 72.72,
      "step": 15380,
      "token_acc": 0.7898089171974523,
      "train_speed(iter/s)": 0.252143
    },
    {
      "epoch": 1.4350340453315922,
      "grad_norm": 4.409756660461426,
      "learning_rate": 8.541418060668147e-06,
      "loss": 0.4581777572631836,
      "memory(GiB)": 72.72,
      "step": 15385,
      "token_acc": 0.9238095238095239,
      "train_speed(iter/s)": 0.252144
    },
    {
      "epoch": 1.435500419736965,
      "grad_norm": 6.8992791175842285,
      "learning_rate": 8.540329143198463e-06,
      "loss": 0.44393043518066405,
      "memory(GiB)": 72.72,
      "step": 15390,
      "train_speed(iter/s)": 0.252146
    },
    {
      "epoch": 1.4359667941423375,
      "grad_norm": 3.6376638412475586,
      "learning_rate": 8.539239888877367e-06,
      "loss": 0.4725767135620117,
      "memory(GiB)": 72.72,
      "step": 15395,
      "train_speed(iter/s)": 0.252147
    },
    {
      "epoch": 1.43643316854771,
      "grad_norm": 6.148218631744385,
      "learning_rate": 8.5381502978085e-06,
      "loss": 0.4727072238922119,
      "memory(GiB)": 72.72,
      "step": 15400,
      "train_speed(iter/s)": 0.252145
    },
    {
      "epoch": 1.4368995429530829,
      "grad_norm": 8.011764526367188,
      "learning_rate": 8.53706037009553e-06,
      "loss": 0.46694655418395997,
      "memory(GiB)": 72.72,
      "step": 15405,
      "train_speed(iter/s)": 0.252145
    },
    {
      "epoch": 1.4373659173584554,
      "grad_norm": 5.097682952880859,
      "learning_rate": 8.535970105842161e-06,
      "loss": 0.4475419521331787,
      "memory(GiB)": 72.72,
      "step": 15410,
      "token_acc": 0.46808510638297873,
      "train_speed(iter/s)": 0.252151
    },
    {
      "epoch": 1.437832291763828,
      "grad_norm": 5.624359130859375,
      "learning_rate": 8.534879505152131e-06,
      "loss": 0.4221766471862793,
      "memory(GiB)": 72.72,
      "step": 15415,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.252155
    },
    {
      "epoch": 1.4382986661692008,
      "grad_norm": 6.886515140533447,
      "learning_rate": 8.533788568129206e-06,
      "loss": 0.4820224761962891,
      "memory(GiB)": 72.72,
      "step": 15420,
      "token_acc": 0.5535714285714286,
      "train_speed(iter/s)": 0.252155
    },
    {
      "epoch": 1.4387650405745733,
      "grad_norm": 5.149798393249512,
      "learning_rate": 8.532697294877184e-06,
      "loss": 0.48021602630615234,
      "memory(GiB)": 72.72,
      "step": 15425,
      "token_acc": 0.5942028985507246,
      "train_speed(iter/s)": 0.252158
    },
    {
      "epoch": 1.4392314149799459,
      "grad_norm": 3.830695390701294,
      "learning_rate": 8.531605685499897e-06,
      "loss": 0.44841485023498534,
      "memory(GiB)": 72.72,
      "step": 15430,
      "token_acc": 0.9342105263157895,
      "train_speed(iter/s)": 0.252161
    },
    {
      "epoch": 1.4396977893853187,
      "grad_norm": 6.9325456619262695,
      "learning_rate": 8.530513740101207e-06,
      "loss": 0.4319697380065918,
      "memory(GiB)": 72.72,
      "step": 15435,
      "train_speed(iter/s)": 0.252163
    },
    {
      "epoch": 1.4401641637906912,
      "grad_norm": 4.900643825531006,
      "learning_rate": 8.529421458785014e-06,
      "loss": 0.43249034881591797,
      "memory(GiB)": 72.72,
      "step": 15440,
      "train_speed(iter/s)": 0.252166
    },
    {
      "epoch": 1.4406305381960638,
      "grad_norm": 3.7222378253936768,
      "learning_rate": 8.52832884165524e-06,
      "loss": 0.43374199867248536,
      "memory(GiB)": 72.72,
      "step": 15445,
      "token_acc": 0.8773584905660378,
      "train_speed(iter/s)": 0.252165
    },
    {
      "epoch": 1.4410969126014364,
      "grad_norm": 5.003897666931152,
      "learning_rate": 8.527235888815845e-06,
      "loss": 0.42300901412963865,
      "memory(GiB)": 72.72,
      "step": 15450,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.252164
    },
    {
      "epoch": 1.4415632870068091,
      "grad_norm": 5.348602294921875,
      "learning_rate": 8.526142600370823e-06,
      "loss": 0.42543697357177734,
      "memory(GiB)": 72.72,
      "step": 15455,
      "token_acc": 0.3673469387755102,
      "train_speed(iter/s)": 0.252163
    },
    {
      "epoch": 1.4420296614121817,
      "grad_norm": 4.039257049560547,
      "learning_rate": 8.525048976424194e-06,
      "loss": 0.4785928726196289,
      "memory(GiB)": 72.72,
      "step": 15460,
      "token_acc": 0.38636363636363635,
      "train_speed(iter/s)": 0.25216
    },
    {
      "epoch": 1.4424960358175543,
      "grad_norm": 4.378120422363281,
      "learning_rate": 8.523955017080015e-06,
      "loss": 0.38169145584106445,
      "memory(GiB)": 72.72,
      "step": 15465,
      "token_acc": 0.6792452830188679,
      "train_speed(iter/s)": 0.252166
    },
    {
      "epoch": 1.442962410222927,
      "grad_norm": 3.4700801372528076,
      "learning_rate": 8.52286072244237e-06,
      "loss": 0.4505641937255859,
      "memory(GiB)": 72.72,
      "step": 15470,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.252167
    },
    {
      "epoch": 1.4434287846282996,
      "grad_norm": 5.956223011016846,
      "learning_rate": 8.521766092615381e-06,
      "loss": 0.4484987258911133,
      "memory(GiB)": 72.72,
      "step": 15475,
      "train_speed(iter/s)": 0.252171
    },
    {
      "epoch": 1.4438951590336722,
      "grad_norm": 11.982229232788086,
      "learning_rate": 8.520671127703197e-06,
      "loss": 0.45752973556518556,
      "memory(GiB)": 72.72,
      "step": 15480,
      "train_speed(iter/s)": 0.252172
    },
    {
      "epoch": 1.444361533439045,
      "grad_norm": 5.281731605529785,
      "learning_rate": 8.519575827810001e-06,
      "loss": 0.46069965362548826,
      "memory(GiB)": 72.72,
      "step": 15485,
      "token_acc": 0.6185567010309279,
      "train_speed(iter/s)": 0.252171
    },
    {
      "epoch": 1.4448279078444175,
      "grad_norm": 2.5209810733795166,
      "learning_rate": 8.518480193040008e-06,
      "loss": 0.46573352813720703,
      "memory(GiB)": 72.72,
      "step": 15490,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.252168
    },
    {
      "epoch": 1.44529428224979,
      "grad_norm": 7.85060977935791,
      "learning_rate": 8.517384223497465e-06,
      "loss": 0.4573081016540527,
      "memory(GiB)": 72.72,
      "step": 15495,
      "train_speed(iter/s)": 0.252173
    },
    {
      "epoch": 1.4457606566551628,
      "grad_norm": 7.252617835998535,
      "learning_rate": 8.516287919286646e-06,
      "loss": 0.40820913314819335,
      "memory(GiB)": 72.72,
      "step": 15500,
      "token_acc": 0.8762886597938144,
      "train_speed(iter/s)": 0.252175
    },
    {
      "epoch": 1.4462270310605354,
      "grad_norm": 4.879464149475098,
      "learning_rate": 8.515191280511864e-06,
      "loss": 0.4460925102233887,
      "memory(GiB)": 72.72,
      "step": 15505,
      "train_speed(iter/s)": 0.252173
    },
    {
      "epoch": 1.446693405465908,
      "grad_norm": 5.871849536895752,
      "learning_rate": 8.51409430727746e-06,
      "loss": 0.45967397689819334,
      "memory(GiB)": 72.72,
      "step": 15510,
      "train_speed(iter/s)": 0.252172
    },
    {
      "epoch": 1.4471597798712805,
      "grad_norm": 15.435667037963867,
      "learning_rate": 8.51299699968781e-06,
      "loss": 0.46088972091674807,
      "memory(GiB)": 72.72,
      "step": 15515,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.252171
    },
    {
      "epoch": 1.4476261542766533,
      "grad_norm": 3.5453813076019287,
      "learning_rate": 8.511899357847317e-06,
      "loss": 0.43290205001831056,
      "memory(GiB)": 72.72,
      "step": 15520,
      "train_speed(iter/s)": 0.252174
    },
    {
      "epoch": 1.4480925286820259,
      "grad_norm": 6.968328475952148,
      "learning_rate": 8.51080138186042e-06,
      "loss": 0.4262510299682617,
      "memory(GiB)": 72.72,
      "step": 15525,
      "train_speed(iter/s)": 0.252172
    },
    {
      "epoch": 1.4485589030873984,
      "grad_norm": 7.006198406219482,
      "learning_rate": 8.509703071831583e-06,
      "loss": 0.43121538162231443,
      "memory(GiB)": 72.72,
      "step": 15530,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.4490252774927712,
      "grad_norm": 17.086946487426758,
      "learning_rate": 8.508604427865313e-06,
      "loss": 0.42420668601989747,
      "memory(GiB)": 72.72,
      "step": 15535,
      "token_acc": 0.5510204081632653,
      "train_speed(iter/s)": 0.252179
    },
    {
      "epoch": 1.4494916518981438,
      "grad_norm": 4.009602069854736,
      "learning_rate": 8.50750545006614e-06,
      "loss": 0.43783063888549806,
      "memory(GiB)": 72.72,
      "step": 15540,
      "train_speed(iter/s)": 0.252178
    },
    {
      "epoch": 1.4499580263035163,
      "grad_norm": 3.4283318519592285,
      "learning_rate": 8.506406138538629e-06,
      "loss": 0.44725022315979,
      "memory(GiB)": 72.72,
      "step": 15545,
      "token_acc": 0.4339622641509434,
      "train_speed(iter/s)": 0.252177
    },
    {
      "epoch": 1.4504244007088891,
      "grad_norm": 4.911835193634033,
      "learning_rate": 8.505306493387376e-06,
      "loss": 0.44423508644104004,
      "memory(GiB)": 72.72,
      "step": 15550,
      "token_acc": 0.6041666666666666,
      "train_speed(iter/s)": 0.252177
    },
    {
      "epoch": 1.4508907751142617,
      "grad_norm": 5.7214789390563965,
      "learning_rate": 8.504206514717006e-06,
      "loss": 0.43085780143737795,
      "memory(GiB)": 72.72,
      "step": 15555,
      "train_speed(iter/s)": 0.25218
    },
    {
      "epoch": 1.4513571495196342,
      "grad_norm": 3.6434006690979004,
      "learning_rate": 8.503106202632183e-06,
      "loss": 0.4440011978149414,
      "memory(GiB)": 72.72,
      "step": 15560,
      "train_speed(iter/s)": 0.252179
    },
    {
      "epoch": 1.451823523925007,
      "grad_norm": 7.981281280517578,
      "learning_rate": 8.502005557237595e-06,
      "loss": 0.4109503746032715,
      "memory(GiB)": 72.72,
      "step": 15565,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.4522898983303796,
      "grad_norm": 3.9619884490966797,
      "learning_rate": 8.500904578637969e-06,
      "loss": 0.4348875045776367,
      "memory(GiB)": 72.72,
      "step": 15570,
      "train_speed(iter/s)": 0.252172
    },
    {
      "epoch": 1.4527562727357521,
      "grad_norm": 3.0777039527893066,
      "learning_rate": 8.499803266938055e-06,
      "loss": 0.49260597229003905,
      "memory(GiB)": 72.72,
      "step": 15575,
      "train_speed(iter/s)": 0.25218
    },
    {
      "epoch": 1.453222647141125,
      "grad_norm": 3.513885974884033,
      "learning_rate": 8.498701622242643e-06,
      "loss": 0.46094679832458496,
      "memory(GiB)": 72.72,
      "step": 15580,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.4536890215464975,
      "grad_norm": 3.807309150695801,
      "learning_rate": 8.49759964465655e-06,
      "loss": 0.3862419366836548,
      "memory(GiB)": 72.72,
      "step": 15585,
      "token_acc": 0.9029126213592233,
      "train_speed(iter/s)": 0.252178
    },
    {
      "epoch": 1.45415539595187,
      "grad_norm": 3.8422563076019287,
      "learning_rate": 8.496497334284625e-06,
      "loss": 0.37901759147644043,
      "memory(GiB)": 72.72,
      "step": 15590,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.4546217703572428,
      "grad_norm": 5.490471363067627,
      "learning_rate": 8.495394691231749e-06,
      "loss": 0.42446722984313967,
      "memory(GiB)": 72.72,
      "step": 15595,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.4550881447626154,
      "grad_norm": 3.5866780281066895,
      "learning_rate": 8.494291715602836e-06,
      "loss": 0.46808414459228515,
      "memory(GiB)": 72.72,
      "step": 15600,
      "train_speed(iter/s)": 0.252176
    },
    {
      "epoch": 1.455554519167988,
      "grad_norm": 6.36568546295166,
      "learning_rate": 8.49318840750283e-06,
      "loss": 0.415540885925293,
      "memory(GiB)": 72.72,
      "step": 15605,
      "token_acc": 0.5221238938053098,
      "train_speed(iter/s)": 0.252173
    },
    {
      "epoch": 1.4560208935733607,
      "grad_norm": 5.27234411239624,
      "learning_rate": 8.49208476703671e-06,
      "loss": 0.468702507019043,
      "memory(GiB)": 72.72,
      "step": 15610,
      "token_acc": 0.41304347826086957,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.4564872679787333,
      "grad_norm": 4.2138848304748535,
      "learning_rate": 8.49098079430948e-06,
      "loss": 0.4407588005065918,
      "memory(GiB)": 72.72,
      "step": 15615,
      "token_acc": 0.532258064516129,
      "train_speed(iter/s)": 0.252054
    },
    {
      "epoch": 1.4569536423841059,
      "grad_norm": 4.428036212921143,
      "learning_rate": 8.489876489426183e-06,
      "loss": 0.41644940376281736,
      "memory(GiB)": 72.72,
      "step": 15620,
      "train_speed(iter/s)": 0.252057
    },
    {
      "epoch": 1.4574200167894786,
      "grad_norm": 8.8748779296875,
      "learning_rate": 8.48877185249189e-06,
      "loss": 0.4628542423248291,
      "memory(GiB)": 72.72,
      "step": 15625,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.4578863911948512,
      "grad_norm": 5.330992698669434,
      "learning_rate": 8.487666883611701e-06,
      "loss": 0.44099769592285154,
      "memory(GiB)": 72.72,
      "step": 15630,
      "token_acc": 0.4431818181818182,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.4583527656002238,
      "grad_norm": 5.785633087158203,
      "learning_rate": 8.486561582890752e-06,
      "loss": 0.4268800735473633,
      "memory(GiB)": 72.72,
      "step": 15635,
      "train_speed(iter/s)": 0.252048
    },
    {
      "epoch": 1.4588191400055965,
      "grad_norm": 14.643814086914062,
      "learning_rate": 8.485455950434209e-06,
      "loss": 0.49761199951171875,
      "memory(GiB)": 72.72,
      "step": 15640,
      "train_speed(iter/s)": 0.252049
    },
    {
      "epoch": 1.459285514410969,
      "grad_norm": 6.289577960968018,
      "learning_rate": 8.484349986347272e-06,
      "loss": 0.5030758857727051,
      "memory(GiB)": 72.72,
      "step": 15645,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.4597518888163417,
      "grad_norm": 4.911273956298828,
      "learning_rate": 8.483243690735163e-06,
      "loss": 0.4572493076324463,
      "memory(GiB)": 72.72,
      "step": 15650,
      "token_acc": 0.65,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.4602182632217144,
      "grad_norm": 4.943737030029297,
      "learning_rate": 8.482137063703152e-06,
      "loss": 0.4669529914855957,
      "memory(GiB)": 72.72,
      "step": 15655,
      "token_acc": 0.9065420560747663,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.460684637627087,
      "grad_norm": 4.238184452056885,
      "learning_rate": 8.481030105356522e-06,
      "loss": 0.41855363845825194,
      "memory(GiB)": 72.72,
      "step": 15660,
      "train_speed(iter/s)": 0.252062
    },
    {
      "epoch": 1.4611510120324596,
      "grad_norm": 7.109651565551758,
      "learning_rate": 8.479922815800603e-06,
      "loss": 0.42142724990844727,
      "memory(GiB)": 72.72,
      "step": 15665,
      "train_speed(iter/s)": 0.252062
    },
    {
      "epoch": 1.4616173864378323,
      "grad_norm": 4.979452610015869,
      "learning_rate": 8.47881519514075e-06,
      "loss": 0.44598774909973143,
      "memory(GiB)": 72.72,
      "step": 15670,
      "train_speed(iter/s)": 0.252064
    },
    {
      "epoch": 1.462083760843205,
      "grad_norm": 3.0329296588897705,
      "learning_rate": 8.477707243482344e-06,
      "loss": 0.4568960189819336,
      "memory(GiB)": 72.72,
      "step": 15675,
      "token_acc": 0.44761904761904764,
      "train_speed(iter/s)": 0.252071
    },
    {
      "epoch": 1.4625501352485775,
      "grad_norm": 4.880144119262695,
      "learning_rate": 8.47659896093081e-06,
      "loss": 0.4628480911254883,
      "memory(GiB)": 72.72,
      "step": 15680,
      "train_speed(iter/s)": 0.252075
    },
    {
      "epoch": 1.4630165096539502,
      "grad_norm": 3.72819185256958,
      "learning_rate": 8.475490347591594e-06,
      "loss": 0.48041338920593263,
      "memory(GiB)": 72.72,
      "step": 15685,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.4634828840593228,
      "grad_norm": 12.735185623168945,
      "learning_rate": 8.47438140357018e-06,
      "loss": 0.42053756713867185,
      "memory(GiB)": 72.72,
      "step": 15690,
      "train_speed(iter/s)": 0.25208
    },
    {
      "epoch": 1.4639492584646954,
      "grad_norm": 4.233554840087891,
      "learning_rate": 8.473272128972077e-06,
      "loss": 0.41068415641784667,
      "memory(GiB)": 72.72,
      "step": 15695,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.4644156328700682,
      "grad_norm": 15.817222595214844,
      "learning_rate": 8.47216252390283e-06,
      "loss": 0.42630724906921386,
      "memory(GiB)": 72.72,
      "step": 15700,
      "token_acc": 0.5274725274725275,
      "train_speed(iter/s)": 0.252078
    },
    {
      "epoch": 1.4648820072754407,
      "grad_norm": 4.670473098754883,
      "learning_rate": 8.471052588468015e-06,
      "loss": 0.4584832191467285,
      "memory(GiB)": 72.72,
      "step": 15705,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.252076
    },
    {
      "epoch": 1.4653483816808133,
      "grad_norm": 4.403029918670654,
      "learning_rate": 8.46994232277324e-06,
      "loss": 0.3987515211105347,
      "memory(GiB)": 72.72,
      "step": 15710,
      "train_speed(iter/s)": 0.252076
    },
    {
      "epoch": 1.465814756086186,
      "grad_norm": 4.13040828704834,
      "learning_rate": 8.468831726924142e-06,
      "loss": 0.41340150833129885,
      "memory(GiB)": 72.72,
      "step": 15715,
      "train_speed(iter/s)": 0.252074
    },
    {
      "epoch": 1.4662811304915586,
      "grad_norm": 4.405722141265869,
      "learning_rate": 8.46772080102639e-06,
      "loss": 0.4144935607910156,
      "memory(GiB)": 72.72,
      "step": 15720,
      "train_speed(iter/s)": 0.252077
    },
    {
      "epoch": 1.4667475048969312,
      "grad_norm": 3.6760311126708984,
      "learning_rate": 8.46660954518569e-06,
      "loss": 0.44481515884399414,
      "memory(GiB)": 72.72,
      "step": 15725,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.252078
    },
    {
      "epoch": 1.467213879302304,
      "grad_norm": 5.773437023162842,
      "learning_rate": 8.465497959507766e-06,
      "loss": 0.4342961311340332,
      "memory(GiB)": 72.72,
      "step": 15730,
      "train_speed(iter/s)": 0.252079
    },
    {
      "epoch": 1.4676802537076765,
      "grad_norm": 3.4930341243743896,
      "learning_rate": 8.46438604409839e-06,
      "loss": 0.43876209259033205,
      "memory(GiB)": 72.72,
      "step": 15735,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.252084
    },
    {
      "epoch": 1.468146628113049,
      "grad_norm": 8.82343864440918,
      "learning_rate": 8.463273799063354e-06,
      "loss": 0.45993719100952146,
      "memory(GiB)": 72.72,
      "step": 15740,
      "train_speed(iter/s)": 0.252087
    },
    {
      "epoch": 1.4686130025184219,
      "grad_norm": 3.621816396713257,
      "learning_rate": 8.462161224508483e-06,
      "loss": 0.43195533752441406,
      "memory(GiB)": 72.72,
      "step": 15745,
      "token_acc": 0.5681818181818182,
      "train_speed(iter/s)": 0.252083
    },
    {
      "epoch": 1.4690793769237944,
      "grad_norm": 4.734154224395752,
      "learning_rate": 8.46104832053964e-06,
      "loss": 0.43023386001586916,
      "memory(GiB)": 72.72,
      "step": 15750,
      "token_acc": 0.484375,
      "train_speed(iter/s)": 0.252088
    },
    {
      "epoch": 1.469545751329167,
      "grad_norm": 9.810859680175781,
      "learning_rate": 8.459935087262709e-06,
      "loss": 0.4390305995941162,
      "memory(GiB)": 72.72,
      "step": 15755,
      "train_speed(iter/s)": 0.252091
    },
    {
      "epoch": 1.4700121257345398,
      "grad_norm": 3.9648988246917725,
      "learning_rate": 8.458821524783613e-06,
      "loss": 0.42971138954162597,
      "memory(GiB)": 72.72,
      "step": 15760,
      "train_speed(iter/s)": 0.252096
    },
    {
      "epoch": 1.4704785001399123,
      "grad_norm": 3.5935919284820557,
      "learning_rate": 8.457707633208305e-06,
      "loss": 0.43204441070556643,
      "memory(GiB)": 72.72,
      "step": 15765,
      "token_acc": 0.6903553299492385,
      "train_speed(iter/s)": 0.252098
    },
    {
      "epoch": 1.4709448745452849,
      "grad_norm": 3.9373228549957275,
      "learning_rate": 8.456593412642767e-06,
      "loss": 0.4354863166809082,
      "memory(GiB)": 72.72,
      "step": 15770,
      "train_speed(iter/s)": 0.252104
    },
    {
      "epoch": 1.4714112489506577,
      "grad_norm": 4.299318790435791,
      "learning_rate": 8.455478863193013e-06,
      "loss": 0.4716053485870361,
      "memory(GiB)": 72.72,
      "step": 15775,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.252101
    },
    {
      "epoch": 1.4718776233560302,
      "grad_norm": 4.561570167541504,
      "learning_rate": 8.454363984965092e-06,
      "loss": 0.41708054542541506,
      "memory(GiB)": 72.72,
      "step": 15780,
      "train_speed(iter/s)": 0.252101
    },
    {
      "epoch": 1.4723439977614028,
      "grad_norm": 3.7633674144744873,
      "learning_rate": 8.45324877806508e-06,
      "loss": 0.44440712928771975,
      "memory(GiB)": 72.72,
      "step": 15785,
      "train_speed(iter/s)": 0.252106
    },
    {
      "epoch": 1.4728103721667756,
      "grad_norm": 4.63531494140625,
      "learning_rate": 8.452133242599083e-06,
      "loss": 0.4439395904541016,
      "memory(GiB)": 72.72,
      "step": 15790,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.252106
    },
    {
      "epoch": 1.4732767465721481,
      "grad_norm": 3.2547903060913086,
      "learning_rate": 8.451017378673242e-06,
      "loss": 0.41935014724731445,
      "memory(GiB)": 72.72,
      "step": 15795,
      "train_speed(iter/s)": 0.252104
    },
    {
      "epoch": 1.4737431209775207,
      "grad_norm": 4.740663528442383,
      "learning_rate": 8.44990118639373e-06,
      "loss": 0.43636488914489746,
      "memory(GiB)": 72.72,
      "step": 15800,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.252104
    },
    {
      "epoch": 1.4742094953828935,
      "grad_norm": 3.79250168800354,
      "learning_rate": 8.448784665866748e-06,
      "loss": 0.4294779300689697,
      "memory(GiB)": 72.72,
      "step": 15805,
      "train_speed(iter/s)": 0.252107
    },
    {
      "epoch": 1.474675869788266,
      "grad_norm": 3.336958885192871,
      "learning_rate": 8.447667817198528e-06,
      "loss": 0.41982011795043944,
      "memory(GiB)": 72.72,
      "step": 15810,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.4751422441936386,
      "grad_norm": 4.910853385925293,
      "learning_rate": 8.446550640495337e-06,
      "loss": 0.39185590744018556,
      "memory(GiB)": 72.72,
      "step": 15815,
      "token_acc": 0.956989247311828,
      "train_speed(iter/s)": 0.252111
    },
    {
      "epoch": 1.4756086185990114,
      "grad_norm": 12.267492294311523,
      "learning_rate": 8.445433135863467e-06,
      "loss": 0.4373334884643555,
      "memory(GiB)": 72.72,
      "step": 15820,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.476074993004384,
      "grad_norm": 5.555398941040039,
      "learning_rate": 8.444315303409252e-06,
      "loss": 0.44139719009399414,
      "memory(GiB)": 72.72,
      "step": 15825,
      "train_speed(iter/s)": 0.252113
    },
    {
      "epoch": 1.4765413674097565,
      "grad_norm": 8.399423599243164,
      "learning_rate": 8.443197143239044e-06,
      "loss": 0.4229758262634277,
      "memory(GiB)": 72.72,
      "step": 15830,
      "token_acc": 0.4423076923076923,
      "train_speed(iter/s)": 0.252113
    },
    {
      "epoch": 1.4770077418151293,
      "grad_norm": 4.034371852874756,
      "learning_rate": 8.442078655459236e-06,
      "loss": 0.44431490898132325,
      "memory(GiB)": 72.72,
      "step": 15835,
      "token_acc": 0.4406779661016949,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.4774741162205018,
      "grad_norm": 4.125364780426025,
      "learning_rate": 8.440959840176247e-06,
      "loss": 0.39450793266296386,
      "memory(GiB)": 72.72,
      "step": 15840,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.4779404906258744,
      "grad_norm": 3.637078285217285,
      "learning_rate": 8.43984069749653e-06,
      "loss": 0.4651339530944824,
      "memory(GiB)": 72.72,
      "step": 15845,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.252111
    },
    {
      "epoch": 1.4784068650312472,
      "grad_norm": 4.041128635406494,
      "learning_rate": 8.438721227526567e-06,
      "loss": 0.486191463470459,
      "memory(GiB)": 72.72,
      "step": 15850,
      "token_acc": 0.5531914893617021,
      "train_speed(iter/s)": 0.252114
    },
    {
      "epoch": 1.4788732394366197,
      "grad_norm": 6.3479719161987305,
      "learning_rate": 8.437601430372871e-06,
      "loss": 0.4398026466369629,
      "memory(GiB)": 72.72,
      "step": 15855,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.4793396138419923,
      "grad_norm": 14.011151313781738,
      "learning_rate": 8.436481306141991e-06,
      "loss": 0.42375645637512205,
      "memory(GiB)": 72.72,
      "step": 15860,
      "token_acc": 0.35555555555555557,
      "train_speed(iter/s)": 0.252114
    },
    {
      "epoch": 1.479805988247365,
      "grad_norm": 8.342239379882812,
      "learning_rate": 8.435360854940499e-06,
      "loss": 0.4254507541656494,
      "memory(GiB)": 72.72,
      "step": 15865,
      "token_acc": 0.41509433962264153,
      "train_speed(iter/s)": 0.252115
    },
    {
      "epoch": 1.4802723626527376,
      "grad_norm": 6.907027244567871,
      "learning_rate": 8.434240076875007e-06,
      "loss": 0.41792917251586914,
      "memory(GiB)": 72.72,
      "step": 15870,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.4807387370581102,
      "grad_norm": 3.2315566539764404,
      "learning_rate": 8.43311897205215e-06,
      "loss": 0.44171552658081054,
      "memory(GiB)": 72.72,
      "step": 15875,
      "token_acc": 0.4818181818181818,
      "train_speed(iter/s)": 0.252107
    },
    {
      "epoch": 1.481205111463483,
      "grad_norm": 5.289167881011963,
      "learning_rate": 8.431997540578599e-06,
      "loss": 0.4225791931152344,
      "memory(GiB)": 72.72,
      "step": 15880,
      "train_speed(iter/s)": 0.252104
    },
    {
      "epoch": 1.4816714858688556,
      "grad_norm": 6.160800457000732,
      "learning_rate": 8.430875782561054e-06,
      "loss": 0.4119254589080811,
      "memory(GiB)": 72.72,
      "step": 15885,
      "train_speed(iter/s)": 0.252107
    },
    {
      "epoch": 1.4821378602742281,
      "grad_norm": 7.349850177764893,
      "learning_rate": 8.429753698106247e-06,
      "loss": 0.45096683502197266,
      "memory(GiB)": 72.72,
      "step": 15890,
      "train_speed(iter/s)": 0.25211
    },
    {
      "epoch": 1.482604234679601,
      "grad_norm": 4.987572193145752,
      "learning_rate": 8.42863128732094e-06,
      "loss": 0.4406131744384766,
      "memory(GiB)": 72.72,
      "step": 15895,
      "train_speed(iter/s)": 0.25211
    },
    {
      "epoch": 1.4830706090849735,
      "grad_norm": 3.815307140350342,
      "learning_rate": 8.427508550311931e-06,
      "loss": 0.4684896469116211,
      "memory(GiB)": 72.72,
      "step": 15900,
      "train_speed(iter/s)": 0.252111
    },
    {
      "epoch": 1.483536983490346,
      "grad_norm": 4.446422576904297,
      "learning_rate": 8.42638548718604e-06,
      "loss": 0.41925630569458006,
      "memory(GiB)": 72.72,
      "step": 15905,
      "train_speed(iter/s)": 0.252112
    },
    {
      "epoch": 1.4840033578957188,
      "grad_norm": 8.969472885131836,
      "learning_rate": 8.425262098050127e-06,
      "loss": 0.446732234954834,
      "memory(GiB)": 72.72,
      "step": 15910,
      "token_acc": 0.49056603773584906,
      "train_speed(iter/s)": 0.25211
    },
    {
      "epoch": 1.4844697323010914,
      "grad_norm": 4.765289783477783,
      "learning_rate": 8.424138383011075e-06,
      "loss": 0.4255941867828369,
      "memory(GiB)": 72.72,
      "step": 15915,
      "train_speed(iter/s)": 0.25211
    },
    {
      "epoch": 1.484936106706464,
      "grad_norm": 4.497351169586182,
      "learning_rate": 8.423014342175805e-06,
      "loss": 0.4284055709838867,
      "memory(GiB)": 72.72,
      "step": 15920,
      "train_speed(iter/s)": 0.252108
    },
    {
      "epoch": 1.4854024811118367,
      "grad_norm": 6.512689590454102,
      "learning_rate": 8.421889975651268e-06,
      "loss": 0.4203904628753662,
      "memory(GiB)": 72.72,
      "step": 15925,
      "train_speed(iter/s)": 0.252109
    },
    {
      "epoch": 1.4858688555172093,
      "grad_norm": 9.034649848937988,
      "learning_rate": 8.420765283544438e-06,
      "loss": 0.45569419860839844,
      "memory(GiB)": 72.72,
      "step": 15930,
      "token_acc": 0.6111111111111112,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.4863352299225818,
      "grad_norm": 5.565673351287842,
      "learning_rate": 8.41964026596233e-06,
      "loss": 0.4202449321746826,
      "memory(GiB)": 72.72,
      "step": 15935,
      "train_speed(iter/s)": 0.252113
    },
    {
      "epoch": 1.4868016043279546,
      "grad_norm": 7.035285949707031,
      "learning_rate": 8.418514923011985e-06,
      "loss": 0.4158653259277344,
      "memory(GiB)": 72.72,
      "step": 15940,
      "token_acc": 0.5142857142857142,
      "train_speed(iter/s)": 0.252115
    },
    {
      "epoch": 1.4872679787333272,
      "grad_norm": 5.580054759979248,
      "learning_rate": 8.417389254800477e-06,
      "loss": 0.43855438232421873,
      "memory(GiB)": 72.72,
      "step": 15945,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.4877343531386997,
      "grad_norm": 5.2443366050720215,
      "learning_rate": 8.416263261434906e-06,
      "loss": 0.43125457763671876,
      "memory(GiB)": 72.72,
      "step": 15950,
      "token_acc": 0.6885245901639344,
      "train_speed(iter/s)": 0.252119
    },
    {
      "epoch": 1.4882007275440725,
      "grad_norm": 3.9021480083465576,
      "learning_rate": 8.415136943022412e-06,
      "loss": 0.4351299285888672,
      "memory(GiB)": 72.72,
      "step": 15955,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.488667101949445,
      "grad_norm": 5.907903671264648,
      "learning_rate": 8.414010299670159e-06,
      "loss": 0.38201260566711426,
      "memory(GiB)": 72.72,
      "step": 15960,
      "train_speed(iter/s)": 0.252117
    },
    {
      "epoch": 1.4891334763548176,
      "grad_norm": 5.559593677520752,
      "learning_rate": 8.412883331485343e-06,
      "loss": 0.4294586181640625,
      "memory(GiB)": 72.72,
      "step": 15965,
      "train_speed(iter/s)": 0.252116
    },
    {
      "epoch": 1.4895998507601904,
      "grad_norm": 4.6189446449279785,
      "learning_rate": 8.411756038575191e-06,
      "loss": 0.4426321029663086,
      "memory(GiB)": 72.72,
      "step": 15970,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.252122
    },
    {
      "epoch": 1.490066225165563,
      "grad_norm": 11.81695556640625,
      "learning_rate": 8.410628421046963e-06,
      "loss": 0.4560566425323486,
      "memory(GiB)": 72.72,
      "step": 15975,
      "token_acc": 0.6170212765957447,
      "train_speed(iter/s)": 0.252118
    },
    {
      "epoch": 1.4905325995709355,
      "grad_norm": 4.225226879119873,
      "learning_rate": 8.409500479007946e-06,
      "loss": 0.43270273208618165,
      "memory(GiB)": 72.72,
      "step": 15980,
      "train_speed(iter/s)": 0.252123
    },
    {
      "epoch": 1.4909989739763083,
      "grad_norm": 11.427242279052734,
      "learning_rate": 8.408372212565463e-06,
      "loss": 0.3922370433807373,
      "memory(GiB)": 72.72,
      "step": 15985,
      "token_acc": 0.49230769230769234,
      "train_speed(iter/s)": 0.252124
    },
    {
      "epoch": 1.4914653483816809,
      "grad_norm": 4.593780517578125,
      "learning_rate": 8.407243621826862e-06,
      "loss": 0.4466578006744385,
      "memory(GiB)": 72.72,
      "step": 15990,
      "train_speed(iter/s)": 0.252125
    },
    {
      "epoch": 1.4919317227870534,
      "grad_norm": 8.714521408081055,
      "learning_rate": 8.406114706899529e-06,
      "loss": 0.47727556228637696,
      "memory(GiB)": 72.72,
      "step": 15995,
      "token_acc": 0.47540983606557374,
      "train_speed(iter/s)": 0.252126
    },
    {
      "epoch": 1.492398097192426,
      "grad_norm": 6.138550758361816,
      "learning_rate": 8.404985467890872e-06,
      "loss": 0.4609241962432861,
      "memory(GiB)": 72.72,
      "step": 16000,
      "token_acc": 0.391304347826087,
      "train_speed(iter/s)": 0.252128
    },
    {
      "epoch": 1.4928644715977988,
      "grad_norm": 8.380926132202148,
      "learning_rate": 8.403855904908338e-06,
      "loss": 0.44223837852478026,
      "memory(GiB)": 72.72,
      "step": 16005,
      "token_acc": 0.4423076923076923,
      "train_speed(iter/s)": 0.252031
    },
    {
      "epoch": 1.4933308460031713,
      "grad_norm": 8.470918655395508,
      "learning_rate": 8.402726018059401e-06,
      "loss": 0.4973764419555664,
      "memory(GiB)": 72.72,
      "step": 16010,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 1.493797220408544,
      "grad_norm": 6.083993434906006,
      "learning_rate": 8.401595807451566e-06,
      "loss": 0.46013836860656737,
      "memory(GiB)": 72.72,
      "step": 16015,
      "token_acc": 0.40540540540540543,
      "train_speed(iter/s)": 0.252028
    },
    {
      "epoch": 1.4942635948139167,
      "grad_norm": 4.980684757232666,
      "learning_rate": 8.400465273192369e-06,
      "loss": 0.4232356071472168,
      "memory(GiB)": 72.72,
      "step": 16020,
      "token_acc": 0.5227272727272727,
      "train_speed(iter/s)": 0.252033
    },
    {
      "epoch": 1.4947299692192892,
      "grad_norm": 10.96664810180664,
      "learning_rate": 8.399334415389374e-06,
      "loss": 0.4296416282653809,
      "memory(GiB)": 72.72,
      "step": 16025,
      "train_speed(iter/s)": 0.252029
    },
    {
      "epoch": 1.4951963436246618,
      "grad_norm": 5.97007942199707,
      "learning_rate": 8.398203234150183e-06,
      "loss": 0.4560372352600098,
      "memory(GiB)": 72.72,
      "step": 16030,
      "train_speed(iter/s)": 0.252026
    },
    {
      "epoch": 1.4956627180300346,
      "grad_norm": 8.213149070739746,
      "learning_rate": 8.397071729582424e-06,
      "loss": 0.4359236717224121,
      "memory(GiB)": 72.72,
      "step": 16035,
      "token_acc": 0.8869565217391304,
      "train_speed(iter/s)": 0.252029
    },
    {
      "epoch": 1.4961290924354071,
      "grad_norm": 4.878579139709473,
      "learning_rate": 8.395939901793753e-06,
      "loss": 0.4421912670135498,
      "memory(GiB)": 72.72,
      "step": 16040,
      "train_speed(iter/s)": 0.252026
    },
    {
      "epoch": 1.4965954668407797,
      "grad_norm": 4.948273658752441,
      "learning_rate": 8.394807750891862e-06,
      "loss": 0.440811824798584,
      "memory(GiB)": 72.72,
      "step": 16045,
      "train_speed(iter/s)": 0.252029
    },
    {
      "epoch": 1.4970618412461525,
      "grad_norm": 7.034048557281494,
      "learning_rate": 8.393675276984474e-06,
      "loss": 0.42684507369995117,
      "memory(GiB)": 72.72,
      "step": 16050,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.497528215651525,
      "grad_norm": 5.810382843017578,
      "learning_rate": 8.392542480179333e-06,
      "loss": 0.4293781280517578,
      "memory(GiB)": 72.72,
      "step": 16055,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 1.4979945900568976,
      "grad_norm": 25.060108184814453,
      "learning_rate": 8.39140936058423e-06,
      "loss": 0.46177196502685547,
      "memory(GiB)": 72.72,
      "step": 16060,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 1.4984609644622702,
      "grad_norm": 3.7251291275024414,
      "learning_rate": 8.390275918306973e-06,
      "loss": 0.42178916931152344,
      "memory(GiB)": 72.72,
      "step": 16065,
      "train_speed(iter/s)": 0.252029
    },
    {
      "epoch": 1.498927338867643,
      "grad_norm": 4.18754768371582,
      "learning_rate": 8.389142153455406e-06,
      "loss": 0.486435079574585,
      "memory(GiB)": 72.72,
      "step": 16070,
      "token_acc": 0.3611111111111111,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 1.4993937132730155,
      "grad_norm": 3.423917531967163,
      "learning_rate": 8.388008066137403e-06,
      "loss": 0.4477090835571289,
      "memory(GiB)": 72.72,
      "step": 16075,
      "token_acc": 0.4954954954954955,
      "train_speed(iter/s)": 0.252034
    },
    {
      "epoch": 1.499860087678388,
      "grad_norm": 7.431049823760986,
      "learning_rate": 8.38687365646087e-06,
      "loss": 0.4837076187133789,
      "memory(GiB)": 72.72,
      "step": 16080,
      "token_acc": 0.4264705882352941,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.5003264620837609,
      "grad_norm": 8.62476634979248,
      "learning_rate": 8.385738924533744e-06,
      "loss": 0.47190022468566895,
      "memory(GiB)": 72.72,
      "step": 16085,
      "token_acc": 0.8164556962025317,
      "train_speed(iter/s)": 0.252036
    },
    {
      "epoch": 1.5007928364891336,
      "grad_norm": 6.083497524261475,
      "learning_rate": 8.384603870463987e-06,
      "loss": 0.40116024017333984,
      "memory(GiB)": 72.72,
      "step": 16090,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.501259210894506,
      "grad_norm": 4.538560390472412,
      "learning_rate": 8.383468494359598e-06,
      "loss": 0.45466203689575196,
      "memory(GiB)": 72.72,
      "step": 16095,
      "token_acc": 0.45652173913043476,
      "train_speed(iter/s)": 0.252034
    },
    {
      "epoch": 1.5017255852998788,
      "grad_norm": 6.870503902435303,
      "learning_rate": 8.382332796328607e-06,
      "loss": 0.45291666984558104,
      "memory(GiB)": 72.72,
      "step": 16100,
      "token_acc": 0.4772727272727273,
      "train_speed(iter/s)": 0.252036
    },
    {
      "epoch": 1.5021919597052513,
      "grad_norm": 8.594141006469727,
      "learning_rate": 8.381196776479068e-06,
      "loss": 0.446943473815918,
      "memory(GiB)": 72.72,
      "step": 16105,
      "token_acc": 0.9166666666666666,
      "train_speed(iter/s)": 0.252031
    },
    {
      "epoch": 1.5026583341106239,
      "grad_norm": 4.204051494598389,
      "learning_rate": 8.380060434919072e-06,
      "loss": 0.46484079360961916,
      "memory(GiB)": 72.72,
      "step": 16110,
      "train_speed(iter/s)": 0.252031
    },
    {
      "epoch": 1.5031247085159967,
      "grad_norm": 3.021604537963867,
      "learning_rate": 8.37892377175674e-06,
      "loss": 0.46259050369262694,
      "memory(GiB)": 72.72,
      "step": 16115,
      "token_acc": 0.9292035398230089,
      "train_speed(iter/s)": 0.252037
    },
    {
      "epoch": 1.5035910829213692,
      "grad_norm": 5.012265205383301,
      "learning_rate": 8.377786787100218e-06,
      "loss": 0.43802294731140134,
      "memory(GiB)": 72.72,
      "step": 16120,
      "train_speed(iter/s)": 0.252038
    },
    {
      "epoch": 1.5040574573267418,
      "grad_norm": 6.5675578117370605,
      "learning_rate": 8.376649481057688e-06,
      "loss": 0.44559507369995116,
      "memory(GiB)": 72.72,
      "step": 16125,
      "token_acc": 0.48333333333333334,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.5045238317321146,
      "grad_norm": 6.780724048614502,
      "learning_rate": 8.375511853737364e-06,
      "loss": 0.4398991584777832,
      "memory(GiB)": 72.72,
      "step": 16130,
      "train_speed(iter/s)": 0.252034
    },
    {
      "epoch": 1.5049902061374871,
      "grad_norm": 4.252011299133301,
      "learning_rate": 8.374373905247486e-06,
      "loss": 0.43127803802490233,
      "memory(GiB)": 72.72,
      "step": 16135,
      "train_speed(iter/s)": 0.252039
    },
    {
      "epoch": 1.5054565805428597,
      "grad_norm": 3.567305088043213,
      "learning_rate": 8.373235635696323e-06,
      "loss": 0.49339680671691893,
      "memory(GiB)": 72.72,
      "step": 16140,
      "token_acc": 0.5662650602409639,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.5059229549482325,
      "grad_norm": 4.40214729309082,
      "learning_rate": 8.372097045192183e-06,
      "loss": 0.42934589385986327,
      "memory(GiB)": 72.72,
      "step": 16145,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.252037
    },
    {
      "epoch": 1.506389329353605,
      "grad_norm": 3.6136109828948975,
      "learning_rate": 8.370958133843398e-06,
      "loss": 0.44159832000732424,
      "memory(GiB)": 72.72,
      "step": 16150,
      "token_acc": 0.4626865671641791,
      "train_speed(iter/s)": 0.252042
    },
    {
      "epoch": 1.5068557037589776,
      "grad_norm": 5.513220310211182,
      "learning_rate": 8.36981890175833e-06,
      "loss": 0.41873912811279296,
      "memory(GiB)": 72.72,
      "step": 16155,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.5073220781643504,
      "grad_norm": 3.570500373840332,
      "learning_rate": 8.368679349045375e-06,
      "loss": 0.40331192016601564,
      "memory(GiB)": 72.72,
      "step": 16160,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.252043
    },
    {
      "epoch": 1.507788452569723,
      "grad_norm": 7.2763190269470215,
      "learning_rate": 8.367539475812956e-06,
      "loss": 0.4522493839263916,
      "memory(GiB)": 72.72,
      "step": 16165,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.5082548269750955,
      "grad_norm": 3.4357752799987793,
      "learning_rate": 8.36639928216953e-06,
      "loss": 0.43207569122314454,
      "memory(GiB)": 72.72,
      "step": 16170,
      "token_acc": 0.6470588235294118,
      "train_speed(iter/s)": 0.252039
    },
    {
      "epoch": 1.5087212013804683,
      "grad_norm": 3.415707588195801,
      "learning_rate": 8.365258768223583e-06,
      "loss": 0.4383867263793945,
      "memory(GiB)": 72.72,
      "step": 16175,
      "token_acc": 0.46938775510204084,
      "train_speed(iter/s)": 0.252046
    },
    {
      "epoch": 1.5091875757858408,
      "grad_norm": 2.5227794647216797,
      "learning_rate": 8.364117934083633e-06,
      "loss": 0.4020657539367676,
      "memory(GiB)": 72.72,
      "step": 16180,
      "token_acc": 0.6585365853658537,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.5096539501912134,
      "grad_norm": 2.834606647491455,
      "learning_rate": 8.362976779858222e-06,
      "loss": 0.4395899295806885,
      "memory(GiB)": 72.72,
      "step": 16185,
      "token_acc": 0.9080459770114943,
      "train_speed(iter/s)": 0.252049
    },
    {
      "epoch": 1.5101203245965862,
      "grad_norm": 3.625828981399536,
      "learning_rate": 8.361835305655933e-06,
      "loss": 0.44535036087036134,
      "memory(GiB)": 72.72,
      "step": 16190,
      "token_acc": 0.5490196078431373,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.5105866990019587,
      "grad_norm": 3.900383949279785,
      "learning_rate": 8.36069351158537e-06,
      "loss": 0.44309301376342775,
      "memory(GiB)": 72.72,
      "step": 16195,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.25205
    },
    {
      "epoch": 1.5110530734073313,
      "grad_norm": 7.5421977043151855,
      "learning_rate": 8.359551397755172e-06,
      "loss": 0.37652695178985596,
      "memory(GiB)": 72.72,
      "step": 16200,
      "token_acc": 0.42,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.511519447812704,
      "grad_norm": 4.9939494132995605,
      "learning_rate": 8.358408964274008e-06,
      "loss": 0.4055224895477295,
      "memory(GiB)": 72.72,
      "step": 16205,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.5119858222180766,
      "grad_norm": 5.322091102600098,
      "learning_rate": 8.357266211250577e-06,
      "loss": 0.46880712509155276,
      "memory(GiB)": 72.72,
      "step": 16210,
      "token_acc": 0.5818181818181818,
      "train_speed(iter/s)": 0.252054
    },
    {
      "epoch": 1.5124521966234492,
      "grad_norm": 5.534890174865723,
      "learning_rate": 8.356123138793608e-06,
      "loss": 0.43133063316345216,
      "memory(GiB)": 72.72,
      "step": 16215,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.512918571028822,
      "grad_norm": 3.761181592941284,
      "learning_rate": 8.354979747011861e-06,
      "loss": 0.42920398712158203,
      "memory(GiB)": 72.72,
      "step": 16220,
      "token_acc": 0.9166666666666666,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.5133849454341946,
      "grad_norm": 4.003259181976318,
      "learning_rate": 8.353836036014126e-06,
      "loss": 0.4722899436950684,
      "memory(GiB)": 72.72,
      "step": 16225,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.5138513198395671,
      "grad_norm": 3.4005439281463623,
      "learning_rate": 8.352692005909224e-06,
      "loss": 0.4638202667236328,
      "memory(GiB)": 72.72,
      "step": 16230,
      "token_acc": 0.4788732394366197,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.51431769424494,
      "grad_norm": 3.3979275226593018,
      "learning_rate": 8.351547656806007e-06,
      "loss": 0.45336389541625977,
      "memory(GiB)": 72.72,
      "step": 16235,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.25206
    },
    {
      "epoch": 1.5147840686503125,
      "grad_norm": 21.447643280029297,
      "learning_rate": 8.350402988813355e-06,
      "loss": 0.4321180820465088,
      "memory(GiB)": 72.72,
      "step": 16240,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.515250443055685,
      "grad_norm": 2.5290446281433105,
      "learning_rate": 8.349258002040179e-06,
      "loss": 0.41519889831542967,
      "memory(GiB)": 72.72,
      "step": 16245,
      "train_speed(iter/s)": 0.25206
    },
    {
      "epoch": 1.5157168174610578,
      "grad_norm": 5.306272506713867,
      "learning_rate": 8.348112696595424e-06,
      "loss": 0.4421224117279053,
      "memory(GiB)": 72.72,
      "step": 16250,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.5161831918664304,
      "grad_norm": 3.3236560821533203,
      "learning_rate": 8.346967072588057e-06,
      "loss": 0.39434902667999266,
      "memory(GiB)": 72.72,
      "step": 16255,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.516649566271803,
      "grad_norm": 6.181533336639404,
      "learning_rate": 8.345821130127085e-06,
      "loss": 0.44831557273864747,
      "memory(GiB)": 72.72,
      "step": 16260,
      "token_acc": 0.5096153846153846,
      "train_speed(iter/s)": 0.252057
    },
    {
      "epoch": 1.5171159406771757,
      "grad_norm": 4.107804775238037,
      "learning_rate": 8.344674869321539e-06,
      "loss": 0.474212646484375,
      "memory(GiB)": 72.72,
      "step": 16265,
      "train_speed(iter/s)": 0.252057
    },
    {
      "epoch": 1.5175823150825483,
      "grad_norm": 2.9842629432678223,
      "learning_rate": 8.343528290280482e-06,
      "loss": 0.4005335807800293,
      "memory(GiB)": 72.72,
      "step": 16270,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.5180486894879208,
      "grad_norm": 4.992892265319824,
      "learning_rate": 8.34238139311301e-06,
      "loss": 0.4325895309448242,
      "memory(GiB)": 72.72,
      "step": 16275,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.5185150638932936,
      "grad_norm": 3.3164327144622803,
      "learning_rate": 8.341234177928243e-06,
      "loss": 0.4109969139099121,
      "memory(GiB)": 72.72,
      "step": 16280,
      "token_acc": 0.8791208791208791,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.5189814382986662,
      "grad_norm": 5.372225284576416,
      "learning_rate": 8.340086644835339e-06,
      "loss": 0.44140262603759767,
      "memory(GiB)": 72.72,
      "step": 16285,
      "token_acc": 0.68,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.5194478127040387,
      "grad_norm": 6.048164367675781,
      "learning_rate": 8.338938793943478e-06,
      "loss": 0.4492677688598633,
      "memory(GiB)": 72.72,
      "step": 16290,
      "token_acc": 0.4608695652173913,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.5199141871094115,
      "grad_norm": 2.9822685718536377,
      "learning_rate": 8.33779062536188e-06,
      "loss": 0.43201169967651365,
      "memory(GiB)": 72.72,
      "step": 16295,
      "train_speed(iter/s)": 0.252053
    },
    {
      "epoch": 1.520380561514784,
      "grad_norm": 4.214868068695068,
      "learning_rate": 8.336642139199782e-06,
      "loss": 0.4442512035369873,
      "memory(GiB)": 72.72,
      "step": 16300,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.5208469359201566,
      "grad_norm": 3.7936787605285645,
      "learning_rate": 8.335493335566467e-06,
      "loss": 0.4765186309814453,
      "memory(GiB)": 72.72,
      "step": 16305,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.5213133103255294,
      "grad_norm": 2.805147409439087,
      "learning_rate": 8.334344214571233e-06,
      "loss": 0.43569369316101075,
      "memory(GiB)": 72.72,
      "step": 16310,
      "token_acc": 0.5172413793103449,
      "train_speed(iter/s)": 0.252061
    },
    {
      "epoch": 1.521779684730902,
      "grad_norm": 4.390549182891846,
      "learning_rate": 8.333194776323422e-06,
      "loss": 0.44747095108032225,
      "memory(GiB)": 72.72,
      "step": 16315,
      "token_acc": 0.6105263157894737,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.5222460591362745,
      "grad_norm": 4.847763538360596,
      "learning_rate": 8.332045020932394e-06,
      "loss": 0.44736452102661134,
      "memory(GiB)": 72.72,
      "step": 16320,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.25206
    },
    {
      "epoch": 1.5227124335416473,
      "grad_norm": 3.039792537689209,
      "learning_rate": 8.330894948507547e-06,
      "loss": 0.4330620288848877,
      "memory(GiB)": 72.72,
      "step": 16325,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.5231788079470199,
      "grad_norm": 5.739315032958984,
      "learning_rate": 8.329744559158307e-06,
      "loss": 0.4272905349731445,
      "memory(GiB)": 72.72,
      "step": 16330,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.25206
    },
    {
      "epoch": 1.5236451823523924,
      "grad_norm": 3.4760305881500244,
      "learning_rate": 8.32859385299413e-06,
      "loss": 0.4362466812133789,
      "memory(GiB)": 72.72,
      "step": 16335,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.5241115567577652,
      "grad_norm": 4.18419075012207,
      "learning_rate": 8.327442830124502e-06,
      "loss": 0.42800559997558596,
      "memory(GiB)": 72.72,
      "step": 16340,
      "train_speed(iter/s)": 0.252062
    },
    {
      "epoch": 1.5245779311631378,
      "grad_norm": 3.782726287841797,
      "learning_rate": 8.326291490658938e-06,
      "loss": 0.43518905639648436,
      "memory(GiB)": 72.72,
      "step": 16345,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251956
    },
    {
      "epoch": 1.5250443055685103,
      "grad_norm": 4.043964385986328,
      "learning_rate": 8.325139834706987e-06,
      "loss": 0.4114924430847168,
      "memory(GiB)": 72.72,
      "step": 16350,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.5255106799738831,
      "grad_norm": 4.967472076416016,
      "learning_rate": 8.323987862378223e-06,
      "loss": 0.41795949935913085,
      "memory(GiB)": 72.72,
      "step": 16355,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.5259770543792557,
      "grad_norm": 3.101207733154297,
      "learning_rate": 8.322835573782255e-06,
      "loss": 0.45896129608154296,
      "memory(GiB)": 72.72,
      "step": 16360,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.5264434287846282,
      "grad_norm": 230.39857482910156,
      "learning_rate": 8.321682969028717e-06,
      "loss": 0.4138747215270996,
      "memory(GiB)": 72.72,
      "step": 16365,
      "train_speed(iter/s)": 0.251932
    },
    {
      "epoch": 1.526909803190001,
      "grad_norm": 2.714932680130005,
      "learning_rate": 8.320530048227278e-06,
      "loss": 0.4032140731811523,
      "memory(GiB)": 72.72,
      "step": 16370,
      "train_speed(iter/s)": 0.251935
    },
    {
      "epoch": 1.5273761775953736,
      "grad_norm": 3.6549084186553955,
      "learning_rate": 8.319376811487635e-06,
      "loss": 0.4650887489318848,
      "memory(GiB)": 72.72,
      "step": 16375,
      "token_acc": 0.7175572519083969,
      "train_speed(iter/s)": 0.25194
    },
    {
      "epoch": 1.5278425520007461,
      "grad_norm": 4.896521091461182,
      "learning_rate": 8.31822325891951e-06,
      "loss": 0.41716761589050294,
      "memory(GiB)": 72.72,
      "step": 16380,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.528308926406119,
      "grad_norm": 3.5255582332611084,
      "learning_rate": 8.317069390632668e-06,
      "loss": 0.4390742301940918,
      "memory(GiB)": 72.72,
      "step": 16385,
      "train_speed(iter/s)": 0.251945
    },
    {
      "epoch": 1.5287753008114915,
      "grad_norm": 3.827354669570923,
      "learning_rate": 8.31591520673689e-06,
      "loss": 0.409969425201416,
      "memory(GiB)": 72.72,
      "step": 16390,
      "train_speed(iter/s)": 0.251947
    },
    {
      "epoch": 1.529241675216864,
      "grad_norm": 3.1388416290283203,
      "learning_rate": 8.314760707341997e-06,
      "loss": 0.38609097003936765,
      "memory(GiB)": 72.72,
      "step": 16395,
      "train_speed(iter/s)": 0.251953
    },
    {
      "epoch": 1.5297080496222368,
      "grad_norm": 3.0097756385803223,
      "learning_rate": 8.313605892557832e-06,
      "loss": 0.43903188705444335,
      "memory(GiB)": 72.72,
      "step": 16400,
      "train_speed(iter/s)": 0.251951
    },
    {
      "epoch": 1.5301744240276094,
      "grad_norm": 3.206118583679199,
      "learning_rate": 8.312450762494275e-06,
      "loss": 0.4457258224487305,
      "memory(GiB)": 72.72,
      "step": 16405,
      "token_acc": 0.4642857142857143,
      "train_speed(iter/s)": 0.251954
    },
    {
      "epoch": 1.530640798432982,
      "grad_norm": 5.070108413696289,
      "learning_rate": 8.311295317261233e-06,
      "loss": 0.4451357364654541,
      "memory(GiB)": 72.72,
      "step": 16410,
      "token_acc": 0.42424242424242425,
      "train_speed(iter/s)": 0.251956
    },
    {
      "epoch": 1.5311071728383547,
      "grad_norm": 5.184505462646484,
      "learning_rate": 8.31013955696864e-06,
      "loss": 0.4063714027404785,
      "memory(GiB)": 72.72,
      "step": 16415,
      "token_acc": 0.4634146341463415,
      "train_speed(iter/s)": 0.251956
    },
    {
      "epoch": 1.5315735472437273,
      "grad_norm": 4.273439407348633,
      "learning_rate": 8.308983481726466e-06,
      "loss": 0.4240458011627197,
      "memory(GiB)": 72.72,
      "step": 16420,
      "train_speed(iter/s)": 0.251958
    },
    {
      "epoch": 1.5320399216490999,
      "grad_norm": 3.0263655185699463,
      "learning_rate": 8.30782709164471e-06,
      "loss": 0.44998745918273925,
      "memory(GiB)": 72.72,
      "step": 16425,
      "token_acc": 0.43548387096774194,
      "train_speed(iter/s)": 0.251962
    },
    {
      "epoch": 1.5325062960544726,
      "grad_norm": 3.5657472610473633,
      "learning_rate": 8.306670386833394e-06,
      "loss": 0.44928708076477053,
      "memory(GiB)": 72.72,
      "step": 16430,
      "token_acc": 0.4827586206896552,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.5329726704598452,
      "grad_norm": 5.256099700927734,
      "learning_rate": 8.305513367402578e-06,
      "loss": 0.43039989471435547,
      "memory(GiB)": 72.72,
      "step": 16435,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.5334390448652178,
      "grad_norm": 4.854068279266357,
      "learning_rate": 8.304356033462346e-06,
      "loss": 0.4331798553466797,
      "memory(GiB)": 72.72,
      "step": 16440,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.5339054192705905,
      "grad_norm": 17.336257934570312,
      "learning_rate": 8.30319838512282e-06,
      "loss": 0.45945310592651367,
      "memory(GiB)": 72.72,
      "step": 16445,
      "train_speed(iter/s)": 0.251966
    },
    {
      "epoch": 1.534371793675963,
      "grad_norm": 4.1606855392456055,
      "learning_rate": 8.30204042249414e-06,
      "loss": 0.4335162162780762,
      "memory(GiB)": 72.72,
      "step": 16450,
      "train_speed(iter/s)": 0.251968
    },
    {
      "epoch": 1.5348381680813357,
      "grad_norm": 2.968451499938965,
      "learning_rate": 8.300882145686488e-06,
      "loss": 0.4263249397277832,
      "memory(GiB)": 72.72,
      "step": 16455,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.251966
    },
    {
      "epoch": 1.5353045424867084,
      "grad_norm": 5.182066917419434,
      "learning_rate": 8.29972355481007e-06,
      "loss": 0.450501537322998,
      "memory(GiB)": 72.72,
      "step": 16460,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.535770916892081,
      "grad_norm": 2.6747853755950928,
      "learning_rate": 8.298564649975117e-06,
      "loss": 0.3866106986999512,
      "memory(GiB)": 72.72,
      "step": 16465,
      "token_acc": 0.9166666666666666,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.5362372912974536,
      "grad_norm": 3.776707410812378,
      "learning_rate": 8.2974054312919e-06,
      "loss": 0.4351149082183838,
      "memory(GiB)": 72.72,
      "step": 16470,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.5367036657028263,
      "grad_norm": 5.271790504455566,
      "learning_rate": 8.296245898870717e-06,
      "loss": 0.3868406295776367,
      "memory(GiB)": 72.72,
      "step": 16475,
      "token_acc": 0.9113924050632911,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.537170040108199,
      "grad_norm": 3.8702006340026855,
      "learning_rate": 8.295086052821887e-06,
      "loss": 0.44924101829528806,
      "memory(GiB)": 72.72,
      "step": 16480,
      "train_speed(iter/s)": 0.251966
    },
    {
      "epoch": 1.5376364145135715,
      "grad_norm": 3.5375170707702637,
      "learning_rate": 8.293925893255773e-06,
      "loss": 0.4555008888244629,
      "memory(GiB)": 72.72,
      "step": 16485,
      "token_acc": 0.6451612903225806,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 1.5381027889189443,
      "grad_norm": 3.7302842140197754,
      "learning_rate": 8.292765420282756e-06,
      "loss": 0.44805278778076174,
      "memory(GiB)": 72.72,
      "step": 16490,
      "train_speed(iter/s)": 0.25197
    },
    {
      "epoch": 1.5385691633243168,
      "grad_norm": 3.690122365951538,
      "learning_rate": 8.291604634013253e-06,
      "loss": 0.44287590980529784,
      "memory(GiB)": 72.72,
      "step": 16495,
      "train_speed(iter/s)": 0.251976
    },
    {
      "epoch": 1.5390355377296894,
      "grad_norm": 2.8604300022125244,
      "learning_rate": 8.290443534557708e-06,
      "loss": 0.39567790031433103,
      "memory(GiB)": 72.72,
      "step": 16500,
      "train_speed(iter/s)": 0.251976
    },
    {
      "epoch": 1.5395019121350622,
      "grad_norm": 14.863774299621582,
      "learning_rate": 8.289282122026598e-06,
      "loss": 0.45032224655151365,
      "memory(GiB)": 72.72,
      "step": 16505,
      "train_speed(iter/s)": 0.251979
    },
    {
      "epoch": 1.5399682865404345,
      "grad_norm": 6.422361373901367,
      "learning_rate": 8.288120396530428e-06,
      "loss": 0.45136146545410155,
      "memory(GiB)": 72.72,
      "step": 16510,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.251982
    },
    {
      "epoch": 1.5404346609458073,
      "grad_norm": 4.307109355926514,
      "learning_rate": 8.28695835817973e-06,
      "loss": 0.46837759017944336,
      "memory(GiB)": 72.72,
      "step": 16515,
      "train_speed(iter/s)": 0.251983
    },
    {
      "epoch": 1.54090103535118,
      "grad_norm": 4.419722080230713,
      "learning_rate": 8.285796007085072e-06,
      "loss": 0.45424699783325195,
      "memory(GiB)": 72.72,
      "step": 16520,
      "token_acc": 0.6190476190476191,
      "train_speed(iter/s)": 0.251986
    },
    {
      "epoch": 1.5413674097565524,
      "grad_norm": 3.0770514011383057,
      "learning_rate": 8.284633343357045e-06,
      "loss": 0.42077460289001467,
      "memory(GiB)": 72.72,
      "step": 16525,
      "train_speed(iter/s)": 0.251985
    },
    {
      "epoch": 1.5418337841619252,
      "grad_norm": 4.804573059082031,
      "learning_rate": 8.283470367106274e-06,
      "loss": 0.4721043586730957,
      "memory(GiB)": 72.72,
      "step": 16530,
      "token_acc": 0.8947368421052632,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.542300158567298,
      "grad_norm": 5.579196929931641,
      "learning_rate": 8.282307078443412e-06,
      "loss": 0.4204409599304199,
      "memory(GiB)": 72.72,
      "step": 16535,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251988
    },
    {
      "epoch": 1.5427665329726703,
      "grad_norm": 4.949027061462402,
      "learning_rate": 8.281143477479144e-06,
      "loss": 0.4871337890625,
      "memory(GiB)": 72.72,
      "step": 16540,
      "token_acc": 0.898876404494382,
      "train_speed(iter/s)": 0.251981
    },
    {
      "epoch": 1.543232907378043,
      "grad_norm": 2.709240198135376,
      "learning_rate": 8.279979564324181e-06,
      "loss": 0.43958683013916017,
      "memory(GiB)": 72.72,
      "step": 16545,
      "train_speed(iter/s)": 0.251985
    },
    {
      "epoch": 1.5436992817834159,
      "grad_norm": 5.210505485534668,
      "learning_rate": 8.278815339089268e-06,
      "loss": 0.4123080253601074,
      "memory(GiB)": 72.72,
      "step": 16550,
      "token_acc": 0.4166666666666667,
      "train_speed(iter/s)": 0.25199
    },
    {
      "epoch": 1.5441656561887882,
      "grad_norm": 3.8795647621154785,
      "learning_rate": 8.277650801885175e-06,
      "loss": 0.4532917499542236,
      "memory(GiB)": 72.72,
      "step": 16555,
      "train_speed(iter/s)": 0.251994
    },
    {
      "epoch": 1.544632030594161,
      "grad_norm": 3.9354512691497803,
      "learning_rate": 8.276485952822705e-06,
      "loss": 0.436940336227417,
      "memory(GiB)": 72.72,
      "step": 16560,
      "token_acc": 0.6046511627906976,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.5450984049995338,
      "grad_norm": 2.731537103652954,
      "learning_rate": 8.27532079201269e-06,
      "loss": 0.43338742256164553,
      "memory(GiB)": 72.72,
      "step": 16565,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.545564779404906,
      "grad_norm": 7.652337074279785,
      "learning_rate": 8.274155319565993e-06,
      "loss": 0.429975700378418,
      "memory(GiB)": 72.72,
      "step": 16570,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.546031153810279,
      "grad_norm": 5.063927173614502,
      "learning_rate": 8.272989535593502e-06,
      "loss": 0.4298866271972656,
      "memory(GiB)": 72.72,
      "step": 16575,
      "train_speed(iter/s)": 0.251994
    },
    {
      "epoch": 1.5464975282156517,
      "grad_norm": 5.498401641845703,
      "learning_rate": 8.271823440206139e-06,
      "loss": 0.4367725372314453,
      "memory(GiB)": 72.72,
      "step": 16580,
      "train_speed(iter/s)": 0.252001
    },
    {
      "epoch": 1.546963902621024,
      "grad_norm": 6.648935317993164,
      "learning_rate": 8.270657033514857e-06,
      "loss": 0.4958689212799072,
      "memory(GiB)": 72.72,
      "step": 16585,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.5474302770263968,
      "grad_norm": 20.338478088378906,
      "learning_rate": 8.269490315630631e-06,
      "loss": 0.43764677047729494,
      "memory(GiB)": 72.72,
      "step": 16590,
      "token_acc": 0.5225225225225225,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.5478966514317696,
      "grad_norm": 4.508950233459473,
      "learning_rate": 8.268323286664475e-06,
      "loss": 0.4168235778808594,
      "memory(GiB)": 72.72,
      "step": 16595,
      "train_speed(iter/s)": 0.252007
    },
    {
      "epoch": 1.548363025837142,
      "grad_norm": 3.346201181411743,
      "learning_rate": 8.267155946727427e-06,
      "loss": 0.4530672550201416,
      "memory(GiB)": 72.72,
      "step": 16600,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.5488294002425147,
      "grad_norm": 3.6599886417388916,
      "learning_rate": 8.265988295930554e-06,
      "loss": 0.4451586723327637,
      "memory(GiB)": 72.72,
      "step": 16605,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.5492957746478875,
      "grad_norm": 3.2430715560913086,
      "learning_rate": 8.264820334384957e-06,
      "loss": 0.4198791980743408,
      "memory(GiB)": 72.72,
      "step": 16610,
      "token_acc": 0.42424242424242425,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.5497621490532598,
      "grad_norm": 4.00825834274292,
      "learning_rate": 8.263652062201762e-06,
      "loss": 0.4477517127990723,
      "memory(GiB)": 72.72,
      "step": 16615,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.5502285234586326,
      "grad_norm": 3.5372653007507324,
      "learning_rate": 8.262483479492129e-06,
      "loss": 0.4298274040222168,
      "memory(GiB)": 72.72,
      "step": 16620,
      "token_acc": 0.673469387755102,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.5506948978640054,
      "grad_norm": 3.7632791996002197,
      "learning_rate": 8.261314586367241e-06,
      "loss": 0.4068737983703613,
      "memory(GiB)": 72.72,
      "step": 16625,
      "token_acc": 0.45535714285714285,
      "train_speed(iter/s)": 0.252001
    },
    {
      "epoch": 1.5511612722693777,
      "grad_norm": 4.790463447570801,
      "learning_rate": 8.260145382938319e-06,
      "loss": 0.38656461238861084,
      "memory(GiB)": 72.72,
      "step": 16630,
      "token_acc": 0.9489795918367347,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.5516276466747505,
      "grad_norm": 6.096407890319824,
      "learning_rate": 8.258975869316604e-06,
      "loss": 0.44607834815979003,
      "memory(GiB)": 72.72,
      "step": 16635,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.5520940210801233,
      "grad_norm": 2.7561280727386475,
      "learning_rate": 8.257806045613375e-06,
      "loss": 0.45798397064208984,
      "memory(GiB)": 72.72,
      "step": 16640,
      "token_acc": 0.5490196078431373,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.5525603954854956,
      "grad_norm": 3.3462464809417725,
      "learning_rate": 8.256635911939939e-06,
      "loss": 0.43724584579467773,
      "memory(GiB)": 72.72,
      "step": 16645,
      "token_acc": 0.6271186440677966,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.5530267698908684,
      "grad_norm": 4.0591325759887695,
      "learning_rate": 8.255465468407626e-06,
      "loss": 0.4314728736877441,
      "memory(GiB)": 72.72,
      "step": 16650,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.553493144296241,
      "grad_norm": 2.841742992401123,
      "learning_rate": 8.254294715127805e-06,
      "loss": 0.4248325347900391,
      "memory(GiB)": 72.72,
      "step": 16655,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.5539595187016135,
      "grad_norm": 17.467525482177734,
      "learning_rate": 8.253123652211865e-06,
      "loss": 0.4398677825927734,
      "memory(GiB)": 72.72,
      "step": 16660,
      "token_acc": 0.4745762711864407,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.5544258931069863,
      "grad_norm": 3.8404922485351562,
      "learning_rate": 8.251952279771232e-06,
      "loss": 0.38392374515533445,
      "memory(GiB)": 72.72,
      "step": 16665,
      "token_acc": 0.94,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.5548922675123589,
      "grad_norm": 8.240335464477539,
      "learning_rate": 8.250780597917357e-06,
      "loss": 0.42712202072143557,
      "memory(GiB)": 72.72,
      "step": 16670,
      "token_acc": 0.9122807017543859,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.5553586419177314,
      "grad_norm": 4.834011077880859,
      "learning_rate": 8.249608606761721e-06,
      "loss": 0.43379926681518555,
      "memory(GiB)": 72.72,
      "step": 16675,
      "token_acc": 0.46808510638297873,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.5558250163231042,
      "grad_norm": 5.579645156860352,
      "learning_rate": 8.24843630641584e-06,
      "loss": 0.44378957748413084,
      "memory(GiB)": 72.72,
      "step": 16680,
      "token_acc": 0.6458333333333334,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.5562913907284768,
      "grad_norm": 2.954390048980713,
      "learning_rate": 8.247263696991247e-06,
      "loss": 0.4270315170288086,
      "memory(GiB)": 72.72,
      "step": 16685,
      "token_acc": 0.9818181818181818,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.5567577651338493,
      "grad_norm": 3.99875545501709,
      "learning_rate": 8.24609077859952e-06,
      "loss": 0.37180612087249754,
      "memory(GiB)": 72.72,
      "step": 16690,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.5572241395392221,
      "grad_norm": 11.300735473632812,
      "learning_rate": 8.244917551352254e-06,
      "loss": 0.4193251609802246,
      "memory(GiB)": 72.72,
      "step": 16695,
      "train_speed(iter/s)": 0.252011
    },
    {
      "epoch": 1.5576905139445947,
      "grad_norm": 5.382977485656738,
      "learning_rate": 8.243744015361079e-06,
      "loss": 0.46195154190063475,
      "memory(GiB)": 72.72,
      "step": 16700,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.5581568883499672,
      "grad_norm": 3.3269991874694824,
      "learning_rate": 8.242570170737654e-06,
      "loss": 0.43215079307556153,
      "memory(GiB)": 72.72,
      "step": 16705,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.55862326275534,
      "grad_norm": 15.915749549865723,
      "learning_rate": 8.241396017593668e-06,
      "loss": 0.3981645107269287,
      "memory(GiB)": 72.72,
      "step": 16710,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.5590896371607126,
      "grad_norm": 3.58636212348938,
      "learning_rate": 8.240221556040833e-06,
      "loss": 0.4506096839904785,
      "memory(GiB)": 72.72,
      "step": 16715,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.5595560115660851,
      "grad_norm": 3.988577127456665,
      "learning_rate": 8.2390467861909e-06,
      "loss": 0.44230875968933103,
      "memory(GiB)": 72.72,
      "step": 16720,
      "token_acc": 0.9444444444444444,
      "train_speed(iter/s)": 0.252019
    },
    {
      "epoch": 1.560022385971458,
      "grad_norm": 3.6220619678497314,
      "learning_rate": 8.237871708155645e-06,
      "loss": 0.4384001731872559,
      "memory(GiB)": 72.72,
      "step": 16725,
      "train_speed(iter/s)": 0.252022
    },
    {
      "epoch": 1.5604887603768305,
      "grad_norm": 7.843181133270264,
      "learning_rate": 8.23669632204687e-06,
      "loss": 0.42551631927490235,
      "memory(GiB)": 72.72,
      "step": 16730,
      "train_speed(iter/s)": 0.252023
    },
    {
      "epoch": 1.560955134782203,
      "grad_norm": 3.261759042739868,
      "learning_rate": 8.235520627976411e-06,
      "loss": 0.42675466537475587,
      "memory(GiB)": 72.72,
      "step": 16735,
      "train_speed(iter/s)": 0.252029
    },
    {
      "epoch": 1.5614215091875758,
      "grad_norm": 3.735860586166382,
      "learning_rate": 8.234344626056133e-06,
      "loss": 0.44951353073120115,
      "memory(GiB)": 72.72,
      "step": 16740,
      "token_acc": 0.8609271523178808,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 1.5618878835929484,
      "grad_norm": 7.312036037445068,
      "learning_rate": 8.233168316397924e-06,
      "loss": 0.47106328010559084,
      "memory(GiB)": 72.72,
      "step": 16745,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.252025
    },
    {
      "epoch": 1.562354257998321,
      "grad_norm": 3.2891223430633545,
      "learning_rate": 8.231991699113712e-06,
      "loss": 0.4169672966003418,
      "memory(GiB)": 72.72,
      "step": 16750,
      "train_speed(iter/s)": 0.252028
    },
    {
      "epoch": 1.5628206324036937,
      "grad_norm": 3.896113157272339,
      "learning_rate": 8.230814774315446e-06,
      "loss": 0.44068660736083987,
      "memory(GiB)": 72.72,
      "step": 16755,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.252027
    },
    {
      "epoch": 1.5632870068090663,
      "grad_norm": 4.222909450531006,
      "learning_rate": 8.229637542115108e-06,
      "loss": 0.43588905334472655,
      "memory(GiB)": 72.72,
      "step": 16760,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 1.5637533812144389,
      "grad_norm": 4.687399387359619,
      "learning_rate": 8.228460002624706e-06,
      "loss": 0.4085094451904297,
      "memory(GiB)": 72.72,
      "step": 16765,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.5642197556198116,
      "grad_norm": 4.744946002960205,
      "learning_rate": 8.22728215595628e-06,
      "loss": 0.42980122566223145,
      "memory(GiB)": 72.72,
      "step": 16770,
      "token_acc": 0.7183098591549296,
      "train_speed(iter/s)": 0.252031
    },
    {
      "epoch": 1.5646861300251842,
      "grad_norm": 5.134387016296387,
      "learning_rate": 8.2261040022219e-06,
      "loss": 0.40723767280578616,
      "memory(GiB)": 72.72,
      "step": 16775,
      "train_speed(iter/s)": 0.25203
    },
    {
      "epoch": 1.5651525044305568,
      "grad_norm": 3.293708086013794,
      "learning_rate": 8.224925541533662e-06,
      "loss": 0.3984535694122314,
      "memory(GiB)": 72.72,
      "step": 16780,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.5656188788359295,
      "grad_norm": 5.903027057647705,
      "learning_rate": 8.22374677400369e-06,
      "loss": 0.42915568351745603,
      "memory(GiB)": 72.72,
      "step": 16785,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.566085253241302,
      "grad_norm": 5.3436689376831055,
      "learning_rate": 8.222567699744148e-06,
      "loss": 0.45608959197998045,
      "memory(GiB)": 72.72,
      "step": 16790,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.5665516276466747,
      "grad_norm": 10.157624244689941,
      "learning_rate": 8.221388318867214e-06,
      "loss": 0.42089405059814455,
      "memory(GiB)": 72.72,
      "step": 16795,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.5670180020520474,
      "grad_norm": 5.256726264953613,
      "learning_rate": 8.220208631485107e-06,
      "loss": 0.4446965217590332,
      "memory(GiB)": 72.72,
      "step": 16800,
      "train_speed(iter/s)": 0.252036
    },
    {
      "epoch": 1.56748437645742,
      "grad_norm": 4.345178604125977,
      "learning_rate": 8.219028637710068e-06,
      "loss": 0.4346150398254395,
      "memory(GiB)": 72.72,
      "step": 16805,
      "train_speed(iter/s)": 0.252038
    },
    {
      "epoch": 1.5679507508627926,
      "grad_norm": 3.9565110206604004,
      "learning_rate": 8.217848337654371e-06,
      "loss": 0.40381650924682616,
      "memory(GiB)": 72.72,
      "step": 16810,
      "train_speed(iter/s)": 0.252038
    },
    {
      "epoch": 1.5684171252681653,
      "grad_norm": 4.199277877807617,
      "learning_rate": 8.216667731430316e-06,
      "loss": 0.43281803131103513,
      "memory(GiB)": 72.72,
      "step": 16815,
      "train_speed(iter/s)": 0.252044
    },
    {
      "epoch": 1.568883499673538,
      "grad_norm": 3.736997365951538,
      "learning_rate": 8.215486819150238e-06,
      "loss": 0.4071203231811523,
      "memory(GiB)": 72.72,
      "step": 16820,
      "token_acc": 0.7076923076923077,
      "train_speed(iter/s)": 0.25205
    },
    {
      "epoch": 1.5693498740789105,
      "grad_norm": 3.491109609603882,
      "learning_rate": 8.214305600926493e-06,
      "loss": 0.4381539344787598,
      "memory(GiB)": 72.72,
      "step": 16825,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.5698162484842832,
      "grad_norm": 4.198320388793945,
      "learning_rate": 8.213124076871472e-06,
      "loss": 0.4202139854431152,
      "memory(GiB)": 72.72,
      "step": 16830,
      "token_acc": 0.48598130841121495,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.5702826228896558,
      "grad_norm": 7.1198248863220215,
      "learning_rate": 8.211942247097595e-06,
      "loss": 0.4390871047973633,
      "memory(GiB)": 72.72,
      "step": 16835,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.5707489972950284,
      "grad_norm": 6.8694047927856445,
      "learning_rate": 8.210760111717307e-06,
      "loss": 0.4132075309753418,
      "memory(GiB)": 72.72,
      "step": 16840,
      "train_speed(iter/s)": 0.252049
    },
    {
      "epoch": 1.5712153717004012,
      "grad_norm": 10.826804161071777,
      "learning_rate": 8.209577670843085e-06,
      "loss": 0.459410572052002,
      "memory(GiB)": 72.72,
      "step": 16845,
      "train_speed(iter/s)": 0.252049
    },
    {
      "epoch": 1.5716817461057737,
      "grad_norm": 4.080464839935303,
      "learning_rate": 8.208394924587434e-06,
      "loss": 0.4663121223449707,
      "memory(GiB)": 72.72,
      "step": 16850,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.252045
    },
    {
      "epoch": 1.5721481205111463,
      "grad_norm": 5.602288722991943,
      "learning_rate": 8.20721187306289e-06,
      "loss": 0.43458170890808107,
      "memory(GiB)": 72.72,
      "step": 16855,
      "train_speed(iter/s)": 0.252044
    },
    {
      "epoch": 1.572614494916519,
      "grad_norm": 4.237656593322754,
      "learning_rate": 8.206028516382016e-06,
      "loss": 0.43275146484375,
      "memory(GiB)": 72.72,
      "step": 16860,
      "train_speed(iter/s)": 0.252045
    },
    {
      "epoch": 1.5730808693218916,
      "grad_norm": 3.6171844005584717,
      "learning_rate": 8.204844854657408e-06,
      "loss": 0.4142695426940918,
      "memory(GiB)": 72.72,
      "step": 16865,
      "train_speed(iter/s)": 0.252048
    },
    {
      "epoch": 1.5735472437272642,
      "grad_norm": 5.921656131744385,
      "learning_rate": 8.20366088800168e-06,
      "loss": 0.42953009605407716,
      "memory(GiB)": 72.72,
      "step": 16870,
      "train_speed(iter/s)": 0.252043
    },
    {
      "epoch": 1.574013618132637,
      "grad_norm": 5.614269256591797,
      "learning_rate": 8.202476616527492e-06,
      "loss": 0.42260122299194336,
      "memory(GiB)": 72.72,
      "step": 16875,
      "token_acc": 0.37735849056603776,
      "train_speed(iter/s)": 0.252042
    },
    {
      "epoch": 1.5744799925380095,
      "grad_norm": 5.13928747177124,
      "learning_rate": 8.201292040347517e-06,
      "loss": 0.39659709930419923,
      "memory(GiB)": 72.72,
      "step": 16880,
      "token_acc": 0.5853658536585366,
      "train_speed(iter/s)": 0.252043
    },
    {
      "epoch": 1.574946366943382,
      "grad_norm": 5.067999362945557,
      "learning_rate": 8.200107159574469e-06,
      "loss": 0.418870735168457,
      "memory(GiB)": 72.72,
      "step": 16885,
      "token_acc": 0.5873015873015873,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.5754127413487549,
      "grad_norm": 4.8455657958984375,
      "learning_rate": 8.198921974321079e-06,
      "loss": 0.39231412410736083,
      "memory(GiB)": 72.72,
      "step": 16890,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252039
    },
    {
      "epoch": 1.5758791157541274,
      "grad_norm": 3.479099750518799,
      "learning_rate": 8.197736484700121e-06,
      "loss": 0.42516632080078126,
      "memory(GiB)": 72.72,
      "step": 16895,
      "token_acc": 0.7358490566037735,
      "train_speed(iter/s)": 0.252043
    },
    {
      "epoch": 1.5763454901595,
      "grad_norm": 7.426527500152588,
      "learning_rate": 8.196550690824385e-06,
      "loss": 0.42776994705200194,
      "memory(GiB)": 72.72,
      "step": 16900,
      "train_speed(iter/s)": 0.252042
    },
    {
      "epoch": 1.5768118645648728,
      "grad_norm": 12.460792541503906,
      "learning_rate": 8.195364592806699e-06,
      "loss": 0.4562385559082031,
      "memory(GiB)": 72.72,
      "step": 16905,
      "token_acc": 0.4214876033057851,
      "train_speed(iter/s)": 0.252046
    },
    {
      "epoch": 1.5772782389702453,
      "grad_norm": 5.681114673614502,
      "learning_rate": 8.194178190759916e-06,
      "loss": 0.4507917881011963,
      "memory(GiB)": 72.72,
      "step": 16910,
      "token_acc": 0.8473282442748091,
      "train_speed(iter/s)": 0.252048
    },
    {
      "epoch": 1.5777446133756179,
      "grad_norm": 4.082294464111328,
      "learning_rate": 8.192991484796917e-06,
      "loss": 0.4360383987426758,
      "memory(GiB)": 72.72,
      "step": 16915,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.5782109877809907,
      "grad_norm": 3.3067033290863037,
      "learning_rate": 8.191804475030616e-06,
      "loss": 0.4457902431488037,
      "memory(GiB)": 72.72,
      "step": 16920,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.5786773621863632,
      "grad_norm": 7.835197448730469,
      "learning_rate": 8.190617161573951e-06,
      "loss": 0.48295164108276367,
      "memory(GiB)": 72.72,
      "step": 16925,
      "train_speed(iter/s)": 0.25206
    },
    {
      "epoch": 1.5791437365917358,
      "grad_norm": 4.10648250579834,
      "learning_rate": 8.189429544539892e-06,
      "loss": 0.40777125358581545,
      "memory(GiB)": 72.72,
      "step": 16930,
      "token_acc": 0.6346153846153846,
      "train_speed(iter/s)": 0.252065
    },
    {
      "epoch": 1.5796101109971086,
      "grad_norm": 10.085089683532715,
      "learning_rate": 8.188241624041437e-06,
      "loss": 0.47240381240844725,
      "memory(GiB)": 72.72,
      "step": 16935,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.5800764854024811,
      "grad_norm": 4.070766925811768,
      "learning_rate": 8.187053400191612e-06,
      "loss": 0.4274178981781006,
      "memory(GiB)": 72.72,
      "step": 16940,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.5805428598078537,
      "grad_norm": 4.5903496742248535,
      "learning_rate": 8.185864873103475e-06,
      "loss": 0.40860691070556643,
      "memory(GiB)": 72.72,
      "step": 16945,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.5810092342132265,
      "grad_norm": 3.8586530685424805,
      "learning_rate": 8.184676042890109e-06,
      "loss": 0.4107095718383789,
      "memory(GiB)": 72.72,
      "step": 16950,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.581475608618599,
      "grad_norm": 6.51003360748291,
      "learning_rate": 8.183486909664629e-06,
      "loss": 0.42411231994628906,
      "memory(GiB)": 72.72,
      "step": 16955,
      "train_speed(iter/s)": 0.252066
    },
    {
      "epoch": 1.5819419830239716,
      "grad_norm": 9.264512062072754,
      "learning_rate": 8.182297473540178e-06,
      "loss": 0.439042854309082,
      "memory(GiB)": 72.72,
      "step": 16960,
      "train_speed(iter/s)": 0.252065
    },
    {
      "epoch": 1.5824083574293444,
      "grad_norm": 7.421511650085449,
      "learning_rate": 8.181107734629923e-06,
      "loss": 0.4649930000305176,
      "memory(GiB)": 72.72,
      "step": 16965,
      "train_speed(iter/s)": 0.25207
    },
    {
      "epoch": 1.582874731834717,
      "grad_norm": 8.993083000183105,
      "learning_rate": 8.179917693047068e-06,
      "loss": 0.4208324432373047,
      "memory(GiB)": 72.72,
      "step": 16970,
      "token_acc": 0.4825174825174825,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.5833411062400895,
      "grad_norm": 3.979118824005127,
      "learning_rate": 8.17872734890484e-06,
      "loss": 0.39480271339416506,
      "memory(GiB)": 72.72,
      "step": 16975,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.5838074806454623,
      "grad_norm": 4.544815540313721,
      "learning_rate": 8.177536702316497e-06,
      "loss": 0.44482421875,
      "memory(GiB)": 72.72,
      "step": 16980,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252065
    },
    {
      "epoch": 1.5842738550508348,
      "grad_norm": 5.980922222137451,
      "learning_rate": 8.176345753395327e-06,
      "loss": 0.4658208847045898,
      "memory(GiB)": 72.72,
      "step": 16985,
      "token_acc": 0.8924731182795699,
      "train_speed(iter/s)": 0.252065
    },
    {
      "epoch": 1.5847402294562074,
      "grad_norm": 5.991041660308838,
      "learning_rate": 8.17515450225464e-06,
      "loss": 0.41431589126586915,
      "memory(GiB)": 72.72,
      "step": 16990,
      "train_speed(iter/s)": 0.252068
    },
    {
      "epoch": 1.5852066038615802,
      "grad_norm": 8.130661964416504,
      "learning_rate": 8.173962949007787e-06,
      "loss": 0.4071380138397217,
      "memory(GiB)": 72.72,
      "step": 16995,
      "train_speed(iter/s)": 0.252066
    },
    {
      "epoch": 1.5856729782669527,
      "grad_norm": 4.330948352813721,
      "learning_rate": 8.172771093768134e-06,
      "loss": 0.4144087791442871,
      "memory(GiB)": 72.72,
      "step": 17000,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.5861393526723253,
      "grad_norm": 5.992647647857666,
      "learning_rate": 8.171578936649087e-06,
      "loss": 0.42641773223876955,
      "memory(GiB)": 72.72,
      "step": 17005,
      "token_acc": 0.9222222222222223,
      "train_speed(iter/s)": 0.252062
    },
    {
      "epoch": 1.586605727077698,
      "grad_norm": 5.149788856506348,
      "learning_rate": 8.170386477764076e-06,
      "loss": 0.48478307723999026,
      "memory(GiB)": 72.72,
      "step": 17010,
      "train_speed(iter/s)": 0.252062
    },
    {
      "epoch": 1.5870721014830707,
      "grad_norm": 3.591942310333252,
      "learning_rate": 8.169193717226556e-06,
      "loss": 0.4657327651977539,
      "memory(GiB)": 72.72,
      "step": 17015,
      "train_speed(iter/s)": 0.252061
    },
    {
      "epoch": 1.5875384758884432,
      "grad_norm": 4.89320707321167,
      "learning_rate": 8.168000655150019e-06,
      "loss": 0.4135787010192871,
      "memory(GiB)": 72.72,
      "step": 17020,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.25206
    },
    {
      "epoch": 1.588004850293816,
      "grad_norm": 3.949910879135132,
      "learning_rate": 8.166807291647976e-06,
      "loss": 0.42323956489562986,
      "memory(GiB)": 72.72,
      "step": 17025,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.5884712246991886,
      "grad_norm": 7.431906700134277,
      "learning_rate": 8.165613626833977e-06,
      "loss": 0.4117532730102539,
      "memory(GiB)": 72.72,
      "step": 17030,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.5889375991045611,
      "grad_norm": 7.553664684295654,
      "learning_rate": 8.164419660821591e-06,
      "loss": 0.41209163665771487,
      "memory(GiB)": 72.72,
      "step": 17035,
      "token_acc": 0.5476190476190477,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.589403973509934,
      "grad_norm": 4.459746837615967,
      "learning_rate": 8.163225393724424e-06,
      "loss": 0.39688255786895754,
      "memory(GiB)": 72.72,
      "step": 17040,
      "token_acc": 0.963302752293578,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.5898703479153065,
      "grad_norm": 4.465145111083984,
      "learning_rate": 8.162030825656107e-06,
      "loss": 0.40234689712524413,
      "memory(GiB)": 72.72,
      "step": 17045,
      "token_acc": 0.9382716049382716,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.590336722320679,
      "grad_norm": 5.358170032501221,
      "learning_rate": 8.160835956730296e-06,
      "loss": 0.4719069957733154,
      "memory(GiB)": 72.72,
      "step": 17050,
      "token_acc": 0.3709677419354839,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.5908030967260518,
      "grad_norm": 4.081764221191406,
      "learning_rate": 8.15964078706068e-06,
      "loss": 0.42199368476867677,
      "memory(GiB)": 72.72,
      "step": 17055,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.5912694711314244,
      "grad_norm": 4.923161029815674,
      "learning_rate": 8.158445316760979e-06,
      "loss": 0.4461881160736084,
      "memory(GiB)": 72.72,
      "step": 17060,
      "token_acc": 0.898989898989899,
      "train_speed(iter/s)": 0.252069
    },
    {
      "epoch": 1.591735845536797,
      "grad_norm": 7.245187282562256,
      "learning_rate": 8.157249545944935e-06,
      "loss": 0.4438204765319824,
      "memory(GiB)": 72.72,
      "step": 17065,
      "token_acc": 0.8974358974358975,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.5922022199421697,
      "grad_norm": 7.517275333404541,
      "learning_rate": 8.156053474726322e-06,
      "loss": 0.4155925750732422,
      "memory(GiB)": 72.72,
      "step": 17070,
      "token_acc": 0.9213483146067416,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.592668594347542,
      "grad_norm": 3.8988633155822754,
      "learning_rate": 8.154857103218943e-06,
      "loss": 0.40889415740966795,
      "memory(GiB)": 72.72,
      "step": 17075,
      "train_speed(iter/s)": 0.252063
    },
    {
      "epoch": 1.5931349687529148,
      "grad_norm": 5.4825592041015625,
      "learning_rate": 8.15366043153663e-06,
      "loss": 0.43885250091552735,
      "memory(GiB)": 72.72,
      "step": 17080,
      "token_acc": 0.6019417475728155,
      "train_speed(iter/s)": 0.252065
    },
    {
      "epoch": 1.5936013431582876,
      "grad_norm": 4.850194454193115,
      "learning_rate": 8.152463459793242e-06,
      "loss": 0.43363494873046876,
      "memory(GiB)": 72.72,
      "step": 17085,
      "token_acc": 0.9134615384615384,
      "train_speed(iter/s)": 0.252067
    },
    {
      "epoch": 1.59406771756366,
      "grad_norm": 4.57470703125,
      "learning_rate": 8.15126618810267e-06,
      "loss": 0.43180174827575685,
      "memory(GiB)": 72.72,
      "step": 17090,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 1.5945340919690327,
      "grad_norm": 3.9639992713928223,
      "learning_rate": 8.150068616578824e-06,
      "loss": 0.4143242359161377,
      "memory(GiB)": 72.72,
      "step": 17095,
      "train_speed(iter/s)": 0.251955
    },
    {
      "epoch": 1.5950004663744055,
      "grad_norm": 4.475736618041992,
      "learning_rate": 8.148870745335655e-06,
      "loss": 0.426939582824707,
      "memory(GiB)": 72.72,
      "step": 17100,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251957
    },
    {
      "epoch": 1.5954668407797779,
      "grad_norm": 14.367805480957031,
      "learning_rate": 8.147672574487133e-06,
      "loss": 0.44729957580566404,
      "memory(GiB)": 72.72,
      "step": 17105,
      "train_speed(iter/s)": 0.251959
    },
    {
      "epoch": 1.5959332151851506,
      "grad_norm": 4.88151741027832,
      "learning_rate": 8.146474104147264e-06,
      "loss": 0.4181502342224121,
      "memory(GiB)": 72.72,
      "step": 17110,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.5963995895905234,
      "grad_norm": 10.566047668457031,
      "learning_rate": 8.145275334430078e-06,
      "loss": 0.44179468154907225,
      "memory(GiB)": 72.72,
      "step": 17115,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.5968659639958958,
      "grad_norm": 4.360854625701904,
      "learning_rate": 8.144076265449632e-06,
      "loss": 0.4328147411346436,
      "memory(GiB)": 72.72,
      "step": 17120,
      "token_acc": 0.8,
      "train_speed(iter/s)": 0.251959
    },
    {
      "epoch": 1.5973323384012685,
      "grad_norm": 5.605313301086426,
      "learning_rate": 8.142876897320013e-06,
      "loss": 0.41457056999206543,
      "memory(GiB)": 72.72,
      "step": 17125,
      "train_speed(iter/s)": 0.251955
    },
    {
      "epoch": 1.5977987128066413,
      "grad_norm": 5.1706767082214355,
      "learning_rate": 8.141677230155343e-06,
      "loss": 0.4383383750915527,
      "memory(GiB)": 72.72,
      "step": 17130,
      "train_speed(iter/s)": 0.25196
    },
    {
      "epoch": 1.5982650872120137,
      "grad_norm": 3.2717015743255615,
      "learning_rate": 8.14047726406976e-06,
      "loss": 0.4012775421142578,
      "memory(GiB)": 72.72,
      "step": 17135,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.5987314616173864,
      "grad_norm": 12.069707870483398,
      "learning_rate": 8.139276999177438e-06,
      "loss": 0.41886148452758787,
      "memory(GiB)": 72.72,
      "step": 17140,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251968
    },
    {
      "epoch": 1.5991978360227592,
      "grad_norm": 6.915541172027588,
      "learning_rate": 8.138076435592585e-06,
      "loss": 0.4434050559997559,
      "memory(GiB)": 72.72,
      "step": 17145,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.5996642104281316,
      "grad_norm": 5.572127342224121,
      "learning_rate": 8.136875573429423e-06,
      "loss": 0.42120723724365233,
      "memory(GiB)": 72.72,
      "step": 17150,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251972
    },
    {
      "epoch": 1.6001305848335043,
      "grad_norm": 4.218975067138672,
      "learning_rate": 8.135674412802215e-06,
      "loss": 0.4495438575744629,
      "memory(GiB)": 72.72,
      "step": 17155,
      "train_speed(iter/s)": 0.251971
    },
    {
      "epoch": 1.6005969592388771,
      "grad_norm": 7.171484470367432,
      "learning_rate": 8.134472953825245e-06,
      "loss": 0.44196624755859376,
      "memory(GiB)": 72.72,
      "step": 17160,
      "token_acc": 0.7894736842105263,
      "train_speed(iter/s)": 0.251973
    },
    {
      "epoch": 1.6010633336442495,
      "grad_norm": 2.858799934387207,
      "learning_rate": 8.133271196612832e-06,
      "loss": 0.43577561378479,
      "memory(GiB)": 72.72,
      "step": 17165,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251973
    },
    {
      "epoch": 1.6015297080496222,
      "grad_norm": 7.53060245513916,
      "learning_rate": 8.132069141279315e-06,
      "loss": 0.45276508331298826,
      "memory(GiB)": 72.72,
      "step": 17170,
      "train_speed(iter/s)": 0.251975
    },
    {
      "epoch": 1.601996082454995,
      "grad_norm": 5.998573303222656,
      "learning_rate": 8.130866787939068e-06,
      "loss": 0.4479537010192871,
      "memory(GiB)": 72.72,
      "step": 17175,
      "token_acc": 0.43103448275862066,
      "train_speed(iter/s)": 0.251977
    },
    {
      "epoch": 1.6024624568603674,
      "grad_norm": 6.487184524536133,
      "learning_rate": 8.12966413670649e-06,
      "loss": 0.40583171844482424,
      "memory(GiB)": 72.72,
      "step": 17180,
      "token_acc": 0.9333333333333333,
      "train_speed(iter/s)": 0.25198
    },
    {
      "epoch": 1.6029288312657402,
      "grad_norm": 4.564438819885254,
      "learning_rate": 8.128461187696011e-06,
      "loss": 0.4051831722259521,
      "memory(GiB)": 72.72,
      "step": 17185,
      "token_acc": 0.7692307692307693,
      "train_speed(iter/s)": 0.251975
    },
    {
      "epoch": 1.603395205671113,
      "grad_norm": 3.57277512550354,
      "learning_rate": 8.127257941022088e-06,
      "loss": 0.4418421745300293,
      "memory(GiB)": 72.72,
      "step": 17190,
      "train_speed(iter/s)": 0.251975
    },
    {
      "epoch": 1.6038615800764853,
      "grad_norm": 4.5660400390625,
      "learning_rate": 8.126054396799205e-06,
      "loss": 0.41262431144714357,
      "memory(GiB)": 72.72,
      "step": 17195,
      "token_acc": 0.4393939393939394,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 1.604327954481858,
      "grad_norm": 9.385750770568848,
      "learning_rate": 8.124850555141877e-06,
      "loss": 0.43154025077819824,
      "memory(GiB)": 72.72,
      "step": 17200,
      "token_acc": 0.8650793650793651,
      "train_speed(iter/s)": 0.251977
    },
    {
      "epoch": 1.6047943288872306,
      "grad_norm": 8.639192581176758,
      "learning_rate": 8.123646416164645e-06,
      "loss": 0.470032262802124,
      "memory(GiB)": 72.72,
      "step": 17205,
      "token_acc": 0.5675675675675675,
      "train_speed(iter/s)": 0.251979
    },
    {
      "epoch": 1.6052607032926032,
      "grad_norm": 6.170304298400879,
      "learning_rate": 8.122441979982079e-06,
      "loss": 0.4387950897216797,
      "memory(GiB)": 72.72,
      "step": 17210,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.605727077697976,
      "grad_norm": 22.803180694580078,
      "learning_rate": 8.121237246708777e-06,
      "loss": 0.4291356563568115,
      "memory(GiB)": 72.72,
      "step": 17215,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.6061934521033485,
      "grad_norm": 3.366509437561035,
      "learning_rate": 8.120032216459367e-06,
      "loss": 0.429613733291626,
      "memory(GiB)": 72.72,
      "step": 17220,
      "train_speed(iter/s)": 0.251989
    },
    {
      "epoch": 1.606659826508721,
      "grad_norm": 4.950899124145508,
      "learning_rate": 8.118826889348503e-06,
      "loss": 0.4042644500732422,
      "memory(GiB)": 72.72,
      "step": 17225,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251993
    },
    {
      "epoch": 1.6071262009140939,
      "grad_norm": 4.231479644775391,
      "learning_rate": 8.117621265490869e-06,
      "loss": 0.4149482250213623,
      "memory(GiB)": 72.72,
      "step": 17230,
      "token_acc": 0.4222222222222222,
      "train_speed(iter/s)": 0.25199
    },
    {
      "epoch": 1.6075925753194664,
      "grad_norm": 8.088500022888184,
      "learning_rate": 8.116415345001175e-06,
      "loss": 0.441561222076416,
      "memory(GiB)": 72.72,
      "step": 17235,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.608058949724839,
      "grad_norm": 11.718972206115723,
      "learning_rate": 8.11520912799416e-06,
      "loss": 0.43801441192626955,
      "memory(GiB)": 72.72,
      "step": 17240,
      "token_acc": 0.4576271186440678,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.6085253241302118,
      "grad_norm": 8.229897499084473,
      "learning_rate": 8.114002614584593e-06,
      "loss": 0.4162099361419678,
      "memory(GiB)": 72.72,
      "step": 17245,
      "train_speed(iter/s)": 0.251997
    },
    {
      "epoch": 1.6089916985355843,
      "grad_norm": 3.9392340183258057,
      "learning_rate": 8.112795804887272e-06,
      "loss": 0.35824873447418215,
      "memory(GiB)": 72.72,
      "step": 17250,
      "token_acc": 0.8421052631578947,
      "train_speed(iter/s)": 0.251997
    },
    {
      "epoch": 1.6094580729409569,
      "grad_norm": 7.824832916259766,
      "learning_rate": 8.111588699017019e-06,
      "loss": 0.38931097984313967,
      "memory(GiB)": 72.72,
      "step": 17255,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251995
    },
    {
      "epoch": 1.6099244473463297,
      "grad_norm": 6.204290866851807,
      "learning_rate": 8.110381297088686e-06,
      "loss": 0.4746278762817383,
      "memory(GiB)": 72.72,
      "step": 17260,
      "token_acc": 0.45614035087719296,
      "train_speed(iter/s)": 0.251993
    },
    {
      "epoch": 1.6103908217517022,
      "grad_norm": 8.08100700378418,
      "learning_rate": 8.109173599217155e-06,
      "loss": 0.42366752624511717,
      "memory(GiB)": 72.72,
      "step": 17265,
      "token_acc": 0.5604395604395604,
      "train_speed(iter/s)": 0.251995
    },
    {
      "epoch": 1.6108571961570748,
      "grad_norm": 8.80070972442627,
      "learning_rate": 8.107965605517334e-06,
      "loss": 0.4535954475402832,
      "memory(GiB)": 72.72,
      "step": 17270,
      "token_acc": 0.7804878048780488,
      "train_speed(iter/s)": 0.251993
    },
    {
      "epoch": 1.6113235705624476,
      "grad_norm": 13.912762641906738,
      "learning_rate": 8.106757316104159e-06,
      "loss": 0.42071218490600587,
      "memory(GiB)": 72.72,
      "step": 17275,
      "token_acc": 0.896551724137931,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.6117899449678201,
      "grad_norm": 10.947541236877441,
      "learning_rate": 8.105548731092597e-06,
      "loss": 0.4655784606933594,
      "memory(GiB)": 72.72,
      "step": 17280,
      "train_speed(iter/s)": 0.251988
    },
    {
      "epoch": 1.6122563193731927,
      "grad_norm": 4.193734169006348,
      "learning_rate": 8.10433985059764e-06,
      "loss": 0.45844554901123047,
      "memory(GiB)": 72.72,
      "step": 17285,
      "token_acc": 0.5168539325842697,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.6127226937785655,
      "grad_norm": 9.02631950378418,
      "learning_rate": 8.10313067473431e-06,
      "loss": 0.4082080841064453,
      "memory(GiB)": 72.72,
      "step": 17290,
      "train_speed(iter/s)": 0.251995
    },
    {
      "epoch": 1.613189068183938,
      "grad_norm": 24.361114501953125,
      "learning_rate": 8.101921203617652e-06,
      "loss": 0.44588193893432615,
      "memory(GiB)": 72.72,
      "step": 17295,
      "token_acc": 0.5411764705882353,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.6136554425893106,
      "grad_norm": 6.124889373779297,
      "learning_rate": 8.100711437362752e-06,
      "loss": 0.4483219623565674,
      "memory(GiB)": 72.72,
      "step": 17300,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.6141218169946834,
      "grad_norm": 4.143982410430908,
      "learning_rate": 8.09950137608471e-06,
      "loss": 0.42254080772399905,
      "memory(GiB)": 72.72,
      "step": 17305,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.614588191400056,
      "grad_norm": 4.491069793701172,
      "learning_rate": 8.09829101989866e-06,
      "loss": 0.4488521575927734,
      "memory(GiB)": 72.72,
      "step": 17310,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.6150545658054285,
      "grad_norm": 5.832365036010742,
      "learning_rate": 8.097080368919762e-06,
      "loss": 0.4367116928100586,
      "memory(GiB)": 72.72,
      "step": 17315,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.6155209402108013,
      "grad_norm": 4.83305549621582,
      "learning_rate": 8.095869423263209e-06,
      "loss": 0.4499650955200195,
      "memory(GiB)": 72.72,
      "step": 17320,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.6159873146161738,
      "grad_norm": 4.923306465148926,
      "learning_rate": 8.094658183044217e-06,
      "loss": 0.4377741813659668,
      "memory(GiB)": 72.72,
      "step": 17325,
      "token_acc": 0.8,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.6164536890215464,
      "grad_norm": 12.005570411682129,
      "learning_rate": 8.093446648378031e-06,
      "loss": 0.3890506744384766,
      "memory(GiB)": 72.72,
      "step": 17330,
      "token_acc": 0.8987341772151899,
      "train_speed(iter/s)": 0.252005
    },
    {
      "epoch": 1.6169200634269192,
      "grad_norm": 6.501343727111816,
      "learning_rate": 8.092234819379929e-06,
      "loss": 0.42959299087524416,
      "memory(GiB)": 72.72,
      "step": 17335,
      "token_acc": 0.7943262411347518,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.6173864378322917,
      "grad_norm": 5.3967742919921875,
      "learning_rate": 8.091022696165206e-06,
      "loss": 0.42748260498046875,
      "memory(GiB)": 72.72,
      "step": 17340,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.6178528122376643,
      "grad_norm": 5.382622718811035,
      "learning_rate": 8.0898102788492e-06,
      "loss": 0.4213038444519043,
      "memory(GiB)": 72.72,
      "step": 17345,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.618319186643037,
      "grad_norm": 5.0152058601379395,
      "learning_rate": 8.088597567547261e-06,
      "loss": 0.42725982666015627,
      "memory(GiB)": 72.72,
      "step": 17350,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.6187855610484096,
      "grad_norm": 7.2671709060668945,
      "learning_rate": 8.08738456237478e-06,
      "loss": 0.4400640964508057,
      "memory(GiB)": 72.72,
      "step": 17355,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.6192519354537822,
      "grad_norm": 10.133042335510254,
      "learning_rate": 8.086171263447168e-06,
      "loss": 0.47841501235961914,
      "memory(GiB)": 72.72,
      "step": 17360,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.619718309859155,
      "grad_norm": 6.426848411560059,
      "learning_rate": 8.084957670879868e-06,
      "loss": 0.4447187423706055,
      "memory(GiB)": 72.72,
      "step": 17365,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.6201846842645276,
      "grad_norm": 9.522210121154785,
      "learning_rate": 8.083743784788348e-06,
      "loss": 0.45589675903320315,
      "memory(GiB)": 72.72,
      "step": 17370,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.6206510586699001,
      "grad_norm": 3.3642964363098145,
      "learning_rate": 8.082529605288108e-06,
      "loss": 0.39684548377990725,
      "memory(GiB)": 72.72,
      "step": 17375,
      "token_acc": 0.9113924050632911,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.621117433075273,
      "grad_norm": 3.875769853591919,
      "learning_rate": 8.081315132494672e-06,
      "loss": 0.3970803260803223,
      "memory(GiB)": 72.72,
      "step": 17380,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.6215838074806455,
      "grad_norm": 8.649236679077148,
      "learning_rate": 8.080100366523592e-06,
      "loss": 0.4695991039276123,
      "memory(GiB)": 72.72,
      "step": 17385,
      "token_acc": 0.5571428571428572,
      "train_speed(iter/s)": 0.252007
    },
    {
      "epoch": 1.622050181886018,
      "grad_norm": 3.9341328144073486,
      "learning_rate": 8.07888530749045e-06,
      "loss": 0.4084317207336426,
      "memory(GiB)": 72.72,
      "step": 17390,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.6225165562913908,
      "grad_norm": 4.027001857757568,
      "learning_rate": 8.077669955510857e-06,
      "loss": 0.41547212600708006,
      "memory(GiB)": 72.72,
      "step": 17395,
      "token_acc": 0.732824427480916,
      "train_speed(iter/s)": 0.25201
    },
    {
      "epoch": 1.6229829306967634,
      "grad_norm": 9.785884857177734,
      "learning_rate": 8.076454310700449e-06,
      "loss": 0.4666607856750488,
      "memory(GiB)": 72.72,
      "step": 17400,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.623449305102136,
      "grad_norm": 5.457606792449951,
      "learning_rate": 8.075238373174892e-06,
      "loss": 0.4093305587768555,
      "memory(GiB)": 72.72,
      "step": 17405,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.6239156795075087,
      "grad_norm": 3.5247514247894287,
      "learning_rate": 8.074022143049876e-06,
      "loss": 0.41501030921936033,
      "memory(GiB)": 72.72,
      "step": 17410,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.6243820539128813,
      "grad_norm": 6.150113105773926,
      "learning_rate": 8.072805620441121e-06,
      "loss": 0.46192331314086915,
      "memory(GiB)": 72.72,
      "step": 17415,
      "token_acc": 0.45,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.6248484283182538,
      "grad_norm": 5.1514811515808105,
      "learning_rate": 8.071588805464378e-06,
      "loss": 0.45456552505493164,
      "memory(GiB)": 72.72,
      "step": 17420,
      "token_acc": 0.967741935483871,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.6253148027236266,
      "grad_norm": 8.257466316223145,
      "learning_rate": 8.070371698235424e-06,
      "loss": 0.40782690048217773,
      "memory(GiB)": 72.72,
      "step": 17425,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.6257811771289992,
      "grad_norm": 3.743973731994629,
      "learning_rate": 8.06915429887006e-06,
      "loss": 0.4238120079040527,
      "memory(GiB)": 72.72,
      "step": 17430,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.6262475515343717,
      "grad_norm": 4.743222713470459,
      "learning_rate": 8.06793660748412e-06,
      "loss": 0.42628960609436034,
      "memory(GiB)": 72.72,
      "step": 17435,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.6267139259397445,
      "grad_norm": 4.20668363571167,
      "learning_rate": 8.066718624193462e-06,
      "loss": 0.4038440704345703,
      "memory(GiB)": 72.72,
      "step": 17440,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.627180300345117,
      "grad_norm": 4.412726402282715,
      "learning_rate": 8.065500349113975e-06,
      "loss": 0.38873610496520994,
      "memory(GiB)": 72.72,
      "step": 17445,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.6276466747504896,
      "grad_norm": 5.221468925476074,
      "learning_rate": 8.064281782361573e-06,
      "loss": 0.4363710880279541,
      "memory(GiB)": 72.72,
      "step": 17450,
      "token_acc": 0.5754716981132075,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.6281130491558624,
      "grad_norm": 4.371291637420654,
      "learning_rate": 8.0630629240522e-06,
      "loss": 0.42728300094604493,
      "memory(GiB)": 72.72,
      "step": 17455,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.628579423561235,
      "grad_norm": 4.507077217102051,
      "learning_rate": 8.061843774301825e-06,
      "loss": 0.4218462944030762,
      "memory(GiB)": 72.72,
      "step": 17460,
      "token_acc": 0.5961538461538461,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.6290457979666075,
      "grad_norm": 6.259402275085449,
      "learning_rate": 8.060624333226445e-06,
      "loss": 0.4564610481262207,
      "memory(GiB)": 72.72,
      "step": 17465,
      "token_acc": 0.5344827586206896,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.6295121723719803,
      "grad_norm": 3.9967756271362305,
      "learning_rate": 8.05940460094209e-06,
      "loss": 0.44910993576049807,
      "memory(GiB)": 72.72,
      "step": 17470,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.6299785467773529,
      "grad_norm": 6.585164546966553,
      "learning_rate": 8.058184577564814e-06,
      "loss": 0.4225008010864258,
      "memory(GiB)": 72.72,
      "step": 17475,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.6304449211827254,
      "grad_norm": 4.324645042419434,
      "learning_rate": 8.056964263210693e-06,
      "loss": 0.44521660804748536,
      "memory(GiB)": 72.72,
      "step": 17480,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.6309112955880982,
      "grad_norm": 4.506555080413818,
      "learning_rate": 8.055743657995843e-06,
      "loss": 0.4530595302581787,
      "memory(GiB)": 72.72,
      "step": 17485,
      "token_acc": 0.9313725490196079,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.6313776699934708,
      "grad_norm": 3.8275606632232666,
      "learning_rate": 8.054522762036395e-06,
      "loss": 0.3912647008895874,
      "memory(GiB)": 72.72,
      "step": 17490,
      "token_acc": 0.782312925170068,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.6318440443988433,
      "grad_norm": 5.7562456130981445,
      "learning_rate": 8.053301575448518e-06,
      "loss": 0.4866387367248535,
      "memory(GiB)": 72.72,
      "step": 17495,
      "train_speed(iter/s)": 0.252019
    },
    {
      "epoch": 1.6323104188042161,
      "grad_norm": 4.058343410491943,
      "learning_rate": 8.052080098348398e-06,
      "loss": 0.4388011932373047,
      "memory(GiB)": 72.72,
      "step": 17500,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.6327767932095887,
      "grad_norm": 3.787186861038208,
      "learning_rate": 8.050858330852263e-06,
      "loss": 0.48053932189941406,
      "memory(GiB)": 72.72,
      "step": 17505,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.252019
    },
    {
      "epoch": 1.6332431676149612,
      "grad_norm": 4.204568386077881,
      "learning_rate": 8.049636273076355e-06,
      "loss": 0.42149863243103025,
      "memory(GiB)": 72.72,
      "step": 17510,
      "train_speed(iter/s)": 0.252023
    },
    {
      "epoch": 1.633709542020334,
      "grad_norm": 7.562971591949463,
      "learning_rate": 8.048413925136949e-06,
      "loss": 0.384309720993042,
      "memory(GiB)": 72.72,
      "step": 17515,
      "token_acc": 0.5666666666666667,
      "train_speed(iter/s)": 0.252023
    },
    {
      "epoch": 1.6341759164257066,
      "grad_norm": 4.827396392822266,
      "learning_rate": 8.04719128715035e-06,
      "loss": 0.42072882652282717,
      "memory(GiB)": 72.72,
      "step": 17520,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.6346422908310791,
      "grad_norm": 3.505624532699585,
      "learning_rate": 8.045968359232886e-06,
      "loss": 0.4606644630432129,
      "memory(GiB)": 72.72,
      "step": 17525,
      "train_speed(iter/s)": 0.252022
    },
    {
      "epoch": 1.635108665236452,
      "grad_norm": 4.579006671905518,
      "learning_rate": 8.044745141500915e-06,
      "loss": 0.4351665496826172,
      "memory(GiB)": 72.72,
      "step": 17530,
      "token_acc": 0.8958333333333334,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.6355750396418245,
      "grad_norm": 4.511868476867676,
      "learning_rate": 8.043521634070827e-06,
      "loss": 0.4134498596191406,
      "memory(GiB)": 72.72,
      "step": 17535,
      "token_acc": 0.46551724137931033,
      "train_speed(iter/s)": 0.252022
    },
    {
      "epoch": 1.636041414047197,
      "grad_norm": 3.4900686740875244,
      "learning_rate": 8.04229783705903e-06,
      "loss": 0.39439847469329836,
      "memory(GiB)": 72.72,
      "step": 17540,
      "token_acc": 0.44285714285714284,
      "train_speed(iter/s)": 0.25202
    },
    {
      "epoch": 1.6365077884525698,
      "grad_norm": 4.569472312927246,
      "learning_rate": 8.041073750581964e-06,
      "loss": 0.438373327255249,
      "memory(GiB)": 72.72,
      "step": 17545,
      "token_acc": 0.43478260869565216,
      "train_speed(iter/s)": 0.252019
    },
    {
      "epoch": 1.6369741628579424,
      "grad_norm": 3.4719138145446777,
      "learning_rate": 8.0398493747561e-06,
      "loss": 0.38593158721923826,
      "memory(GiB)": 72.72,
      "step": 17550,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.637440537263315,
      "grad_norm": 5.1257548332214355,
      "learning_rate": 8.038624709697932e-06,
      "loss": 0.44595794677734374,
      "memory(GiB)": 72.72,
      "step": 17555,
      "token_acc": 0.5208333333333334,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.6379069116686877,
      "grad_norm": 3.660979986190796,
      "learning_rate": 8.037399755523986e-06,
      "loss": 0.4342613697052002,
      "memory(GiB)": 72.72,
      "step": 17560,
      "token_acc": 0.6595744680851063,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.6383732860740603,
      "grad_norm": 5.5485687255859375,
      "learning_rate": 8.036174512350807e-06,
      "loss": 0.44728403091430663,
      "memory(GiB)": 72.72,
      "step": 17565,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.6388396604794329,
      "grad_norm": 4.387235641479492,
      "learning_rate": 8.034948980294979e-06,
      "loss": 0.40658769607543943,
      "memory(GiB)": 72.72,
      "step": 17570,
      "token_acc": 0.43902439024390244,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.6393060348848056,
      "grad_norm": 4.883896350860596,
      "learning_rate": 8.033723159473104e-06,
      "loss": 0.45449056625366213,
      "memory(GiB)": 72.72,
      "step": 17575,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.6397724092901782,
      "grad_norm": 3.189361810684204,
      "learning_rate": 8.032497050001815e-06,
      "loss": 0.41454324722290037,
      "memory(GiB)": 72.72,
      "step": 17580,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.6402387836955508,
      "grad_norm": 6.804073333740234,
      "learning_rate": 8.031270651997774e-06,
      "loss": 0.41786041259765627,
      "memory(GiB)": 72.72,
      "step": 17585,
      "token_acc": 0.4805194805194805,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.6407051581009235,
      "grad_norm": 3.5081300735473633,
      "learning_rate": 8.030043965577668e-06,
      "loss": 0.3840212345123291,
      "memory(GiB)": 72.72,
      "step": 17590,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.641171532506296,
      "grad_norm": 6.760675430297852,
      "learning_rate": 8.028816990858216e-06,
      "loss": 0.447511100769043,
      "memory(GiB)": 72.72,
      "step": 17595,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.6416379069116687,
      "grad_norm": 3.676807403564453,
      "learning_rate": 8.027589727956153e-06,
      "loss": 0.4231729507446289,
      "memory(GiB)": 72.72,
      "step": 17600,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.6421042813170414,
      "grad_norm": 5.501657962799072,
      "learning_rate": 8.026362176988259e-06,
      "loss": 0.4390843391418457,
      "memory(GiB)": 72.72,
      "step": 17605,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.642570655722414,
      "grad_norm": 10.175227165222168,
      "learning_rate": 8.025134338071324e-06,
      "loss": 0.38728699684143064,
      "memory(GiB)": 72.72,
      "step": 17610,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.6430370301277866,
      "grad_norm": 4.02226448059082,
      "learning_rate": 8.023906211322175e-06,
      "loss": 0.4259613513946533,
      "memory(GiB)": 72.72,
      "step": 17615,
      "token_acc": 0.7720588235294118,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.6435034045331594,
      "grad_norm": 7.846753120422363,
      "learning_rate": 8.022677796857667e-06,
      "loss": 0.4388397216796875,
      "memory(GiB)": 72.72,
      "step": 17620,
      "token_acc": 0.875,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.6439697789385317,
      "grad_norm": 3.2699038982391357,
      "learning_rate": 8.021449094794677e-06,
      "loss": 0.40596675872802734,
      "memory(GiB)": 72.72,
      "step": 17625,
      "train_speed(iter/s)": 0.252011
    },
    {
      "epoch": 1.6444361533439045,
      "grad_norm": 3.6945674419403076,
      "learning_rate": 8.020220105250115e-06,
      "loss": 0.42898831367492674,
      "memory(GiB)": 72.72,
      "step": 17630,
      "token_acc": 0.8389261744966443,
      "train_speed(iter/s)": 0.252007
    },
    {
      "epoch": 1.6449025277492773,
      "grad_norm": 5.017506122589111,
      "learning_rate": 8.018990828340914e-06,
      "loss": 0.4213124752044678,
      "memory(GiB)": 72.72,
      "step": 17635,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.6453689021546496,
      "grad_norm": 4.745933532714844,
      "learning_rate": 8.017761264184035e-06,
      "loss": 0.44671220779418946,
      "memory(GiB)": 72.72,
      "step": 17640,
      "token_acc": 0.8133333333333334,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.6458352765600224,
      "grad_norm": 5.686323642730713,
      "learning_rate": 8.016531412896468e-06,
      "loss": 0.42416629791259763,
      "memory(GiB)": 72.72,
      "step": 17645,
      "train_speed(iter/s)": 0.252001
    },
    {
      "epoch": 1.6463016509653952,
      "grad_norm": 4.857537269592285,
      "learning_rate": 8.015301274595229e-06,
      "loss": 0.4467108726501465,
      "memory(GiB)": 72.72,
      "step": 17650,
      "train_speed(iter/s)": 0.252007
    },
    {
      "epoch": 1.6467680253707675,
      "grad_norm": 4.51658296585083,
      "learning_rate": 8.014070849397365e-06,
      "loss": 0.43960275650024416,
      "memory(GiB)": 72.72,
      "step": 17655,
      "token_acc": 0.8533333333333334,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.6472343997761403,
      "grad_norm": 3.740513324737549,
      "learning_rate": 8.012840137419942e-06,
      "loss": 0.437970495223999,
      "memory(GiB)": 72.72,
      "step": 17660,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.252007
    },
    {
      "epoch": 1.647700774181513,
      "grad_norm": 3.8736517429351807,
      "learning_rate": 8.011609138780063e-06,
      "loss": 0.4115731239318848,
      "memory(GiB)": 72.72,
      "step": 17665,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.6481671485868854,
      "grad_norm": 5.397472381591797,
      "learning_rate": 8.010377853594851e-06,
      "loss": 0.3902381658554077,
      "memory(GiB)": 72.72,
      "step": 17670,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.6486335229922582,
      "grad_norm": 4.898148536682129,
      "learning_rate": 8.009146281981461e-06,
      "loss": 0.4477978706359863,
      "memory(GiB)": 72.72,
      "step": 17675,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.649099897397631,
      "grad_norm": 2.984008550643921,
      "learning_rate": 8.007914424057072e-06,
      "loss": 0.4447624206542969,
      "memory(GiB)": 72.72,
      "step": 17680,
      "token_acc": 0.9866666666666667,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.6495662718030033,
      "grad_norm": 4.0265655517578125,
      "learning_rate": 8.006682279938892e-06,
      "loss": 0.42700653076171874,
      "memory(GiB)": 72.72,
      "step": 17685,
      "train_speed(iter/s)": 0.252026
    },
    {
      "epoch": 1.650032646208376,
      "grad_norm": 4.494564056396484,
      "learning_rate": 8.005449849744153e-06,
      "loss": 0.4140007019042969,
      "memory(GiB)": 72.72,
      "step": 17690,
      "token_acc": 0.4339622641509434,
      "train_speed(iter/s)": 0.252028
    },
    {
      "epoch": 1.6504990206137489,
      "grad_norm": 8.251947402954102,
      "learning_rate": 8.004217133590122e-06,
      "loss": 0.47617535591125487,
      "memory(GiB)": 72.72,
      "step": 17695,
      "token_acc": 0.7553956834532374,
      "train_speed(iter/s)": 0.252033
    },
    {
      "epoch": 1.6509653950191212,
      "grad_norm": 9.863224983215332,
      "learning_rate": 8.002984131594086e-06,
      "loss": 0.42218379974365233,
      "memory(GiB)": 72.72,
      "step": 17700,
      "train_speed(iter/s)": 0.252034
    },
    {
      "epoch": 1.651431769424494,
      "grad_norm": 3.579880952835083,
      "learning_rate": 8.001750843873357e-06,
      "loss": 0.4085193634033203,
      "memory(GiB)": 72.72,
      "step": 17705,
      "train_speed(iter/s)": 0.252036
    },
    {
      "epoch": 1.6518981438298668,
      "grad_norm": 5.544497966766357,
      "learning_rate": 8.000517270545285e-06,
      "loss": 0.44781951904296874,
      "memory(GiB)": 72.72,
      "step": 17710,
      "train_speed(iter/s)": 0.252037
    },
    {
      "epoch": 1.652364518235239,
      "grad_norm": 3.622687339782715,
      "learning_rate": 7.999283411727239e-06,
      "loss": 0.449599552154541,
      "memory(GiB)": 72.72,
      "step": 17715,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.252036
    },
    {
      "epoch": 1.652830892640612,
      "grad_norm": 4.975557327270508,
      "learning_rate": 7.998049267536614e-06,
      "loss": 0.41949806213378904,
      "memory(GiB)": 72.72,
      "step": 17720,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.6532972670459847,
      "grad_norm": 3.459690809249878,
      "learning_rate": 7.996814838090837e-06,
      "loss": 0.4272941589355469,
      "memory(GiB)": 72.72,
      "step": 17725,
      "train_speed(iter/s)": 0.252033
    },
    {
      "epoch": 1.653763641451357,
      "grad_norm": 3.191328763961792,
      "learning_rate": 7.99558012350736e-06,
      "loss": 0.4254470348358154,
      "memory(GiB)": 72.72,
      "step": 17730,
      "train_speed(iter/s)": 0.252038
    },
    {
      "epoch": 1.6542300158567298,
      "grad_norm": 3.701636791229248,
      "learning_rate": 7.994345123903663e-06,
      "loss": 0.4166041374206543,
      "memory(GiB)": 72.72,
      "step": 17735,
      "token_acc": 0.5416666666666666,
      "train_speed(iter/s)": 0.252038
    },
    {
      "epoch": 1.6546963902621026,
      "grad_norm": 3.517798900604248,
      "learning_rate": 7.993109839397253e-06,
      "loss": 0.4360386371612549,
      "memory(GiB)": 72.72,
      "step": 17740,
      "train_speed(iter/s)": 0.252043
    },
    {
      "epoch": 1.655162764667475,
      "grad_norm": 3.56738018989563,
      "learning_rate": 7.99187427010566e-06,
      "loss": 0.42548561096191406,
      "memory(GiB)": 72.72,
      "step": 17745,
      "token_acc": 0.39215686274509803,
      "train_speed(iter/s)": 0.252046
    },
    {
      "epoch": 1.6556291390728477,
      "grad_norm": 6.267224311828613,
      "learning_rate": 7.990638416146448e-06,
      "loss": 0.40793137550354003,
      "memory(GiB)": 72.72,
      "step": 17750,
      "train_speed(iter/s)": 0.252053
    },
    {
      "epoch": 1.6560955134782203,
      "grad_norm": 5.4121623039245605,
      "learning_rate": 7.989402277637204e-06,
      "loss": 0.4173006057739258,
      "memory(GiB)": 72.72,
      "step": 17755,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.6565618878835928,
      "grad_norm": 4.043698787689209,
      "learning_rate": 7.988165854695541e-06,
      "loss": 0.43799700736999514,
      "memory(GiB)": 72.72,
      "step": 17760,
      "token_acc": 0.4418604651162791,
      "train_speed(iter/s)": 0.252054
    },
    {
      "epoch": 1.6570282622889656,
      "grad_norm": 6.259217262268066,
      "learning_rate": 7.986929147439102e-06,
      "loss": 0.44343934059143064,
      "memory(GiB)": 72.72,
      "step": 17765,
      "token_acc": 0.8366013071895425,
      "train_speed(iter/s)": 0.252053
    },
    {
      "epoch": 1.6574946366943382,
      "grad_norm": 10.986774444580078,
      "learning_rate": 7.985692155985558e-06,
      "loss": 0.45909509658813474,
      "memory(GiB)": 72.72,
      "step": 17770,
      "token_acc": 0.5084745762711864,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.6579610110997107,
      "grad_norm": 3.9623804092407227,
      "learning_rate": 7.9844548804526e-06,
      "loss": 0.4459378719329834,
      "memory(GiB)": 72.72,
      "step": 17775,
      "token_acc": 0.5964912280701754,
      "train_speed(iter/s)": 0.252057
    },
    {
      "epoch": 1.6584273855050835,
      "grad_norm": 13.058424949645996,
      "learning_rate": 7.983217320957958e-06,
      "loss": 0.47313232421875,
      "memory(GiB)": 72.72,
      "step": 17780,
      "train_speed(iter/s)": 0.252057
    },
    {
      "epoch": 1.658893759910456,
      "grad_norm": 5.221495151519775,
      "learning_rate": 7.981979477619375e-06,
      "loss": 0.407773494720459,
      "memory(GiB)": 72.72,
      "step": 17785,
      "token_acc": 0.7310344827586207,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.6593601343158286,
      "grad_norm": 4.166413307189941,
      "learning_rate": 7.980741350554633e-06,
      "loss": 0.4551806926727295,
      "memory(GiB)": 72.72,
      "step": 17790,
      "token_acc": 0.4807692307692308,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.6598265087212014,
      "grad_norm": 5.9716997146606445,
      "learning_rate": 7.979502939881532e-06,
      "loss": 0.4117547035217285,
      "memory(GiB)": 72.72,
      "step": 17795,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.660292883126574,
      "grad_norm": 5.135018348693848,
      "learning_rate": 7.978264245717906e-06,
      "loss": 0.44739999771118166,
      "memory(GiB)": 72.72,
      "step": 17800,
      "token_acc": 0.9142857142857143,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.6607592575319465,
      "grad_norm": 6.0586256980896,
      "learning_rate": 7.97702526818161e-06,
      "loss": 0.3860630035400391,
      "memory(GiB)": 72.72,
      "step": 17805,
      "train_speed(iter/s)": 0.25206
    },
    {
      "epoch": 1.6612256319373193,
      "grad_norm": 4.758581161499023,
      "learning_rate": 7.975786007390534e-06,
      "loss": 0.4198338985443115,
      "memory(GiB)": 72.72,
      "step": 17810,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.6616920063426919,
      "grad_norm": 8.478202819824219,
      "learning_rate": 7.974546463462585e-06,
      "loss": 0.39007105827331545,
      "memory(GiB)": 72.72,
      "step": 17815,
      "token_acc": 0.5178571428571429,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.6621583807480644,
      "grad_norm": 3.6110424995422363,
      "learning_rate": 7.973306636515702e-06,
      "loss": 0.39527430534362795,
      "memory(GiB)": 72.72,
      "step": 17820,
      "token_acc": 0.37209302325581395,
      "train_speed(iter/s)": 0.252057
    },
    {
      "epoch": 1.6626247551534372,
      "grad_norm": 33.293094635009766,
      "learning_rate": 7.972066526667853e-06,
      "loss": 0.40181307792663573,
      "memory(GiB)": 72.72,
      "step": 17825,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.6630911295588098,
      "grad_norm": 5.483829021453857,
      "learning_rate": 7.97082613403703e-06,
      "loss": 0.4172266960144043,
      "memory(GiB)": 72.72,
      "step": 17830,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.252062
    },
    {
      "epoch": 1.6635575039641823,
      "grad_norm": 12.17884349822998,
      "learning_rate": 7.969585458741252e-06,
      "loss": 0.4066757678985596,
      "memory(GiB)": 72.72,
      "step": 17835,
      "token_acc": 0.6906474820143885,
      "train_speed(iter/s)": 0.252064
    },
    {
      "epoch": 1.6640238783695551,
      "grad_norm": 4.083310127258301,
      "learning_rate": 7.968344500898566e-06,
      "loss": 0.4200150489807129,
      "memory(GiB)": 72.72,
      "step": 17840,
      "token_acc": 0.38181818181818183,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.6644902527749277,
      "grad_norm": 3.7274599075317383,
      "learning_rate": 7.967103260627044e-06,
      "loss": 0.46149301528930664,
      "memory(GiB)": 72.72,
      "step": 17845,
      "token_acc": 0.4631578947368421,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.6649566271803002,
      "grad_norm": 5.108497619628906,
      "learning_rate": 7.965861738044787e-06,
      "loss": 0.3945744037628174,
      "memory(GiB)": 72.72,
      "step": 17850,
      "token_acc": 0.48484848484848486,
      "train_speed(iter/s)": 0.251961
    },
    {
      "epoch": 1.665423001585673,
      "grad_norm": 3.2921483516693115,
      "learning_rate": 7.964619933269924e-06,
      "loss": 0.4647984027862549,
      "memory(GiB)": 72.72,
      "step": 17855,
      "token_acc": 0.7740384615384616,
      "train_speed(iter/s)": 0.251966
    },
    {
      "epoch": 1.6658893759910456,
      "grad_norm": 4.287644386291504,
      "learning_rate": 7.963377846420605e-06,
      "loss": 0.4141056537628174,
      "memory(GiB)": 72.72,
      "step": 17860,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.6663557503964181,
      "grad_norm": 8.76500415802002,
      "learning_rate": 7.962135477615015e-06,
      "loss": 0.46830081939697266,
      "memory(GiB)": 72.72,
      "step": 17865,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.666822124801791,
      "grad_norm": 4.758941650390625,
      "learning_rate": 7.960892826971357e-06,
      "loss": 0.46475605964660643,
      "memory(GiB)": 72.72,
      "step": 17870,
      "token_acc": 0.6037735849056604,
      "train_speed(iter/s)": 0.251962
    },
    {
      "epoch": 1.6672884992071635,
      "grad_norm": 7.75550651550293,
      "learning_rate": 7.959649894607869e-06,
      "loss": 0.40333805084228513,
      "memory(GiB)": 72.72,
      "step": 17875,
      "train_speed(iter/s)": 0.251959
    },
    {
      "epoch": 1.667754873612536,
      "grad_norm": 8.599081993103027,
      "learning_rate": 7.958406680642811e-06,
      "loss": 0.37567648887634275,
      "memory(GiB)": 72.72,
      "step": 17880,
      "train_speed(iter/s)": 0.251961
    },
    {
      "epoch": 1.6682212480179088,
      "grad_norm": 5.9205217361450195,
      "learning_rate": 7.95716318519447e-06,
      "loss": 0.4350318431854248,
      "memory(GiB)": 72.72,
      "step": 17885,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.6686876224232814,
      "grad_norm": 13.041391372680664,
      "learning_rate": 7.955919408381164e-06,
      "loss": 0.41777591705322265,
      "memory(GiB)": 72.72,
      "step": 17890,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.669153996828654,
      "grad_norm": 3.7500152587890625,
      "learning_rate": 7.95467535032123e-06,
      "loss": 0.4323689937591553,
      "memory(GiB)": 72.72,
      "step": 17895,
      "token_acc": 0.47560975609756095,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.6696203712340267,
      "grad_norm": 5.1544671058654785,
      "learning_rate": 7.953431011133037e-06,
      "loss": 0.4367230415344238,
      "memory(GiB)": 72.72,
      "step": 17900,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.6700867456393993,
      "grad_norm": 5.647364139556885,
      "learning_rate": 7.952186390934984e-06,
      "loss": 0.4419704437255859,
      "memory(GiB)": 72.72,
      "step": 17905,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.6705531200447719,
      "grad_norm": 16.142385482788086,
      "learning_rate": 7.95094148984549e-06,
      "loss": 0.426290225982666,
      "memory(GiB)": 72.72,
      "step": 17910,
      "token_acc": 0.6612903225806451,
      "train_speed(iter/s)": 0.251966
    },
    {
      "epoch": 1.6710194944501446,
      "grad_norm": 5.605223178863525,
      "learning_rate": 7.949696307983004e-06,
      "loss": 0.42804927825927735,
      "memory(GiB)": 72.72,
      "step": 17915,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.6714858688555172,
      "grad_norm": 3.824622631072998,
      "learning_rate": 7.948450845466e-06,
      "loss": 0.4274591445922852,
      "memory(GiB)": 72.72,
      "step": 17920,
      "token_acc": 0.9367088607594937,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.6719522432608898,
      "grad_norm": 8.976401329040527,
      "learning_rate": 7.947205102412984e-06,
      "loss": 0.44003829956054685,
      "memory(GiB)": 72.72,
      "step": 17925,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.6724186176662625,
      "grad_norm": 4.18312931060791,
      "learning_rate": 7.94595907894248e-06,
      "loss": 0.41211881637573244,
      "memory(GiB)": 72.72,
      "step": 17930,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.672884992071635,
      "grad_norm": 3.1173598766326904,
      "learning_rate": 7.944712775173045e-06,
      "loss": 0.38822054862976074,
      "memory(GiB)": 72.72,
      "step": 17935,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.6733513664770077,
      "grad_norm": 3.128722906112671,
      "learning_rate": 7.94346619122326e-06,
      "loss": 0.40009369850158694,
      "memory(GiB)": 72.72,
      "step": 17940,
      "token_acc": 0.5421686746987951,
      "train_speed(iter/s)": 0.251966
    },
    {
      "epoch": 1.6738177408823804,
      "grad_norm": 3.301647663116455,
      "learning_rate": 7.942219327211733e-06,
      "loss": 0.44250946044921874,
      "memory(GiB)": 72.72,
      "step": 17945,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251973
    },
    {
      "epoch": 1.674284115287753,
      "grad_norm": 7.399308681488037,
      "learning_rate": 7.940972183257104e-06,
      "loss": 0.42130002975463865,
      "memory(GiB)": 72.72,
      "step": 17950,
      "train_speed(iter/s)": 0.251974
    },
    {
      "epoch": 1.6747504896931256,
      "grad_norm": 4.50758695602417,
      "learning_rate": 7.93972475947803e-06,
      "loss": 0.41596317291259766,
      "memory(GiB)": 72.72,
      "step": 17955,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251981
    },
    {
      "epoch": 1.6752168640984983,
      "grad_norm": 3.4150137901306152,
      "learning_rate": 7.938477055993202e-06,
      "loss": 0.4014856815338135,
      "memory(GiB)": 72.72,
      "step": 17960,
      "train_speed(iter/s)": 0.251981
    },
    {
      "epoch": 1.675683238503871,
      "grad_norm": 2.9941322803497314,
      "learning_rate": 7.937229072921333e-06,
      "loss": 0.43636622428894045,
      "memory(GiB)": 72.72,
      "step": 17965,
      "token_acc": 0.4406779661016949,
      "train_speed(iter/s)": 0.251982
    },
    {
      "epoch": 1.6761496129092435,
      "grad_norm": 4.595310688018799,
      "learning_rate": 7.935980810381166e-06,
      "loss": 0.4502130031585693,
      "memory(GiB)": 72.72,
      "step": 17970,
      "token_acc": 0.5490196078431373,
      "train_speed(iter/s)": 0.251981
    },
    {
      "epoch": 1.6766159873146163,
      "grad_norm": 6.195744514465332,
      "learning_rate": 7.93473226849147e-06,
      "loss": 0.4291933536529541,
      "memory(GiB)": 72.72,
      "step": 17975,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.6770823617199888,
      "grad_norm": 3.4142327308654785,
      "learning_rate": 7.93348344737104e-06,
      "loss": 0.42960305213928224,
      "memory(GiB)": 72.72,
      "step": 17980,
      "train_speed(iter/s)": 0.251986
    },
    {
      "epoch": 1.6775487361253614,
      "grad_norm": 4.903477668762207,
      "learning_rate": 7.932234347138696e-06,
      "loss": 0.4335890769958496,
      "memory(GiB)": 72.72,
      "step": 17985,
      "train_speed(iter/s)": 0.251988
    },
    {
      "epoch": 1.6780151105307342,
      "grad_norm": 3.7515931129455566,
      "learning_rate": 7.930984967913287e-06,
      "loss": 0.4309999942779541,
      "memory(GiB)": 72.72,
      "step": 17990,
      "token_acc": 0.4358974358974359,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.6784814849361067,
      "grad_norm": 4.409213542938232,
      "learning_rate": 7.929735309813688e-06,
      "loss": 0.39854238033294676,
      "memory(GiB)": 72.72,
      "step": 17995,
      "train_speed(iter/s)": 0.251986
    },
    {
      "epoch": 1.6789478593414793,
      "grad_norm": 5.305566310882568,
      "learning_rate": 7.9284853729588e-06,
      "loss": 0.4275654792785645,
      "memory(GiB)": 72.72,
      "step": 18000,
      "token_acc": 0.6721311475409836,
      "train_speed(iter/s)": 0.251985
    },
    {
      "epoch": 1.679414233746852,
      "grad_norm": 5.021092891693115,
      "learning_rate": 7.927235157467548e-06,
      "loss": 0.41707792282104494,
      "memory(GiB)": 72.72,
      "step": 18005,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251898
    },
    {
      "epoch": 1.6798806081522246,
      "grad_norm": 2.6428184509277344,
      "learning_rate": 7.92598466345889e-06,
      "loss": 0.39909188747406005,
      "memory(GiB)": 72.72,
      "step": 18010,
      "token_acc": 0.6956521739130435,
      "train_speed(iter/s)": 0.251896
    },
    {
      "epoch": 1.6803469825575972,
      "grad_norm": 3.9172229766845703,
      "learning_rate": 7.924733891051805e-06,
      "loss": 0.45527009963989257,
      "memory(GiB)": 72.72,
      "step": 18015,
      "token_acc": 0.5925925925925926,
      "train_speed(iter/s)": 0.251899
    },
    {
      "epoch": 1.68081335696297,
      "grad_norm": 2.844744920730591,
      "learning_rate": 7.923482840365299e-06,
      "loss": 0.4083150863647461,
      "memory(GiB)": 72.72,
      "step": 18020,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251903
    },
    {
      "epoch": 1.6812797313683425,
      "grad_norm": 4.230657577514648,
      "learning_rate": 7.922231511518408e-06,
      "loss": 0.4357504367828369,
      "memory(GiB)": 72.72,
      "step": 18025,
      "train_speed(iter/s)": 0.251898
    },
    {
      "epoch": 1.681746105773715,
      "grad_norm": 4.748021602630615,
      "learning_rate": 7.92097990463019e-06,
      "loss": 0.3997486114501953,
      "memory(GiB)": 72.72,
      "step": 18030,
      "token_acc": 0.8450704225352113,
      "train_speed(iter/s)": 0.251894
    },
    {
      "epoch": 1.6822124801790879,
      "grad_norm": 4.756033897399902,
      "learning_rate": 7.919728019819732e-06,
      "loss": 0.4321488380432129,
      "memory(GiB)": 72.72,
      "step": 18035,
      "token_acc": 0.9583333333333334,
      "train_speed(iter/s)": 0.251895
    },
    {
      "epoch": 1.6826788545844604,
      "grad_norm": 2.9655685424804688,
      "learning_rate": 7.918475857206149e-06,
      "loss": 0.44343061447143556,
      "memory(GiB)": 72.72,
      "step": 18040,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251895
    },
    {
      "epoch": 1.683145228989833,
      "grad_norm": 2.7211053371429443,
      "learning_rate": 7.917223416908577e-06,
      "loss": 0.4404839038848877,
      "memory(GiB)": 72.72,
      "step": 18045,
      "train_speed(iter/s)": 0.251895
    },
    {
      "epoch": 1.6836116033952058,
      "grad_norm": 4.387409210205078,
      "learning_rate": 7.915970699046184e-06,
      "loss": 0.41496753692626953,
      "memory(GiB)": 72.72,
      "step": 18050,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251899
    },
    {
      "epoch": 1.6840779778005783,
      "grad_norm": 8.542135238647461,
      "learning_rate": 7.914717703738163e-06,
      "loss": 0.43233652114868165,
      "memory(GiB)": 72.72,
      "step": 18055,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251899
    },
    {
      "epoch": 1.684544352205951,
      "grad_norm": 3.6361310482025146,
      "learning_rate": 7.91346443110373e-06,
      "loss": 0.45292158126831056,
      "memory(GiB)": 72.72,
      "step": 18060,
      "token_acc": 0.5423728813559322,
      "train_speed(iter/s)": 0.251905
    },
    {
      "epoch": 1.6850107266113237,
      "grad_norm": 2.934887409210205,
      "learning_rate": 7.912210881262132e-06,
      "loss": 0.4281466484069824,
      "memory(GiB)": 72.72,
      "step": 18065,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.25191
    },
    {
      "epoch": 1.6854771010166962,
      "grad_norm": 3.506662368774414,
      "learning_rate": 7.910957054332642e-06,
      "loss": 0.3830891132354736,
      "memory(GiB)": 72.72,
      "step": 18070,
      "train_speed(iter/s)": 0.251909
    },
    {
      "epoch": 1.6859434754220688,
      "grad_norm": 3.8695359230041504,
      "learning_rate": 7.909702950434552e-06,
      "loss": 0.40548315048217776,
      "memory(GiB)": 72.72,
      "step": 18075,
      "train_speed(iter/s)": 0.251908
    },
    {
      "epoch": 1.6864098498274416,
      "grad_norm": 4.657360553741455,
      "learning_rate": 7.908448569687193e-06,
      "loss": 0.40050082206726073,
      "memory(GiB)": 72.72,
      "step": 18080,
      "token_acc": 0.5565217391304348,
      "train_speed(iter/s)": 0.251905
    },
    {
      "epoch": 1.6868762242328141,
      "grad_norm": 3.9823861122131348,
      "learning_rate": 7.907193912209912e-06,
      "loss": 0.4412433624267578,
      "memory(GiB)": 72.72,
      "step": 18085,
      "train_speed(iter/s)": 0.251908
    },
    {
      "epoch": 1.6873425986381867,
      "grad_norm": 3.0371246337890625,
      "learning_rate": 7.905938978122083e-06,
      "loss": 0.4132420539855957,
      "memory(GiB)": 72.72,
      "step": 18090,
      "train_speed(iter/s)": 0.251912
    },
    {
      "epoch": 1.6878089730435595,
      "grad_norm": 7.695077419281006,
      "learning_rate": 7.904683767543116e-06,
      "loss": 0.4012912273406982,
      "memory(GiB)": 72.72,
      "step": 18095,
      "token_acc": 0.7987421383647799,
      "train_speed(iter/s)": 0.251912
    },
    {
      "epoch": 1.688275347448932,
      "grad_norm": 5.25541353225708,
      "learning_rate": 7.903428280592433e-06,
      "loss": 0.4074049949645996,
      "memory(GiB)": 72.72,
      "step": 18100,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.25191
    },
    {
      "epoch": 1.6887417218543046,
      "grad_norm": 4.177816390991211,
      "learning_rate": 7.902172517389497e-06,
      "loss": 0.3719943046569824,
      "memory(GiB)": 72.72,
      "step": 18105,
      "token_acc": 0.9010989010989011,
      "train_speed(iter/s)": 0.251907
    },
    {
      "epoch": 1.6892080962596774,
      "grad_norm": 4.001177787780762,
      "learning_rate": 7.900916478053784e-06,
      "loss": 0.4187631130218506,
      "memory(GiB)": 72.72,
      "step": 18110,
      "train_speed(iter/s)": 0.251907
    },
    {
      "epoch": 1.68967447066505,
      "grad_norm": 3.1003952026367188,
      "learning_rate": 7.899660162704806e-06,
      "loss": 0.39666152000427246,
      "memory(GiB)": 72.72,
      "step": 18115,
      "train_speed(iter/s)": 0.251907
    },
    {
      "epoch": 1.6901408450704225,
      "grad_norm": 11.075093269348145,
      "learning_rate": 7.898403571462095e-06,
      "loss": 0.4663419246673584,
      "memory(GiB)": 72.72,
      "step": 18120,
      "train_speed(iter/s)": 0.251909
    },
    {
      "epoch": 1.6906072194757953,
      "grad_norm": 5.43228006362915,
      "learning_rate": 7.897146704445213e-06,
      "loss": 0.42902178764343263,
      "memory(GiB)": 72.72,
      "step": 18125,
      "train_speed(iter/s)": 0.251908
    },
    {
      "epoch": 1.6910735938811678,
      "grad_norm": 3.055162191390991,
      "learning_rate": 7.895889561773747e-06,
      "loss": 0.44705653190612793,
      "memory(GiB)": 72.72,
      "step": 18130,
      "train_speed(iter/s)": 0.251915
    },
    {
      "epoch": 1.6915399682865404,
      "grad_norm": 9.36861801147461,
      "learning_rate": 7.89463214356731e-06,
      "loss": 0.39890260696411134,
      "memory(GiB)": 72.72,
      "step": 18135,
      "token_acc": 0.9156626506024096,
      "train_speed(iter/s)": 0.251917
    },
    {
      "epoch": 1.6920063426919132,
      "grad_norm": 5.074132442474365,
      "learning_rate": 7.893374449945543e-06,
      "loss": 0.4255661964416504,
      "memory(GiB)": 72.72,
      "step": 18140,
      "train_speed(iter/s)": 0.25192
    },
    {
      "epoch": 1.6924727170972858,
      "grad_norm": 4.506407737731934,
      "learning_rate": 7.892116481028109e-06,
      "loss": 0.4027705669403076,
      "memory(GiB)": 72.72,
      "step": 18145,
      "train_speed(iter/s)": 0.251927
    },
    {
      "epoch": 1.6929390915026583,
      "grad_norm": 5.174916744232178,
      "learning_rate": 7.890858236934702e-06,
      "loss": 0.4611656188964844,
      "memory(GiB)": 72.72,
      "step": 18150,
      "token_acc": 0.6481481481481481,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.693405465908031,
      "grad_norm": 5.154485702514648,
      "learning_rate": 7.889599717785039e-06,
      "loss": 0.4258391857147217,
      "memory(GiB)": 72.72,
      "step": 18155,
      "train_speed(iter/s)": 0.251933
    },
    {
      "epoch": 1.6938718403134037,
      "grad_norm": 17.503299713134766,
      "learning_rate": 7.888340923698865e-06,
      "loss": 0.4506951332092285,
      "memory(GiB)": 72.72,
      "step": 18160,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.6943382147187762,
      "grad_norm": 4.8822150230407715,
      "learning_rate": 7.887081854795947e-06,
      "loss": 0.438356876373291,
      "memory(GiB)": 72.72,
      "step": 18165,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.694804589124149,
      "grad_norm": 4.395509719848633,
      "learning_rate": 7.885822511196088e-06,
      "loss": 0.41614570617675783,
      "memory(GiB)": 72.72,
      "step": 18170,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.6952709635295213,
      "grad_norm": 5.922647476196289,
      "learning_rate": 7.884562893019105e-06,
      "loss": 0.4118363857269287,
      "memory(GiB)": 72.72,
      "step": 18175,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.251932
    },
    {
      "epoch": 1.6957373379348941,
      "grad_norm": 3.3728175163269043,
      "learning_rate": 7.88330300038485e-06,
      "loss": 0.3940990209579468,
      "memory(GiB)": 72.72,
      "step": 18180,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.696203712340267,
      "grad_norm": 3.4430530071258545,
      "learning_rate": 7.882042833413198e-06,
      "loss": 0.4348157405853271,
      "memory(GiB)": 72.72,
      "step": 18185,
      "token_acc": 0.941747572815534,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.6966700867456392,
      "grad_norm": 3.8972060680389404,
      "learning_rate": 7.880782392224047e-06,
      "loss": 0.39864301681518555,
      "memory(GiB)": 72.72,
      "step": 18190,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.697136461151012,
      "grad_norm": 4.091121673583984,
      "learning_rate": 7.879521676937326e-06,
      "loss": 0.41270790100097654,
      "memory(GiB)": 72.72,
      "step": 18195,
      "token_acc": 0.5957446808510638,
      "train_speed(iter/s)": 0.251936
    },
    {
      "epoch": 1.6976028355563848,
      "grad_norm": 9.355596542358398,
      "learning_rate": 7.878260687672988e-06,
      "loss": 0.4653632164001465,
      "memory(GiB)": 72.72,
      "step": 18200,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.6980692099617571,
      "grad_norm": 4.915448188781738,
      "learning_rate": 7.876999424551012e-06,
      "loss": 0.4457437992095947,
      "memory(GiB)": 72.72,
      "step": 18205,
      "train_speed(iter/s)": 0.251935
    },
    {
      "epoch": 1.69853558436713,
      "grad_norm": 8.380305290222168,
      "learning_rate": 7.875737887691402e-06,
      "loss": 0.43302364349365235,
      "memory(GiB)": 72.72,
      "step": 18210,
      "token_acc": 0.8133333333333334,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.6990019587725027,
      "grad_norm": 10.515424728393555,
      "learning_rate": 7.874476077214195e-06,
      "loss": 0.43732943534851076,
      "memory(GiB)": 72.72,
      "step": 18215,
      "train_speed(iter/s)": 0.251935
    },
    {
      "epoch": 1.699468333177875,
      "grad_norm": 3.9140024185180664,
      "learning_rate": 7.873213993239441e-06,
      "loss": 0.39679441452026365,
      "memory(GiB)": 72.72,
      "step": 18220,
      "train_speed(iter/s)": 0.251935
    },
    {
      "epoch": 1.6999347075832478,
      "grad_norm": 5.153194904327393,
      "learning_rate": 7.871951635887227e-06,
      "loss": 0.4073446273803711,
      "memory(GiB)": 72.72,
      "step": 18225,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.7004010819886206,
      "grad_norm": 4.52365255355835,
      "learning_rate": 7.870689005277663e-06,
      "loss": 0.42693147659301756,
      "memory(GiB)": 72.72,
      "step": 18230,
      "train_speed(iter/s)": 0.251936
    },
    {
      "epoch": 1.700867456393993,
      "grad_norm": 4.365629196166992,
      "learning_rate": 7.869426101530884e-06,
      "loss": 0.44551944732666016,
      "memory(GiB)": 72.72,
      "step": 18235,
      "token_acc": 0.6988636363636364,
      "train_speed(iter/s)": 0.251937
    },
    {
      "epoch": 1.7013338307993657,
      "grad_norm": 5.314007759094238,
      "learning_rate": 7.868162924767051e-06,
      "loss": 0.4087959289550781,
      "memory(GiB)": 72.72,
      "step": 18240,
      "token_acc": 0.8387096774193549,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.7018002052047385,
      "grad_norm": 3.8352105617523193,
      "learning_rate": 7.866899475106348e-06,
      "loss": 0.4305156707763672,
      "memory(GiB)": 72.72,
      "step": 18245,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.7022665796101109,
      "grad_norm": 4.8531270027160645,
      "learning_rate": 7.865635752668997e-06,
      "loss": 0.4438453674316406,
      "memory(GiB)": 72.72,
      "step": 18250,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.7027329540154836,
      "grad_norm": 13.87714958190918,
      "learning_rate": 7.864371757575229e-06,
      "loss": 0.4438188076019287,
      "memory(GiB)": 72.72,
      "step": 18255,
      "token_acc": 0.574468085106383,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.7031993284208564,
      "grad_norm": 4.186459541320801,
      "learning_rate": 7.86310748994531e-06,
      "loss": 0.4528536796569824,
      "memory(GiB)": 72.72,
      "step": 18260,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.7036657028262288,
      "grad_norm": 5.16752815246582,
      "learning_rate": 7.861842949899537e-06,
      "loss": 0.4532731056213379,
      "memory(GiB)": 72.72,
      "step": 18265,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.7041320772316015,
      "grad_norm": 4.594882965087891,
      "learning_rate": 7.860578137558222e-06,
      "loss": 0.431276798248291,
      "memory(GiB)": 72.72,
      "step": 18270,
      "token_acc": 0.5106382978723404,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.7045984516369743,
      "grad_norm": 5.492188930511475,
      "learning_rate": 7.859313053041711e-06,
      "loss": 0.4072686195373535,
      "memory(GiB)": 72.72,
      "step": 18275,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.7050648260423467,
      "grad_norm": 3.6801931858062744,
      "learning_rate": 7.85804769647037e-06,
      "loss": 0.4476773262023926,
      "memory(GiB)": 72.72,
      "step": 18280,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.7055312004477194,
      "grad_norm": 5.248712062835693,
      "learning_rate": 7.856782067964595e-06,
      "loss": 0.4055327415466309,
      "memory(GiB)": 72.72,
      "step": 18285,
      "train_speed(iter/s)": 0.251949
    },
    {
      "epoch": 1.7059975748530922,
      "grad_norm": 4.84063196182251,
      "learning_rate": 7.855516167644805e-06,
      "loss": 0.41277594566345216,
      "memory(GiB)": 72.72,
      "step": 18290,
      "token_acc": 0.9333333333333333,
      "train_speed(iter/s)": 0.251952
    },
    {
      "epoch": 1.7064639492584646,
      "grad_norm": 3.6533305644989014,
      "learning_rate": 7.854249995631452e-06,
      "loss": 0.3981640338897705,
      "memory(GiB)": 72.72,
      "step": 18295,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.251956
    },
    {
      "epoch": 1.7069303236638373,
      "grad_norm": 3.3071675300598145,
      "learning_rate": 7.852983552045002e-06,
      "loss": 0.4321156978607178,
      "memory(GiB)": 72.72,
      "step": 18300,
      "train_speed(iter/s)": 0.251956
    },
    {
      "epoch": 1.7073966980692101,
      "grad_norm": 4.268211841583252,
      "learning_rate": 7.851716837005956e-06,
      "loss": 0.42404804229736326,
      "memory(GiB)": 72.72,
      "step": 18305,
      "train_speed(iter/s)": 0.251961
    },
    {
      "epoch": 1.7078630724745825,
      "grad_norm": 5.1602983474731445,
      "learning_rate": 7.850449850634839e-06,
      "loss": 0.4224395275115967,
      "memory(GiB)": 72.72,
      "step": 18310,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.7083294468799552,
      "grad_norm": 4.294389724731445,
      "learning_rate": 7.849182593052198e-06,
      "loss": 0.4217202186584473,
      "memory(GiB)": 72.72,
      "step": 18315,
      "token_acc": 0.6523809523809524,
      "train_speed(iter/s)": 0.25196
    },
    {
      "epoch": 1.7087958212853278,
      "grad_norm": 13.481193542480469,
      "learning_rate": 7.847915064378613e-06,
      "loss": 0.43468198776245115,
      "memory(GiB)": 72.72,
      "step": 18320,
      "train_speed(iter/s)": 0.251962
    },
    {
      "epoch": 1.7092621956907004,
      "grad_norm": 8.689055442810059,
      "learning_rate": 7.846647264734682e-06,
      "loss": 0.4481049537658691,
      "memory(GiB)": 72.72,
      "step": 18325,
      "token_acc": 0.4074074074074074,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.7097285700960732,
      "grad_norm": 6.29459285736084,
      "learning_rate": 7.845379194241032e-06,
      "loss": 0.4553940773010254,
      "memory(GiB)": 72.72,
      "step": 18330,
      "token_acc": 0.5116279069767442,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.7101949445014457,
      "grad_norm": 3.509561777114868,
      "learning_rate": 7.844110853018317e-06,
      "loss": 0.40458106994628906,
      "memory(GiB)": 72.72,
      "step": 18335,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.7106613189068183,
      "grad_norm": 4.204221725463867,
      "learning_rate": 7.842842241187216e-06,
      "loss": 0.4437066078186035,
      "memory(GiB)": 72.72,
      "step": 18340,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.711127693312191,
      "grad_norm": 5.1422200202941895,
      "learning_rate": 7.841573358868435e-06,
      "loss": 0.4140150547027588,
      "memory(GiB)": 72.72,
      "step": 18345,
      "token_acc": 0.49206349206349204,
      "train_speed(iter/s)": 0.251968
    },
    {
      "epoch": 1.7115940677175636,
      "grad_norm": 4.590857028961182,
      "learning_rate": 7.840304206182701e-06,
      "loss": 0.46632814407348633,
      "memory(GiB)": 72.72,
      "step": 18350,
      "token_acc": 0.64,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 1.7120604421229362,
      "grad_norm": 3.58369517326355,
      "learning_rate": 7.839034783250772e-06,
      "loss": 0.409030818939209,
      "memory(GiB)": 72.72,
      "step": 18355,
      "train_speed(iter/s)": 0.251973
    },
    {
      "epoch": 1.712526816528309,
      "grad_norm": 4.02997350692749,
      "learning_rate": 7.83776509019343e-06,
      "loss": 0.3907020092010498,
      "memory(GiB)": 72.72,
      "step": 18360,
      "token_acc": 0.7619047619047619,
      "train_speed(iter/s)": 0.251972
    },
    {
      "epoch": 1.7129931909336815,
      "grad_norm": 3.8018429279327393,
      "learning_rate": 7.83649512713148e-06,
      "loss": 0.4149959087371826,
      "memory(GiB)": 72.72,
      "step": 18365,
      "token_acc": 0.5666666666666667,
      "train_speed(iter/s)": 0.251971
    },
    {
      "epoch": 1.713459565339054,
      "grad_norm": 6.736908435821533,
      "learning_rate": 7.835224894185758e-06,
      "loss": 0.35704765319824217,
      "memory(GiB)": 72.72,
      "step": 18370,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 1.7139259397444269,
      "grad_norm": 4.956534385681152,
      "learning_rate": 7.83395439147712e-06,
      "loss": 0.46683664321899415,
      "memory(GiB)": 72.72,
      "step": 18375,
      "train_speed(iter/s)": 0.251968
    },
    {
      "epoch": 1.7143923141497994,
      "grad_norm": 5.328985214233398,
      "learning_rate": 7.832683619126453e-06,
      "loss": 0.41995086669921877,
      "memory(GiB)": 72.72,
      "step": 18380,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.714858688555172,
      "grad_norm": 4.986999034881592,
      "learning_rate": 7.831412577254665e-06,
      "loss": 0.4251394271850586,
      "memory(GiB)": 72.72,
      "step": 18385,
      "token_acc": 0.6415094339622641,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.7153250629605448,
      "grad_norm": 5.002682685852051,
      "learning_rate": 7.830141265982694e-06,
      "loss": 0.42209386825561523,
      "memory(GiB)": 72.72,
      "step": 18390,
      "token_acc": 0.946236559139785,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.7157914373659173,
      "grad_norm": 5.331793308258057,
      "learning_rate": 7.8288696854315e-06,
      "loss": 0.40471563339233396,
      "memory(GiB)": 72.72,
      "step": 18395,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.7162578117712899,
      "grad_norm": 4.116353988647461,
      "learning_rate": 7.827597835722069e-06,
      "loss": 0.4280956268310547,
      "memory(GiB)": 72.72,
      "step": 18400,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.7167241861766627,
      "grad_norm": 4.139169216156006,
      "learning_rate": 7.826325716975414e-06,
      "loss": 0.40311565399169924,
      "memory(GiB)": 72.72,
      "step": 18405,
      "token_acc": 0.5277777777777778,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 1.7171905605820352,
      "grad_norm": 5.0860724449157715,
      "learning_rate": 7.825053329312575e-06,
      "loss": 0.4070094108581543,
      "memory(GiB)": 72.72,
      "step": 18410,
      "train_speed(iter/s)": 0.251971
    },
    {
      "epoch": 1.7176569349874078,
      "grad_norm": 35.924537658691406,
      "learning_rate": 7.823780672854614e-06,
      "loss": 0.3977142572402954,
      "memory(GiB)": 72.72,
      "step": 18415,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 1.7181233093927806,
      "grad_norm": 5.301132678985596,
      "learning_rate": 7.822507747722621e-06,
      "loss": 0.44783897399902345,
      "memory(GiB)": 72.72,
      "step": 18420,
      "token_acc": 0.7575757575757576,
      "train_speed(iter/s)": 0.251972
    },
    {
      "epoch": 1.7185896837981531,
      "grad_norm": 3.6043074131011963,
      "learning_rate": 7.82123455403771e-06,
      "loss": 0.4155452728271484,
      "memory(GiB)": 72.72,
      "step": 18425,
      "token_acc": 0.4107142857142857,
      "train_speed(iter/s)": 0.251976
    },
    {
      "epoch": 1.7190560582035257,
      "grad_norm": 4.705009937286377,
      "learning_rate": 7.819961091921025e-06,
      "loss": 0.46916952133178713,
      "memory(GiB)": 72.72,
      "step": 18430,
      "train_speed(iter/s)": 0.251977
    },
    {
      "epoch": 1.7195224326088985,
      "grad_norm": 3.956141471862793,
      "learning_rate": 7.818687361493726e-06,
      "loss": 0.42648916244506835,
      "memory(GiB)": 72.72,
      "step": 18435,
      "token_acc": 0.5061728395061729,
      "train_speed(iter/s)": 0.251977
    },
    {
      "epoch": 1.719988807014271,
      "grad_norm": 3.4513168334960938,
      "learning_rate": 7.81741336287701e-06,
      "loss": 0.44075326919555663,
      "memory(GiB)": 72.72,
      "step": 18440,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.251982
    },
    {
      "epoch": 1.7204551814196436,
      "grad_norm": 10.795075416564941,
      "learning_rate": 7.81613909619209e-06,
      "loss": 0.39964752197265624,
      "memory(GiB)": 72.72,
      "step": 18445,
      "train_speed(iter/s)": 0.251981
    },
    {
      "epoch": 1.7209215558250164,
      "grad_norm": 4.344003200531006,
      "learning_rate": 7.814864561560212e-06,
      "loss": 0.476072883605957,
      "memory(GiB)": 72.72,
      "step": 18450,
      "token_acc": 0.48863636363636365,
      "train_speed(iter/s)": 0.251985
    },
    {
      "epoch": 1.721387930230389,
      "grad_norm": 8.563632011413574,
      "learning_rate": 7.81358975910264e-06,
      "loss": 0.3937511920928955,
      "memory(GiB)": 72.72,
      "step": 18455,
      "token_acc": 0.6086956521739131,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.7218543046357615,
      "grad_norm": 3.3288068771362305,
      "learning_rate": 7.812314688940671e-06,
      "loss": 0.4340837478637695,
      "memory(GiB)": 72.72,
      "step": 18460,
      "train_speed(iter/s)": 0.251995
    },
    {
      "epoch": 1.7223206790411343,
      "grad_norm": 2.6832706928253174,
      "learning_rate": 7.811039351195623e-06,
      "loss": 0.41513500213623045,
      "memory(GiB)": 72.72,
      "step": 18465,
      "token_acc": 0.732484076433121,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.7227870534465068,
      "grad_norm": 3.325380802154541,
      "learning_rate": 7.80976374598884e-06,
      "loss": 0.4202157974243164,
      "memory(GiB)": 72.72,
      "step": 18470,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.251994
    },
    {
      "epoch": 1.7232534278518794,
      "grad_norm": 4.3377275466918945,
      "learning_rate": 7.808487873441694e-06,
      "loss": 0.44386930465698243,
      "memory(GiB)": 72.72,
      "step": 18475,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.7237198022572522,
      "grad_norm": 2.941636323928833,
      "learning_rate": 7.807211733675577e-06,
      "loss": 0.43070297241210936,
      "memory(GiB)": 72.72,
      "step": 18480,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.7241861766626247,
      "grad_norm": 5.500768184661865,
      "learning_rate": 7.805935326811913e-06,
      "loss": 0.4608583927154541,
      "memory(GiB)": 72.72,
      "step": 18485,
      "token_acc": 0.49523809523809526,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.7246525510679973,
      "grad_norm": 5.038103103637695,
      "learning_rate": 7.804658652972146e-06,
      "loss": 0.42867298126220704,
      "memory(GiB)": 72.72,
      "step": 18490,
      "train_speed(iter/s)": 0.252007
    },
    {
      "epoch": 1.72511892547337,
      "grad_norm": 3.3146965503692627,
      "learning_rate": 7.803381712277747e-06,
      "loss": 0.3893864870071411,
      "memory(GiB)": 72.72,
      "step": 18495,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.7255852998787427,
      "grad_norm": 3.9659483432769775,
      "learning_rate": 7.802104504850214e-06,
      "loss": 0.4482542037963867,
      "memory(GiB)": 72.72,
      "step": 18500,
      "token_acc": 0.9444444444444444,
      "train_speed(iter/s)": 0.25201
    },
    {
      "epoch": 1.7260516742841152,
      "grad_norm": 5.632133960723877,
      "learning_rate": 7.80082703081107e-06,
      "loss": 0.4065141201019287,
      "memory(GiB)": 72.72,
      "step": 18505,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.726518048689488,
      "grad_norm": 4.663681983947754,
      "learning_rate": 7.799549290281863e-06,
      "loss": 0.42635378837585447,
      "memory(GiB)": 72.72,
      "step": 18510,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.7269844230948606,
      "grad_norm": 4.4786577224731445,
      "learning_rate": 7.798271283384163e-06,
      "loss": 0.4081913471221924,
      "memory(GiB)": 72.72,
      "step": 18515,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.7274507975002331,
      "grad_norm": 9.320352554321289,
      "learning_rate": 7.796993010239572e-06,
      "loss": 0.37668790817260744,
      "memory(GiB)": 72.72,
      "step": 18520,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.727917171905606,
      "grad_norm": 5.168875694274902,
      "learning_rate": 7.795714470969715e-06,
      "loss": 0.4286326885223389,
      "memory(GiB)": 72.72,
      "step": 18525,
      "token_acc": 0.7301587301587301,
      "train_speed(iter/s)": 0.252015
    },
    {
      "epoch": 1.7283835463109785,
      "grad_norm": 2.901040554046631,
      "learning_rate": 7.794435665696234e-06,
      "loss": 0.41875786781311036,
      "memory(GiB)": 72.72,
      "step": 18530,
      "token_acc": 0.4925373134328358,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.728849920716351,
      "grad_norm": 2.4755446910858154,
      "learning_rate": 7.79315659454081e-06,
      "loss": 0.3900606155395508,
      "memory(GiB)": 72.72,
      "step": 18535,
      "train_speed(iter/s)": 0.252018
    },
    {
      "epoch": 1.7293162951217238,
      "grad_norm": 4.428140163421631,
      "learning_rate": 7.791877257625142e-06,
      "loss": 0.3972789287567139,
      "memory(GiB)": 72.72,
      "step": 18540,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.7297826695270964,
      "grad_norm": 3.0315873622894287,
      "learning_rate": 7.790597655070951e-06,
      "loss": 0.4512491226196289,
      "memory(GiB)": 72.72,
      "step": 18545,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.252007
    },
    {
      "epoch": 1.730249043932469,
      "grad_norm": 3.0159058570861816,
      "learning_rate": 7.78931778699999e-06,
      "loss": 0.447922945022583,
      "memory(GiB)": 72.72,
      "step": 18550,
      "token_acc": 0.49056603773584906,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.7307154183378417,
      "grad_norm": 4.937812328338623,
      "learning_rate": 7.788037653534036e-06,
      "loss": 0.43951191902160647,
      "memory(GiB)": 72.72,
      "step": 18555,
      "token_acc": 0.6379310344827587,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.7311817927432143,
      "grad_norm": 6.391448020935059,
      "learning_rate": 7.786757254794887e-06,
      "loss": 0.4326587677001953,
      "memory(GiB)": 72.72,
      "step": 18560,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.7316481671485868,
      "grad_norm": 2.8418924808502197,
      "learning_rate": 7.785476590904371e-06,
      "loss": 0.42194271087646484,
      "memory(GiB)": 72.72,
      "step": 18565,
      "token_acc": 0.4533333333333333,
      "train_speed(iter/s)": 0.252019
    },
    {
      "epoch": 1.7321145415539596,
      "grad_norm": 15.965030670166016,
      "learning_rate": 7.784195661984336e-06,
      "loss": 0.40270209312438965,
      "memory(GiB)": 72.72,
      "step": 18570,
      "token_acc": 0.8760330578512396,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.7325809159593322,
      "grad_norm": 4.697840690612793,
      "learning_rate": 7.782914468156663e-06,
      "loss": 0.4621294021606445,
      "memory(GiB)": 72.72,
      "step": 18575,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.7330472903647047,
      "grad_norm": 3.939082384109497,
      "learning_rate": 7.78163300954325e-06,
      "loss": 0.40176639556884763,
      "memory(GiB)": 72.72,
      "step": 18580,
      "train_speed(iter/s)": 0.252016
    },
    {
      "epoch": 1.7335136647700775,
      "grad_norm": 5.661137104034424,
      "learning_rate": 7.780351286266027e-06,
      "loss": 0.4329483985900879,
      "memory(GiB)": 72.72,
      "step": 18585,
      "token_acc": 0.9347826086956522,
      "train_speed(iter/s)": 0.25194
    },
    {
      "epoch": 1.73398003917545,
      "grad_norm": 3.2580034732818604,
      "learning_rate": 7.779069298446941e-06,
      "loss": 0.40312914848327636,
      "memory(GiB)": 72.72,
      "step": 18590,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.251932
    },
    {
      "epoch": 1.7344464135808226,
      "grad_norm": 4.380742073059082,
      "learning_rate": 7.777787046207975e-06,
      "loss": 0.4194390296936035,
      "memory(GiB)": 72.72,
      "step": 18595,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.7349127879861954,
      "grad_norm": 3.857943058013916,
      "learning_rate": 7.776504529671127e-06,
      "loss": 0.4276262283325195,
      "memory(GiB)": 72.72,
      "step": 18600,
      "token_acc": 0.5470085470085471,
      "train_speed(iter/s)": 0.251935
    },
    {
      "epoch": 1.735379162391568,
      "grad_norm": 3.922996759414673,
      "learning_rate": 7.775221748958428e-06,
      "loss": 0.4282264709472656,
      "memory(GiB)": 72.72,
      "step": 18605,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.7358455367969405,
      "grad_norm": 2.988746166229248,
      "learning_rate": 7.773938704191928e-06,
      "loss": 0.44860067367553713,
      "memory(GiB)": 72.72,
      "step": 18610,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.251935
    },
    {
      "epoch": 1.7363119112023133,
      "grad_norm": 3.376756191253662,
      "learning_rate": 7.772655395493706e-06,
      "loss": 0.406345272064209,
      "memory(GiB)": 72.72,
      "step": 18615,
      "train_speed(iter/s)": 0.251936
    },
    {
      "epoch": 1.7367782856076859,
      "grad_norm": 3.302766799926758,
      "learning_rate": 7.771371822985862e-06,
      "loss": 0.41439080238342285,
      "memory(GiB)": 72.72,
      "step": 18620,
      "token_acc": 0.9215686274509803,
      "train_speed(iter/s)": 0.251939
    },
    {
      "epoch": 1.7372446600130584,
      "grad_norm": 5.2673139572143555,
      "learning_rate": 7.77008798679053e-06,
      "loss": 0.3879827976226807,
      "memory(GiB)": 72.72,
      "step": 18625,
      "token_acc": 0.45714285714285713,
      "train_speed(iter/s)": 0.251936
    },
    {
      "epoch": 1.7377110344184312,
      "grad_norm": 4.574873447418213,
      "learning_rate": 7.768803887029859e-06,
      "loss": 0.4108715057373047,
      "memory(GiB)": 72.72,
      "step": 18630,
      "token_acc": 0.912621359223301,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.7381774088238038,
      "grad_norm": 3.0910990238189697,
      "learning_rate": 7.767519523826025e-06,
      "loss": 0.4128929615020752,
      "memory(GiB)": 72.72,
      "step": 18635,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251933
    },
    {
      "epoch": 1.7386437832291763,
      "grad_norm": 3.059595823287964,
      "learning_rate": 7.766234897301237e-06,
      "loss": 0.4112729549407959,
      "memory(GiB)": 72.72,
      "step": 18640,
      "train_speed(iter/s)": 0.251933
    },
    {
      "epoch": 1.7391101576345491,
      "grad_norm": 3.12860107421875,
      "learning_rate": 7.764950007577719e-06,
      "loss": 0.37510392665863035,
      "memory(GiB)": 72.72,
      "step": 18645,
      "train_speed(iter/s)": 0.251933
    },
    {
      "epoch": 1.7395765320399217,
      "grad_norm": 2.9953842163085938,
      "learning_rate": 7.763664854777723e-06,
      "loss": 0.3812148332595825,
      "memory(GiB)": 72.72,
      "step": 18650,
      "train_speed(iter/s)": 0.251932
    },
    {
      "epoch": 1.7400429064452942,
      "grad_norm": 2.765554428100586,
      "learning_rate": 7.762379439023532e-06,
      "loss": 0.3773628234863281,
      "memory(GiB)": 72.72,
      "step": 18655,
      "token_acc": 0.7941176470588235,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.740509280850667,
      "grad_norm": 3.3050999641418457,
      "learning_rate": 7.761093760437449e-06,
      "loss": 0.4018394470214844,
      "memory(GiB)": 72.72,
      "step": 18660,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.7409756552560396,
      "grad_norm": 5.972390651702881,
      "learning_rate": 7.759807819141798e-06,
      "loss": 0.4646879196166992,
      "memory(GiB)": 72.72,
      "step": 18665,
      "token_acc": 0.5206611570247934,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.7414420296614121,
      "grad_norm": 3.862156867980957,
      "learning_rate": 7.758521615258935e-06,
      "loss": 0.4332114219665527,
      "memory(GiB)": 72.72,
      "step": 18670,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.741908404066785,
      "grad_norm": 8.305011749267578,
      "learning_rate": 7.75723514891124e-06,
      "loss": 0.43224639892578126,
      "memory(GiB)": 72.72,
      "step": 18675,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.7423747784721575,
      "grad_norm": 4.047956466674805,
      "learning_rate": 7.755948420221112e-06,
      "loss": 0.4574784278869629,
      "memory(GiB)": 72.72,
      "step": 18680,
      "token_acc": 0.4262295081967213,
      "train_speed(iter/s)": 0.251933
    },
    {
      "epoch": 1.74284115287753,
      "grad_norm": 7.835611343383789,
      "learning_rate": 7.754661429310982e-06,
      "loss": 0.4540858268737793,
      "memory(GiB)": 72.72,
      "step": 18685,
      "train_speed(iter/s)": 0.251936
    },
    {
      "epoch": 1.7433075272829028,
      "grad_norm": 3.906486749649048,
      "learning_rate": 7.753374176303303e-06,
      "loss": 0.4226393699645996,
      "memory(GiB)": 72.72,
      "step": 18690,
      "token_acc": 0.5348837209302325,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.7437739016882754,
      "grad_norm": 4.331478595733643,
      "learning_rate": 7.752086661320555e-06,
      "loss": 0.43745875358581543,
      "memory(GiB)": 72.72,
      "step": 18695,
      "train_speed(iter/s)": 0.251939
    },
    {
      "epoch": 1.744240276093648,
      "grad_norm": 3.995652675628662,
      "learning_rate": 7.750798884485237e-06,
      "loss": 0.42560997009277346,
      "memory(GiB)": 72.72,
      "step": 18700,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.251937
    },
    {
      "epoch": 1.7447066504990207,
      "grad_norm": 4.364152908325195,
      "learning_rate": 7.74951084591988e-06,
      "loss": 0.4197849273681641,
      "memory(GiB)": 72.72,
      "step": 18705,
      "train_speed(iter/s)": 0.251938
    },
    {
      "epoch": 1.7451730249043933,
      "grad_norm": 4.898680686950684,
      "learning_rate": 7.748222545747036e-06,
      "loss": 0.4432417392730713,
      "memory(GiB)": 72.72,
      "step": 18710,
      "train_speed(iter/s)": 0.251938
    },
    {
      "epoch": 1.7456393993097659,
      "grad_norm": 4.622725486755371,
      "learning_rate": 7.746933984089284e-06,
      "loss": 0.4996318817138672,
      "memory(GiB)": 72.72,
      "step": 18715,
      "token_acc": 0.5666666666666667,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.7461057737151386,
      "grad_norm": 3.408292770385742,
      "learning_rate": 7.745645161069224e-06,
      "loss": 0.41741123199462893,
      "memory(GiB)": 72.72,
      "step": 18720,
      "token_acc": 0.5247524752475248,
      "train_speed(iter/s)": 0.25194
    },
    {
      "epoch": 1.746572148120511,
      "grad_norm": 4.012350559234619,
      "learning_rate": 7.744356076809484e-06,
      "loss": 0.4549283981323242,
      "memory(GiB)": 72.72,
      "step": 18725,
      "token_acc": 0.4642857142857143,
      "train_speed(iter/s)": 0.251939
    },
    {
      "epoch": 1.7470385225258838,
      "grad_norm": 4.188498497009277,
      "learning_rate": 7.74306673143272e-06,
      "loss": 0.38918113708496094,
      "memory(GiB)": 72.72,
      "step": 18730,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.7475048969312565,
      "grad_norm": 5.3285040855407715,
      "learning_rate": 7.741777125061607e-06,
      "loss": 0.44735050201416016,
      "memory(GiB)": 72.72,
      "step": 18735,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.7479712713366289,
      "grad_norm": 4.344521999359131,
      "learning_rate": 7.740487257818844e-06,
      "loss": 0.3831333637237549,
      "memory(GiB)": 72.72,
      "step": 18740,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.7484376457420017,
      "grad_norm": 4.617924690246582,
      "learning_rate": 7.739197129827163e-06,
      "loss": 0.43594183921813967,
      "memory(GiB)": 72.72,
      "step": 18745,
      "token_acc": 0.40350877192982454,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.7489040201473744,
      "grad_norm": 3.6815404891967773,
      "learning_rate": 7.737906741209314e-06,
      "loss": 0.4110411643981934,
      "memory(GiB)": 72.72,
      "step": 18750,
      "token_acc": 0.38461538461538464,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.7493703945527468,
      "grad_norm": 4.729268550872803,
      "learning_rate": 7.73661609208807e-06,
      "loss": 0.4050872802734375,
      "memory(GiB)": 72.72,
      "step": 18755,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.7498367689581196,
      "grad_norm": 3.294506072998047,
      "learning_rate": 7.735325182586238e-06,
      "loss": 0.44737606048583983,
      "memory(GiB)": 72.72,
      "step": 18760,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.251947
    },
    {
      "epoch": 1.7503031433634924,
      "grad_norm": 4.0518293380737305,
      "learning_rate": 7.73403401282664e-06,
      "loss": 0.43132381439208983,
      "memory(GiB)": 72.72,
      "step": 18765,
      "train_speed(iter/s)": 0.251947
    },
    {
      "epoch": 1.7507695177688647,
      "grad_norm": 2.604903221130371,
      "learning_rate": 7.732742582932128e-06,
      "loss": 0.41071743965148927,
      "memory(GiB)": 72.72,
      "step": 18770,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.7512358921742375,
      "grad_norm": 3.439671039581299,
      "learning_rate": 7.731450893025578e-06,
      "loss": 0.42746829986572266,
      "memory(GiB)": 72.72,
      "step": 18775,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.7517022665796103,
      "grad_norm": 2.9683032035827637,
      "learning_rate": 7.73015894322989e-06,
      "loss": 0.4124476909637451,
      "memory(GiB)": 72.72,
      "step": 18780,
      "train_speed(iter/s)": 0.251945
    },
    {
      "epoch": 1.7521686409849826,
      "grad_norm": 3.1376423835754395,
      "learning_rate": 7.728866733667987e-06,
      "loss": 0.4020101547241211,
      "memory(GiB)": 72.72,
      "step": 18785,
      "token_acc": 0.7734375,
      "train_speed(iter/s)": 0.25195
    },
    {
      "epoch": 1.7526350153903554,
      "grad_norm": 2.480947732925415,
      "learning_rate": 7.727574264462825e-06,
      "loss": 0.4137004852294922,
      "memory(GiB)": 72.72,
      "step": 18790,
      "train_speed(iter/s)": 0.251952
    },
    {
      "epoch": 1.7531013897957282,
      "grad_norm": 2.3595216274261475,
      "learning_rate": 7.72628153573737e-06,
      "loss": 0.3912350654602051,
      "memory(GiB)": 72.72,
      "step": 18795,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.251954
    },
    {
      "epoch": 1.7535677642011005,
      "grad_norm": 8.789573669433594,
      "learning_rate": 7.724988547614629e-06,
      "loss": 0.4266839027404785,
      "memory(GiB)": 72.72,
      "step": 18800,
      "train_speed(iter/s)": 0.251951
    },
    {
      "epoch": 1.7540341386064733,
      "grad_norm": 4.2814836502075195,
      "learning_rate": 7.72369530021762e-06,
      "loss": 0.44057412147521974,
      "memory(GiB)": 72.72,
      "step": 18805,
      "train_speed(iter/s)": 0.251955
    },
    {
      "epoch": 1.754500513011846,
      "grad_norm": 3.4384841918945312,
      "learning_rate": 7.722401793669394e-06,
      "loss": 0.4265897750854492,
      "memory(GiB)": 72.72,
      "step": 18810,
      "train_speed(iter/s)": 0.251955
    },
    {
      "epoch": 1.7549668874172184,
      "grad_norm": 2.9731712341308594,
      "learning_rate": 7.721108028093025e-06,
      "loss": 0.4083893299102783,
      "memory(GiB)": 72.72,
      "step": 18815,
      "token_acc": 0.3888888888888889,
      "train_speed(iter/s)": 0.25196
    },
    {
      "epoch": 1.7554332618225912,
      "grad_norm": 3.5284171104431152,
      "learning_rate": 7.719814003611608e-06,
      "loss": 0.4052455425262451,
      "memory(GiB)": 72.72,
      "step": 18820,
      "train_speed(iter/s)": 0.251958
    },
    {
      "epoch": 1.755899636227964,
      "grad_norm": 4.023275375366211,
      "learning_rate": 7.718519720348268e-06,
      "loss": 0.3775469779968262,
      "memory(GiB)": 72.72,
      "step": 18825,
      "train_speed(iter/s)": 0.251961
    },
    {
      "epoch": 1.7563660106333363,
      "grad_norm": 3.1869053840637207,
      "learning_rate": 7.717225178426152e-06,
      "loss": 0.40447211265563965,
      "memory(GiB)": 72.72,
      "step": 18830,
      "token_acc": 0.6031746031746031,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.756832385038709,
      "grad_norm": 3.4722392559051514,
      "learning_rate": 7.71593037796843e-06,
      "loss": 0.4055314064025879,
      "memory(GiB)": 72.72,
      "step": 18835,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.7572987594440819,
      "grad_norm": 3.71018648147583,
      "learning_rate": 7.714635319098299e-06,
      "loss": 0.40124192237854006,
      "memory(GiB)": 72.72,
      "step": 18840,
      "train_speed(iter/s)": 0.251963
    },
    {
      "epoch": 1.7577651338494542,
      "grad_norm": 3.1109023094177246,
      "learning_rate": 7.71334000193898e-06,
      "loss": 0.4103063106536865,
      "memory(GiB)": 72.72,
      "step": 18845,
      "train_speed(iter/s)": 0.251968
    },
    {
      "epoch": 1.758231508254827,
      "grad_norm": 3.144702196121216,
      "learning_rate": 7.712044426613718e-06,
      "loss": 0.4348135471343994,
      "memory(GiB)": 72.72,
      "step": 18850,
      "train_speed(iter/s)": 0.251968
    },
    {
      "epoch": 1.7586978826601998,
      "grad_norm": 2.6989409923553467,
      "learning_rate": 7.710748593245785e-06,
      "loss": 0.4036229133605957,
      "memory(GiB)": 72.72,
      "step": 18855,
      "train_speed(iter/s)": 0.251965
    },
    {
      "epoch": 1.7591642570655721,
      "grad_norm": 10.119950294494629,
      "learning_rate": 7.709452501958472e-06,
      "loss": 0.4288051605224609,
      "memory(GiB)": 72.72,
      "step": 18860,
      "token_acc": 0.41818181818181815,
      "train_speed(iter/s)": 0.251971
    },
    {
      "epoch": 1.759630631470945,
      "grad_norm": 3.5586509704589844,
      "learning_rate": 7.708156152875101e-06,
      "loss": 0.47261571884155273,
      "memory(GiB)": 72.72,
      "step": 18865,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.251974
    },
    {
      "epoch": 1.7600970058763175,
      "grad_norm": 3.9845590591430664,
      "learning_rate": 7.706859546119016e-06,
      "loss": 0.39850425720214844,
      "memory(GiB)": 72.72,
      "step": 18870,
      "train_speed(iter/s)": 0.251976
    },
    {
      "epoch": 1.76056338028169,
      "grad_norm": 6.888428688049316,
      "learning_rate": 7.705562681813583e-06,
      "loss": 0.46378750801086427,
      "memory(GiB)": 72.72,
      "step": 18875,
      "token_acc": 0.4909090909090909,
      "train_speed(iter/s)": 0.251976
    },
    {
      "epoch": 1.7610297546870628,
      "grad_norm": 2.92825984954834,
      "learning_rate": 7.704265560082196e-06,
      "loss": 0.40645513534545896,
      "memory(GiB)": 72.72,
      "step": 18880,
      "token_acc": 0.49473684210526314,
      "train_speed(iter/s)": 0.25198
    },
    {
      "epoch": 1.7614961290924354,
      "grad_norm": 3.7268548011779785,
      "learning_rate": 7.702968181048271e-06,
      "loss": 0.4054893493652344,
      "memory(GiB)": 72.72,
      "step": 18885,
      "token_acc": 0.5135135135135135,
      "train_speed(iter/s)": 0.25198
    },
    {
      "epoch": 1.761962503497808,
      "grad_norm": 4.680159091949463,
      "learning_rate": 7.701670544835248e-06,
      "loss": 0.4265553951263428,
      "memory(GiB)": 72.72,
      "step": 18890,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 1.7624288779031807,
      "grad_norm": 5.406089782714844,
      "learning_rate": 7.700372651566598e-06,
      "loss": 0.42642946243286134,
      "memory(GiB)": 72.72,
      "step": 18895,
      "token_acc": 0.8828125,
      "train_speed(iter/s)": 0.251979
    },
    {
      "epoch": 1.7628952523085533,
      "grad_norm": 4.639497756958008,
      "learning_rate": 7.699074501365811e-06,
      "loss": 0.3988151550292969,
      "memory(GiB)": 72.72,
      "step": 18900,
      "train_speed(iter/s)": 0.251977
    },
    {
      "epoch": 1.7633616267139258,
      "grad_norm": 5.5789666175842285,
      "learning_rate": 7.697776094356398e-06,
      "loss": 0.4002796173095703,
      "memory(GiB)": 72.72,
      "step": 18905,
      "token_acc": 0.9069767441860465,
      "train_speed(iter/s)": 0.251977
    },
    {
      "epoch": 1.7638280011192986,
      "grad_norm": 3.024101734161377,
      "learning_rate": 7.6964774306619e-06,
      "loss": 0.47183752059936523,
      "memory(GiB)": 72.72,
      "step": 18910,
      "token_acc": 0.47692307692307695,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 1.7642943755246712,
      "grad_norm": 2.8468101024627686,
      "learning_rate": 7.695178510405881e-06,
      "loss": 0.4049258232116699,
      "memory(GiB)": 72.72,
      "step": 18915,
      "token_acc": 0.9120879120879121,
      "train_speed(iter/s)": 0.251979
    },
    {
      "epoch": 1.7647607499300437,
      "grad_norm": 4.3163604736328125,
      "learning_rate": 7.693879333711928e-06,
      "loss": 0.40358381271362304,
      "memory(GiB)": 72.72,
      "step": 18920,
      "train_speed(iter/s)": 0.251985
    },
    {
      "epoch": 1.7652271243354165,
      "grad_norm": 4.091021537780762,
      "learning_rate": 7.692579900703656e-06,
      "loss": 0.4298126220703125,
      "memory(GiB)": 72.72,
      "step": 18925,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.765693498740789,
      "grad_norm": 9.801507949829102,
      "learning_rate": 7.691280211504704e-06,
      "loss": 0.43193483352661133,
      "memory(GiB)": 72.72,
      "step": 18930,
      "train_speed(iter/s)": 0.251988
    },
    {
      "epoch": 1.7661598731461616,
      "grad_norm": 5.576137542724609,
      "learning_rate": 7.689980266238728e-06,
      "loss": 0.45983014106750486,
      "memory(GiB)": 72.72,
      "step": 18935,
      "train_speed(iter/s)": 0.251986
    },
    {
      "epoch": 1.7666262475515344,
      "grad_norm": 11.240663528442383,
      "learning_rate": 7.688680065029415e-06,
      "loss": 0.4006062984466553,
      "memory(GiB)": 72.72,
      "step": 18940,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.767092621956907,
      "grad_norm": 16.81865119934082,
      "learning_rate": 7.687379608000478e-06,
      "loss": 0.411298131942749,
      "memory(GiB)": 72.72,
      "step": 18945,
      "train_speed(iter/s)": 0.251986
    },
    {
      "epoch": 1.7675589963622795,
      "grad_norm": 5.038753032684326,
      "learning_rate": 7.68607889527565e-06,
      "loss": 0.4038515090942383,
      "memory(GiB)": 72.72,
      "step": 18950,
      "token_acc": 0.8470588235294118,
      "train_speed(iter/s)": 0.251981
    },
    {
      "epoch": 1.7680253707676523,
      "grad_norm": 8.936391830444336,
      "learning_rate": 7.68477792697869e-06,
      "loss": 0.3932830572128296,
      "memory(GiB)": 72.72,
      "step": 18955,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.7684917451730249,
      "grad_norm": 5.180032730102539,
      "learning_rate": 7.683476703233381e-06,
      "loss": 0.42276759147644044,
      "memory(GiB)": 72.72,
      "step": 18960,
      "token_acc": 0.9534883720930233,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.7689581195783974,
      "grad_norm": 4.5407915115356445,
      "learning_rate": 7.682175224163531e-06,
      "loss": 0.39300625324249266,
      "memory(GiB)": 72.72,
      "step": 18965,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.7694244939837702,
      "grad_norm": 6.348669528961182,
      "learning_rate": 7.680873489892971e-06,
      "loss": 0.42441654205322266,
      "memory(GiB)": 72.72,
      "step": 18970,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.7698908683891428,
      "grad_norm": 3.5674679279327393,
      "learning_rate": 7.679571500545556e-06,
      "loss": 0.42547998428344724,
      "memory(GiB)": 72.72,
      "step": 18975,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.7703572427945153,
      "grad_norm": 4.058348655700684,
      "learning_rate": 7.678269256245167e-06,
      "loss": 0.42680788040161133,
      "memory(GiB)": 72.72,
      "step": 18980,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.7708236171998881,
      "grad_norm": 3.774651527404785,
      "learning_rate": 7.676966757115709e-06,
      "loss": 0.41443710327148436,
      "memory(GiB)": 72.72,
      "step": 18985,
      "train_speed(iter/s)": 0.25199
    },
    {
      "epoch": 1.7712899916052607,
      "grad_norm": 3.280575752258301,
      "learning_rate": 7.67566400328111e-06,
      "loss": 0.4588616371154785,
      "memory(GiB)": 72.72,
      "step": 18990,
      "token_acc": 0.9069767441860465,
      "train_speed(iter/s)": 0.251987
    },
    {
      "epoch": 1.7717563660106332,
      "grad_norm": 3.497403144836426,
      "learning_rate": 7.674360994865326e-06,
      "loss": 0.4067673683166504,
      "memory(GiB)": 72.72,
      "step": 18995,
      "token_acc": 0.944954128440367,
      "train_speed(iter/s)": 0.251988
    },
    {
      "epoch": 1.772222740416006,
      "grad_norm": 3.905956983566284,
      "learning_rate": 7.67305773199233e-06,
      "loss": 0.3971033334732056,
      "memory(GiB)": 72.72,
      "step": 19000,
      "train_speed(iter/s)": 0.251988
    },
    {
      "epoch": 1.7726891148213786,
      "grad_norm": 3.9401087760925293,
      "learning_rate": 7.671754214786126e-06,
      "loss": 0.3759465217590332,
      "memory(GiB)": 72.72,
      "step": 19005,
      "train_speed(iter/s)": 0.25199
    },
    {
      "epoch": 1.7731554892267511,
      "grad_norm": 7.741378307342529,
      "learning_rate": 7.67045044337074e-06,
      "loss": 0.44528989791870116,
      "memory(GiB)": 72.72,
      "step": 19010,
      "train_speed(iter/s)": 0.251993
    },
    {
      "epoch": 1.773621863632124,
      "grad_norm": 4.251987934112549,
      "learning_rate": 7.66914641787022e-06,
      "loss": 0.3882130146026611,
      "memory(GiB)": 72.72,
      "step": 19015,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.7740882380374965,
      "grad_norm": 5.077249050140381,
      "learning_rate": 7.66784213840864e-06,
      "loss": 0.42376484870910647,
      "memory(GiB)": 72.72,
      "step": 19020,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.774554612442869,
      "grad_norm": 2.992295980453491,
      "learning_rate": 7.6665376051101e-06,
      "loss": 0.44243412017822265,
      "memory(GiB)": 72.72,
      "step": 19025,
      "token_acc": 0.4462809917355372,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.7750209868482418,
      "grad_norm": 2.6073532104492188,
      "learning_rate": 7.665232818098722e-06,
      "loss": 0.3965855598449707,
      "memory(GiB)": 72.72,
      "step": 19030,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.7754873612536144,
      "grad_norm": 3.4626963138580322,
      "learning_rate": 7.663927777498652e-06,
      "loss": 0.3962447166442871,
      "memory(GiB)": 72.72,
      "step": 19035,
      "token_acc": 0.6146788990825688,
      "train_speed(iter/s)": 0.252001
    },
    {
      "epoch": 1.775953735658987,
      "grad_norm": 3.920370578765869,
      "learning_rate": 7.662622483434058e-06,
      "loss": 0.42498130798339845,
      "memory(GiB)": 72.72,
      "step": 19040,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.7764201100643597,
      "grad_norm": 5.178534984588623,
      "learning_rate": 7.66131693602914e-06,
      "loss": 0.46353974342346194,
      "memory(GiB)": 72.72,
      "step": 19045,
      "token_acc": 0.7181818181818181,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.7768864844697323,
      "grad_norm": 3.1714651584625244,
      "learning_rate": 7.660011135408111e-06,
      "loss": 0.4071680545806885,
      "memory(GiB)": 72.72,
      "step": 19050,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.7773528588751049,
      "grad_norm": 3.6322555541992188,
      "learning_rate": 7.658705081695219e-06,
      "loss": 0.4104900360107422,
      "memory(GiB)": 72.72,
      "step": 19055,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.7778192332804776,
      "grad_norm": 4.453840255737305,
      "learning_rate": 7.657398775014728e-06,
      "loss": 0.4266364097595215,
      "memory(GiB)": 72.72,
      "step": 19060,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.25201
    },
    {
      "epoch": 1.7782856076858502,
      "grad_norm": 4.124779224395752,
      "learning_rate": 7.65609221549093e-06,
      "loss": 0.4191250801086426,
      "memory(GiB)": 72.72,
      "step": 19065,
      "token_acc": 0.6382978723404256,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.7787519820912228,
      "grad_norm": 2.352759599685669,
      "learning_rate": 7.65478540324814e-06,
      "loss": 0.3839243412017822,
      "memory(GiB)": 72.72,
      "step": 19070,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.7792183564965955,
      "grad_norm": 2.0545527935028076,
      "learning_rate": 7.653478338410696e-06,
      "loss": 0.4224492073059082,
      "memory(GiB)": 72.72,
      "step": 19075,
      "token_acc": 0.8673469387755102,
      "train_speed(iter/s)": 0.252017
    },
    {
      "epoch": 1.779684730901968,
      "grad_norm": 3.257145881652832,
      "learning_rate": 7.652171021102965e-06,
      "loss": 0.40140466690063475,
      "memory(GiB)": 72.72,
      "step": 19080,
      "train_speed(iter/s)": 0.252021
    },
    {
      "epoch": 1.7801511053073407,
      "grad_norm": 4.1319580078125,
      "learning_rate": 7.65086345144933e-06,
      "loss": 0.3960277795791626,
      "memory(GiB)": 72.72,
      "step": 19085,
      "token_acc": 0.5409836065573771,
      "train_speed(iter/s)": 0.252025
    },
    {
      "epoch": 1.7806174797127134,
      "grad_norm": 3.9057068824768066,
      "learning_rate": 7.649555629574203e-06,
      "loss": 0.4559739112854004,
      "memory(GiB)": 72.72,
      "step": 19090,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252023
    },
    {
      "epoch": 1.781083854118086,
      "grad_norm": 5.708846092224121,
      "learning_rate": 7.64824755560202e-06,
      "loss": 0.41053075790405275,
      "memory(GiB)": 72.72,
      "step": 19095,
      "train_speed(iter/s)": 0.252022
    },
    {
      "epoch": 1.7815502285234586,
      "grad_norm": 4.0796589851379395,
      "learning_rate": 7.646939229657242e-06,
      "loss": 0.41143360137939455,
      "memory(GiB)": 72.72,
      "step": 19100,
      "train_speed(iter/s)": 0.25202
    },
    {
      "epoch": 1.7820166029288314,
      "grad_norm": 2.6896145343780518,
      "learning_rate": 7.645630651864351e-06,
      "loss": 0.4012882232666016,
      "memory(GiB)": 72.72,
      "step": 19105,
      "token_acc": 0.6037735849056604,
      "train_speed(iter/s)": 0.252025
    },
    {
      "epoch": 1.782482977334204,
      "grad_norm": 4.294190406799316,
      "learning_rate": 7.64432182234785e-06,
      "loss": 0.3956874370574951,
      "memory(GiB)": 72.72,
      "step": 19110,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.252026
    },
    {
      "epoch": 1.7829493517395765,
      "grad_norm": 6.936224937438965,
      "learning_rate": 7.643012741232277e-06,
      "loss": 0.41927690505981446,
      "memory(GiB)": 72.72,
      "step": 19115,
      "train_speed(iter/s)": 0.252029
    },
    {
      "epoch": 1.7834157261449493,
      "grad_norm": 4.137026786804199,
      "learning_rate": 7.64170340864218e-06,
      "loss": 0.44354982376098634,
      "memory(GiB)": 72.72,
      "step": 19120,
      "train_speed(iter/s)": 0.252032
    },
    {
      "epoch": 1.7838821005503218,
      "grad_norm": 4.597311973571777,
      "learning_rate": 7.640393824702146e-06,
      "loss": 0.42656354904174804,
      "memory(GiB)": 72.72,
      "step": 19125,
      "train_speed(iter/s)": 0.252035
    },
    {
      "epoch": 1.7843484749556944,
      "grad_norm": 3.4007554054260254,
      "learning_rate": 7.63908398953677e-06,
      "loss": 0.38080224990844724,
      "memory(GiB)": 72.72,
      "step": 19130,
      "token_acc": 0.5849056603773585,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.7848148493610672,
      "grad_norm": 5.493332862854004,
      "learning_rate": 7.637773903270684e-06,
      "loss": 0.433594799041748,
      "memory(GiB)": 72.72,
      "step": 19135,
      "token_acc": 0.9479166666666666,
      "train_speed(iter/s)": 0.252038
    },
    {
      "epoch": 1.7852812237664397,
      "grad_norm": 5.3395466804504395,
      "learning_rate": 7.636463566028536e-06,
      "loss": 0.4047402381896973,
      "memory(GiB)": 72.72,
      "step": 19140,
      "train_speed(iter/s)": 0.252045
    },
    {
      "epoch": 1.7857475981718123,
      "grad_norm": 4.490689754486084,
      "learning_rate": 7.635152977935003e-06,
      "loss": 0.42410941123962403,
      "memory(GiB)": 72.72,
      "step": 19145,
      "token_acc": 0.484375,
      "train_speed(iter/s)": 0.252045
    },
    {
      "epoch": 1.786213972577185,
      "grad_norm": 3.945409059524536,
      "learning_rate": 7.63384213911478e-06,
      "loss": 0.41012797355651853,
      "memory(GiB)": 72.72,
      "step": 19150,
      "token_acc": 0.5098039215686274,
      "train_speed(iter/s)": 0.252043
    },
    {
      "epoch": 1.7866803469825576,
      "grad_norm": 3.806652307510376,
      "learning_rate": 7.632531049692594e-06,
      "loss": 0.394534969329834,
      "memory(GiB)": 72.72,
      "step": 19155,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.252039
    },
    {
      "epoch": 1.7871467213879302,
      "grad_norm": 4.995843410491943,
      "learning_rate": 7.631219709793185e-06,
      "loss": 0.39295206069946287,
      "memory(GiB)": 72.72,
      "step": 19160,
      "token_acc": 0.631578947368421,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.787613095793303,
      "grad_norm": 3.8212668895721436,
      "learning_rate": 7.62990811954133e-06,
      "loss": 0.41591711044311525,
      "memory(GiB)": 72.72,
      "step": 19165,
      "train_speed(iter/s)": 0.252041
    },
    {
      "epoch": 1.7880794701986755,
      "grad_norm": 3.661149024963379,
      "learning_rate": 7.628596279061816e-06,
      "loss": 0.44614739418029786,
      "memory(GiB)": 72.72,
      "step": 19170,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.252041
    },
    {
      "epoch": 1.788545844604048,
      "grad_norm": 3.4826927185058594,
      "learning_rate": 7.627284188479464e-06,
      "loss": 0.39566960334777834,
      "memory(GiB)": 72.72,
      "step": 19175,
      "train_speed(iter/s)": 0.25204
    },
    {
      "epoch": 1.7890122190094209,
      "grad_norm": 12.778754234313965,
      "learning_rate": 7.625971847919116e-06,
      "loss": 0.4313328742980957,
      "memory(GiB)": 72.72,
      "step": 19180,
      "train_speed(iter/s)": 0.252043
    },
    {
      "epoch": 1.7894785934147934,
      "grad_norm": 3.485753059387207,
      "learning_rate": 7.624659257505636e-06,
      "loss": 0.42008233070373535,
      "memory(GiB)": 72.72,
      "step": 19185,
      "token_acc": 0.8888888888888888,
      "train_speed(iter/s)": 0.252043
    },
    {
      "epoch": 1.789944967820166,
      "grad_norm": 8.305191040039062,
      "learning_rate": 7.623346417363913e-06,
      "loss": 0.40238151550292967,
      "memory(GiB)": 72.72,
      "step": 19190,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.252048
    },
    {
      "epoch": 1.7904113422255388,
      "grad_norm": 3.2351324558258057,
      "learning_rate": 7.622033327618859e-06,
      "loss": 0.43862075805664064,
      "memory(GiB)": 72.72,
      "step": 19195,
      "token_acc": 0.417910447761194,
      "train_speed(iter/s)": 0.252045
    },
    {
      "epoch": 1.7908777166309113,
      "grad_norm": 3.631829261779785,
      "learning_rate": 7.6207199883954134e-06,
      "loss": 0.4367011547088623,
      "memory(GiB)": 72.72,
      "step": 19200,
      "token_acc": 0.30303030303030304,
      "train_speed(iter/s)": 0.252045
    },
    {
      "epoch": 1.791344091036284,
      "grad_norm": 4.596127986907959,
      "learning_rate": 7.619406399818533e-06,
      "loss": 0.4495512008666992,
      "memory(GiB)": 72.72,
      "step": 19205,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.252045
    },
    {
      "epoch": 1.7918104654416567,
      "grad_norm": 4.178008079528809,
      "learning_rate": 7.618092562013202e-06,
      "loss": 0.41950674057006837,
      "memory(GiB)": 72.72,
      "step": 19210,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.252044
    },
    {
      "epoch": 1.7922768398470292,
      "grad_norm": 5.134700775146484,
      "learning_rate": 7.6167784751044294e-06,
      "loss": 0.4023723602294922,
      "memory(GiB)": 72.72,
      "step": 19215,
      "token_acc": 0.4423076923076923,
      "train_speed(iter/s)": 0.252044
    },
    {
      "epoch": 1.7927432142524018,
      "grad_norm": 2.7238423824310303,
      "learning_rate": 7.615464139217247e-06,
      "loss": 0.4508157253265381,
      "memory(GiB)": 72.72,
      "step": 19220,
      "token_acc": 0.484375,
      "train_speed(iter/s)": 0.252047
    },
    {
      "epoch": 1.7932095886577746,
      "grad_norm": 4.406303405761719,
      "learning_rate": 7.614149554476709e-06,
      "loss": 0.3934839487075806,
      "memory(GiB)": 72.72,
      "step": 19225,
      "train_speed(iter/s)": 0.252048
    },
    {
      "epoch": 1.7936759630631471,
      "grad_norm": 3.0341320037841797,
      "learning_rate": 7.612834721007892e-06,
      "loss": 0.3835744857788086,
      "memory(GiB)": 72.72,
      "step": 19230,
      "token_acc": 0.4794520547945205,
      "train_speed(iter/s)": 0.252049
    },
    {
      "epoch": 1.7941423374685197,
      "grad_norm": 3.0582528114318848,
      "learning_rate": 7.611519638935902e-06,
      "loss": 0.4193564414978027,
      "memory(GiB)": 72.72,
      "step": 19235,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.7946087118738925,
      "grad_norm": 4.5899481773376465,
      "learning_rate": 7.610204308385864e-06,
      "loss": 0.4256728172302246,
      "memory(GiB)": 72.72,
      "step": 19240,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.795075086279265,
      "grad_norm": 2.801321029663086,
      "learning_rate": 7.608888729482924e-06,
      "loss": 0.4013681411743164,
      "memory(GiB)": 72.72,
      "step": 19245,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.7955414606846376,
      "grad_norm": 3.0438029766082764,
      "learning_rate": 7.607572902352261e-06,
      "loss": 0.46117415428161623,
      "memory(GiB)": 72.72,
      "step": 19250,
      "train_speed(iter/s)": 0.252054
    },
    {
      "epoch": 1.7960078350900104,
      "grad_norm": 4.026623249053955,
      "learning_rate": 7.60625682711907e-06,
      "loss": 0.43620834350585935,
      "memory(GiB)": 72.72,
      "step": 19255,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.796474209495383,
      "grad_norm": 2.1907644271850586,
      "learning_rate": 7.604940503908566e-06,
      "loss": 0.3983549833297729,
      "memory(GiB)": 72.72,
      "step": 19260,
      "train_speed(iter/s)": 0.252052
    },
    {
      "epoch": 1.7969405839007555,
      "grad_norm": 3.6938750743865967,
      "learning_rate": 7.6036239328460025e-06,
      "loss": 0.45041723251342775,
      "memory(GiB)": 72.72,
      "step": 19265,
      "token_acc": 0.9342105263157895,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.7974069583061283,
      "grad_norm": 2.8817474842071533,
      "learning_rate": 7.6023071140566405e-06,
      "loss": 0.44723048210144045,
      "memory(GiB)": 72.72,
      "step": 19270,
      "token_acc": 0.9583333333333334,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.7978733327115006,
      "grad_norm": 4.503242015838623,
      "learning_rate": 7.6009900476657736e-06,
      "loss": 0.42354412078857423,
      "memory(GiB)": 72.72,
      "step": 19275,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.252053
    },
    {
      "epoch": 1.7983397071168734,
      "grad_norm": 3.6509411334991455,
      "learning_rate": 7.599672733798716e-06,
      "loss": 0.42571654319763186,
      "memory(GiB)": 72.72,
      "step": 19280,
      "train_speed(iter/s)": 0.252053
    },
    {
      "epoch": 1.7988060815222462,
      "grad_norm": 3.831669330596924,
      "learning_rate": 7.598355172580807e-06,
      "loss": 0.44199428558349607,
      "memory(GiB)": 72.72,
      "step": 19285,
      "train_speed(iter/s)": 0.252054
    },
    {
      "epoch": 1.7992724559276185,
      "grad_norm": 3.261578321456909,
      "learning_rate": 7.597037364137407e-06,
      "loss": 0.4034561634063721,
      "memory(GiB)": 72.72,
      "step": 19290,
      "train_speed(iter/s)": 0.252055
    },
    {
      "epoch": 1.7997388303329913,
      "grad_norm": 8.985422134399414,
      "learning_rate": 7.595719308593901e-06,
      "loss": 0.4275691032409668,
      "memory(GiB)": 72.72,
      "step": 19295,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.252056
    },
    {
      "epoch": 1.800205204738364,
      "grad_norm": 2.6413819789886475,
      "learning_rate": 7.5944010060757e-06,
      "loss": 0.4197376251220703,
      "memory(GiB)": 72.72,
      "step": 19300,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.8006715791437364,
      "grad_norm": 5.798164367675781,
      "learning_rate": 7.593082456708238e-06,
      "loss": 0.40700478553771974,
      "memory(GiB)": 72.72,
      "step": 19305,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.25206
    },
    {
      "epoch": 1.8011379535491092,
      "grad_norm": 2.9861223697662354,
      "learning_rate": 7.591763660616967e-06,
      "loss": 0.40474414825439453,
      "memory(GiB)": 72.72,
      "step": 19310,
      "train_speed(iter/s)": 0.252059
    },
    {
      "epoch": 1.801604327954482,
      "grad_norm": 2.972795009613037,
      "learning_rate": 7.590444617927366e-06,
      "loss": 0.3765589475631714,
      "memory(GiB)": 72.72,
      "step": 19315,
      "token_acc": 0.7777777777777778,
      "train_speed(iter/s)": 0.252054
    },
    {
      "epoch": 1.8020707023598543,
      "grad_norm": 3.069401741027832,
      "learning_rate": 7.5891253287649405e-06,
      "loss": 0.4031824111938477,
      "memory(GiB)": 72.72,
      "step": 19320,
      "train_speed(iter/s)": 0.252051
    },
    {
      "epoch": 1.8025370767652271,
      "grad_norm": 2.7502517700195312,
      "learning_rate": 7.587805793255216e-06,
      "loss": 0.4083869934082031,
      "memory(GiB)": 72.72,
      "step": 19325,
      "token_acc": 0.45901639344262296,
      "train_speed(iter/s)": 0.252058
    },
    {
      "epoch": 1.8030034511706,
      "grad_norm": 2.958287477493286,
      "learning_rate": 7.586486011523743e-06,
      "loss": 0.43286933898925783,
      "memory(GiB)": 72.72,
      "step": 19330,
      "token_acc": 0.38095238095238093,
      "train_speed(iter/s)": 0.252057
    },
    {
      "epoch": 1.8034698255759722,
      "grad_norm": 3.219414472579956,
      "learning_rate": 7.585165983696093e-06,
      "loss": 0.41203765869140624,
      "memory(GiB)": 72.72,
      "step": 19335,
      "train_speed(iter/s)": 0.251952
    },
    {
      "epoch": 1.803936199981345,
      "grad_norm": 2.9017245769500732,
      "learning_rate": 7.583845709897863e-06,
      "loss": 0.403875732421875,
      "memory(GiB)": 72.72,
      "step": 19340,
      "token_acc": 0.9145299145299145,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.8044025743867178,
      "grad_norm": 2.254058599472046,
      "learning_rate": 7.582525190254675e-06,
      "loss": 0.37526798248291016,
      "memory(GiB)": 72.72,
      "step": 19345,
      "train_speed(iter/s)": 0.251937
    },
    {
      "epoch": 1.8048689487920901,
      "grad_norm": 3.9906539916992188,
      "learning_rate": 7.58120442489217e-06,
      "loss": 0.4066776275634766,
      "memory(GiB)": 72.72,
      "step": 19350,
      "token_acc": 0.4931506849315068,
      "train_speed(iter/s)": 0.251937
    },
    {
      "epoch": 1.805335323197463,
      "grad_norm": 2.237750291824341,
      "learning_rate": 7.579883413936017e-06,
      "loss": 0.4084494113922119,
      "memory(GiB)": 72.72,
      "step": 19355,
      "token_acc": 0.6285714285714286,
      "train_speed(iter/s)": 0.251939
    },
    {
      "epoch": 1.8058016976028357,
      "grad_norm": 14.501555442810059,
      "learning_rate": 7.578562157511903e-06,
      "loss": 0.3900244474411011,
      "memory(GiB)": 72.72,
      "step": 19360,
      "token_acc": 0.9101123595505618,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.806268072008208,
      "grad_norm": 2.394584894180298,
      "learning_rate": 7.577240655745542e-06,
      "loss": 0.39027178287506104,
      "memory(GiB)": 72.72,
      "step": 19365,
      "token_acc": 0.5121951219512195,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.8067344464135808,
      "grad_norm": 4.725165843963623,
      "learning_rate": 7.575918908762674e-06,
      "loss": 0.44325828552246094,
      "memory(GiB)": 72.72,
      "step": 19370,
      "token_acc": 0.9560439560439561,
      "train_speed(iter/s)": 0.25194
    },
    {
      "epoch": 1.8072008208189536,
      "grad_norm": 4.472546100616455,
      "learning_rate": 7.574596916689057e-06,
      "loss": 0.4313908576965332,
      "memory(GiB)": 72.72,
      "step": 19375,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.807667195224326,
      "grad_norm": 4.54602575302124,
      "learning_rate": 7.573274679650474e-06,
      "loss": 0.4166553974151611,
      "memory(GiB)": 72.72,
      "step": 19380,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.8081335696296987,
      "grad_norm": 2.937373399734497,
      "learning_rate": 7.571952197772733e-06,
      "loss": 0.42608046531677246,
      "memory(GiB)": 72.72,
      "step": 19385,
      "token_acc": 0.6796116504854369,
      "train_speed(iter/s)": 0.251945
    },
    {
      "epoch": 1.8085999440350715,
      "grad_norm": 3.7955222129821777,
      "learning_rate": 7.570629471181663e-06,
      "loss": 0.3775202512741089,
      "memory(GiB)": 72.72,
      "step": 19390,
      "train_speed(iter/s)": 0.251947
    },
    {
      "epoch": 1.8090663184404439,
      "grad_norm": 5.136619567871094,
      "learning_rate": 7.569306500003117e-06,
      "loss": 0.3742868423461914,
      "memory(GiB)": 72.72,
      "step": 19395,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.8095326928458166,
      "grad_norm": 4.117616176605225,
      "learning_rate": 7.567983284362974e-06,
      "loss": 0.4417116165161133,
      "memory(GiB)": 72.72,
      "step": 19400,
      "token_acc": 0.912621359223301,
      "train_speed(iter/s)": 0.251948
    },
    {
      "epoch": 1.8099990672511894,
      "grad_norm": 3.141049861907959,
      "learning_rate": 7.566659824387133e-06,
      "loss": 0.36420249938964844,
      "memory(GiB)": 72.72,
      "step": 19405,
      "train_speed(iter/s)": 0.251952
    },
    {
      "epoch": 1.8104654416565618,
      "grad_norm": 3.8634960651397705,
      "learning_rate": 7.565336120201515e-06,
      "loss": 0.4163675785064697,
      "memory(GiB)": 72.72,
      "step": 19410,
      "train_speed(iter/s)": 0.25195
    },
    {
      "epoch": 1.8109318160619345,
      "grad_norm": 3.2853994369506836,
      "learning_rate": 7.564012171932067e-06,
      "loss": 0.43274412155151365,
      "memory(GiB)": 72.72,
      "step": 19415,
      "token_acc": 0.48031496062992124,
      "train_speed(iter/s)": 0.251956
    },
    {
      "epoch": 1.811398190467307,
      "grad_norm": 4.923366546630859,
      "learning_rate": 7.562687979704761e-06,
      "loss": 0.40391340255737307,
      "memory(GiB)": 72.72,
      "step": 19420,
      "train_speed(iter/s)": 0.251959
    },
    {
      "epoch": 1.8118645648726797,
      "grad_norm": 4.107237815856934,
      "learning_rate": 7.561363543645588e-06,
      "loss": 0.4032928466796875,
      "memory(GiB)": 72.72,
      "step": 19425,
      "token_acc": 0.5846153846153846,
      "train_speed(iter/s)": 0.251955
    },
    {
      "epoch": 1.8123309392780524,
      "grad_norm": 2.6443681716918945,
      "learning_rate": 7.560038863880564e-06,
      "loss": 0.43433513641357424,
      "memory(GiB)": 72.72,
      "step": 19430,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.251954
    },
    {
      "epoch": 1.812797313683425,
      "grad_norm": 3.782653331756592,
      "learning_rate": 7.558713940535729e-06,
      "loss": 0.37764501571655273,
      "memory(GiB)": 72.72,
      "step": 19435,
      "train_speed(iter/s)": 0.251955
    },
    {
      "epoch": 1.8132636880887976,
      "grad_norm": 4.803250312805176,
      "learning_rate": 7.5573887737371445e-06,
      "loss": 0.3776125907897949,
      "memory(GiB)": 72.72,
      "step": 19440,
      "token_acc": 0.6078431372549019,
      "train_speed(iter/s)": 0.251959
    },
    {
      "epoch": 1.8137300624941703,
      "grad_norm": 3.00091814994812,
      "learning_rate": 7.556063363610897e-06,
      "loss": 0.40771021842956545,
      "memory(GiB)": 72.72,
      "step": 19445,
      "train_speed(iter/s)": 0.251951
    },
    {
      "epoch": 1.814196436899543,
      "grad_norm": 3.186751365661621,
      "learning_rate": 7.554737710283094e-06,
      "loss": 0.38167951107025144,
      "memory(GiB)": 72.72,
      "step": 19450,
      "token_acc": 0.4827586206896552,
      "train_speed(iter/s)": 0.251945
    },
    {
      "epoch": 1.8146628113049155,
      "grad_norm": 3.441403388977051,
      "learning_rate": 7.553411813879868e-06,
      "loss": 0.43344988822937014,
      "memory(GiB)": 72.72,
      "step": 19455,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.8151291857102883,
      "grad_norm": 3.718224048614502,
      "learning_rate": 7.552085674527374e-06,
      "loss": 0.3889589548110962,
      "memory(GiB)": 72.72,
      "step": 19460,
      "train_speed(iter/s)": 0.251939
    },
    {
      "epoch": 1.8155955601156608,
      "grad_norm": 3.2280712127685547,
      "learning_rate": 7.550759292351789e-06,
      "loss": 0.4309530258178711,
      "memory(GiB)": 72.72,
      "step": 19465,
      "token_acc": 0.6875,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.8160619345210334,
      "grad_norm": 3.990093946456909,
      "learning_rate": 7.549432667479317e-06,
      "loss": 0.3936702966690063,
      "memory(GiB)": 72.72,
      "step": 19470,
      "token_acc": 0.9512195121951219,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.8165283089264062,
      "grad_norm": 2.595327377319336,
      "learning_rate": 7.548105800036178e-06,
      "loss": 0.4338123321533203,
      "memory(GiB)": 72.72,
      "step": 19475,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.8169946833317787,
      "grad_norm": 3.832977294921875,
      "learning_rate": 7.546778690148624e-06,
      "loss": 0.40719151496887207,
      "memory(GiB)": 72.72,
      "step": 19480,
      "token_acc": 0.5121951219512195,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.8174610577371513,
      "grad_norm": 2.93833327293396,
      "learning_rate": 7.545451337942923e-06,
      "loss": 0.41189117431640626,
      "memory(GiB)": 72.72,
      "step": 19485,
      "token_acc": 0.9393939393939394,
      "train_speed(iter/s)": 0.251938
    },
    {
      "epoch": 1.817927432142524,
      "grad_norm": 4.1596221923828125,
      "learning_rate": 7.544123743545369e-06,
      "loss": 0.4275535583496094,
      "memory(GiB)": 72.72,
      "step": 19490,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.8183938065478966,
      "grad_norm": 3.380338668823242,
      "learning_rate": 7.542795907082276e-06,
      "loss": 0.4525128364562988,
      "memory(GiB)": 72.72,
      "step": 19495,
      "token_acc": 0.4807692307692308,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.8188601809532692,
      "grad_norm": 4.421688556671143,
      "learning_rate": 7.541467828679987e-06,
      "loss": 0.4114088535308838,
      "memory(GiB)": 72.72,
      "step": 19500,
      "token_acc": 0.4727272727272727,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.819326555358642,
      "grad_norm": 3.0791049003601074,
      "learning_rate": 7.540139508464863e-06,
      "loss": 0.42391390800476075,
      "memory(GiB)": 72.72,
      "step": 19505,
      "train_speed(iter/s)": 0.251939
    },
    {
      "epoch": 1.8197929297640145,
      "grad_norm": 3.301589012145996,
      "learning_rate": 7.538810946563291e-06,
      "loss": 0.4126120090484619,
      "memory(GiB)": 72.72,
      "step": 19510,
      "token_acc": 0.8366013071895425,
      "train_speed(iter/s)": 0.25194
    },
    {
      "epoch": 1.820259304169387,
      "grad_norm": 4.23828125,
      "learning_rate": 7.5374821431016765e-06,
      "loss": 0.40786037445068357,
      "memory(GiB)": 72.72,
      "step": 19515,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.8207256785747599,
      "grad_norm": 3.4211440086364746,
      "learning_rate": 7.536153098206453e-06,
      "loss": 0.4152270793914795,
      "memory(GiB)": 72.72,
      "step": 19520,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.8211920529801324,
      "grad_norm": 2.977607250213623,
      "learning_rate": 7.5348238120040774e-06,
      "loss": 0.38703289031982424,
      "memory(GiB)": 72.72,
      "step": 19525,
      "token_acc": 0.5675675675675675,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.821658427385505,
      "grad_norm": 2.6683318614959717,
      "learning_rate": 7.533494284621023e-06,
      "loss": 0.3919523239135742,
      "memory(GiB)": 72.72,
      "step": 19530,
      "token_acc": 0.6451612903225806,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.8221248017908778,
      "grad_norm": 4.16232967376709,
      "learning_rate": 7.532164516183793e-06,
      "loss": 0.46084232330322267,
      "memory(GiB)": 72.72,
      "step": 19535,
      "token_acc": 0.5614035087719298,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.8225911761962503,
      "grad_norm": 3.370577335357666,
      "learning_rate": 7.530834506818909e-06,
      "loss": 0.43807554244995117,
      "memory(GiB)": 72.72,
      "step": 19540,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.251941
    },
    {
      "epoch": 1.823057550601623,
      "grad_norm": 6.23118782043457,
      "learning_rate": 7.529504256652918e-06,
      "loss": 0.40033798217773436,
      "memory(GiB)": 72.72,
      "step": 19545,
      "token_acc": 0.5901639344262295,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.8235239250069957,
      "grad_norm": 4.531373023986816,
      "learning_rate": 7.52817376581239e-06,
      "loss": 0.41711902618408203,
      "memory(GiB)": 72.72,
      "step": 19550,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.8239902994123682,
      "grad_norm": 5.000532150268555,
      "learning_rate": 7.526843034423916e-06,
      "loss": 0.371496844291687,
      "memory(GiB)": 72.72,
      "step": 19555,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.8244566738177408,
      "grad_norm": 3.289823293685913,
      "learning_rate": 7.525512062614112e-06,
      "loss": 0.41860122680664064,
      "memory(GiB)": 72.72,
      "step": 19560,
      "token_acc": 0.4421768707482993,
      "train_speed(iter/s)": 0.251942
    },
    {
      "epoch": 1.8249230482231136,
      "grad_norm": 3.914886236190796,
      "learning_rate": 7.524180850509614e-06,
      "loss": 0.41425323486328125,
      "memory(GiB)": 72.72,
      "step": 19565,
      "train_speed(iter/s)": 0.251944
    },
    {
      "epoch": 1.8253894226284861,
      "grad_norm": 3.1688456535339355,
      "learning_rate": 7.5228493982370846e-06,
      "loss": 0.40873332023620607,
      "memory(GiB)": 72.72,
      "step": 19570,
      "train_speed(iter/s)": 0.25194
    },
    {
      "epoch": 1.8258557970338587,
      "grad_norm": 3.6312384605407715,
      "learning_rate": 7.521517705923207e-06,
      "loss": 0.4080974578857422,
      "memory(GiB)": 72.72,
      "step": 19575,
      "train_speed(iter/s)": 0.251946
    },
    {
      "epoch": 1.8263221714392315,
      "grad_norm": 9.259349822998047,
      "learning_rate": 7.5201857736946885e-06,
      "loss": 0.39564321041107176,
      "memory(GiB)": 72.72,
      "step": 19580,
      "token_acc": 0.897196261682243,
      "train_speed(iter/s)": 0.251943
    },
    {
      "epoch": 1.826788545844604,
      "grad_norm": 2.603227376937866,
      "learning_rate": 7.5188536016782555e-06,
      "loss": 0.403123664855957,
      "memory(GiB)": 72.72,
      "step": 19585,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.251945
    },
    {
      "epoch": 1.8272549202499766,
      "grad_norm": 3.6975185871124268,
      "learning_rate": 7.517521190000663e-06,
      "loss": 0.4361382007598877,
      "memory(GiB)": 72.72,
      "step": 19590,
      "train_speed(iter/s)": 0.251948
    },
    {
      "epoch": 1.8277212946553494,
      "grad_norm": 11.903666496276855,
      "learning_rate": 7.516188538788683e-06,
      "loss": 0.40511226654052734,
      "memory(GiB)": 72.72,
      "step": 19595,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.251956
    },
    {
      "epoch": 1.828187669060722,
      "grad_norm": 2.5857861042022705,
      "learning_rate": 7.514855648169117e-06,
      "loss": 0.43220090866088867,
      "memory(GiB)": 72.72,
      "step": 19600,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.25196
    },
    {
      "epoch": 1.8286540434660945,
      "grad_norm": 3.9052376747131348,
      "learning_rate": 7.513522518268782e-06,
      "loss": 0.43450608253479006,
      "memory(GiB)": 72.72,
      "step": 19605,
      "train_speed(iter/s)": 0.251961
    },
    {
      "epoch": 1.8291204178714673,
      "grad_norm": 4.1574883460998535,
      "learning_rate": 7.512189149214522e-06,
      "loss": 0.40667095184326174,
      "memory(GiB)": 72.72,
      "step": 19610,
      "train_speed(iter/s)": 0.251961
    },
    {
      "epoch": 1.8295867922768398,
      "grad_norm": 3.835836172103882,
      "learning_rate": 7.510855541133205e-06,
      "loss": 0.44379053115844724,
      "memory(GiB)": 72.72,
      "step": 19615,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.251964
    },
    {
      "epoch": 1.8300531666822124,
      "grad_norm": 3.877427339553833,
      "learning_rate": 7.509521694151717e-06,
      "loss": 0.41963510513305663,
      "memory(GiB)": 72.72,
      "step": 19620,
      "train_speed(iter/s)": 0.251967
    },
    {
      "epoch": 1.8305195410875852,
      "grad_norm": 23.58512306213379,
      "learning_rate": 7.508187608396971e-06,
      "loss": 0.4243030548095703,
      "memory(GiB)": 72.72,
      "step": 19625,
      "train_speed(iter/s)": 0.251969
    },
    {
      "epoch": 1.8309859154929577,
      "grad_norm": 3.2773001194000244,
      "learning_rate": 7.506853283995901e-06,
      "loss": 0.41318535804748535,
      "memory(GiB)": 72.72,
      "step": 19630,
      "token_acc": 0.5227272727272727,
      "train_speed(iter/s)": 0.251968
    },
    {
      "epoch": 1.8314522898983303,
      "grad_norm": 2.3531877994537354,
      "learning_rate": 7.505518721075462e-06,
      "loss": 0.4003751277923584,
      "memory(GiB)": 72.72,
      "step": 19635,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251973
    },
    {
      "epoch": 1.831918664303703,
      "grad_norm": 3.457876443862915,
      "learning_rate": 7.504183919762638e-06,
      "loss": 0.39321155548095704,
      "memory(GiB)": 72.72,
      "step": 19640,
      "token_acc": 0.4634146341463415,
      "train_speed(iter/s)": 0.251971
    },
    {
      "epoch": 1.8323850387090757,
      "grad_norm": 2.633342742919922,
      "learning_rate": 7.502848880184426e-06,
      "loss": 0.43507070541381837,
      "memory(GiB)": 72.72,
      "step": 19645,
      "token_acc": 0.6946107784431138,
      "train_speed(iter/s)": 0.251972
    },
    {
      "epoch": 1.8328514131144482,
      "grad_norm": 2.7075986862182617,
      "learning_rate": 7.501513602467854e-06,
      "loss": 0.37802574634552,
      "memory(GiB)": 72.72,
      "step": 19650,
      "token_acc": 0.46464646464646464,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 1.833317787519821,
      "grad_norm": 6.350768566131592,
      "learning_rate": 7.500178086739969e-06,
      "loss": 0.41036334037780764,
      "memory(GiB)": 72.72,
      "step": 19655,
      "train_speed(iter/s)": 0.251976
    },
    {
      "epoch": 1.8337841619251936,
      "grad_norm": 3.4544107913970947,
      "learning_rate": 7.49884233312784e-06,
      "loss": 0.39615912437438966,
      "memory(GiB)": 72.72,
      "step": 19660,
      "train_speed(iter/s)": 0.251976
    },
    {
      "epoch": 1.8342505363305661,
      "grad_norm": 3.499587059020996,
      "learning_rate": 7.497506341758563e-06,
      "loss": 0.40529618263244627,
      "memory(GiB)": 72.72,
      "step": 19665,
      "train_speed(iter/s)": 0.251979
    },
    {
      "epoch": 1.834716910735939,
      "grad_norm": 3.0177078247070312,
      "learning_rate": 7.496170112759249e-06,
      "loss": 0.41330347061157224,
      "memory(GiB)": 72.72,
      "step": 19670,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 1.8351832851413115,
      "grad_norm": 6.095434188842773,
      "learning_rate": 7.494833646257041e-06,
      "loss": 0.4498889923095703,
      "memory(GiB)": 72.72,
      "step": 19675,
      "token_acc": 0.8194444444444444,
      "train_speed(iter/s)": 0.25198
    },
    {
      "epoch": 1.835649659546684,
      "grad_norm": 3.5576417446136475,
      "learning_rate": 7.493496942379095e-06,
      "loss": 0.4247591495513916,
      "memory(GiB)": 72.72,
      "step": 19680,
      "train_speed(iter/s)": 0.251979
    },
    {
      "epoch": 1.8361160339520568,
      "grad_norm": 4.03490686416626,
      "learning_rate": 7.492160001252596e-06,
      "loss": 0.3960663080215454,
      "memory(GiB)": 72.72,
      "step": 19685,
      "token_acc": 0.9770114942528736,
      "train_speed(iter/s)": 0.251978
    },
    {
      "epoch": 1.8365824083574294,
      "grad_norm": 2.423238754272461,
      "learning_rate": 7.490822823004751e-06,
      "loss": 0.4097134590148926,
      "memory(GiB)": 72.72,
      "step": 19690,
      "train_speed(iter/s)": 0.251981
    },
    {
      "epoch": 1.837048782762802,
      "grad_norm": 3.65989351272583,
      "learning_rate": 7.489485407762788e-06,
      "loss": 0.4394363880157471,
      "memory(GiB)": 72.72,
      "step": 19695,
      "token_acc": 0.9381443298969072,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.8375151571681747,
      "grad_norm": 4.869113922119141,
      "learning_rate": 7.488147755653957e-06,
      "loss": 0.4547691345214844,
      "memory(GiB)": 72.72,
      "step": 19700,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.8379815315735473,
      "grad_norm": 3.537310838699341,
      "learning_rate": 7.486809866805533e-06,
      "loss": 0.44058847427368164,
      "memory(GiB)": 72.72,
      "step": 19705,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.251984
    },
    {
      "epoch": 1.8384479059789198,
      "grad_norm": 5.547440052032471,
      "learning_rate": 7.48547174134481e-06,
      "loss": 0.427731990814209,
      "memory(GiB)": 72.72,
      "step": 19710,
      "train_speed(iter/s)": 0.251989
    },
    {
      "epoch": 1.8389142803842926,
      "grad_norm": 3.077449321746826,
      "learning_rate": 7.484133379399108e-06,
      "loss": 0.3856049537658691,
      "memory(GiB)": 72.72,
      "step": 19715,
      "train_speed(iter/s)": 0.25199
    },
    {
      "epoch": 1.8393806547896652,
      "grad_norm": 3.9072911739349365,
      "learning_rate": 7.482794781095766e-06,
      "loss": 0.41708173751831057,
      "memory(GiB)": 72.72,
      "step": 19720,
      "token_acc": 0.6938775510204082,
      "train_speed(iter/s)": 0.251989
    },
    {
      "epoch": 1.8398470291950377,
      "grad_norm": 3.066777467727661,
      "learning_rate": 7.481455946562151e-06,
      "loss": 0.3938467979431152,
      "memory(GiB)": 72.72,
      "step": 19725,
      "token_acc": 0.8947368421052632,
      "train_speed(iter/s)": 0.251992
    },
    {
      "epoch": 1.8403134036004105,
      "grad_norm": 7.255022048950195,
      "learning_rate": 7.480116875925646e-06,
      "loss": 0.4249265670776367,
      "memory(GiB)": 72.72,
      "step": 19730,
      "token_acc": 0.532258064516129,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.840779778005783,
      "grad_norm": 3.4604413509368896,
      "learning_rate": 7.47877756931366e-06,
      "loss": 0.40445690155029296,
      "memory(GiB)": 72.72,
      "step": 19735,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.251995
    },
    {
      "epoch": 1.8412461524111556,
      "grad_norm": 4.120476722717285,
      "learning_rate": 7.477438026853624e-06,
      "loss": 0.39173600673675535,
      "memory(GiB)": 72.72,
      "step": 19740,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251995
    },
    {
      "epoch": 1.8417125268165284,
      "grad_norm": 3.0397539138793945,
      "learning_rate": 7.476098248672993e-06,
      "loss": 0.4009381294250488,
      "memory(GiB)": 72.72,
      "step": 19745,
      "token_acc": 0.7848101265822784,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.842178901221901,
      "grad_norm": 2.987058639526367,
      "learning_rate": 7.4747582348992406e-06,
      "loss": 0.4085050582885742,
      "memory(GiB)": 72.72,
      "step": 19750,
      "token_acc": 0.9487179487179487,
      "train_speed(iter/s)": 0.251997
    },
    {
      "epoch": 1.8426452756272735,
      "grad_norm": 3.119880199432373,
      "learning_rate": 7.473417985659866e-06,
      "loss": 0.4361856937408447,
      "memory(GiB)": 72.72,
      "step": 19755,
      "token_acc": 0.5533980582524272,
      "train_speed(iter/s)": 0.251994
    },
    {
      "epoch": 1.8431116500326463,
      "grad_norm": 3.9539003372192383,
      "learning_rate": 7.472077501082391e-06,
      "loss": 0.39276623725891113,
      "memory(GiB)": 72.72,
      "step": 19760,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251993
    },
    {
      "epoch": 1.8435780244380189,
      "grad_norm": 4.993639945983887,
      "learning_rate": 7.4707367812943565e-06,
      "loss": 0.3875561237335205,
      "memory(GiB)": 72.72,
      "step": 19765,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.8440443988433914,
      "grad_norm": 2.9947991371154785,
      "learning_rate": 7.469395826423327e-06,
      "loss": 0.4581024169921875,
      "memory(GiB)": 72.72,
      "step": 19770,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.8445107732487642,
      "grad_norm": 3.8011372089385986,
      "learning_rate": 7.468054636596893e-06,
      "loss": 0.43417787551879883,
      "memory(GiB)": 72.72,
      "step": 19775,
      "token_acc": 0.7307692307692307,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.8449771476541368,
      "grad_norm": 3.126445770263672,
      "learning_rate": 7.4667132119426644e-06,
      "loss": 0.40792412757873536,
      "memory(GiB)": 72.72,
      "step": 19780,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.8454435220595093,
      "grad_norm": 2.7216506004333496,
      "learning_rate": 7.465371552588271e-06,
      "loss": 0.4234179973602295,
      "memory(GiB)": 72.72,
      "step": 19785,
      "token_acc": 0.49,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.8459098964648821,
      "grad_norm": 3.0269546508789062,
      "learning_rate": 7.464029658661369e-06,
      "loss": 0.39230620861053467,
      "memory(GiB)": 72.72,
      "step": 19790,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.8463762708702547,
      "grad_norm": 3.1918253898620605,
      "learning_rate": 7.462687530289636e-06,
      "loss": 0.422770357131958,
      "memory(GiB)": 72.72,
      "step": 19795,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.8468426452756272,
      "grad_norm": 3.2895236015319824,
      "learning_rate": 7.461345167600771e-06,
      "loss": 0.42814292907714846,
      "memory(GiB)": 72.72,
      "step": 19800,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.847309019681,
      "grad_norm": 2.6447854042053223,
      "learning_rate": 7.460002570722497e-06,
      "loss": 0.4476309776306152,
      "memory(GiB)": 72.72,
      "step": 19805,
      "token_acc": 0.6304347826086957,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.8477753940863726,
      "grad_norm": 4.507006645202637,
      "learning_rate": 7.458659739782554e-06,
      "loss": 0.41837263107299805,
      "memory(GiB)": 72.72,
      "step": 19810,
      "train_speed(iter/s)": 0.25201
    },
    {
      "epoch": 1.8482417684917452,
      "grad_norm": 3.4836175441741943,
      "learning_rate": 7.457316674908714e-06,
      "loss": 0.4058240413665771,
      "memory(GiB)": 72.72,
      "step": 19815,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.25201
    },
    {
      "epoch": 1.848708142897118,
      "grad_norm": 3.3960165977478027,
      "learning_rate": 7.455973376228759e-06,
      "loss": 0.45432024002075194,
      "memory(GiB)": 72.72,
      "step": 19820,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.8491745173024905,
      "grad_norm": 2.4208295345306396,
      "learning_rate": 7.454629843870506e-06,
      "loss": 0.3828462839126587,
      "memory(GiB)": 72.72,
      "step": 19825,
      "token_acc": 0.5076923076923077,
      "train_speed(iter/s)": 0.252014
    },
    {
      "epoch": 1.849640891707863,
      "grad_norm": 2.7156615257263184,
      "learning_rate": 7.4532860779617835e-06,
      "loss": 0.43736953735351564,
      "memory(GiB)": 72.72,
      "step": 19830,
      "token_acc": 0.6595744680851063,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.8501072661132358,
      "grad_norm": 3.28955340385437,
      "learning_rate": 7.4519420786304485e-06,
      "loss": 0.4217384338378906,
      "memory(GiB)": 72.72,
      "step": 19835,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.8505736405186082,
      "grad_norm": 4.257155895233154,
      "learning_rate": 7.450597846004377e-06,
      "loss": 0.3826838493347168,
      "memory(GiB)": 72.72,
      "step": 19840,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.851040014923981,
      "grad_norm": 4.053611755371094,
      "learning_rate": 7.449253380211471e-06,
      "loss": 0.4372860908508301,
      "memory(GiB)": 72.72,
      "step": 19845,
      "train_speed(iter/s)": 0.252011
    },
    {
      "epoch": 1.8515063893293537,
      "grad_norm": 3.3750171661376953,
      "learning_rate": 7.447908681379651e-06,
      "loss": 0.40981597900390626,
      "memory(GiB)": 72.72,
      "step": 19850,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.851972763734726,
      "grad_norm": 4.363186359405518,
      "learning_rate": 7.44656374963686e-06,
      "loss": 0.41581077575683595,
      "memory(GiB)": 72.72,
      "step": 19855,
      "train_speed(iter/s)": 0.252007
    },
    {
      "epoch": 1.8524391381400989,
      "grad_norm": 3.5560028553009033,
      "learning_rate": 7.445218585111067e-06,
      "loss": 0.3864975690841675,
      "memory(GiB)": 72.72,
      "step": 19860,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.8529055125454716,
      "grad_norm": 4.839468955993652,
      "learning_rate": 7.4438731879302576e-06,
      "loss": 0.39540872573852537,
      "memory(GiB)": 72.72,
      "step": 19865,
      "train_speed(iter/s)": 0.252003
    },
    {
      "epoch": 1.853371886950844,
      "grad_norm": 4.193699359893799,
      "learning_rate": 7.442527558222441e-06,
      "loss": 0.4488373756408691,
      "memory(GiB)": 72.72,
      "step": 19870,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.252004
    },
    {
      "epoch": 1.8538382613562168,
      "grad_norm": 3.6413605213165283,
      "learning_rate": 7.4411816961156536e-06,
      "loss": 0.40659542083740235,
      "memory(GiB)": 72.72,
      "step": 19875,
      "train_speed(iter/s)": 0.251991
    },
    {
      "epoch": 1.8543046357615895,
      "grad_norm": 2.959285020828247,
      "learning_rate": 7.439835601737948e-06,
      "loss": 0.38218557834625244,
      "memory(GiB)": 72.72,
      "step": 19880,
      "token_acc": 0.6724137931034483,
      "train_speed(iter/s)": 0.251989
    },
    {
      "epoch": 1.8547710101669619,
      "grad_norm": 2.74013090133667,
      "learning_rate": 7.4384892752174e-06,
      "loss": 0.37613797187805176,
      "memory(GiB)": 72.72,
      "step": 19885,
      "train_speed(iter/s)": 0.251988
    },
    {
      "epoch": 1.8552373845723347,
      "grad_norm": 3.0723841190338135,
      "learning_rate": 7.437142716682109e-06,
      "loss": 0.45157814025878906,
      "memory(GiB)": 72.72,
      "step": 19890,
      "train_speed(iter/s)": 0.251986
    },
    {
      "epoch": 1.8557037589777075,
      "grad_norm": 2.730229616165161,
      "learning_rate": 7.4357959262601965e-06,
      "loss": 0.44767093658447266,
      "memory(GiB)": 72.72,
      "step": 19895,
      "train_speed(iter/s)": 0.251986
    },
    {
      "epoch": 1.8561701333830798,
      "grad_norm": 4.025893688201904,
      "learning_rate": 7.4344489040798065e-06,
      "loss": 0.4119534492492676,
      "memory(GiB)": 72.72,
      "step": 19900,
      "train_speed(iter/s)": 0.25199
    },
    {
      "epoch": 1.8566365077884526,
      "grad_norm": 2.9927167892456055,
      "learning_rate": 7.433101650269102e-06,
      "loss": 0.40728044509887695,
      "memory(GiB)": 72.72,
      "step": 19905,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.251995
    },
    {
      "epoch": 1.8571028821938254,
      "grad_norm": 3.204869508743286,
      "learning_rate": 7.431754164956272e-06,
      "loss": 0.3798090934753418,
      "memory(GiB)": 72.72,
      "step": 19910,
      "token_acc": 0.44642857142857145,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.8575692565991977,
      "grad_norm": 2.4417951107025146,
      "learning_rate": 7.430406448269522e-06,
      "loss": 0.40603299140930177,
      "memory(GiB)": 72.72,
      "step": 19915,
      "train_speed(iter/s)": 0.252002
    },
    {
      "epoch": 1.8580356310045705,
      "grad_norm": 2.686039447784424,
      "learning_rate": 7.429058500337087e-06,
      "loss": 0.4402353286743164,
      "memory(GiB)": 72.72,
      "step": 19920,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251999
    },
    {
      "epoch": 1.8585020054099433,
      "grad_norm": 2.9966485500335693,
      "learning_rate": 7.42771032128722e-06,
      "loss": 0.4022525310516357,
      "memory(GiB)": 72.72,
      "step": 19925,
      "train_speed(iter/s)": 0.251998
    },
    {
      "epoch": 1.8589683798153156,
      "grad_norm": 2.9057555198669434,
      "learning_rate": 7.4263619112481935e-06,
      "loss": 0.39716548919677735,
      "memory(GiB)": 72.72,
      "step": 19930,
      "token_acc": 0.7266666666666667,
      "train_speed(iter/s)": 0.251996
    },
    {
      "epoch": 1.8594347542206884,
      "grad_norm": 3.4443321228027344,
      "learning_rate": 7.425013270348304e-06,
      "loss": 0.42627487182617185,
      "memory(GiB)": 72.72,
      "step": 19935,
      "train_speed(iter/s)": 0.251997
    },
    {
      "epoch": 1.8599011286260612,
      "grad_norm": 3.186699867248535,
      "learning_rate": 7.423664398715874e-06,
      "loss": 0.42353239059448244,
      "memory(GiB)": 72.72,
      "step": 19940,
      "train_speed(iter/s)": 0.251997
    },
    {
      "epoch": 1.8603675030314335,
      "grad_norm": 2.679356575012207,
      "learning_rate": 7.422315296479242e-06,
      "loss": 0.4218754291534424,
      "memory(GiB)": 72.72,
      "step": 19945,
      "train_speed(iter/s)": 0.252
    },
    {
      "epoch": 1.8608338774368063,
      "grad_norm": 2.794905424118042,
      "learning_rate": 7.420965963766773e-06,
      "loss": 0.40055217742919924,
      "memory(GiB)": 72.72,
      "step": 19950,
      "train_speed(iter/s)": 0.252001
    },
    {
      "epoch": 1.861300251842179,
      "grad_norm": 4.036169052124023,
      "learning_rate": 7.419616400706849e-06,
      "loss": 0.42055368423461914,
      "memory(GiB)": 72.72,
      "step": 19955,
      "train_speed(iter/s)": 0.252005
    },
    {
      "epoch": 1.8617666262475514,
      "grad_norm": 4.285209655761719,
      "learning_rate": 7.41826660742788e-06,
      "loss": 0.4270313262939453,
      "memory(GiB)": 72.72,
      "step": 19960,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.8622330006529242,
      "grad_norm": 3.765793800354004,
      "learning_rate": 7.416916584058291e-06,
      "loss": 0.4156144142150879,
      "memory(GiB)": 72.72,
      "step": 19965,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.8626993750582967,
      "grad_norm": 3.5300021171569824,
      "learning_rate": 7.415566330726536e-06,
      "loss": 0.404601526260376,
      "memory(GiB)": 72.72,
      "step": 19970,
      "train_speed(iter/s)": 0.252006
    },
    {
      "epoch": 1.8631657494636693,
      "grad_norm": 3.248960256576538,
      "learning_rate": 7.414215847561086e-06,
      "loss": 0.4062919616699219,
      "memory(GiB)": 72.72,
      "step": 19975,
      "train_speed(iter/s)": 0.252009
    },
    {
      "epoch": 1.863632123869042,
      "grad_norm": 2.3695530891418457,
      "learning_rate": 7.412865134690435e-06,
      "loss": 0.37715065479278564,
      "memory(GiB)": 72.72,
      "step": 19980,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.252011
    },
    {
      "epoch": 1.8640984982744147,
      "grad_norm": 4.254524230957031,
      "learning_rate": 7.411514192243099e-06,
      "loss": 0.41972761154174804,
      "memory(GiB)": 72.72,
      "step": 19985,
      "train_speed(iter/s)": 0.252013
    },
    {
      "epoch": 1.8645648726797872,
      "grad_norm": 3.3092288970947266,
      "learning_rate": 7.410163020347615e-06,
      "loss": 0.4033688545227051,
      "memory(GiB)": 72.72,
      "step": 19990,
      "train_speed(iter/s)": 0.252011
    },
    {
      "epoch": 1.86503124708516,
      "grad_norm": 3.382617473602295,
      "learning_rate": 7.4088116191325454e-06,
      "loss": 0.38851633071899416,
      "memory(GiB)": 72.72,
      "step": 19995,
      "token_acc": 0.8014184397163121,
      "train_speed(iter/s)": 0.252012
    },
    {
      "epoch": 1.8654976214905326,
      "grad_norm": 2.505885124206543,
      "learning_rate": 7.407459988726473e-06,
      "loss": 0.42224922180175783,
      "memory(GiB)": 72.72,
      "step": 20000,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.252008
    },
    {
      "epoch": 1.8659639958959051,
      "grad_norm": 2.7157137393951416,
      "learning_rate": 7.406108129257997e-06,
      "loss": 0.3580683946609497,
      "memory(GiB)": 72.72,
      "step": 20005,
      "train_speed(iter/s)": 0.251928
    },
    {
      "epoch": 1.866430370301278,
      "grad_norm": 2.449249267578125,
      "learning_rate": 7.404756040855744e-06,
      "loss": 0.4153244972229004,
      "memory(GiB)": 72.72,
      "step": 20010,
      "train_speed(iter/s)": 0.251933
    },
    {
      "epoch": 1.8668967447066505,
      "grad_norm": 2.565319299697876,
      "learning_rate": 7.403403723648363e-06,
      "loss": 0.42111806869506835,
      "memory(GiB)": 72.72,
      "step": 20015,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.867363119112023,
      "grad_norm": 3.402988910675049,
      "learning_rate": 7.402051177764522e-06,
      "loss": 0.4399252414703369,
      "memory(GiB)": 72.72,
      "step": 20020,
      "train_speed(iter/s)": 0.251932
    },
    {
      "epoch": 1.8678294935173958,
      "grad_norm": 4.544323921203613,
      "learning_rate": 7.40069840333291e-06,
      "loss": 0.4270771503448486,
      "memory(GiB)": 72.72,
      "step": 20025,
      "token_acc": 0.697986577181208,
      "train_speed(iter/s)": 0.251927
    },
    {
      "epoch": 1.8682958679227684,
      "grad_norm": 3.7611465454101562,
      "learning_rate": 7.39934540048224e-06,
      "loss": 0.41840667724609376,
      "memory(GiB)": 72.72,
      "step": 20030,
      "token_acc": 0.44,
      "train_speed(iter/s)": 0.251926
    },
    {
      "epoch": 1.868762242328141,
      "grad_norm": 5.394194602966309,
      "learning_rate": 7.397992169341248e-06,
      "loss": 0.42520532608032224,
      "memory(GiB)": 72.72,
      "step": 20035,
      "train_speed(iter/s)": 0.251925
    },
    {
      "epoch": 1.8692286167335137,
      "grad_norm": 2.2129478454589844,
      "learning_rate": 7.396638710038687e-06,
      "loss": 0.42860045433044436,
      "memory(GiB)": 72.72,
      "step": 20040,
      "token_acc": 0.9318181818181818,
      "train_speed(iter/s)": 0.251926
    },
    {
      "epoch": 1.8696949911388863,
      "grad_norm": 4.349258899688721,
      "learning_rate": 7.395285022703337e-06,
      "loss": 0.36585221290588377,
      "memory(GiB)": 72.72,
      "step": 20045,
      "train_speed(iter/s)": 0.251926
    },
    {
      "epoch": 1.8701613655442588,
      "grad_norm": 3.0688469409942627,
      "learning_rate": 7.393931107463996e-06,
      "loss": 0.4124157905578613,
      "memory(GiB)": 72.72,
      "step": 20050,
      "train_speed(iter/s)": 0.251927
    },
    {
      "epoch": 1.8706277399496316,
      "grad_norm": 2.954359531402588,
      "learning_rate": 7.392576964449485e-06,
      "loss": 0.41762847900390626,
      "memory(GiB)": 72.72,
      "step": 20055,
      "token_acc": 0.5897435897435898,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.8710941143550042,
      "grad_norm": 5.438385486602783,
      "learning_rate": 7.391222593788644e-06,
      "loss": 0.44492201805114745,
      "memory(GiB)": 72.72,
      "step": 20060,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.251934
    },
    {
      "epoch": 1.8715604887603767,
      "grad_norm": 3.626938581466675,
      "learning_rate": 7.389867995610342e-06,
      "loss": 0.38773236274719236,
      "memory(GiB)": 72.72,
      "step": 20065,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.8720268631657495,
      "grad_norm": 2.488731861114502,
      "learning_rate": 7.388513170043461e-06,
      "loss": 0.42200479507446287,
      "memory(GiB)": 72.72,
      "step": 20070,
      "token_acc": 0.49019607843137253,
      "train_speed(iter/s)": 0.251925
    },
    {
      "epoch": 1.872493237571122,
      "grad_norm": 4.760101795196533,
      "learning_rate": 7.3871581172169105e-06,
      "loss": 0.4037014961242676,
      "memory(GiB)": 72.72,
      "step": 20075,
      "train_speed(iter/s)": 0.251854
    },
    {
      "epoch": 1.8729596119764946,
      "grad_norm": 8.335660934448242,
      "learning_rate": 7.3858028372596195e-06,
      "loss": 0.4044105052947998,
      "memory(GiB)": 72.72,
      "step": 20080,
      "token_acc": 0.9565217391304348,
      "train_speed(iter/s)": 0.251853
    },
    {
      "epoch": 1.8734259863818674,
      "grad_norm": 3.279163360595703,
      "learning_rate": 7.384447330300537e-06,
      "loss": 0.41242175102233886,
      "memory(GiB)": 72.72,
      "step": 20085,
      "train_speed(iter/s)": 0.251855
    },
    {
      "epoch": 1.87389236078724,
      "grad_norm": 2.4847400188446045,
      "learning_rate": 7.383091596468636e-06,
      "loss": 0.43994903564453125,
      "memory(GiB)": 72.72,
      "step": 20090,
      "token_acc": 0.9473684210526315,
      "train_speed(iter/s)": 0.251853
    },
    {
      "epoch": 1.8743587351926125,
      "grad_norm": 2.709346055984497,
      "learning_rate": 7.381735635892911e-06,
      "loss": 0.40668611526489257,
      "memory(GiB)": 72.72,
      "step": 20095,
      "token_acc": 0.4485981308411215,
      "train_speed(iter/s)": 0.25185
    },
    {
      "epoch": 1.8748251095979853,
      "grad_norm": 2.922287940979004,
      "learning_rate": 7.38037944870238e-06,
      "loss": 0.40270085334777833,
      "memory(GiB)": 72.72,
      "step": 20100,
      "token_acc": 0.43636363636363634,
      "train_speed(iter/s)": 0.251855
    },
    {
      "epoch": 1.8752914840033579,
      "grad_norm": 5.8280463218688965,
      "learning_rate": 7.379023035026076e-06,
      "loss": 0.4085884094238281,
      "memory(GiB)": 72.72,
      "step": 20105,
      "token_acc": 0.6206896551724138,
      "train_speed(iter/s)": 0.251857
    },
    {
      "epoch": 1.8757578584087304,
      "grad_norm": 4.178469181060791,
      "learning_rate": 7.377666394993057e-06,
      "loss": 0.42004785537719724,
      "memory(GiB)": 72.72,
      "step": 20110,
      "token_acc": 0.68,
      "train_speed(iter/s)": 0.251856
    },
    {
      "epoch": 1.8762242328141032,
      "grad_norm": 4.910122394561768,
      "learning_rate": 7.376309528732407e-06,
      "loss": 0.4047813415527344,
      "memory(GiB)": 72.72,
      "step": 20115,
      "token_acc": 0.6307692307692307,
      "train_speed(iter/s)": 0.251857
    },
    {
      "epoch": 1.8766906072194758,
      "grad_norm": 3.5844922065734863,
      "learning_rate": 7.374952436373226e-06,
      "loss": 0.41722917556762695,
      "memory(GiB)": 72.72,
      "step": 20120,
      "train_speed(iter/s)": 0.251853
    },
    {
      "epoch": 1.8771569816248483,
      "grad_norm": 3.1817774772644043,
      "learning_rate": 7.373595118044636e-06,
      "loss": 0.37039139270782473,
      "memory(GiB)": 72.72,
      "step": 20125,
      "token_acc": 0.5588235294117647,
      "train_speed(iter/s)": 0.251857
    },
    {
      "epoch": 1.8776233560302211,
      "grad_norm": 2.670069932937622,
      "learning_rate": 7.372237573875783e-06,
      "loss": 0.4115097999572754,
      "memory(GiB)": 72.72,
      "step": 20130,
      "train_speed(iter/s)": 0.251863
    },
    {
      "epoch": 1.8780897304355937,
      "grad_norm": 3.301283836364746,
      "learning_rate": 7.370879803995833e-06,
      "loss": 0.4182760715484619,
      "memory(GiB)": 72.72,
      "step": 20135,
      "token_acc": 0.6274509803921569,
      "train_speed(iter/s)": 0.251866
    },
    {
      "epoch": 1.8785561048409662,
      "grad_norm": 2.9121294021606445,
      "learning_rate": 7.369521808533973e-06,
      "loss": 0.4190469741821289,
      "memory(GiB)": 72.72,
      "step": 20140,
      "train_speed(iter/s)": 0.251867
    },
    {
      "epoch": 1.879022479246339,
      "grad_norm": 2.9050040245056152,
      "learning_rate": 7.368163587619412e-06,
      "loss": 0.4011536598205566,
      "memory(GiB)": 72.72,
      "step": 20145,
      "train_speed(iter/s)": 0.25187
    },
    {
      "epoch": 1.8794888536517116,
      "grad_norm": 24.691848754882812,
      "learning_rate": 7.366805141381383e-06,
      "loss": 0.42060098648071287,
      "memory(GiB)": 72.72,
      "step": 20150,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.251871
    },
    {
      "epoch": 1.8799552280570841,
      "grad_norm": 2.590219259262085,
      "learning_rate": 7.365446469949133e-06,
      "loss": 0.37715396881103513,
      "memory(GiB)": 72.72,
      "step": 20155,
      "train_speed(iter/s)": 0.251873
    },
    {
      "epoch": 1.880421602462457,
      "grad_norm": 4.822561264038086,
      "learning_rate": 7.364087573451939e-06,
      "loss": 0.4324631690979004,
      "memory(GiB)": 72.72,
      "step": 20160,
      "token_acc": 0.6744186046511628,
      "train_speed(iter/s)": 0.251875
    },
    {
      "epoch": 1.8808879768678295,
      "grad_norm": 4.684298992156982,
      "learning_rate": 7.362728452019096e-06,
      "loss": 0.39035305976867674,
      "memory(GiB)": 72.72,
      "step": 20165,
      "train_speed(iter/s)": 0.251872
    },
    {
      "epoch": 1.881354351273202,
      "grad_norm": 2.78383731842041,
      "learning_rate": 7.361369105779919e-06,
      "loss": 0.40400266647338867,
      "memory(GiB)": 72.72,
      "step": 20170,
      "train_speed(iter/s)": 0.251867
    },
    {
      "epoch": 1.8818207256785748,
      "grad_norm": 2.296367645263672,
      "learning_rate": 7.360009534863746e-06,
      "loss": 0.3505992889404297,
      "memory(GiB)": 72.72,
      "step": 20175,
      "train_speed(iter/s)": 0.251869
    },
    {
      "epoch": 1.8822871000839474,
      "grad_norm": 2.8586981296539307,
      "learning_rate": 7.358649739399935e-06,
      "loss": 0.40987348556518555,
      "memory(GiB)": 72.72,
      "step": 20180,
      "train_speed(iter/s)": 0.251871
    },
    {
      "epoch": 1.88275347448932,
      "grad_norm": 2.360640525817871,
      "learning_rate": 7.3572897195178695e-06,
      "loss": 0.39395880699157715,
      "memory(GiB)": 72.72,
      "step": 20185,
      "token_acc": 0.9166666666666666,
      "train_speed(iter/s)": 0.25187
    },
    {
      "epoch": 1.8832198488946927,
      "grad_norm": 3.499260425567627,
      "learning_rate": 7.355929475346948e-06,
      "loss": 0.40522565841674807,
      "memory(GiB)": 72.72,
      "step": 20190,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.251869
    },
    {
      "epoch": 1.8836862233000653,
      "grad_norm": 4.239160537719727,
      "learning_rate": 7.354569007016593e-06,
      "loss": 0.42572360038757323,
      "memory(GiB)": 72.72,
      "step": 20195,
      "train_speed(iter/s)": 0.251865
    },
    {
      "epoch": 1.8841525977054379,
      "grad_norm": 2.574514627456665,
      "learning_rate": 7.353208314656253e-06,
      "loss": 0.4064815044403076,
      "memory(GiB)": 72.72,
      "step": 20200,
      "token_acc": 0.4222222222222222,
      "train_speed(iter/s)": 0.251868
    },
    {
      "epoch": 1.8846189721108106,
      "grad_norm": 2.8561627864837646,
      "learning_rate": 7.35184739839539e-06,
      "loss": 0.43372812271118166,
      "memory(GiB)": 72.72,
      "step": 20205,
      "token_acc": 0.45714285714285713,
      "train_speed(iter/s)": 0.251871
    },
    {
      "epoch": 1.8850853465161832,
      "grad_norm": 3.117757797241211,
      "learning_rate": 7.350486258363491e-06,
      "loss": 0.39448912143707277,
      "memory(GiB)": 72.72,
      "step": 20210,
      "token_acc": 0.92,
      "train_speed(iter/s)": 0.25187
    },
    {
      "epoch": 1.8855517209215558,
      "grad_norm": 2.8822786808013916,
      "learning_rate": 7.349124894690066e-06,
      "loss": 0.4399928092956543,
      "memory(GiB)": 72.72,
      "step": 20215,
      "token_acc": 0.5471698113207547,
      "train_speed(iter/s)": 0.251873
    },
    {
      "epoch": 1.8860180953269285,
      "grad_norm": 3.0097782611846924,
      "learning_rate": 7.347763307504644e-06,
      "loss": 0.4049856662750244,
      "memory(GiB)": 72.72,
      "step": 20220,
      "train_speed(iter/s)": 0.251876
    },
    {
      "epoch": 1.886484469732301,
      "grad_norm": 3.9645168781280518,
      "learning_rate": 7.346401496936777e-06,
      "loss": 0.39467573165893555,
      "memory(GiB)": 72.72,
      "step": 20225,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.251875
    },
    {
      "epoch": 1.8869508441376737,
      "grad_norm": 3.9133050441741943,
      "learning_rate": 7.345039463116034e-06,
      "loss": 0.4047098159790039,
      "memory(GiB)": 72.72,
      "step": 20230,
      "token_acc": 0.45161290322580644,
      "train_speed(iter/s)": 0.251873
    },
    {
      "epoch": 1.8874172185430464,
      "grad_norm": 2.3117799758911133,
      "learning_rate": 7.3436772061720106e-06,
      "loss": 0.38182868957519533,
      "memory(GiB)": 72.72,
      "step": 20235,
      "train_speed(iter/s)": 0.25187
    },
    {
      "epoch": 1.887883592948419,
      "grad_norm": 3.7844836711883545,
      "learning_rate": 7.342314726234322e-06,
      "loss": 0.42785181999206545,
      "memory(GiB)": 72.72,
      "step": 20240,
      "token_acc": 0.5588235294117647,
      "train_speed(iter/s)": 0.251876
    },
    {
      "epoch": 1.8883499673537916,
      "grad_norm": 2.821840524673462,
      "learning_rate": 7.3409520234326016e-06,
      "loss": 0.3833550691604614,
      "memory(GiB)": 72.72,
      "step": 20245,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251881
    },
    {
      "epoch": 1.8888163417591644,
      "grad_norm": 4.757867336273193,
      "learning_rate": 7.339589097896509e-06,
      "loss": 0.45096802711486816,
      "memory(GiB)": 72.72,
      "step": 20250,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.251882
    },
    {
      "epoch": 1.889282716164537,
      "grad_norm": 4.539431571960449,
      "learning_rate": 7.33822594975572e-06,
      "loss": 0.4085777759552002,
      "memory(GiB)": 72.72,
      "step": 20255,
      "token_acc": 0.5945945945945946,
      "train_speed(iter/s)": 0.251884
    },
    {
      "epoch": 1.8897490905699095,
      "grad_norm": 2.471121311187744,
      "learning_rate": 7.336862579139934e-06,
      "loss": 0.41266632080078125,
      "memory(GiB)": 72.72,
      "step": 20260,
      "train_speed(iter/s)": 0.251885
    },
    {
      "epoch": 1.8902154649752823,
      "grad_norm": 2.91584849357605,
      "learning_rate": 7.335498986178874e-06,
      "loss": 0.39674038887023927,
      "memory(GiB)": 72.72,
      "step": 20265,
      "train_speed(iter/s)": 0.251885
    },
    {
      "epoch": 1.8906818393806548,
      "grad_norm": 3.9210071563720703,
      "learning_rate": 7.33413517100228e-06,
      "loss": 0.4501204967498779,
      "memory(GiB)": 72.72,
      "step": 20270,
      "train_speed(iter/s)": 0.251885
    },
    {
      "epoch": 1.8911482137860274,
      "grad_norm": 2.9874520301818848,
      "learning_rate": 7.332771133739915e-06,
      "loss": 0.3979971885681152,
      "memory(GiB)": 72.72,
      "step": 20275,
      "token_acc": 0.673469387755102,
      "train_speed(iter/s)": 0.251889
    },
    {
      "epoch": 1.8916145881914002,
      "grad_norm": 3.2213807106018066,
      "learning_rate": 7.331406874521563e-06,
      "loss": 0.4379408836364746,
      "memory(GiB)": 72.72,
      "step": 20280,
      "train_speed(iter/s)": 0.251891
    },
    {
      "epoch": 1.8920809625967727,
      "grad_norm": 3.742039203643799,
      "learning_rate": 7.330042393477028e-06,
      "loss": 0.4203508377075195,
      "memory(GiB)": 72.72,
      "step": 20285,
      "train_speed(iter/s)": 0.251895
    },
    {
      "epoch": 1.8925473370021453,
      "grad_norm": 2.3882148265838623,
      "learning_rate": 7.328677690736138e-06,
      "loss": 0.4057610034942627,
      "memory(GiB)": 72.72,
      "step": 20290,
      "train_speed(iter/s)": 0.251899
    },
    {
      "epoch": 1.893013711407518,
      "grad_norm": 3.828720808029175,
      "learning_rate": 7.327312766428739e-06,
      "loss": 0.3941181659698486,
      "memory(GiB)": 72.72,
      "step": 20295,
      "train_speed(iter/s)": 0.251901
    },
    {
      "epoch": 1.8934800858128906,
      "grad_norm": 6.84733247756958,
      "learning_rate": 7.3259476206847e-06,
      "loss": 0.40809192657470705,
      "memory(GiB)": 72.72,
      "step": 20300,
      "train_speed(iter/s)": 0.251901
    },
    {
      "epoch": 1.8939464602182632,
      "grad_norm": 3.029130697250366,
      "learning_rate": 7.324582253633909e-06,
      "loss": 0.43783249855041506,
      "memory(GiB)": 72.72,
      "step": 20305,
      "train_speed(iter/s)": 0.251902
    },
    {
      "epoch": 1.894412834623636,
      "grad_norm": 3.267132520675659,
      "learning_rate": 7.32321666540628e-06,
      "loss": 0.42278232574462893,
      "memory(GiB)": 72.72,
      "step": 20310,
      "train_speed(iter/s)": 0.251901
    },
    {
      "epoch": 1.8948792090290085,
      "grad_norm": 3.130622148513794,
      "learning_rate": 7.3218508561317405e-06,
      "loss": 0.4253811836242676,
      "memory(GiB)": 72.72,
      "step": 20315,
      "train_speed(iter/s)": 0.251902
    },
    {
      "epoch": 1.895345583434381,
      "grad_norm": 4.136404514312744,
      "learning_rate": 7.320484825940244e-06,
      "loss": 0.41187119483947754,
      "memory(GiB)": 72.72,
      "step": 20320,
      "train_speed(iter/s)": 0.251904
    },
    {
      "epoch": 1.8958119578397539,
      "grad_norm": 3.8196234703063965,
      "learning_rate": 7.319118574961767e-06,
      "loss": 0.3998784065246582,
      "memory(GiB)": 72.72,
      "step": 20325,
      "train_speed(iter/s)": 0.251908
    },
    {
      "epoch": 1.8962783322451264,
      "grad_norm": 2.694436550140381,
      "learning_rate": 7.3177521033263e-06,
      "loss": 0.4286309242248535,
      "memory(GiB)": 72.72,
      "step": 20330,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.251905
    },
    {
      "epoch": 1.896744706650499,
      "grad_norm": 2.557107925415039,
      "learning_rate": 7.31638541116386e-06,
      "loss": 0.4185877799987793,
      "memory(GiB)": 72.72,
      "step": 20335,
      "token_acc": 0.7171717171717171,
      "train_speed(iter/s)": 0.251905
    },
    {
      "epoch": 1.8972110810558718,
      "grad_norm": 2.646697998046875,
      "learning_rate": 7.3150184986044845e-06,
      "loss": 0.3952667713165283,
      "memory(GiB)": 72.72,
      "step": 20340,
      "train_speed(iter/s)": 0.251908
    },
    {
      "epoch": 1.8976774554612443,
      "grad_norm": 3.8038763999938965,
      "learning_rate": 7.3136513657782315e-06,
      "loss": 0.4406529426574707,
      "memory(GiB)": 72.72,
      "step": 20345,
      "train_speed(iter/s)": 0.251904
    },
    {
      "epoch": 1.898143829866617,
      "grad_norm": 2.329620361328125,
      "learning_rate": 7.312284012815178e-06,
      "loss": 0.39510269165039064,
      "memory(GiB)": 72.72,
      "step": 20350,
      "token_acc": 0.52,
      "train_speed(iter/s)": 0.251907
    },
    {
      "epoch": 1.8986102042719897,
      "grad_norm": 3.054959297180176,
      "learning_rate": 7.310916439845423e-06,
      "loss": 0.3962404251098633,
      "memory(GiB)": 72.72,
      "step": 20355,
      "train_speed(iter/s)": 0.251904
    },
    {
      "epoch": 1.8990765786773622,
      "grad_norm": 3.7526204586029053,
      "learning_rate": 7.3095486469990895e-06,
      "loss": 0.3894016265869141,
      "memory(GiB)": 72.72,
      "step": 20360,
      "train_speed(iter/s)": 0.251903
    },
    {
      "epoch": 1.8995429530827348,
      "grad_norm": 2.994817018508911,
      "learning_rate": 7.3081806344063145e-06,
      "loss": 0.4157057285308838,
      "memory(GiB)": 72.72,
      "step": 20365,
      "train_speed(iter/s)": 0.2519
    },
    {
      "epoch": 1.9000093274881076,
      "grad_norm": 3.1957075595855713,
      "learning_rate": 7.306812402197263e-06,
      "loss": 0.40703277587890624,
      "memory(GiB)": 72.72,
      "step": 20370,
      "token_acc": 0.5609756097560976,
      "train_speed(iter/s)": 0.251899
    },
    {
      "epoch": 1.9004757018934801,
      "grad_norm": 7.666754245758057,
      "learning_rate": 7.30544395050212e-06,
      "loss": 0.3856384515762329,
      "memory(GiB)": 72.72,
      "step": 20375,
      "train_speed(iter/s)": 0.251898
    },
    {
      "epoch": 1.9009420762988527,
      "grad_norm": 5.226815223693848,
      "learning_rate": 7.304075279451085e-06,
      "loss": 0.43477377891540525,
      "memory(GiB)": 72.72,
      "step": 20380,
      "train_speed(iter/s)": 0.251896
    },
    {
      "epoch": 1.9014084507042255,
      "grad_norm": 4.60526180267334,
      "learning_rate": 7.302706389174387e-06,
      "loss": 0.41582598686218264,
      "memory(GiB)": 72.72,
      "step": 20385,
      "train_speed(iter/s)": 0.251898
    },
    {
      "epoch": 1.9018748251095978,
      "grad_norm": 12.562400817871094,
      "learning_rate": 7.301337279802267e-06,
      "loss": 0.38980989456176757,
      "memory(GiB)": 72.72,
      "step": 20390,
      "train_speed(iter/s)": 0.2519
    },
    {
      "epoch": 1.9023411995149706,
      "grad_norm": 2.9065053462982178,
      "learning_rate": 7.299967951464996e-06,
      "loss": 0.3580598831176758,
      "memory(GiB)": 72.72,
      "step": 20395,
      "train_speed(iter/s)": 0.251901
    },
    {
      "epoch": 1.9028075739203434,
      "grad_norm": 3.205207109451294,
      "learning_rate": 7.29859840429286e-06,
      "loss": 0.44391870498657227,
      "memory(GiB)": 72.72,
      "step": 20400,
      "train_speed(iter/s)": 0.251903
    },
    {
      "epoch": 1.9032739483257157,
      "grad_norm": 5.421878337860107,
      "learning_rate": 7.297228638416167e-06,
      "loss": 0.42555904388427734,
      "memory(GiB)": 72.72,
      "step": 20405,
      "train_speed(iter/s)": 0.251909
    },
    {
      "epoch": 1.9037403227310885,
      "grad_norm": 3.130084753036499,
      "learning_rate": 7.2958586539652454e-06,
      "loss": 0.38955078125,
      "memory(GiB)": 72.72,
      "step": 20410,
      "token_acc": 0.39285714285714285,
      "train_speed(iter/s)": 0.251909
    },
    {
      "epoch": 1.9042066971364613,
      "grad_norm": 2.908780336380005,
      "learning_rate": 7.294488451070444e-06,
      "loss": 0.41432504653930663,
      "memory(GiB)": 72.72,
      "step": 20415,
      "token_acc": 0.9027027027027027,
      "train_speed(iter/s)": 0.251911
    },
    {
      "epoch": 1.9046730715418336,
      "grad_norm": 4.48472785949707,
      "learning_rate": 7.293118029862136e-06,
      "loss": 0.39821064472198486,
      "memory(GiB)": 72.72,
      "step": 20420,
      "train_speed(iter/s)": 0.251914
    },
    {
      "epoch": 1.9051394459472064,
      "grad_norm": 3.0235331058502197,
      "learning_rate": 7.291747390470713e-06,
      "loss": 0.390557861328125,
      "memory(GiB)": 72.72,
      "step": 20425,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251912
    },
    {
      "epoch": 1.9056058203525792,
      "grad_norm": 4.300982475280762,
      "learning_rate": 7.290376533026584e-06,
      "loss": 0.41878719329833985,
      "memory(GiB)": 72.72,
      "step": 20430,
      "token_acc": 0.9518072289156626,
      "train_speed(iter/s)": 0.251913
    },
    {
      "epoch": 1.9060721947579515,
      "grad_norm": 5.068215370178223,
      "learning_rate": 7.289005457660183e-06,
      "loss": 0.38620781898498535,
      "memory(GiB)": 72.72,
      "step": 20435,
      "token_acc": 0.4473684210526316,
      "train_speed(iter/s)": 0.251914
    },
    {
      "epoch": 1.9065385691633243,
      "grad_norm": 3.9334442615509033,
      "learning_rate": 7.2876341645019654e-06,
      "loss": 0.4112717151641846,
      "memory(GiB)": 72.72,
      "step": 20440,
      "token_acc": 0.7633587786259542,
      "train_speed(iter/s)": 0.251914
    },
    {
      "epoch": 1.907004943568697,
      "grad_norm": 6.730188369750977,
      "learning_rate": 7.2862626536824044e-06,
      "loss": 0.41478943824768066,
      "memory(GiB)": 72.72,
      "step": 20445,
      "train_speed(iter/s)": 0.251912
    },
    {
      "epoch": 1.9074713179740694,
      "grad_norm": 3.5171947479248047,
      "learning_rate": 7.284890925331994e-06,
      "loss": 0.41830029487609866,
      "memory(GiB)": 72.72,
      "step": 20450,
      "train_speed(iter/s)": 0.251914
    },
    {
      "epoch": 1.9079376923794422,
      "grad_norm": 2.8407299518585205,
      "learning_rate": 7.283518979581252e-06,
      "loss": 0.41794347763061523,
      "memory(GiB)": 72.72,
      "step": 20455,
      "train_speed(iter/s)": 0.251914
    },
    {
      "epoch": 1.908404066784815,
      "grad_norm": 6.084282398223877,
      "learning_rate": 7.2821468165607135e-06,
      "loss": 0.4293623924255371,
      "memory(GiB)": 72.72,
      "step": 20460,
      "train_speed(iter/s)": 0.25192
    },
    {
      "epoch": 1.9088704411901873,
      "grad_norm": 2.347175359725952,
      "learning_rate": 7.2807744364009336e-06,
      "loss": 0.39580137729644777,
      "memory(GiB)": 72.72,
      "step": 20465,
      "token_acc": 0.41025641025641024,
      "train_speed(iter/s)": 0.251924
    },
    {
      "epoch": 1.9093368155955601,
      "grad_norm": 2.7349042892456055,
      "learning_rate": 7.279401839232494e-06,
      "loss": 0.3965193510055542,
      "memory(GiB)": 72.72,
      "step": 20470,
      "train_speed(iter/s)": 0.251926
    },
    {
      "epoch": 1.909803190000933,
      "grad_norm": 3.6275081634521484,
      "learning_rate": 7.278029025185992e-06,
      "loss": 0.4168252944946289,
      "memory(GiB)": 72.72,
      "step": 20475,
      "token_acc": 0.7037037037037037,
      "train_speed(iter/s)": 0.251925
    },
    {
      "epoch": 1.9102695644063052,
      "grad_norm": 5.778218746185303,
      "learning_rate": 7.2766559943920445e-06,
      "loss": 0.40663986206054686,
      "memory(GiB)": 72.72,
      "step": 20480,
      "token_acc": 0.4946236559139785,
      "train_speed(iter/s)": 0.251924
    },
    {
      "epoch": 1.910735938811678,
      "grad_norm": 6.126959323883057,
      "learning_rate": 7.275282746981292e-06,
      "loss": 0.43763084411621095,
      "memory(GiB)": 72.72,
      "step": 20485,
      "train_speed(iter/s)": 0.251923
    },
    {
      "epoch": 1.9112023132170508,
      "grad_norm": 2.9300262928009033,
      "learning_rate": 7.273909283084397e-06,
      "loss": 0.35961194038391114,
      "memory(GiB)": 72.72,
      "step": 20490,
      "token_acc": 0.4888888888888889,
      "train_speed(iter/s)": 0.251922
    },
    {
      "epoch": 1.9116686876224231,
      "grad_norm": 4.272167682647705,
      "learning_rate": 7.272535602832038e-06,
      "loss": 0.409168004989624,
      "memory(GiB)": 72.72,
      "step": 20495,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.251922
    },
    {
      "epoch": 1.912135062027796,
      "grad_norm": 2.580770492553711,
      "learning_rate": 7.271161706354917e-06,
      "loss": 0.4330599308013916,
      "memory(GiB)": 72.72,
      "step": 20500,
      "token_acc": 0.7933884297520661,
      "train_speed(iter/s)": 0.25192
    },
    {
      "epoch": 1.9126014364331687,
      "grad_norm": 7.185776710510254,
      "learning_rate": 7.269787593783756e-06,
      "loss": 0.4711755275726318,
      "memory(GiB)": 72.72,
      "step": 20505,
      "token_acc": 0.9578947368421052,
      "train_speed(iter/s)": 0.251922
    },
    {
      "epoch": 1.913067810838541,
      "grad_norm": 2.9690446853637695,
      "learning_rate": 7.268413265249298e-06,
      "loss": 0.38092947006225586,
      "memory(GiB)": 72.72,
      "step": 20510,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251923
    },
    {
      "epoch": 1.9135341852439138,
      "grad_norm": 3.5415308475494385,
      "learning_rate": 7.267038720882304e-06,
      "loss": 0.46074934005737306,
      "memory(GiB)": 72.72,
      "step": 20515,
      "train_speed(iter/s)": 0.251923
    },
    {
      "epoch": 1.9140005596492864,
      "grad_norm": 2.409618854522705,
      "learning_rate": 7.265663960813563e-06,
      "loss": 0.41602067947387694,
      "memory(GiB)": 72.72,
      "step": 20520,
      "train_speed(iter/s)": 0.251927
    },
    {
      "epoch": 1.914466934054659,
      "grad_norm": 3.0814146995544434,
      "learning_rate": 7.264288985173874e-06,
      "loss": 0.38585572242736815,
      "memory(GiB)": 72.72,
      "step": 20525,
      "token_acc": 0.5164835164835165,
      "train_speed(iter/s)": 0.251925
    },
    {
      "epoch": 1.9149333084600317,
      "grad_norm": 3.6214382648468018,
      "learning_rate": 7.262913794094063e-06,
      "loss": 0.3789297342300415,
      "memory(GiB)": 72.72,
      "step": 20530,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.9153996828654043,
      "grad_norm": 2.50478458404541,
      "learning_rate": 7.261538387704975e-06,
      "loss": 0.4127616882324219,
      "memory(GiB)": 72.72,
      "step": 20535,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.251933
    },
    {
      "epoch": 1.9158660572707769,
      "grad_norm": 2.918348789215088,
      "learning_rate": 7.260162766137477e-06,
      "loss": 0.4095432281494141,
      "memory(GiB)": 72.72,
      "step": 20540,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.9163324316761496,
      "grad_norm": 3.154221773147583,
      "learning_rate": 7.258786929522454e-06,
      "loss": 0.43874897956848147,
      "memory(GiB)": 72.72,
      "step": 20545,
      "token_acc": 0.4626865671641791,
      "train_speed(iter/s)": 0.251931
    },
    {
      "epoch": 1.9167988060815222,
      "grad_norm": 3.1230292320251465,
      "learning_rate": 7.257410877990815e-06,
      "loss": 0.3816998481750488,
      "memory(GiB)": 72.72,
      "step": 20550,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.9172651804868948,
      "grad_norm": 6.142305374145508,
      "learning_rate": 7.2560346116734835e-06,
      "loss": 0.36243348121643065,
      "memory(GiB)": 72.72,
      "step": 20555,
      "train_speed(iter/s)": 0.251928
    },
    {
      "epoch": 1.9177315548922675,
      "grad_norm": 5.830071449279785,
      "learning_rate": 7.254658130701408e-06,
      "loss": 0.40996646881103516,
      "memory(GiB)": 72.72,
      "step": 20560,
      "train_speed(iter/s)": 0.251926
    },
    {
      "epoch": 1.91819792929764,
      "grad_norm": 6.023980617523193,
      "learning_rate": 7.253281435205558e-06,
      "loss": 0.4364465713500977,
      "memory(GiB)": 72.72,
      "step": 20565,
      "train_speed(iter/s)": 0.251928
    },
    {
      "epoch": 1.9186643037030127,
      "grad_norm": 3.590386390686035,
      "learning_rate": 7.251904525316921e-06,
      "loss": 0.41309518814086915,
      "memory(GiB)": 72.72,
      "step": 20570,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.9191306781083854,
      "grad_norm": 2.6739797592163086,
      "learning_rate": 7.250527401166505e-06,
      "loss": 0.36623618602752683,
      "memory(GiB)": 72.72,
      "step": 20575,
      "token_acc": 0.7485380116959064,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.919597052513758,
      "grad_norm": 2.381763458251953,
      "learning_rate": 7.2491500628853395e-06,
      "loss": 0.3915241003036499,
      "memory(GiB)": 72.72,
      "step": 20580,
      "token_acc": 0.5974025974025974,
      "train_speed(iter/s)": 0.251932
    },
    {
      "epoch": 1.9200634269191306,
      "grad_norm": 2.9712345600128174,
      "learning_rate": 7.247772510604474e-06,
      "loss": 0.3904665470123291,
      "memory(GiB)": 72.72,
      "step": 20585,
      "train_speed(iter/s)": 0.251932
    },
    {
      "epoch": 1.9205298013245033,
      "grad_norm": 3.944424629211426,
      "learning_rate": 7.246394744454979e-06,
      "loss": 0.4110257148742676,
      "memory(GiB)": 72.72,
      "step": 20590,
      "token_acc": 0.6557377049180327,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.920996175729876,
      "grad_norm": 3.8859925270080566,
      "learning_rate": 7.245016764567944e-06,
      "loss": 0.36298997402191163,
      "memory(GiB)": 72.72,
      "step": 20595,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.9214625501352485,
      "grad_norm": 5.514297962188721,
      "learning_rate": 7.24363857107448e-06,
      "loss": 0.3993709087371826,
      "memory(GiB)": 72.72,
      "step": 20600,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.9219289245406213,
      "grad_norm": 2.562145948410034,
      "learning_rate": 7.242260164105719e-06,
      "loss": 0.4082807064056396,
      "memory(GiB)": 72.72,
      "step": 20605,
      "token_acc": 0.9423076923076923,
      "train_speed(iter/s)": 0.251928
    },
    {
      "epoch": 1.9223952989459938,
      "grad_norm": 2.6387174129486084,
      "learning_rate": 7.240881543792809e-06,
      "loss": 0.40083866119384765,
      "memory(GiB)": 72.72,
      "step": 20610,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.9228616733513664,
      "grad_norm": 2.3499577045440674,
      "learning_rate": 7.2395027102669236e-06,
      "loss": 0.3950913667678833,
      "memory(GiB)": 72.72,
      "step": 20615,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.9233280477567392,
      "grad_norm": 2.5101709365844727,
      "learning_rate": 7.238123663659255e-06,
      "loss": 0.3922374963760376,
      "memory(GiB)": 72.72,
      "step": 20620,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.9237944221621117,
      "grad_norm": 3.8466591835021973,
      "learning_rate": 7.236744404101015e-06,
      "loss": 0.3987199068069458,
      "memory(GiB)": 72.72,
      "step": 20625,
      "train_speed(iter/s)": 0.25193
    },
    {
      "epoch": 1.9242607965674843,
      "grad_norm": 2.35345458984375,
      "learning_rate": 7.235364931723434e-06,
      "loss": 0.47272677421569825,
      "memory(GiB)": 72.72,
      "step": 20630,
      "token_acc": 0.6885245901639344,
      "train_speed(iter/s)": 0.251933
    },
    {
      "epoch": 1.924727170972857,
      "grad_norm": 3.400954246520996,
      "learning_rate": 7.233985246657766e-06,
      "loss": 0.4455528736114502,
      "memory(GiB)": 72.72,
      "step": 20635,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.9251935453782296,
      "grad_norm": 3.3498501777648926,
      "learning_rate": 7.232605349035285e-06,
      "loss": 0.38524229526519777,
      "memory(GiB)": 72.72,
      "step": 20640,
      "token_acc": 0.7073170731707317,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.9256599197836022,
      "grad_norm": 3.545306444168091,
      "learning_rate": 7.23122523898728e-06,
      "loss": 0.3953056573867798,
      "memory(GiB)": 72.72,
      "step": 20645,
      "train_speed(iter/s)": 0.251928
    },
    {
      "epoch": 1.926126294188975,
      "grad_norm": 2.7259793281555176,
      "learning_rate": 7.22984491664507e-06,
      "loss": 0.4054412364959717,
      "memory(GiB)": 72.72,
      "step": 20650,
      "train_speed(iter/s)": 0.251927
    },
    {
      "epoch": 1.9265926685943475,
      "grad_norm": 2.9652950763702393,
      "learning_rate": 7.228464382139983e-06,
      "loss": 0.4580052852630615,
      "memory(GiB)": 72.72,
      "step": 20655,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.92705904299972,
      "grad_norm": 3.124030351638794,
      "learning_rate": 7.227083635603378e-06,
      "loss": 0.37588651180267335,
      "memory(GiB)": 72.72,
      "step": 20660,
      "train_speed(iter/s)": 0.251929
    },
    {
      "epoch": 1.9275254174050929,
      "grad_norm": 5.730712413787842,
      "learning_rate": 7.225702677166624e-06,
      "loss": 0.4299309730529785,
      "memory(GiB)": 72.72,
      "step": 20665,
      "train_speed(iter/s)": 0.251925
    },
    {
      "epoch": 1.9279917918104654,
      "grad_norm": 4.21582555770874,
      "learning_rate": 7.224321506961116e-06,
      "loss": 0.4303943634033203,
      "memory(GiB)": 72.72,
      "step": 20670,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.251923
    },
    {
      "epoch": 1.928458166215838,
      "grad_norm": 4.404770851135254,
      "learning_rate": 7.222940125118269e-06,
      "loss": 0.4168850421905518,
      "memory(GiB)": 72.72,
      "step": 20675,
      "train_speed(iter/s)": 0.251924
    },
    {
      "epoch": 1.9289245406212108,
      "grad_norm": 3.1988637447357178,
      "learning_rate": 7.221558531769519e-06,
      "loss": 0.3921957969665527,
      "memory(GiB)": 72.72,
      "step": 20680,
      "train_speed(iter/s)": 0.251919
    },
    {
      "epoch": 1.9293909150265833,
      "grad_norm": 2.842193126678467,
      "learning_rate": 7.2201767270463165e-06,
      "loss": 0.39702482223510743,
      "memory(GiB)": 72.72,
      "step": 20685,
      "token_acc": 0.5666666666666667,
      "train_speed(iter/s)": 0.25192
    },
    {
      "epoch": 1.929857289431956,
      "grad_norm": 2.93784761428833,
      "learning_rate": 7.218794711080138e-06,
      "loss": 0.40322022438049315,
      "memory(GiB)": 72.72,
      "step": 20690,
      "train_speed(iter/s)": 0.251921
    },
    {
      "epoch": 1.9303236638373287,
      "grad_norm": 2.6323888301849365,
      "learning_rate": 7.217412484002478e-06,
      "loss": 0.41636481285095217,
      "memory(GiB)": 72.72,
      "step": 20695,
      "train_speed(iter/s)": 0.251922
    },
    {
      "epoch": 1.9307900382427012,
      "grad_norm": 2.8603949546813965,
      "learning_rate": 7.216030045944853e-06,
      "loss": 0.39479546546936034,
      "memory(GiB)": 72.72,
      "step": 20700,
      "token_acc": 0.48484848484848486,
      "train_speed(iter/s)": 0.251918
    },
    {
      "epoch": 1.9312564126480738,
      "grad_norm": 4.027777194976807,
      "learning_rate": 7.2146473970387935e-06,
      "loss": 0.39702529907226564,
      "memory(GiB)": 72.72,
      "step": 20705,
      "train_speed(iter/s)": 0.251917
    },
    {
      "epoch": 1.9317227870534466,
      "grad_norm": 3.480577230453491,
      "learning_rate": 7.213264537415856e-06,
      "loss": 0.4204872608184814,
      "memory(GiB)": 72.72,
      "step": 20710,
      "token_acc": 0.5681818181818182,
      "train_speed(iter/s)": 0.25192
    },
    {
      "epoch": 1.9321891614588191,
      "grad_norm": 3.404067039489746,
      "learning_rate": 7.211881467207617e-06,
      "loss": 0.46572413444519045,
      "memory(GiB)": 72.72,
      "step": 20715,
      "train_speed(iter/s)": 0.251923
    },
    {
      "epoch": 1.9326555358641917,
      "grad_norm": 6.172232151031494,
      "learning_rate": 7.210498186545671e-06,
      "loss": 0.4107682704925537,
      "memory(GiB)": 72.72,
      "step": 20720,
      "token_acc": 0.6262626262626263,
      "train_speed(iter/s)": 0.251923
    },
    {
      "epoch": 1.9331219102695645,
      "grad_norm": 4.0157790184021,
      "learning_rate": 7.209114695561632e-06,
      "loss": 0.3972346305847168,
      "memory(GiB)": 72.72,
      "step": 20725,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.251913
    },
    {
      "epoch": 1.933588284674937,
      "grad_norm": 6.652671813964844,
      "learning_rate": 7.207730994387134e-06,
      "loss": 0.43845787048339846,
      "memory(GiB)": 72.72,
      "step": 20730,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.251907
    },
    {
      "epoch": 1.9340546590803096,
      "grad_norm": 3.861121654510498,
      "learning_rate": 7.206347083153833e-06,
      "loss": 0.37798423767089845,
      "memory(GiB)": 72.72,
      "step": 20735,
      "token_acc": 0.6122448979591837,
      "train_speed(iter/s)": 0.251908
    },
    {
      "epoch": 1.9345210334856824,
      "grad_norm": 3.7131035327911377,
      "learning_rate": 7.204962961993405e-06,
      "loss": 0.4460242748260498,
      "memory(GiB)": 72.72,
      "step": 20740,
      "train_speed(iter/s)": 0.251909
    },
    {
      "epoch": 1.934987407891055,
      "grad_norm": 2.707059144973755,
      "learning_rate": 7.203578631037542e-06,
      "loss": 0.443953800201416,
      "memory(GiB)": 72.72,
      "step": 20745,
      "token_acc": 0.9108910891089109,
      "train_speed(iter/s)": 0.251909
    },
    {
      "epoch": 1.9354537822964275,
      "grad_norm": 2.816929340362549,
      "learning_rate": 7.202194090417963e-06,
      "loss": 0.44422388076782227,
      "memory(GiB)": 72.72,
      "step": 20750,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.251912
    },
    {
      "epoch": 1.9359201567018003,
      "grad_norm": 3.1684467792510986,
      "learning_rate": 7.200809340266398e-06,
      "loss": 0.37671380043029784,
      "memory(GiB)": 72.72,
      "step": 20755,
      "train_speed(iter/s)": 0.251916
    },
    {
      "epoch": 1.9363865311071728,
      "grad_norm": 5.413597583770752,
      "learning_rate": 7.199424380714606e-06,
      "loss": 0.3877020120620728,
      "memory(GiB)": 72.72,
      "step": 20760,
      "token_acc": 0.9320388349514563,
      "train_speed(iter/s)": 0.251914
    },
    {
      "epoch": 1.9368529055125454,
      "grad_norm": 15.253255844116211,
      "learning_rate": 7.198039211894359e-06,
      "loss": 0.4144155025482178,
      "memory(GiB)": 72.72,
      "step": 20765,
      "train_speed(iter/s)": 0.251913
    },
    {
      "epoch": 1.9373192799179182,
      "grad_norm": 2.9485745429992676,
      "learning_rate": 7.196653833937452e-06,
      "loss": 0.3938953161239624,
      "memory(GiB)": 72.72,
      "step": 20770,
      "token_acc": 0.9101123595505618,
      "train_speed(iter/s)": 0.251911
    },
    {
      "epoch": 1.9377856543232908,
      "grad_norm": 7.287611484527588,
      "learning_rate": 7.195268246975699e-06,
      "loss": 0.4214338302612305,
      "memory(GiB)": 72.72,
      "step": 20775,
      "train_speed(iter/s)": 0.251908
    },
    {
      "epoch": 1.9382520287286633,
      "grad_norm": 4.525262832641602,
      "learning_rate": 7.193882451140936e-06,
      "loss": 0.41376690864562987,
      "memory(GiB)": 72.72,
      "step": 20780,
      "train_speed(iter/s)": 0.251909
    },
    {
      "epoch": 1.938718403134036,
      "grad_norm": 3.8587214946746826,
      "learning_rate": 7.192496446565015e-06,
      "loss": 0.4080068111419678,
      "memory(GiB)": 72.72,
      "step": 20785,
      "token_acc": 0.532258064516129,
      "train_speed(iter/s)": 0.251909
    },
    {
      "epoch": 1.9391847775394087,
      "grad_norm": 3.88002610206604,
      "learning_rate": 7.191110233379811e-06,
      "loss": 0.3970576047897339,
      "memory(GiB)": 72.72,
      "step": 20790,
      "train_speed(iter/s)": 0.25191
    },
    {
      "epoch": 1.9396511519447812,
      "grad_norm": 3.2151997089385986,
      "learning_rate": 7.189723811717219e-06,
      "loss": 0.4037187576293945,
      "memory(GiB)": 72.72,
      "step": 20795,
      "token_acc": 0.6323529411764706,
      "train_speed(iter/s)": 0.251911
    },
    {
      "epoch": 1.940117526350154,
      "grad_norm": 5.201674461364746,
      "learning_rate": 7.188337181709153e-06,
      "loss": 0.4120189666748047,
      "memory(GiB)": 72.72,
      "step": 20800,
      "train_speed(iter/s)": 0.251914
    },
    {
      "epoch": 1.9405839007555266,
      "grad_norm": 6.126834869384766,
      "learning_rate": 7.1869503434875445e-06,
      "loss": 0.4036696434020996,
      "memory(GiB)": 72.72,
      "step": 20805,
      "token_acc": 0.9479166666666666,
      "train_speed(iter/s)": 0.251913
    },
    {
      "epoch": 1.9410502751608991,
      "grad_norm": 3.894507646560669,
      "learning_rate": 7.185563297184348e-06,
      "loss": 0.4026071548461914,
      "memory(GiB)": 72.72,
      "step": 20810,
      "train_speed(iter/s)": 0.251919
    },
    {
      "epoch": 1.941516649566272,
      "grad_norm": 2.7597649097442627,
      "learning_rate": 7.184176042931536e-06,
      "loss": 0.4216471672058105,
      "memory(GiB)": 72.72,
      "step": 20815,
      "token_acc": 0.425,
      "train_speed(iter/s)": 0.25183
    },
    {
      "epoch": 1.9419830239716445,
      "grad_norm": 4.358127117156982,
      "learning_rate": 7.182788580861103e-06,
      "loss": 0.4083886623382568,
      "memory(GiB)": 72.72,
      "step": 20820,
      "train_speed(iter/s)": 0.251816
    },
    {
      "epoch": 1.942449398377017,
      "grad_norm": 3.4423651695251465,
      "learning_rate": 7.181400911105061e-06,
      "loss": 0.364083456993103,
      "memory(GiB)": 72.72,
      "step": 20825,
      "train_speed(iter/s)": 0.251815
    },
    {
      "epoch": 1.9429157727823898,
      "grad_norm": 3.02177095413208,
      "learning_rate": 7.180013033795441e-06,
      "loss": 0.42682600021362305,
      "memory(GiB)": 72.72,
      "step": 20830,
      "train_speed(iter/s)": 0.251816
    },
    {
      "epoch": 1.9433821471877624,
      "grad_norm": 3.1599645614624023,
      "learning_rate": 7.1786249490642965e-06,
      "loss": 0.4176520347595215,
      "memory(GiB)": 72.72,
      "step": 20835,
      "token_acc": 0.7254901960784313,
      "train_speed(iter/s)": 0.251812
    },
    {
      "epoch": 1.943848521593135,
      "grad_norm": 3.0300133228302,
      "learning_rate": 7.1772366570437e-06,
      "loss": 0.40402812957763673,
      "memory(GiB)": 72.72,
      "step": 20840,
      "token_acc": 0.52,
      "train_speed(iter/s)": 0.25181
    },
    {
      "epoch": 1.9443148959985077,
      "grad_norm": 3.6312029361724854,
      "learning_rate": 7.175848157865743e-06,
      "loss": 0.43688192367553713,
      "memory(GiB)": 72.72,
      "step": 20845,
      "token_acc": 0.40425531914893614,
      "train_speed(iter/s)": 0.251813
    },
    {
      "epoch": 1.9447812704038803,
      "grad_norm": 3.1368165016174316,
      "learning_rate": 7.174459451662537e-06,
      "loss": 0.3960965394973755,
      "memory(GiB)": 72.72,
      "step": 20850,
      "token_acc": 0.6444444444444445,
      "train_speed(iter/s)": 0.251815
    },
    {
      "epoch": 1.9452476448092528,
      "grad_norm": 3.136716365814209,
      "learning_rate": 7.173070538566212e-06,
      "loss": 0.4192349433898926,
      "memory(GiB)": 72.72,
      "step": 20855,
      "token_acc": 0.49019607843137253,
      "train_speed(iter/s)": 0.251815
    },
    {
      "epoch": 1.9457140192146256,
      "grad_norm": 2.6116690635681152,
      "learning_rate": 7.1716814187089204e-06,
      "loss": 0.41303491592407227,
      "memory(GiB)": 72.72,
      "step": 20860,
      "token_acc": 0.5517241379310345,
      "train_speed(iter/s)": 0.251815
    },
    {
      "epoch": 1.9461803936199982,
      "grad_norm": 3.892411947250366,
      "learning_rate": 7.170292092222832e-06,
      "loss": 0.4131340503692627,
      "memory(GiB)": 72.72,
      "step": 20865,
      "train_speed(iter/s)": 0.251815
    },
    {
      "epoch": 1.9466467680253707,
      "grad_norm": 3.648761510848999,
      "learning_rate": 7.168902559240135e-06,
      "loss": 0.4098078727722168,
      "memory(GiB)": 72.72,
      "step": 20870,
      "train_speed(iter/s)": 0.251813
    },
    {
      "epoch": 1.9471131424307435,
      "grad_norm": 3.2757179737091064,
      "learning_rate": 7.1675128198930425e-06,
      "loss": 0.3720823287963867,
      "memory(GiB)": 72.72,
      "step": 20875,
      "train_speed(iter/s)": 0.251813
    },
    {
      "epoch": 1.947579516836116,
      "grad_norm": 3.487323760986328,
      "learning_rate": 7.166122874313782e-06,
      "loss": 0.42182340621948244,
      "memory(GiB)": 72.72,
      "step": 20880,
      "train_speed(iter/s)": 0.25181
    },
    {
      "epoch": 1.9480458912414886,
      "grad_norm": 3.050727605819702,
      "learning_rate": 7.164732722634603e-06,
      "loss": 0.3926530361175537,
      "memory(GiB)": 72.72,
      "step": 20885,
      "train_speed(iter/s)": 0.25181
    },
    {
      "epoch": 1.9485122656468614,
      "grad_norm": 3.130080461502075,
      "learning_rate": 7.163342364987773e-06,
      "loss": 0.4042516231536865,
      "memory(GiB)": 72.72,
      "step": 20890,
      "token_acc": 0.8244274809160306,
      "train_speed(iter/s)": 0.251808
    },
    {
      "epoch": 1.948978640052234,
      "grad_norm": 15.73735237121582,
      "learning_rate": 7.161951801505583e-06,
      "loss": 0.4007683277130127,
      "memory(GiB)": 72.72,
      "step": 20895,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.25181
    },
    {
      "epoch": 1.9494450144576065,
      "grad_norm": 3.148920774459839,
      "learning_rate": 7.160561032320339e-06,
      "loss": 0.3757059335708618,
      "memory(GiB)": 72.72,
      "step": 20900,
      "train_speed(iter/s)": 0.25181
    },
    {
      "epoch": 1.9499113888629793,
      "grad_norm": 3.3320815563201904,
      "learning_rate": 7.159170057564366e-06,
      "loss": 0.39639151096343994,
      "memory(GiB)": 72.72,
      "step": 20905,
      "train_speed(iter/s)": 0.251808
    },
    {
      "epoch": 1.9503777632683519,
      "grad_norm": 2.462045431137085,
      "learning_rate": 7.157778877370016e-06,
      "loss": 0.36684279441833495,
      "memory(GiB)": 72.72,
      "step": 20910,
      "train_speed(iter/s)": 0.251807
    },
    {
      "epoch": 1.9508441376737244,
      "grad_norm": 4.443762302398682,
      "learning_rate": 7.1563874918696515e-06,
      "loss": 0.3813927412033081,
      "memory(GiB)": 72.72,
      "step": 20915,
      "token_acc": 0.5846153846153846,
      "train_speed(iter/s)": 0.251809
    },
    {
      "epoch": 1.9513105120790972,
      "grad_norm": 2.839703321456909,
      "learning_rate": 7.1549959011956624e-06,
      "loss": 0.3885844945907593,
      "memory(GiB)": 72.72,
      "step": 20920,
      "train_speed(iter/s)": 0.251808
    },
    {
      "epoch": 1.9517768864844698,
      "grad_norm": 3.8745312690734863,
      "learning_rate": 7.15360410548045e-06,
      "loss": 0.4338863372802734,
      "memory(GiB)": 72.72,
      "step": 20925,
      "train_speed(iter/s)": 0.251808
    },
    {
      "epoch": 1.9522432608898423,
      "grad_norm": 2.898859739303589,
      "learning_rate": 7.1522121048564415e-06,
      "loss": 0.3995544910430908,
      "memory(GiB)": 72.72,
      "step": 20930,
      "token_acc": 0.543859649122807,
      "train_speed(iter/s)": 0.251807
    },
    {
      "epoch": 1.9527096352952151,
      "grad_norm": 2.7252566814422607,
      "learning_rate": 7.150819899456083e-06,
      "loss": 0.4183452606201172,
      "memory(GiB)": 72.72,
      "step": 20935,
      "train_speed(iter/s)": 0.251811
    },
    {
      "epoch": 1.9531760097005875,
      "grad_norm": 5.00580358505249,
      "learning_rate": 7.149427489411834e-06,
      "loss": 0.39318556785583497,
      "memory(GiB)": 72.72,
      "step": 20940,
      "token_acc": 0.5327102803738317,
      "train_speed(iter/s)": 0.251809
    },
    {
      "epoch": 1.9536423841059603,
      "grad_norm": 5.153938293457031,
      "learning_rate": 7.1480348748561835e-06,
      "loss": 0.4076167106628418,
      "memory(GiB)": 72.72,
      "step": 20945,
      "token_acc": 0.5853658536585366,
      "train_speed(iter/s)": 0.251809
    },
    {
      "epoch": 1.954108758511333,
      "grad_norm": 4.527319431304932,
      "learning_rate": 7.146642055921631e-06,
      "loss": 0.3987952947616577,
      "memory(GiB)": 72.72,
      "step": 20950,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.251809
    },
    {
      "epoch": 1.9545751329167054,
      "grad_norm": 2.868100881576538,
      "learning_rate": 7.145249032740699e-06,
      "loss": 0.4054516315460205,
      "memory(GiB)": 72.72,
      "step": 20955,
      "token_acc": 0.5272727272727272,
      "train_speed(iter/s)": 0.251811
    },
    {
      "epoch": 1.9550415073220782,
      "grad_norm": 3.856832265853882,
      "learning_rate": 7.14385580544593e-06,
      "loss": 0.4549698829650879,
      "memory(GiB)": 72.72,
      "step": 20960,
      "token_acc": 0.46464646464646464,
      "train_speed(iter/s)": 0.251812
    },
    {
      "epoch": 1.955507881727451,
      "grad_norm": 4.647054672241211,
      "learning_rate": 7.142462374169885e-06,
      "loss": 0.41701478958129884,
      "memory(GiB)": 72.72,
      "step": 20965,
      "train_speed(iter/s)": 0.251811
    },
    {
      "epoch": 1.9559742561328233,
      "grad_norm": 3.7398362159729004,
      "learning_rate": 7.141068739045147e-06,
      "loss": 0.41971960067749026,
      "memory(GiB)": 72.72,
      "step": 20970,
      "train_speed(iter/s)": 0.251816
    },
    {
      "epoch": 1.956440630538196,
      "grad_norm": 2.687601089477539,
      "learning_rate": 7.139674900204313e-06,
      "loss": 0.38954591751098633,
      "memory(GiB)": 72.72,
      "step": 20975,
      "train_speed(iter/s)": 0.251816
    },
    {
      "epoch": 1.9569070049435688,
      "grad_norm": 3.793116569519043,
      "learning_rate": 7.138280857780004e-06,
      "loss": 0.37281200885772703,
      "memory(GiB)": 72.72,
      "step": 20980,
      "token_acc": 0.9479166666666666,
      "train_speed(iter/s)": 0.251822
    },
    {
      "epoch": 1.9573733793489412,
      "grad_norm": 2.6823489665985107,
      "learning_rate": 7.136886611904858e-06,
      "loss": 0.4027230262756348,
      "memory(GiB)": 72.72,
      "step": 20985,
      "train_speed(iter/s)": 0.25182
    },
    {
      "epoch": 1.957839753754314,
      "grad_norm": 3.360819101333618,
      "learning_rate": 7.135492162711535e-06,
      "loss": 0.39770500659942626,
      "memory(GiB)": 72.72,
      "step": 20990,
      "train_speed(iter/s)": 0.251823
    },
    {
      "epoch": 1.9583061281596867,
      "grad_norm": 2.631408214569092,
      "learning_rate": 7.13409751033271e-06,
      "loss": 0.42209482192993164,
      "memory(GiB)": 72.72,
      "step": 20995,
      "token_acc": 0.5726495726495726,
      "train_speed(iter/s)": 0.251826
    },
    {
      "epoch": 1.958772502565059,
      "grad_norm": 3.111654281616211,
      "learning_rate": 7.132702654901082e-06,
      "loss": 0.44402599334716797,
      "memory(GiB)": 72.72,
      "step": 21000,
      "train_speed(iter/s)": 0.251826
    },
    {
      "epoch": 1.9592388769704319,
      "grad_norm": 9.117246627807617,
      "learning_rate": 7.131307596549366e-06,
      "loss": 0.4595627307891846,
      "memory(GiB)": 72.72,
      "step": 21005,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251828
    },
    {
      "epoch": 1.9597052513758046,
      "grad_norm": 7.475810527801514,
      "learning_rate": 7.129912335410297e-06,
      "loss": 0.41487321853637693,
      "memory(GiB)": 72.72,
      "step": 21010,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.251831
    },
    {
      "epoch": 1.960171625781177,
      "grad_norm": 5.6870269775390625,
      "learning_rate": 7.128516871616632e-06,
      "loss": 0.39623093605041504,
      "memory(GiB)": 72.72,
      "step": 21015,
      "token_acc": 0.49230769230769234,
      "train_speed(iter/s)": 0.251832
    },
    {
      "epoch": 1.9606380001865498,
      "grad_norm": 3.163166046142578,
      "learning_rate": 7.127121205301143e-06,
      "loss": 0.4338728904724121,
      "memory(GiB)": 72.72,
      "step": 21020,
      "token_acc": 0.7876712328767124,
      "train_speed(iter/s)": 0.251836
    },
    {
      "epoch": 1.9611043745919226,
      "grad_norm": 3.923459529876709,
      "learning_rate": 7.125725336596625e-06,
      "loss": 0.39870786666870117,
      "memory(GiB)": 72.72,
      "step": 21025,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251832
    },
    {
      "epoch": 1.9615707489972949,
      "grad_norm": 3.890097141265869,
      "learning_rate": 7.124329265635888e-06,
      "loss": 0.4355340480804443,
      "memory(GiB)": 72.72,
      "step": 21030,
      "token_acc": 0.7055555555555556,
      "train_speed(iter/s)": 0.251835
    },
    {
      "epoch": 1.9620371234026677,
      "grad_norm": 3.0563886165618896,
      "learning_rate": 7.122932992551768e-06,
      "loss": 0.37609128952026366,
      "memory(GiB)": 72.72,
      "step": 21035,
      "train_speed(iter/s)": 0.251834
    },
    {
      "epoch": 1.9625034978080405,
      "grad_norm": 2.7008752822875977,
      "learning_rate": 7.12153651747711e-06,
      "loss": 0.39892594814300536,
      "memory(GiB)": 72.72,
      "step": 21040,
      "token_acc": 0.5473684210526316,
      "train_speed(iter/s)": 0.251837
    },
    {
      "epoch": 1.9629698722134128,
      "grad_norm": 3.514448404312134,
      "learning_rate": 7.120139840544791e-06,
      "loss": 0.38505327701568604,
      "memory(GiB)": 72.72,
      "step": 21045,
      "train_speed(iter/s)": 0.251836
    },
    {
      "epoch": 1.9634362466187856,
      "grad_norm": 3.141697883605957,
      "learning_rate": 7.118742961887697e-06,
      "loss": 0.42453794479370116,
      "memory(GiB)": 72.72,
      "step": 21050,
      "train_speed(iter/s)": 0.251836
    },
    {
      "epoch": 1.9639026210241584,
      "grad_norm": 3.602008581161499,
      "learning_rate": 7.117345881638736e-06,
      "loss": 0.4028316497802734,
      "memory(GiB)": 72.72,
      "step": 21055,
      "train_speed(iter/s)": 0.251835
    },
    {
      "epoch": 1.9643689954295307,
      "grad_norm": 3.461073160171509,
      "learning_rate": 7.115948599930837e-06,
      "loss": 0.4047995567321777,
      "memory(GiB)": 72.72,
      "step": 21060,
      "train_speed(iter/s)": 0.251837
    },
    {
      "epoch": 1.9648353698349035,
      "grad_norm": 5.3767828941345215,
      "learning_rate": 7.1145511168969475e-06,
      "loss": 0.4309781551361084,
      "memory(GiB)": 72.72,
      "step": 21065,
      "token_acc": 0.5869565217391305,
      "train_speed(iter/s)": 0.251837
    },
    {
      "epoch": 1.965301744240276,
      "grad_norm": 23.6191463470459,
      "learning_rate": 7.113153432670035e-06,
      "loss": 0.4388256549835205,
      "memory(GiB)": 72.72,
      "step": 21070,
      "train_speed(iter/s)": 0.25184
    },
    {
      "epoch": 1.9657681186456486,
      "grad_norm": 3.179577589035034,
      "learning_rate": 7.11175554738308e-06,
      "loss": 0.3800089359283447,
      "memory(GiB)": 72.72,
      "step": 21075,
      "token_acc": 0.9468085106382979,
      "train_speed(iter/s)": 0.251841
    },
    {
      "epoch": 1.9662344930510214,
      "grad_norm": 2.766521453857422,
      "learning_rate": 7.110357461169092e-06,
      "loss": 0.3838536024093628,
      "memory(GiB)": 72.72,
      "step": 21080,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251841
    },
    {
      "epoch": 1.966700867456394,
      "grad_norm": 2.7875497341156006,
      "learning_rate": 7.108959174161092e-06,
      "loss": 0.3863945484161377,
      "memory(GiB)": 72.72,
      "step": 21085,
      "train_speed(iter/s)": 0.251838
    },
    {
      "epoch": 1.9671672418617665,
      "grad_norm": 2.9413082599639893,
      "learning_rate": 7.107560686492123e-06,
      "loss": 0.43554325103759767,
      "memory(GiB)": 72.72,
      "step": 21090,
      "token_acc": 0.46808510638297873,
      "train_speed(iter/s)": 0.251843
    },
    {
      "epoch": 1.9676336162671393,
      "grad_norm": 2.493082046508789,
      "learning_rate": 7.106161998295249e-06,
      "loss": 0.40861196517944337,
      "memory(GiB)": 72.72,
      "step": 21095,
      "train_speed(iter/s)": 0.251844
    },
    {
      "epoch": 1.9680999906725118,
      "grad_norm": 4.864688396453857,
      "learning_rate": 7.104763109703547e-06,
      "loss": 0.3941168308258057,
      "memory(GiB)": 72.72,
      "step": 21100,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251845
    },
    {
      "epoch": 1.9685663650778844,
      "grad_norm": 3.3038666248321533,
      "learning_rate": 7.103364020850121e-06,
      "loss": 0.38408143520355226,
      "memory(GiB)": 72.72,
      "step": 21105,
      "train_speed(iter/s)": 0.251845
    },
    {
      "epoch": 1.9690327394832572,
      "grad_norm": 2.8080148696899414,
      "learning_rate": 7.101964731868085e-06,
      "loss": 0.4013843059539795,
      "memory(GiB)": 72.72,
      "step": 21110,
      "token_acc": 0.9393939393939394,
      "train_speed(iter/s)": 0.251846
    },
    {
      "epoch": 1.9694991138886297,
      "grad_norm": 3.5050415992736816,
      "learning_rate": 7.1005652428905825e-06,
      "loss": 0.4305871486663818,
      "memory(GiB)": 72.72,
      "step": 21115,
      "token_acc": 0.9565217391304348,
      "train_speed(iter/s)": 0.251844
    },
    {
      "epoch": 1.9699654882940023,
      "grad_norm": 2.746363639831543,
      "learning_rate": 7.0991655540507685e-06,
      "loss": 0.4148137092590332,
      "memory(GiB)": 72.72,
      "step": 21120,
      "train_speed(iter/s)": 0.251847
    },
    {
      "epoch": 1.970431862699375,
      "grad_norm": 2.6721456050872803,
      "learning_rate": 7.097765665481817e-06,
      "loss": 0.414951229095459,
      "memory(GiB)": 72.72,
      "step": 21125,
      "token_acc": 0.9743589743589743,
      "train_speed(iter/s)": 0.251842
    },
    {
      "epoch": 1.9708982371047477,
      "grad_norm": 7.571504592895508,
      "learning_rate": 7.0963655773169245e-06,
      "loss": 0.42541208267211916,
      "memory(GiB)": 72.72,
      "step": 21130,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.251843
    },
    {
      "epoch": 1.9713646115101202,
      "grad_norm": 4.542508125305176,
      "learning_rate": 7.094965289689307e-06,
      "loss": 0.40177154541015625,
      "memory(GiB)": 72.72,
      "step": 21135,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.251843
    },
    {
      "epoch": 1.971830985915493,
      "grad_norm": 2.791364908218384,
      "learning_rate": 7.093564802732196e-06,
      "loss": 0.42001895904541015,
      "memory(GiB)": 72.72,
      "step": 21140,
      "train_speed(iter/s)": 0.251842
    },
    {
      "epoch": 1.9722973603208656,
      "grad_norm": 3.0115084648132324,
      "learning_rate": 7.0921641165788415e-06,
      "loss": 0.4072603225708008,
      "memory(GiB)": 72.72,
      "step": 21145,
      "token_acc": 0.9888888888888889,
      "train_speed(iter/s)": 0.25184
    },
    {
      "epoch": 1.9727637347262381,
      "grad_norm": 2.72994065284729,
      "learning_rate": 7.0907632313625175e-06,
      "loss": 0.4097146034240723,
      "memory(GiB)": 72.72,
      "step": 21150,
      "train_speed(iter/s)": 0.251833
    },
    {
      "epoch": 1.973230109131611,
      "grad_norm": 2.450666904449463,
      "learning_rate": 7.089362147216513e-06,
      "loss": 0.39454174041748047,
      "memory(GiB)": 72.72,
      "step": 21155,
      "train_speed(iter/s)": 0.251834
    },
    {
      "epoch": 1.9736964835369835,
      "grad_norm": 3.0859649181365967,
      "learning_rate": 7.087960864274135e-06,
      "loss": 0.4243044376373291,
      "memory(GiB)": 72.72,
      "step": 21160,
      "token_acc": 0.4117647058823529,
      "train_speed(iter/s)": 0.251834
    },
    {
      "epoch": 1.974162857942356,
      "grad_norm": 2.932365894317627,
      "learning_rate": 7.086559382668715e-06,
      "loss": 0.4140296936035156,
      "memory(GiB)": 72.72,
      "step": 21165,
      "train_speed(iter/s)": 0.251833
    },
    {
      "epoch": 1.9746292323477288,
      "grad_norm": 3.246675968170166,
      "learning_rate": 7.085157702533598e-06,
      "loss": 0.4144306659698486,
      "memory(GiB)": 72.72,
      "step": 21170,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.251834
    },
    {
      "epoch": 1.9750956067531014,
      "grad_norm": 4.553386211395264,
      "learning_rate": 7.083755824002148e-06,
      "loss": 0.4009409427642822,
      "memory(GiB)": 72.72,
      "step": 21175,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.251837
    },
    {
      "epoch": 1.975561981158474,
      "grad_norm": 3.012711763381958,
      "learning_rate": 7.0823537472077486e-06,
      "loss": 0.4327854156494141,
      "memory(GiB)": 72.72,
      "step": 21180,
      "token_acc": 0.4888888888888889,
      "train_speed(iter/s)": 0.251838
    },
    {
      "epoch": 1.9760283555638467,
      "grad_norm": 2.6409451961517334,
      "learning_rate": 7.080951472283807e-06,
      "loss": 0.42271718978881834,
      "memory(GiB)": 72.72,
      "step": 21185,
      "train_speed(iter/s)": 0.251841
    },
    {
      "epoch": 1.9764947299692193,
      "grad_norm": 2.324622869491577,
      "learning_rate": 7.079548999363743e-06,
      "loss": 0.38993396759033205,
      "memory(GiB)": 72.72,
      "step": 21190,
      "train_speed(iter/s)": 0.251842
    },
    {
      "epoch": 1.9769611043745918,
      "grad_norm": 3.8690898418426514,
      "learning_rate": 7.078146328580998e-06,
      "loss": 0.43037109375,
      "memory(GiB)": 72.72,
      "step": 21195,
      "token_acc": 0.6306306306306306,
      "train_speed(iter/s)": 0.251845
    },
    {
      "epoch": 1.9774274787799646,
      "grad_norm": 3.2321617603302,
      "learning_rate": 7.076743460069032e-06,
      "loss": 0.38795108795166017,
      "memory(GiB)": 72.72,
      "step": 21200,
      "token_acc": 0.91,
      "train_speed(iter/s)": 0.251847
    },
    {
      "epoch": 1.9778938531853372,
      "grad_norm": 4.506494045257568,
      "learning_rate": 7.075340393961323e-06,
      "loss": 0.39559934139251707,
      "memory(GiB)": 72.72,
      "step": 21205,
      "train_speed(iter/s)": 0.251848
    },
    {
      "epoch": 1.9783602275907097,
      "grad_norm": 3.5930349826812744,
      "learning_rate": 7.073937130391368e-06,
      "loss": 0.4012166976928711,
      "memory(GiB)": 72.72,
      "step": 21210,
      "token_acc": 0.9489795918367347,
      "train_speed(iter/s)": 0.251847
    },
    {
      "epoch": 1.9788266019960825,
      "grad_norm": 2.7326579093933105,
      "learning_rate": 7.072533669492685e-06,
      "loss": 0.44073939323425293,
      "memory(GiB)": 72.72,
      "step": 21215,
      "train_speed(iter/s)": 0.251846
    },
    {
      "epoch": 1.979292976401455,
      "grad_norm": 2.4391164779663086,
      "learning_rate": 7.071130011398809e-06,
      "loss": 0.40656390190124514,
      "memory(GiB)": 72.72,
      "step": 21220,
      "train_speed(iter/s)": 0.251849
    },
    {
      "epoch": 1.9797593508068276,
      "grad_norm": 2.9309334754943848,
      "learning_rate": 7.0697261562432914e-06,
      "loss": 0.42105398178100584,
      "memory(GiB)": 72.72,
      "step": 21225,
      "train_speed(iter/s)": 0.251851
    },
    {
      "epoch": 1.9802257252122004,
      "grad_norm": 3.500929117202759,
      "learning_rate": 7.068322104159706e-06,
      "loss": 0.4046139717102051,
      "memory(GiB)": 72.72,
      "step": 21230,
      "train_speed(iter/s)": 0.25185
    },
    {
      "epoch": 1.980692099617573,
      "grad_norm": 2.7410147190093994,
      "learning_rate": 7.066917855281643e-06,
      "loss": 0.3995924949645996,
      "memory(GiB)": 72.72,
      "step": 21235,
      "train_speed(iter/s)": 0.25185
    },
    {
      "epoch": 1.9811584740229455,
      "grad_norm": 2.701761484146118,
      "learning_rate": 7.065513409742715e-06,
      "loss": 0.4286208152770996,
      "memory(GiB)": 72.72,
      "step": 21240,
      "train_speed(iter/s)": 0.251852
    },
    {
      "epoch": 1.9816248484283183,
      "grad_norm": 2.8697869777679443,
      "learning_rate": 7.064108767676549e-06,
      "loss": 0.3892742395401001,
      "memory(GiB)": 72.72,
      "step": 21245,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251853
    },
    {
      "epoch": 1.9820912228336909,
      "grad_norm": 2.8345839977264404,
      "learning_rate": 7.062703929216792e-06,
      "loss": 0.41062345504760744,
      "memory(GiB)": 72.72,
      "step": 21250,
      "train_speed(iter/s)": 0.251853
    },
    {
      "epoch": 1.9825575972390634,
      "grad_norm": 3.9703781604766846,
      "learning_rate": 7.061298894497109e-06,
      "loss": 0.41913371086120604,
      "memory(GiB)": 72.72,
      "step": 21255,
      "token_acc": 0.6481481481481481,
      "train_speed(iter/s)": 0.251854
    },
    {
      "epoch": 1.9830239716444362,
      "grad_norm": 2.7208969593048096,
      "learning_rate": 7.059893663651188e-06,
      "loss": 0.3618993520736694,
      "memory(GiB)": 72.72,
      "step": 21260,
      "train_speed(iter/s)": 0.251853
    },
    {
      "epoch": 1.9834903460498088,
      "grad_norm": 2.5243749618530273,
      "learning_rate": 7.058488236812729e-06,
      "loss": 0.4301429748535156,
      "memory(GiB)": 72.72,
      "step": 21265,
      "train_speed(iter/s)": 0.251857
    },
    {
      "epoch": 1.9839567204551813,
      "grad_norm": 3.807873487472534,
      "learning_rate": 7.057082614115458e-06,
      "loss": 0.3956601619720459,
      "memory(GiB)": 72.72,
      "step": 21270,
      "train_speed(iter/s)": 0.25186
    },
    {
      "epoch": 1.9844230948605541,
      "grad_norm": 3.746662139892578,
      "learning_rate": 7.055676795693112e-06,
      "loss": 0.42700910568237305,
      "memory(GiB)": 72.72,
      "step": 21275,
      "token_acc": 0.5113636363636364,
      "train_speed(iter/s)": 0.25186
    },
    {
      "epoch": 1.9848894692659267,
      "grad_norm": 4.632829189300537,
      "learning_rate": 7.054270781679451e-06,
      "loss": 0.40995020866394044,
      "memory(GiB)": 72.72,
      "step": 21280,
      "train_speed(iter/s)": 0.251862
    },
    {
      "epoch": 1.9853558436712992,
      "grad_norm": 5.329375267028809,
      "learning_rate": 7.052864572208254e-06,
      "loss": 0.35792591571807864,
      "memory(GiB)": 72.72,
      "step": 21285,
      "train_speed(iter/s)": 0.25186
    },
    {
      "epoch": 1.985822218076672,
      "grad_norm": 3.7026522159576416,
      "learning_rate": 7.051458167413316e-06,
      "loss": 0.4042979717254639,
      "memory(GiB)": 72.72,
      "step": 21290,
      "token_acc": 0.5327868852459017,
      "train_speed(iter/s)": 0.251861
    },
    {
      "epoch": 1.9862885924820446,
      "grad_norm": 3.6209988594055176,
      "learning_rate": 7.050051567428455e-06,
      "loss": 0.408817720413208,
      "memory(GiB)": 72.72,
      "step": 21295,
      "token_acc": 0.9375,
      "train_speed(iter/s)": 0.25186
    },
    {
      "epoch": 1.9867549668874172,
      "grad_norm": 3.128277063369751,
      "learning_rate": 7.048644772387501e-06,
      "loss": 0.392927360534668,
      "memory(GiB)": 72.72,
      "step": 21300,
      "train_speed(iter/s)": 0.251862
    },
    {
      "epoch": 1.98722134129279,
      "grad_norm": 4.706923007965088,
      "learning_rate": 7.0472377824243085e-06,
      "loss": 0.4034251689910889,
      "memory(GiB)": 72.72,
      "step": 21305,
      "train_speed(iter/s)": 0.25186
    },
    {
      "epoch": 1.9876877156981625,
      "grad_norm": 3.5636203289031982,
      "learning_rate": 7.045830597672748e-06,
      "loss": 0.4153275012969971,
      "memory(GiB)": 72.72,
      "step": 21310,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.251861
    },
    {
      "epoch": 1.988154090103535,
      "grad_norm": 2.752455472946167,
      "learning_rate": 7.044423218266707e-06,
      "loss": 0.3720392227172852,
      "memory(GiB)": 72.72,
      "step": 21315,
      "train_speed(iter/s)": 0.251862
    },
    {
      "epoch": 1.9886204645089078,
      "grad_norm": 3.3343143463134766,
      "learning_rate": 7.043015644340098e-06,
      "loss": 0.3968240737915039,
      "memory(GiB)": 72.72,
      "step": 21320,
      "token_acc": 0.5030674846625767,
      "train_speed(iter/s)": 0.251861
    },
    {
      "epoch": 1.9890868389142804,
      "grad_norm": 5.169008255004883,
      "learning_rate": 7.0416078760268415e-06,
      "loss": 0.3955601692199707,
      "memory(GiB)": 72.72,
      "step": 21325,
      "train_speed(iter/s)": 0.251866
    },
    {
      "epoch": 1.989553213319653,
      "grad_norm": 2.919705390930176,
      "learning_rate": 7.040199913460884e-06,
      "loss": 0.39337854385375975,
      "memory(GiB)": 72.72,
      "step": 21330,
      "train_speed(iter/s)": 0.251863
    },
    {
      "epoch": 1.9900195877250257,
      "grad_norm": 4.580760478973389,
      "learning_rate": 7.038791756776192e-06,
      "loss": 0.42462520599365233,
      "memory(GiB)": 72.72,
      "step": 21335,
      "token_acc": 0.547945205479452,
      "train_speed(iter/s)": 0.251861
    },
    {
      "epoch": 1.9904859621303983,
      "grad_norm": 2.9892730712890625,
      "learning_rate": 7.037383406106744e-06,
      "loss": 0.4035393238067627,
      "memory(GiB)": 72.72,
      "step": 21340,
      "train_speed(iter/s)": 0.251862
    },
    {
      "epoch": 1.9909523365357709,
      "grad_norm": 6.883941173553467,
      "learning_rate": 7.0359748615865435e-06,
      "loss": 0.4429010391235352,
      "memory(GiB)": 72.72,
      "step": 21345,
      "token_acc": 0.5737704918032787,
      "train_speed(iter/s)": 0.251864
    },
    {
      "epoch": 1.9914187109411436,
      "grad_norm": 4.873069763183594,
      "learning_rate": 7.034566123349603e-06,
      "loss": 0.41235990524291993,
      "memory(GiB)": 72.72,
      "step": 21350,
      "token_acc": 0.5538461538461539,
      "train_speed(iter/s)": 0.251863
    },
    {
      "epoch": 1.9918850853465162,
      "grad_norm": 4.1953959465026855,
      "learning_rate": 7.033157191529966e-06,
      "loss": 0.42963523864746095,
      "memory(GiB)": 72.72,
      "step": 21355,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251864
    },
    {
      "epoch": 1.9923514597518888,
      "grad_norm": 2.787175416946411,
      "learning_rate": 7.0317480662616845e-06,
      "loss": 0.40461077690124514,
      "memory(GiB)": 72.72,
      "step": 21360,
      "train_speed(iter/s)": 0.251863
    },
    {
      "epoch": 1.9928178341572615,
      "grad_norm": 2.643690347671509,
      "learning_rate": 7.030338747678833e-06,
      "loss": 0.4140024662017822,
      "memory(GiB)": 72.72,
      "step": 21365,
      "token_acc": 0.6285714285714286,
      "train_speed(iter/s)": 0.251863
    },
    {
      "epoch": 1.993284208562634,
      "grad_norm": 3.076127767562866,
      "learning_rate": 7.028929235915506e-06,
      "loss": 0.42599048614501955,
      "memory(GiB)": 72.72,
      "step": 21370,
      "token_acc": 0.8029197080291971,
      "train_speed(iter/s)": 0.251863
    },
    {
      "epoch": 1.9937505829680067,
      "grad_norm": 4.435416221618652,
      "learning_rate": 7.027519531105812e-06,
      "loss": 0.4054464340209961,
      "memory(GiB)": 72.72,
      "step": 21375,
      "token_acc": 0.8411214953271028,
      "train_speed(iter/s)": 0.251868
    },
    {
      "epoch": 1.9942169573733795,
      "grad_norm": 3.7682549953460693,
      "learning_rate": 7.026109633383879e-06,
      "loss": 0.392671012878418,
      "memory(GiB)": 72.72,
      "step": 21380,
      "train_speed(iter/s)": 0.25187
    },
    {
      "epoch": 1.994683331778752,
      "grad_norm": 3.5440046787261963,
      "learning_rate": 7.024699542883857e-06,
      "loss": 0.3977894067764282,
      "memory(GiB)": 72.72,
      "step": 21385,
      "train_speed(iter/s)": 0.251874
    },
    {
      "epoch": 1.9951497061841246,
      "grad_norm": 2.650224208831787,
      "learning_rate": 7.023289259739911e-06,
      "loss": 0.3962725639343262,
      "memory(GiB)": 72.72,
      "step": 21390,
      "token_acc": 0.5925925925925926,
      "train_speed(iter/s)": 0.251877
    },
    {
      "epoch": 1.9956160805894974,
      "grad_norm": 2.627591848373413,
      "learning_rate": 7.021878784086226e-06,
      "loss": 0.3911464691162109,
      "memory(GiB)": 72.72,
      "step": 21395,
      "token_acc": 0.9411764705882353,
      "train_speed(iter/s)": 0.251878
    },
    {
      "epoch": 1.99608245499487,
      "grad_norm": 3.224637746810913,
      "learning_rate": 7.020468116057001e-06,
      "loss": 0.4422883987426758,
      "memory(GiB)": 72.72,
      "step": 21400,
      "token_acc": 0.5227272727272727,
      "train_speed(iter/s)": 0.251879
    },
    {
      "epoch": 1.9965488294002425,
      "grad_norm": 3.0952627658843994,
      "learning_rate": 7.019057255786459e-06,
      "loss": 0.3957012176513672,
      "memory(GiB)": 72.72,
      "step": 21405,
      "token_acc": 0.41025641025641024,
      "train_speed(iter/s)": 0.251879
    },
    {
      "epoch": 1.9970152038056153,
      "grad_norm": 2.6405978202819824,
      "learning_rate": 7.01764620340884e-06,
      "loss": 0.39886250495910647,
      "memory(GiB)": 72.72,
      "step": 21410,
      "train_speed(iter/s)": 0.25188
    },
    {
      "epoch": 1.9974815782109878,
      "grad_norm": 3.7298800945281982,
      "learning_rate": 7.016234959058401e-06,
      "loss": 0.4245875358581543,
      "memory(GiB)": 72.72,
      "step": 21415,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.251884
    },
    {
      "epoch": 1.9979479526163604,
      "grad_norm": 79.92304229736328,
      "learning_rate": 7.014823522869415e-06,
      "loss": 0.39431915283203123,
      "memory(GiB)": 72.72,
      "step": 21420,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.251885
    },
    {
      "epoch": 1.9984143270217332,
      "grad_norm": 3.912050724029541,
      "learning_rate": 7.013411894976179e-06,
      "loss": 0.42884063720703125,
      "memory(GiB)": 72.72,
      "step": 21425,
      "train_speed(iter/s)": 0.251887
    },
    {
      "epoch": 1.9988807014271057,
      "grad_norm": 3.1765246391296387,
      "learning_rate": 7.0120000755130024e-06,
      "loss": 0.417222785949707,
      "memory(GiB)": 72.72,
      "step": 21430,
      "token_acc": 0.6410256410256411,
      "train_speed(iter/s)": 0.251885
    },
    {
      "epoch": 1.9993470758324783,
      "grad_norm": 4.0832743644714355,
      "learning_rate": 7.010588064614218e-06,
      "loss": 0.3830610752105713,
      "memory(GiB)": 72.72,
      "step": 21435,
      "train_speed(iter/s)": 0.251884
    },
    {
      "epoch": 1.999813450237851,
      "grad_norm": 5.230395793914795,
      "learning_rate": 7.0091758624141725e-06,
      "loss": 0.4180903434753418,
      "memory(GiB)": 72.72,
      "step": 21440,
      "train_speed(iter/s)": 0.251884
    },
    {
      "epoch": 2.0002798246432234,
      "grad_norm": 2.786520481109619,
      "learning_rate": 7.007763469047234e-06,
      "loss": 0.3898709058761597,
      "memory(GiB)": 72.72,
      "step": 21445,
      "train_speed(iter/s)": 0.251815
    },
    {
      "epoch": 2.000746199048596,
      "grad_norm": 2.4980833530426025,
      "learning_rate": 7.006350884647784e-06,
      "loss": 0.37289416790008545,
      "memory(GiB)": 72.72,
      "step": 21450,
      "token_acc": 0.9468085106382979,
      "train_speed(iter/s)": 0.251817
    },
    {
      "epoch": 2.001212573453969,
      "grad_norm": 2.635812520980835,
      "learning_rate": 7.00493810935023e-06,
      "loss": 0.4099228858947754,
      "memory(GiB)": 72.72,
      "step": 21455,
      "train_speed(iter/s)": 0.251822
    },
    {
      "epoch": 2.0016789478593413,
      "grad_norm": 3.577104330062866,
      "learning_rate": 7.003525143288992e-06,
      "loss": 0.4128434181213379,
      "memory(GiB)": 72.72,
      "step": 21460,
      "train_speed(iter/s)": 0.251825
    },
    {
      "epoch": 2.002145322264714,
      "grad_norm": 3.5755133628845215,
      "learning_rate": 7.002111986598506e-06,
      "loss": 0.4321287155151367,
      "memory(GiB)": 72.72,
      "step": 21465,
      "train_speed(iter/s)": 0.251826
    },
    {
      "epoch": 2.002611696670087,
      "grad_norm": 6.9583001136779785,
      "learning_rate": 7.000698639413235e-06,
      "loss": 0.39419553279876707,
      "memory(GiB)": 72.72,
      "step": 21470,
      "token_acc": 0.9523809523809523,
      "train_speed(iter/s)": 0.251832
    },
    {
      "epoch": 2.003078071075459,
      "grad_norm": 3.188803195953369,
      "learning_rate": 6.99928510186765e-06,
      "loss": 0.3739734172821045,
      "memory(GiB)": 72.72,
      "step": 21475,
      "train_speed(iter/s)": 0.251837
    },
    {
      "epoch": 2.003544445480832,
      "grad_norm": 4.055863380432129,
      "learning_rate": 6.997871374096247e-06,
      "loss": 0.38472886085510255,
      "memory(GiB)": 72.72,
      "step": 21480,
      "train_speed(iter/s)": 0.251835
    },
    {
      "epoch": 2.0040108198862048,
      "grad_norm": 3.4875118732452393,
      "learning_rate": 6.996457456233536e-06,
      "loss": 0.41856775283813474,
      "memory(GiB)": 72.72,
      "step": 21485,
      "train_speed(iter/s)": 0.251838
    },
    {
      "epoch": 2.004477194291577,
      "grad_norm": 2.9992306232452393,
      "learning_rate": 6.99504334841405e-06,
      "loss": 0.4825885772705078,
      "memory(GiB)": 72.72,
      "step": 21490,
      "token_acc": 0.46774193548387094,
      "train_speed(iter/s)": 0.251838
    },
    {
      "epoch": 2.00494356869695,
      "grad_norm": 5.297791004180908,
      "learning_rate": 6.993629050772336e-06,
      "loss": 0.4375151634216309,
      "memory(GiB)": 72.72,
      "step": 21495,
      "train_speed(iter/s)": 0.251841
    },
    {
      "epoch": 2.0054099431023227,
      "grad_norm": 4.05225944519043,
      "learning_rate": 6.992214563442957e-06,
      "loss": 0.4191082000732422,
      "memory(GiB)": 72.72,
      "step": 21500,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251839
    },
    {
      "epoch": 2.005876317507695,
      "grad_norm": 3.7800564765930176,
      "learning_rate": 6.990799886560501e-06,
      "loss": 0.38321685791015625,
      "memory(GiB)": 72.72,
      "step": 21505,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.251839
    },
    {
      "epoch": 2.006342691913068,
      "grad_norm": 4.424188613891602,
      "learning_rate": 6.989385020259568e-06,
      "loss": 0.41668028831481935,
      "memory(GiB)": 72.72,
      "step": 21510,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.251842
    },
    {
      "epoch": 2.0068090663184406,
      "grad_norm": 3.873255968093872,
      "learning_rate": 6.987969964674779e-06,
      "loss": 0.38048853874206545,
      "memory(GiB)": 72.72,
      "step": 21515,
      "token_acc": 0.8725490196078431,
      "train_speed(iter/s)": 0.251845
    },
    {
      "epoch": 2.007275440723813,
      "grad_norm": 5.059205532073975,
      "learning_rate": 6.986554719940772e-06,
      "loss": 0.3918910026550293,
      "memory(GiB)": 72.72,
      "step": 21520,
      "train_speed(iter/s)": 0.251845
    },
    {
      "epoch": 2.0077418151291857,
      "grad_norm": 3.2110953330993652,
      "learning_rate": 6.985139286192204e-06,
      "loss": 0.4142740726470947,
      "memory(GiB)": 72.72,
      "step": 21525,
      "train_speed(iter/s)": 0.251849
    },
    {
      "epoch": 2.0082081895345585,
      "grad_norm": 3.2358787059783936,
      "learning_rate": 6.9837236635637476e-06,
      "loss": 0.37927143573760985,
      "memory(GiB)": 72.72,
      "step": 21530,
      "train_speed(iter/s)": 0.251849
    },
    {
      "epoch": 2.008674563939931,
      "grad_norm": 3.0510599613189697,
      "learning_rate": 6.982307852190093e-06,
      "loss": 0.40280613899230955,
      "memory(GiB)": 72.72,
      "step": 21535,
      "train_speed(iter/s)": 0.251851
    },
    {
      "epoch": 2.0091409383453036,
      "grad_norm": 3.736605405807495,
      "learning_rate": 6.980891852205957e-06,
      "loss": 0.4190423011779785,
      "memory(GiB)": 72.72,
      "step": 21540,
      "token_acc": 0.6533333333333333,
      "train_speed(iter/s)": 0.251852
    },
    {
      "epoch": 2.0096073127506764,
      "grad_norm": 4.030500888824463,
      "learning_rate": 6.9794756637460626e-06,
      "loss": 0.4165502071380615,
      "memory(GiB)": 72.72,
      "step": 21545,
      "train_speed(iter/s)": 0.251853
    },
    {
      "epoch": 2.0100736871560487,
      "grad_norm": 2.8991858959198,
      "learning_rate": 6.978059286945155e-06,
      "loss": 0.46129703521728516,
      "memory(GiB)": 72.72,
      "step": 21550,
      "train_speed(iter/s)": 0.251852
    },
    {
      "epoch": 2.0105400615614215,
      "grad_norm": 2.9737141132354736,
      "learning_rate": 6.976642721938001e-06,
      "loss": 0.38447723388671873,
      "memory(GiB)": 72.72,
      "step": 21555,
      "train_speed(iter/s)": 0.251773
    },
    {
      "epoch": 2.0110064359667943,
      "grad_norm": 2.462688446044922,
      "learning_rate": 6.97522596885938e-06,
      "loss": 0.42114596366882323,
      "memory(GiB)": 72.72,
      "step": 21560,
      "train_speed(iter/s)": 0.251762
    },
    {
      "epoch": 2.0114728103721666,
      "grad_norm": 5.210971355438232,
      "learning_rate": 6.973809027844095e-06,
      "loss": 0.4094086170196533,
      "memory(GiB)": 72.72,
      "step": 21565,
      "token_acc": 0.66,
      "train_speed(iter/s)": 0.251761
    },
    {
      "epoch": 2.0119391847775394,
      "grad_norm": 3.6419124603271484,
      "learning_rate": 6.97239189902696e-06,
      "loss": 0.41192045211791994,
      "memory(GiB)": 72.72,
      "step": 21570,
      "train_speed(iter/s)": 0.251758
    },
    {
      "epoch": 2.012405559182912,
      "grad_norm": 7.206343650817871,
      "learning_rate": 6.970974582542814e-06,
      "loss": 0.39036667346954346,
      "memory(GiB)": 72.72,
      "step": 21575,
      "train_speed(iter/s)": 0.251752
    },
    {
      "epoch": 2.0128719335882845,
      "grad_norm": 4.686860084533691,
      "learning_rate": 6.969557078526505e-06,
      "loss": 0.43371896743774413,
      "memory(GiB)": 72.72,
      "step": 21580,
      "train_speed(iter/s)": 0.251748
    },
    {
      "epoch": 2.0133383079936573,
      "grad_norm": 3.2743349075317383,
      "learning_rate": 6.968139387112909e-06,
      "loss": 0.41483421325683595,
      "memory(GiB)": 72.72,
      "step": 21585,
      "train_speed(iter/s)": 0.251748
    },
    {
      "epoch": 2.01380468239903,
      "grad_norm": 2.523789405822754,
      "learning_rate": 6.9667215084369125e-06,
      "loss": 0.3929128170013428,
      "memory(GiB)": 72.72,
      "step": 21590,
      "train_speed(iter/s)": 0.251751
    },
    {
      "epoch": 2.0142710568044024,
      "grad_norm": 3.1924490928649902,
      "learning_rate": 6.965303442633424e-06,
      "loss": 0.3838778018951416,
      "memory(GiB)": 72.72,
      "step": 21595,
      "token_acc": 0.5747126436781609,
      "train_speed(iter/s)": 0.251749
    },
    {
      "epoch": 2.014737431209775,
      "grad_norm": 3.855821371078491,
      "learning_rate": 6.963885189837367e-06,
      "loss": 0.4707955837249756,
      "memory(GiB)": 72.72,
      "step": 21600,
      "train_speed(iter/s)": 0.251752
    },
    {
      "epoch": 2.015203805615148,
      "grad_norm": 3.834791660308838,
      "learning_rate": 6.962466750183684e-06,
      "loss": 0.39704849720001223,
      "memory(GiB)": 72.72,
      "step": 21605,
      "train_speed(iter/s)": 0.251756
    },
    {
      "epoch": 2.0156701800205203,
      "grad_norm": 4.89282751083374,
      "learning_rate": 6.961048123807336e-06,
      "loss": 0.3648845195770264,
      "memory(GiB)": 72.72,
      "step": 21610,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251758
    },
    {
      "epoch": 2.016136554425893,
      "grad_norm": 3.5175929069519043,
      "learning_rate": 6.9596293108432984e-06,
      "loss": 0.3722386837005615,
      "memory(GiB)": 72.72,
      "step": 21615,
      "token_acc": 0.9587628865979382,
      "train_speed(iter/s)": 0.251756
    },
    {
      "epoch": 2.016602928831266,
      "grad_norm": 3.8503305912017822,
      "learning_rate": 6.958210311426571e-06,
      "loss": 0.37479333877563475,
      "memory(GiB)": 72.72,
      "step": 21620,
      "train_speed(iter/s)": 0.251756
    },
    {
      "epoch": 2.0170693032366382,
      "grad_norm": 4.145346641540527,
      "learning_rate": 6.956791125692164e-06,
      "loss": 0.40095157623291017,
      "memory(GiB)": 72.72,
      "step": 21625,
      "train_speed(iter/s)": 0.251762
    },
    {
      "epoch": 2.017535677642011,
      "grad_norm": 2.4031031131744385,
      "learning_rate": 6.955371753775109e-06,
      "loss": 0.3391557693481445,
      "memory(GiB)": 72.72,
      "step": 21630,
      "train_speed(iter/s)": 0.251763
    },
    {
      "epoch": 2.018002052047384,
      "grad_norm": 2.67290997505188,
      "learning_rate": 6.953952195810454e-06,
      "loss": 0.4264835834503174,
      "memory(GiB)": 72.72,
      "step": 21635,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251763
    },
    {
      "epoch": 2.018468426452756,
      "grad_norm": 3.5879712104797363,
      "learning_rate": 6.9525324519332685e-06,
      "loss": 0.3980783700942993,
      "memory(GiB)": 72.72,
      "step": 21640,
      "token_acc": 0.7058823529411765,
      "train_speed(iter/s)": 0.251766
    },
    {
      "epoch": 2.018934800858129,
      "grad_norm": 3.671480178833008,
      "learning_rate": 6.9511125222786354e-06,
      "loss": 0.4270327568054199,
      "memory(GiB)": 72.72,
      "step": 21645,
      "token_acc": 0.47692307692307695,
      "train_speed(iter/s)": 0.251765
    },
    {
      "epoch": 2.0194011752635017,
      "grad_norm": 3.4023079872131348,
      "learning_rate": 6.9496924069816565e-06,
      "loss": 0.40285115242004393,
      "memory(GiB)": 72.72,
      "step": 21650,
      "token_acc": 0.6190476190476191,
      "train_speed(iter/s)": 0.25177
    },
    {
      "epoch": 2.019867549668874,
      "grad_norm": 2.394033670425415,
      "learning_rate": 6.9482721061774494e-06,
      "loss": 0.43602523803710935,
      "memory(GiB)": 72.72,
      "step": 21655,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.251769
    },
    {
      "epoch": 2.020333924074247,
      "grad_norm": 4.262580394744873,
      "learning_rate": 6.9468516200011534e-06,
      "loss": 0.3993155717849731,
      "memory(GiB)": 72.72,
      "step": 21660,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251771
    },
    {
      "epoch": 2.0208002984796196,
      "grad_norm": 5.346717357635498,
      "learning_rate": 6.945430948587926e-06,
      "loss": 0.4581582069396973,
      "memory(GiB)": 72.72,
      "step": 21665,
      "token_acc": 0.7619047619047619,
      "train_speed(iter/s)": 0.251774
    },
    {
      "epoch": 2.021266672884992,
      "grad_norm": 4.504680633544922,
      "learning_rate": 6.944010092072935e-06,
      "loss": 0.42672929763793943,
      "memory(GiB)": 72.72,
      "step": 21670,
      "token_acc": 0.9166666666666666,
      "train_speed(iter/s)": 0.251769
    },
    {
      "epoch": 2.0217330472903647,
      "grad_norm": 3.3314523696899414,
      "learning_rate": 6.942589050591371e-06,
      "loss": 0.40301012992858887,
      "memory(GiB)": 72.72,
      "step": 21675,
      "train_speed(iter/s)": 0.251768
    },
    {
      "epoch": 2.0221994216957375,
      "grad_norm": 2.707327127456665,
      "learning_rate": 6.941167824278445e-06,
      "loss": 0.42960801124572756,
      "memory(GiB)": 72.72,
      "step": 21680,
      "token_acc": 0.9090909090909091,
      "train_speed(iter/s)": 0.251772
    },
    {
      "epoch": 2.02266579610111,
      "grad_norm": 2.0434069633483887,
      "learning_rate": 6.939746413269379e-06,
      "loss": 0.3773343086242676,
      "memory(GiB)": 72.72,
      "step": 21685,
      "token_acc": 0.5648148148148148,
      "train_speed(iter/s)": 0.251771
    },
    {
      "epoch": 2.0231321705064826,
      "grad_norm": 6.060408592224121,
      "learning_rate": 6.93832481769942e-06,
      "loss": 0.41827545166015623,
      "memory(GiB)": 72.72,
      "step": 21690,
      "token_acc": 0.8933333333333333,
      "train_speed(iter/s)": 0.251766
    },
    {
      "epoch": 2.0235985449118554,
      "grad_norm": 7.7410993576049805,
      "learning_rate": 6.936903037703824e-06,
      "loss": 0.3990753173828125,
      "memory(GiB)": 72.72,
      "step": 21695,
      "train_speed(iter/s)": 0.25177
    },
    {
      "epoch": 2.0240649193172278,
      "grad_norm": 2.8340587615966797,
      "learning_rate": 6.935481073417871e-06,
      "loss": 0.4095428943634033,
      "memory(GiB)": 72.72,
      "step": 21700,
      "token_acc": 0.39285714285714285,
      "train_speed(iter/s)": 0.251771
    },
    {
      "epoch": 2.0245312937226005,
      "grad_norm": 2.579212188720703,
      "learning_rate": 6.934058924976855e-06,
      "loss": 0.4000411033630371,
      "memory(GiB)": 72.72,
      "step": 21705,
      "token_acc": 0.8014184397163121,
      "train_speed(iter/s)": 0.251771
    },
    {
      "epoch": 2.0249976681279733,
      "grad_norm": 13.16091251373291,
      "learning_rate": 6.932636592516091e-06,
      "loss": 0.3848991394042969,
      "memory(GiB)": 72.72,
      "step": 21710,
      "token_acc": 0.864406779661017,
      "train_speed(iter/s)": 0.251768
    },
    {
      "epoch": 2.0254640425333457,
      "grad_norm": 11.399114608764648,
      "learning_rate": 6.9312140761709105e-06,
      "loss": 0.43778390884399415,
      "memory(GiB)": 72.72,
      "step": 21715,
      "train_speed(iter/s)": 0.251766
    },
    {
      "epoch": 2.0259304169387184,
      "grad_norm": 15.745347023010254,
      "learning_rate": 6.9297913760766575e-06,
      "loss": 0.41690492630004883,
      "memory(GiB)": 72.72,
      "step": 21720,
      "train_speed(iter/s)": 0.251767
    },
    {
      "epoch": 2.0263967913440912,
      "grad_norm": 5.108190059661865,
      "learning_rate": 6.9283684923687025e-06,
      "loss": 0.4123319149017334,
      "memory(GiB)": 72.72,
      "step": 21725,
      "train_speed(iter/s)": 0.251771
    },
    {
      "epoch": 2.0268631657494636,
      "grad_norm": 4.940425872802734,
      "learning_rate": 6.926945425182424e-06,
      "loss": 0.38139824867248534,
      "memory(GiB)": 72.72,
      "step": 21730,
      "token_acc": 0.961038961038961,
      "train_speed(iter/s)": 0.251776
    },
    {
      "epoch": 2.0273295401548364,
      "grad_norm": 2.6670987606048584,
      "learning_rate": 6.925522174653225e-06,
      "loss": 0.41039505004882815,
      "memory(GiB)": 72.72,
      "step": 21735,
      "train_speed(iter/s)": 0.251772
    },
    {
      "epoch": 2.027795914560209,
      "grad_norm": 5.054180145263672,
      "learning_rate": 6.924098740916523e-06,
      "loss": 0.3855892181396484,
      "memory(GiB)": 72.72,
      "step": 21740,
      "token_acc": 0.92,
      "train_speed(iter/s)": 0.251775
    },
    {
      "epoch": 2.0282622889655815,
      "grad_norm": 4.990494728088379,
      "learning_rate": 6.9226751241077525e-06,
      "loss": 0.3733105182647705,
      "memory(GiB)": 72.72,
      "step": 21745,
      "train_speed(iter/s)": 0.251774
    },
    {
      "epoch": 2.0287286633709543,
      "grad_norm": 3.3860294818878174,
      "learning_rate": 6.921251324362368e-06,
      "loss": 0.43369369506835936,
      "memory(GiB)": 72.72,
      "step": 21750,
      "train_speed(iter/s)": 0.251776
    },
    {
      "epoch": 2.029195037776327,
      "grad_norm": 6.453916549682617,
      "learning_rate": 6.919827341815837e-06,
      "loss": 0.40970621109008787,
      "memory(GiB)": 72.72,
      "step": 21755,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.251779
    },
    {
      "epoch": 2.0296614121816994,
      "grad_norm": 3.1334288120269775,
      "learning_rate": 6.918403176603648e-06,
      "loss": 0.45075368881225586,
      "memory(GiB)": 72.72,
      "step": 21760,
      "train_speed(iter/s)": 0.251781
    },
    {
      "epoch": 2.030127786587072,
      "grad_norm": 3.5209953784942627,
      "learning_rate": 6.9169788288613096e-06,
      "loss": 0.394600510597229,
      "memory(GiB)": 72.72,
      "step": 21765,
      "token_acc": 0.6086956521739131,
      "train_speed(iter/s)": 0.25178
    },
    {
      "epoch": 2.030594160992445,
      "grad_norm": 11.530204772949219,
      "learning_rate": 6.915554298724339e-06,
      "loss": 0.3993664741516113,
      "memory(GiB)": 72.72,
      "step": 21770,
      "train_speed(iter/s)": 0.251785
    },
    {
      "epoch": 2.0310605353978173,
      "grad_norm": 4.077153205871582,
      "learning_rate": 6.914129586328278e-06,
      "loss": 0.4023219108581543,
      "memory(GiB)": 72.72,
      "step": 21775,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.251788
    },
    {
      "epoch": 2.03152690980319,
      "grad_norm": 6.840610504150391,
      "learning_rate": 6.912704691808684e-06,
      "loss": 0.42179012298583984,
      "memory(GiB)": 72.72,
      "step": 21780,
      "token_acc": 0.9529411764705882,
      "train_speed(iter/s)": 0.251792
    },
    {
      "epoch": 2.031993284208563,
      "grad_norm": 5.444644927978516,
      "learning_rate": 6.911279615301131e-06,
      "loss": 0.43405561447143554,
      "memory(GiB)": 72.72,
      "step": 21785,
      "token_acc": 0.9439252336448598,
      "train_speed(iter/s)": 0.251795
    },
    {
      "epoch": 2.032459658613935,
      "grad_norm": 5.073716163635254,
      "learning_rate": 6.909854356941209e-06,
      "loss": 0.43184452056884765,
      "memory(GiB)": 72.72,
      "step": 21790,
      "token_acc": 0.9649122807017544,
      "train_speed(iter/s)": 0.251792
    },
    {
      "epoch": 2.032926033019308,
      "grad_norm": 4.387089252471924,
      "learning_rate": 6.90842891686453e-06,
      "loss": 0.42370333671569826,
      "memory(GiB)": 72.72,
      "step": 21795,
      "token_acc": 0.4126984126984127,
      "train_speed(iter/s)": 0.25179
    },
    {
      "epoch": 2.0333924074246807,
      "grad_norm": 3.034679889678955,
      "learning_rate": 6.907003295206718e-06,
      "loss": 0.42627997398376466,
      "memory(GiB)": 72.72,
      "step": 21800,
      "token_acc": 0.5642857142857143,
      "train_speed(iter/s)": 0.251788
    },
    {
      "epoch": 2.033858781830053,
      "grad_norm": 3.2614214420318604,
      "learning_rate": 6.9055774921034165e-06,
      "loss": 0.40869340896606443,
      "memory(GiB)": 72.72,
      "step": 21805,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251787
    },
    {
      "epoch": 2.034325156235426,
      "grad_norm": 3.6594786643981934,
      "learning_rate": 6.904151507690287e-06,
      "loss": 0.4145792484283447,
      "memory(GiB)": 72.72,
      "step": 21810,
      "train_speed(iter/s)": 0.251785
    },
    {
      "epoch": 2.0347915306407987,
      "grad_norm": 3.0471930503845215,
      "learning_rate": 6.902725342103008e-06,
      "loss": 0.41008706092834474,
      "memory(GiB)": 72.72,
      "step": 21815,
      "token_acc": 0.9532710280373832,
      "train_speed(iter/s)": 0.251782
    },
    {
      "epoch": 2.035257905046171,
      "grad_norm": 4.585639953613281,
      "learning_rate": 6.9012989954772744e-06,
      "loss": 0.406927490234375,
      "memory(GiB)": 72.72,
      "step": 21820,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.251783
    },
    {
      "epoch": 2.0357242794515438,
      "grad_norm": 4.107143878936768,
      "learning_rate": 6.899872467948798e-06,
      "loss": 0.40916714668273924,
      "memory(GiB)": 72.72,
      "step": 21825,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251786
    },
    {
      "epoch": 2.0361906538569166,
      "grad_norm": 4.1958160400390625,
      "learning_rate": 6.898445759653309e-06,
      "loss": 0.39447410106658937,
      "memory(GiB)": 72.72,
      "step": 21830,
      "train_speed(iter/s)": 0.251787
    },
    {
      "epoch": 2.036657028262289,
      "grad_norm": 8.374794006347656,
      "learning_rate": 6.8970188707265555e-06,
      "loss": 0.3761174201965332,
      "memory(GiB)": 72.72,
      "step": 21835,
      "token_acc": 0.5847457627118644,
      "train_speed(iter/s)": 0.25179
    },
    {
      "epoch": 2.0371234026676617,
      "grad_norm": 2.8836705684661865,
      "learning_rate": 6.895591801304299e-06,
      "loss": 0.3652310609817505,
      "memory(GiB)": 72.72,
      "step": 21840,
      "token_acc": 0.5277777777777778,
      "train_speed(iter/s)": 0.251793
    },
    {
      "epoch": 2.037589777073034,
      "grad_norm": 2.7794582843780518,
      "learning_rate": 6.894164551522322e-06,
      "loss": 0.3994934558868408,
      "memory(GiB)": 72.72,
      "step": 21845,
      "train_speed(iter/s)": 0.251793
    },
    {
      "epoch": 2.038056151478407,
      "grad_norm": 3.188615560531616,
      "learning_rate": 6.892737121516424e-06,
      "loss": 0.43988633155822754,
      "memory(GiB)": 72.72,
      "step": 21850,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251793
    },
    {
      "epoch": 2.0385225258837796,
      "grad_norm": 2.7171406745910645,
      "learning_rate": 6.891309511422419e-06,
      "loss": 0.3820629119873047,
      "memory(GiB)": 72.72,
      "step": 21855,
      "train_speed(iter/s)": 0.251793
    },
    {
      "epoch": 2.038988900289152,
      "grad_norm": 3.662950277328491,
      "learning_rate": 6.889881721376139e-06,
      "loss": 0.3818298578262329,
      "memory(GiB)": 72.72,
      "step": 21860,
      "token_acc": 0.5616438356164384,
      "train_speed(iter/s)": 0.251795
    },
    {
      "epoch": 2.0394552746945247,
      "grad_norm": 3.9813730716705322,
      "learning_rate": 6.888453751513437e-06,
      "loss": 0.38176865577697755,
      "memory(GiB)": 72.72,
      "step": 21865,
      "train_speed(iter/s)": 0.2518
    },
    {
      "epoch": 2.0399216490998975,
      "grad_norm": 3.09440016746521,
      "learning_rate": 6.887025601970178e-06,
      "loss": 0.4224998950958252,
      "memory(GiB)": 72.72,
      "step": 21870,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251795
    },
    {
      "epoch": 2.04038802350527,
      "grad_norm": 4.750086784362793,
      "learning_rate": 6.885597272882246e-06,
      "loss": 0.40888247489929197,
      "memory(GiB)": 72.72,
      "step": 21875,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.251796
    },
    {
      "epoch": 2.0408543979106426,
      "grad_norm": 3.0902018547058105,
      "learning_rate": 6.884168764385541e-06,
      "loss": 0.42772741317749025,
      "memory(GiB)": 72.72,
      "step": 21880,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.2518
    },
    {
      "epoch": 2.0413207723160154,
      "grad_norm": 3.0514705181121826,
      "learning_rate": 6.882740076615985e-06,
      "loss": 0.4270869255065918,
      "memory(GiB)": 72.72,
      "step": 21885,
      "train_speed(iter/s)": 0.251802
    },
    {
      "epoch": 2.0417871467213877,
      "grad_norm": 4.101802349090576,
      "learning_rate": 6.881311209709508e-06,
      "loss": 0.3850371837615967,
      "memory(GiB)": 72.72,
      "step": 21890,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.2518
    },
    {
      "epoch": 2.0422535211267605,
      "grad_norm": 46.15728759765625,
      "learning_rate": 6.879882163802066e-06,
      "loss": 0.46585755348205565,
      "memory(GiB)": 72.72,
      "step": 21895,
      "token_acc": 0.34,
      "train_speed(iter/s)": 0.251802
    },
    {
      "epoch": 2.0427198955321333,
      "grad_norm": 2.2547876834869385,
      "learning_rate": 6.8784529390296275e-06,
      "loss": 0.4153151988983154,
      "memory(GiB)": 72.72,
      "step": 21900,
      "train_speed(iter/s)": 0.251804
    },
    {
      "epoch": 2.0431862699375056,
      "grad_norm": 3.5037028789520264,
      "learning_rate": 6.8770235355281775e-06,
      "loss": 0.44181270599365235,
      "memory(GiB)": 72.72,
      "step": 21905,
      "train_speed(iter/s)": 0.251803
    },
    {
      "epoch": 2.0436526443428784,
      "grad_norm": 3.1511483192443848,
      "learning_rate": 6.875593953433721e-06,
      "loss": 0.39051802158355714,
      "memory(GiB)": 72.72,
      "step": 21910,
      "train_speed(iter/s)": 0.251804
    },
    {
      "epoch": 2.044119018748251,
      "grad_norm": 3.443286657333374,
      "learning_rate": 6.874164192882279e-06,
      "loss": 0.37925479412078855,
      "memory(GiB)": 72.72,
      "step": 21915,
      "token_acc": 0.45614035087719296,
      "train_speed(iter/s)": 0.251806
    },
    {
      "epoch": 2.0445853931536235,
      "grad_norm": 3.694074869155884,
      "learning_rate": 6.872734254009886e-06,
      "loss": 0.3901166200637817,
      "memory(GiB)": 72.72,
      "step": 21920,
      "train_speed(iter/s)": 0.251809
    },
    {
      "epoch": 2.0450517675589963,
      "grad_norm": 5.68799352645874,
      "learning_rate": 6.871304136952598e-06,
      "loss": 0.35788784027099607,
      "memory(GiB)": 72.72,
      "step": 21925,
      "train_speed(iter/s)": 0.251809
    },
    {
      "epoch": 2.045518141964369,
      "grad_norm": 3.6107823848724365,
      "learning_rate": 6.869873841846486e-06,
      "loss": 0.4031551361083984,
      "memory(GiB)": 72.72,
      "step": 21930,
      "train_speed(iter/s)": 0.251811
    },
    {
      "epoch": 2.0459845163697414,
      "grad_norm": 4.413819313049316,
      "learning_rate": 6.868443368827638e-06,
      "loss": 0.42414150238037107,
      "memory(GiB)": 72.72,
      "step": 21935,
      "token_acc": 0.5111111111111111,
      "train_speed(iter/s)": 0.251814
    },
    {
      "epoch": 2.046450890775114,
      "grad_norm": 3.4791433811187744,
      "learning_rate": 6.8670127180321596e-06,
      "loss": 0.4058207035064697,
      "memory(GiB)": 72.72,
      "step": 21940,
      "token_acc": 0.8,
      "train_speed(iter/s)": 0.251814
    },
    {
      "epoch": 2.046917265180487,
      "grad_norm": 3.814598798751831,
      "learning_rate": 6.865581889596174e-06,
      "loss": 0.3913844108581543,
      "memory(GiB)": 72.72,
      "step": 21945,
      "token_acc": 0.5982142857142857,
      "train_speed(iter/s)": 0.251817
    },
    {
      "epoch": 2.0473836395858593,
      "grad_norm": 3.222160816192627,
      "learning_rate": 6.864150883655818e-06,
      "loss": 0.4095569133758545,
      "memory(GiB)": 72.72,
      "step": 21950,
      "train_speed(iter/s)": 0.251815
    },
    {
      "epoch": 2.047850013991232,
      "grad_norm": 8.543272972106934,
      "learning_rate": 6.8627197003472465e-06,
      "loss": 0.38802375793457033,
      "memory(GiB)": 72.72,
      "step": 21955,
      "train_speed(iter/s)": 0.251814
    },
    {
      "epoch": 2.048316388396605,
      "grad_norm": 3.333927631378174,
      "learning_rate": 6.8612883398066346e-06,
      "loss": 0.37064051628112793,
      "memory(GiB)": 72.72,
      "step": 21960,
      "train_speed(iter/s)": 0.251813
    },
    {
      "epoch": 2.0487827628019772,
      "grad_norm": 3.726275682449341,
      "learning_rate": 6.859856802170171e-06,
      "loss": 0.4546614170074463,
      "memory(GiB)": 72.72,
      "step": 21965,
      "train_speed(iter/s)": 0.25181
    },
    {
      "epoch": 2.04924913720735,
      "grad_norm": 3.7772555351257324,
      "learning_rate": 6.858425087574063e-06,
      "loss": 0.4030323028564453,
      "memory(GiB)": 72.72,
      "step": 21970,
      "token_acc": 0.9294117647058824,
      "train_speed(iter/s)": 0.251811
    },
    {
      "epoch": 2.049715511612723,
      "grad_norm": 3.6002368927001953,
      "learning_rate": 6.856993196154531e-06,
      "loss": 0.3962737560272217,
      "memory(GiB)": 72.72,
      "step": 21975,
      "train_speed(iter/s)": 0.251809
    },
    {
      "epoch": 2.050181886018095,
      "grad_norm": 2.523484706878662,
      "learning_rate": 6.855561128047819e-06,
      "loss": 0.4148531436920166,
      "memory(GiB)": 72.72,
      "step": 21980,
      "token_acc": 0.36538461538461536,
      "train_speed(iter/s)": 0.25181
    },
    {
      "epoch": 2.050648260423468,
      "grad_norm": 6.150594711303711,
      "learning_rate": 6.854128883390181e-06,
      "loss": 0.3646132469177246,
      "memory(GiB)": 72.72,
      "step": 21985,
      "token_acc": 0.6052631578947368,
      "train_speed(iter/s)": 0.251811
    },
    {
      "epoch": 2.0511146348288407,
      "grad_norm": 4.279210567474365,
      "learning_rate": 6.852696462317891e-06,
      "loss": 0.3951008081436157,
      "memory(GiB)": 72.72,
      "step": 21990,
      "token_acc": 0.4594594594594595,
      "train_speed(iter/s)": 0.251813
    },
    {
      "epoch": 2.051581009234213,
      "grad_norm": 2.696472644805908,
      "learning_rate": 6.8512638649672415e-06,
      "loss": 0.3471372127532959,
      "memory(GiB)": 72.72,
      "step": 21995,
      "train_speed(iter/s)": 0.251812
    },
    {
      "epoch": 2.052047383639586,
      "grad_norm": 3.816150188446045,
      "learning_rate": 6.849831091474537e-06,
      "loss": 0.3926517963409424,
      "memory(GiB)": 72.72,
      "step": 22000,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.25181
    },
    {
      "epoch": 2.0525137580449586,
      "grad_norm": 6.600322246551514,
      "learning_rate": 6.848398141976103e-06,
      "loss": 0.39976837635040285,
      "memory(GiB)": 72.72,
      "step": 22005,
      "train_speed(iter/s)": 0.251707
    },
    {
      "epoch": 2.052980132450331,
      "grad_norm": 2.5495738983154297,
      "learning_rate": 6.84696501660828e-06,
      "loss": 0.3680314540863037,
      "memory(GiB)": 72.72,
      "step": 22010,
      "token_acc": 0.631578947368421,
      "train_speed(iter/s)": 0.251707
    },
    {
      "epoch": 2.0534465068557037,
      "grad_norm": 4.020017623901367,
      "learning_rate": 6.845531715507426e-06,
      "loss": 0.38660564422607424,
      "memory(GiB)": 72.72,
      "step": 22015,
      "train_speed(iter/s)": 0.251706
    },
    {
      "epoch": 2.0539128812610765,
      "grad_norm": 4.243447303771973,
      "learning_rate": 6.844098238809914e-06,
      "loss": 0.4206245422363281,
      "memory(GiB)": 72.72,
      "step": 22020,
      "train_speed(iter/s)": 0.251708
    },
    {
      "epoch": 2.054379255666449,
      "grad_norm": 2.976271629333496,
      "learning_rate": 6.842664586652135e-06,
      "loss": 0.3998111248016357,
      "memory(GiB)": 72.72,
      "step": 22025,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251707
    },
    {
      "epoch": 2.0548456300718216,
      "grad_norm": 4.8336639404296875,
      "learning_rate": 6.841230759170498e-06,
      "loss": 0.40618505477905276,
      "memory(GiB)": 72.72,
      "step": 22030,
      "train_speed(iter/s)": 0.251711
    },
    {
      "epoch": 2.0553120044771944,
      "grad_norm": 3.4136948585510254,
      "learning_rate": 6.839796756501425e-06,
      "loss": 0.39591896533966064,
      "memory(GiB)": 72.72,
      "step": 22035,
      "train_speed(iter/s)": 0.251712
    },
    {
      "epoch": 2.0557783788825668,
      "grad_norm": 3.4298691749572754,
      "learning_rate": 6.838362578781359e-06,
      "loss": 0.41930618286132815,
      "memory(GiB)": 72.72,
      "step": 22040,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.25171
    },
    {
      "epoch": 2.0562447532879395,
      "grad_norm": 5.2851643562316895,
      "learning_rate": 6.836928226146757e-06,
      "loss": 0.4423304557800293,
      "memory(GiB)": 72.72,
      "step": 22045,
      "train_speed(iter/s)": 0.251713
    },
    {
      "epoch": 2.0567111276933123,
      "grad_norm": 4.4390363693237305,
      "learning_rate": 6.835493698734093e-06,
      "loss": 0.4364316940307617,
      "memory(GiB)": 72.72,
      "step": 22050,
      "token_acc": 0.7433155080213903,
      "train_speed(iter/s)": 0.25171
    },
    {
      "epoch": 2.0571775020986847,
      "grad_norm": 2.6852331161499023,
      "learning_rate": 6.834058996679858e-06,
      "loss": 0.3804923057556152,
      "memory(GiB)": 72.72,
      "step": 22055,
      "train_speed(iter/s)": 0.251708
    },
    {
      "epoch": 2.0576438765040574,
      "grad_norm": 4.1610307693481445,
      "learning_rate": 6.832624120120558e-06,
      "loss": 0.40880842208862306,
      "memory(GiB)": 72.72,
      "step": 22060,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.25171
    },
    {
      "epoch": 2.0581102509094302,
      "grad_norm": 9.738165855407715,
      "learning_rate": 6.831189069192721e-06,
      "loss": 0.37703514099121094,
      "memory(GiB)": 72.72,
      "step": 22065,
      "train_speed(iter/s)": 0.251712
    },
    {
      "epoch": 2.0585766253148026,
      "grad_norm": 3.181356191635132,
      "learning_rate": 6.829753844032884e-06,
      "loss": 0.3822184562683105,
      "memory(GiB)": 72.72,
      "step": 22070,
      "token_acc": 0.7692307692307693,
      "train_speed(iter/s)": 0.251719
    },
    {
      "epoch": 2.0590429997201753,
      "grad_norm": 3.3918654918670654,
      "learning_rate": 6.828318444777604e-06,
      "loss": 0.408402681350708,
      "memory(GiB)": 72.72,
      "step": 22075,
      "train_speed(iter/s)": 0.251715
    },
    {
      "epoch": 2.059509374125548,
      "grad_norm": 3.4625775814056396,
      "learning_rate": 6.826882871563458e-06,
      "loss": 0.3891527414321899,
      "memory(GiB)": 72.72,
      "step": 22080,
      "train_speed(iter/s)": 0.251717
    },
    {
      "epoch": 2.0599757485309205,
      "grad_norm": 4.2633490562438965,
      "learning_rate": 6.825447124527035e-06,
      "loss": 0.38238024711608887,
      "memory(GiB)": 72.72,
      "step": 22085,
      "train_speed(iter/s)": 0.251716
    },
    {
      "epoch": 2.0604421229362933,
      "grad_norm": 3.6502528190612793,
      "learning_rate": 6.824011203804941e-06,
      "loss": 0.4215736389160156,
      "memory(GiB)": 72.72,
      "step": 22090,
      "train_speed(iter/s)": 0.251717
    },
    {
      "epoch": 2.060908497341666,
      "grad_norm": 3.9022908210754395,
      "learning_rate": 6.8225751095338e-06,
      "loss": 0.40193681716918944,
      "memory(GiB)": 72.72,
      "step": 22095,
      "train_speed(iter/s)": 0.251718
    },
    {
      "epoch": 2.0613748717470384,
      "grad_norm": 3.9982030391693115,
      "learning_rate": 6.821138841850251e-06,
      "loss": 0.41916141510009763,
      "memory(GiB)": 72.72,
      "step": 22100,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.251714
    },
    {
      "epoch": 2.061841246152411,
      "grad_norm": 4.752323627471924,
      "learning_rate": 6.819702400890952e-06,
      "loss": 0.41402268409729004,
      "memory(GiB)": 72.72,
      "step": 22105,
      "train_speed(iter/s)": 0.2517
    },
    {
      "epoch": 2.062307620557784,
      "grad_norm": 9.130350112915039,
      "learning_rate": 6.818265786792575e-06,
      "loss": 0.42052202224731444,
      "memory(GiB)": 72.72,
      "step": 22110,
      "token_acc": 0.6545454545454545,
      "train_speed(iter/s)": 0.251692
    },
    {
      "epoch": 2.0627739949631563,
      "grad_norm": 3.5971570014953613,
      "learning_rate": 6.816828999691811e-06,
      "loss": 0.3818973064422607,
      "memory(GiB)": 72.72,
      "step": 22115,
      "train_speed(iter/s)": 0.251687
    },
    {
      "epoch": 2.063240369368529,
      "grad_norm": 2.77030086517334,
      "learning_rate": 6.815392039725364e-06,
      "loss": 0.39141039848327636,
      "memory(GiB)": 72.72,
      "step": 22120,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.251687
    },
    {
      "epoch": 2.063706743773902,
      "grad_norm": 5.812612056732178,
      "learning_rate": 6.813954907029956e-06,
      "loss": 0.43822503089904785,
      "memory(GiB)": 72.72,
      "step": 22125,
      "token_acc": 0.5510204081632653,
      "train_speed(iter/s)": 0.251688
    },
    {
      "epoch": 2.064173118179274,
      "grad_norm": 3.190365791320801,
      "learning_rate": 6.8125176017423255e-06,
      "loss": 0.4011248588562012,
      "memory(GiB)": 72.72,
      "step": 22130,
      "token_acc": 0.2903225806451613,
      "train_speed(iter/s)": 0.251689
    },
    {
      "epoch": 2.064639492584647,
      "grad_norm": 3.067565679550171,
      "learning_rate": 6.811080123999231e-06,
      "loss": 0.39781486988067627,
      "memory(GiB)": 72.72,
      "step": 22135,
      "token_acc": 0.68,
      "train_speed(iter/s)": 0.251686
    },
    {
      "epoch": 2.0651058669900197,
      "grad_norm": 2.6173624992370605,
      "learning_rate": 6.809642473937441e-06,
      "loss": 0.37557220458984375,
      "memory(GiB)": 72.72,
      "step": 22140,
      "token_acc": 0.9215686274509803,
      "train_speed(iter/s)": 0.251685
    },
    {
      "epoch": 2.065572241395392,
      "grad_norm": 2.7625467777252197,
      "learning_rate": 6.808204651693745e-06,
      "loss": 0.38684046268463135,
      "memory(GiB)": 72.72,
      "step": 22145,
      "train_speed(iter/s)": 0.251686
    },
    {
      "epoch": 2.066038615800765,
      "grad_norm": 4.100198268890381,
      "learning_rate": 6.806766657404946e-06,
      "loss": 0.4079941749572754,
      "memory(GiB)": 72.72,
      "step": 22150,
      "token_acc": 0.9469026548672567,
      "train_speed(iter/s)": 0.251682
    },
    {
      "epoch": 2.0665049902061376,
      "grad_norm": 8.180336952209473,
      "learning_rate": 6.805328491207865e-06,
      "loss": 0.4583451271057129,
      "memory(GiB)": 72.72,
      "step": 22155,
      "token_acc": 0.582089552238806,
      "train_speed(iter/s)": 0.25168
    },
    {
      "epoch": 2.06697136461151,
      "grad_norm": 3.6715214252471924,
      "learning_rate": 6.8038901532393405e-06,
      "loss": 0.40345191955566406,
      "memory(GiB)": 72.72,
      "step": 22160,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.25168
    },
    {
      "epoch": 2.0674377390168828,
      "grad_norm": 3.1458117961883545,
      "learning_rate": 6.802451643636226e-06,
      "loss": 0.3754962205886841,
      "memory(GiB)": 72.72,
      "step": 22165,
      "train_speed(iter/s)": 0.251681
    },
    {
      "epoch": 2.0679041134222556,
      "grad_norm": 4.60437536239624,
      "learning_rate": 6.801012962535388e-06,
      "loss": 0.40294737815856935,
      "memory(GiB)": 72.72,
      "step": 22170,
      "train_speed(iter/s)": 0.251677
    },
    {
      "epoch": 2.068370487827628,
      "grad_norm": 5.559909343719482,
      "learning_rate": 6.799574110073717e-06,
      "loss": 0.41247782707214353,
      "memory(GiB)": 72.72,
      "step": 22175,
      "token_acc": 0.4594594594594595,
      "train_speed(iter/s)": 0.251679
    },
    {
      "epoch": 2.0688368622330007,
      "grad_norm": 4.268206596374512,
      "learning_rate": 6.79813508638811e-06,
      "loss": 0.3808527946472168,
      "memory(GiB)": 72.72,
      "step": 22180,
      "train_speed(iter/s)": 0.251677
    },
    {
      "epoch": 2.0693032366383735,
      "grad_norm": 3.426449775695801,
      "learning_rate": 6.7966958916154915e-06,
      "loss": 0.43149938583374026,
      "memory(GiB)": 72.72,
      "step": 22185,
      "train_speed(iter/s)": 0.251677
    },
    {
      "epoch": 2.069769611043746,
      "grad_norm": 3.7051000595092773,
      "learning_rate": 6.795256525892793e-06,
      "loss": 0.43685050010681153,
      "memory(GiB)": 72.72,
      "step": 22190,
      "token_acc": 0.4369747899159664,
      "train_speed(iter/s)": 0.251677
    },
    {
      "epoch": 2.0702359854491186,
      "grad_norm": 4.9918599128723145,
      "learning_rate": 6.793816989356966e-06,
      "loss": 0.3256171703338623,
      "memory(GiB)": 72.72,
      "step": 22195,
      "token_acc": 0.7972027972027972,
      "train_speed(iter/s)": 0.251678
    },
    {
      "epoch": 2.0707023598544914,
      "grad_norm": 3.971173048019409,
      "learning_rate": 6.792377282144978e-06,
      "loss": 0.38135585784912107,
      "memory(GiB)": 72.72,
      "step": 22200,
      "token_acc": 0.627906976744186,
      "train_speed(iter/s)": 0.251675
    },
    {
      "epoch": 2.0711687342598637,
      "grad_norm": 2.8376481533050537,
      "learning_rate": 6.790937404393815e-06,
      "loss": 0.38701820373535156,
      "memory(GiB)": 72.72,
      "step": 22205,
      "token_acc": 0.4411764705882353,
      "train_speed(iter/s)": 0.251678
    },
    {
      "epoch": 2.0716351086652365,
      "grad_norm": 6.070639133453369,
      "learning_rate": 6.789497356240473e-06,
      "loss": 0.4132472038269043,
      "memory(GiB)": 72.72,
      "step": 22210,
      "train_speed(iter/s)": 0.251675
    },
    {
      "epoch": 2.0721014830706093,
      "grad_norm": 2.9187707901000977,
      "learning_rate": 6.788057137821973e-06,
      "loss": 0.4494288444519043,
      "memory(GiB)": 72.72,
      "step": 22215,
      "train_speed(iter/s)": 0.251678
    },
    {
      "epoch": 2.0725678574759816,
      "grad_norm": 5.0619964599609375,
      "learning_rate": 6.7866167492753425e-06,
      "loss": 0.3536978721618652,
      "memory(GiB)": 72.72,
      "step": 22220,
      "token_acc": 0.8012820512820513,
      "train_speed(iter/s)": 0.251676
    },
    {
      "epoch": 2.0730342318813544,
      "grad_norm": 5.228015899658203,
      "learning_rate": 6.785176190737632e-06,
      "loss": 0.3979053974151611,
      "memory(GiB)": 72.72,
      "step": 22225,
      "token_acc": 0.5806451612903226,
      "train_speed(iter/s)": 0.251681
    },
    {
      "epoch": 2.073500606286727,
      "grad_norm": 2.7287986278533936,
      "learning_rate": 6.783735462345906e-06,
      "loss": 0.4052267074584961,
      "memory(GiB)": 72.72,
      "step": 22230,
      "train_speed(iter/s)": 0.25168
    },
    {
      "epoch": 2.0739669806920995,
      "grad_norm": 2.7729287147521973,
      "learning_rate": 6.782294564237246e-06,
      "loss": 0.3769470930099487,
      "memory(GiB)": 72.72,
      "step": 22235,
      "token_acc": 0.8503401360544217,
      "train_speed(iter/s)": 0.251679
    },
    {
      "epoch": 2.0744333550974723,
      "grad_norm": 7.41016149520874,
      "learning_rate": 6.780853496548752e-06,
      "loss": 0.38630836009979247,
      "memory(GiB)": 72.72,
      "step": 22240,
      "train_speed(iter/s)": 0.251678
    },
    {
      "epoch": 2.074899729502845,
      "grad_norm": 2.2427918910980225,
      "learning_rate": 6.779412259417529e-06,
      "loss": 0.41419687271118166,
      "memory(GiB)": 72.72,
      "step": 22245,
      "train_speed(iter/s)": 0.251674
    },
    {
      "epoch": 2.0753661039082174,
      "grad_norm": 2.234482765197754,
      "learning_rate": 6.777970852980713e-06,
      "loss": 0.3643545627593994,
      "memory(GiB)": 72.72,
      "step": 22250,
      "train_speed(iter/s)": 0.251675
    },
    {
      "epoch": 2.07583247831359,
      "grad_norm": 5.034802436828613,
      "learning_rate": 6.776529277375449e-06,
      "loss": 0.40754170417785646,
      "memory(GiB)": 72.72,
      "step": 22255,
      "train_speed(iter/s)": 0.251673
    },
    {
      "epoch": 2.076298852718963,
      "grad_norm": 4.565492153167725,
      "learning_rate": 6.7750875327388955e-06,
      "loss": 0.4137849807739258,
      "memory(GiB)": 72.72,
      "step": 22260,
      "token_acc": 0.4536082474226804,
      "train_speed(iter/s)": 0.251676
    },
    {
      "epoch": 2.0767652271243353,
      "grad_norm": 2.813922166824341,
      "learning_rate": 6.7736456192082314e-06,
      "loss": 0.41983442306518554,
      "memory(GiB)": 72.72,
      "step": 22265,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.251676
    },
    {
      "epoch": 2.077231601529708,
      "grad_norm": 3.4409713745117188,
      "learning_rate": 6.7722035369206505e-06,
      "loss": 0.4352858543395996,
      "memory(GiB)": 72.72,
      "step": 22270,
      "train_speed(iter/s)": 0.251677
    },
    {
      "epoch": 2.077697975935081,
      "grad_norm": 3.3104233741760254,
      "learning_rate": 6.770761286013363e-06,
      "loss": 0.411672306060791,
      "memory(GiB)": 72.72,
      "step": 22275,
      "train_speed(iter/s)": 0.251679
    },
    {
      "epoch": 2.078164350340453,
      "grad_norm": 2.306894540786743,
      "learning_rate": 6.7693188666235935e-06,
      "loss": 0.42807741165161134,
      "memory(GiB)": 72.72,
      "step": 22280,
      "train_speed(iter/s)": 0.25168
    },
    {
      "epoch": 2.078630724745826,
      "grad_norm": 3.4352846145629883,
      "learning_rate": 6.767876278888586e-06,
      "loss": 0.4149614334106445,
      "memory(GiB)": 72.72,
      "step": 22285,
      "train_speed(iter/s)": 0.251563
    },
    {
      "epoch": 2.079097099151199,
      "grad_norm": 3.0893688201904297,
      "learning_rate": 6.766433522945596e-06,
      "loss": 0.43825788497924806,
      "memory(GiB)": 72.72,
      "step": 22290,
      "token_acc": 0.9587628865979382,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.079563473556571,
      "grad_norm": 3.3901584148406982,
      "learning_rate": 6.764990598931895e-06,
      "loss": 0.3795615196228027,
      "memory(GiB)": 72.72,
      "step": 22295,
      "train_speed(iter/s)": 0.251557
    },
    {
      "epoch": 2.080029847961944,
      "grad_norm": 2.8943793773651123,
      "learning_rate": 6.763547506984779e-06,
      "loss": 0.4138930320739746,
      "memory(GiB)": 72.72,
      "step": 22300,
      "train_speed(iter/s)": 0.251556
    },
    {
      "epoch": 2.0804962223673167,
      "grad_norm": 4.225114822387695,
      "learning_rate": 6.76210424724155e-06,
      "loss": 0.4343252182006836,
      "memory(GiB)": 72.72,
      "step": 22305,
      "train_speed(iter/s)": 0.251554
    },
    {
      "epoch": 2.080962596772689,
      "grad_norm": 3.0818278789520264,
      "learning_rate": 6.76066081983953e-06,
      "loss": 0.37875564098358155,
      "memory(GiB)": 72.72,
      "step": 22310,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.081428971178062,
      "grad_norm": 3.382606029510498,
      "learning_rate": 6.759217224916056e-06,
      "loss": 0.4051209926605225,
      "memory(GiB)": 72.72,
      "step": 22315,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.0818953455834346,
      "grad_norm": 4.057602882385254,
      "learning_rate": 6.7577734626084835e-06,
      "loss": 0.40558681488037107,
      "memory(GiB)": 72.72,
      "step": 22320,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.082361719988807,
      "grad_norm": 3.2609875202178955,
      "learning_rate": 6.75632953305418e-06,
      "loss": 0.39864506721496584,
      "memory(GiB)": 72.72,
      "step": 22325,
      "train_speed(iter/s)": 0.251555
    },
    {
      "epoch": 2.0828280943941797,
      "grad_norm": 3.8267385959625244,
      "learning_rate": 6.754885436390532e-06,
      "loss": 0.4128258228302002,
      "memory(GiB)": 72.72,
      "step": 22330,
      "train_speed(iter/s)": 0.251559
    },
    {
      "epoch": 2.0832944687995525,
      "grad_norm": 4.204024314880371,
      "learning_rate": 6.753441172754941e-06,
      "loss": 0.4080328941345215,
      "memory(GiB)": 72.72,
      "step": 22335,
      "train_speed(iter/s)": 0.251557
    },
    {
      "epoch": 2.083760843204925,
      "grad_norm": 3.4180803298950195,
      "learning_rate": 6.751996742284825e-06,
      "loss": 0.3488345146179199,
      "memory(GiB)": 72.72,
      "step": 22340,
      "token_acc": 0.4222222222222222,
      "train_speed(iter/s)": 0.25156
    },
    {
      "epoch": 2.0842272176102976,
      "grad_norm": 3.7791292667388916,
      "learning_rate": 6.7505521451176145e-06,
      "loss": 0.4151947021484375,
      "memory(GiB)": 72.72,
      "step": 22345,
      "train_speed(iter/s)": 0.251562
    },
    {
      "epoch": 2.0846935920156704,
      "grad_norm": 2.9040868282318115,
      "learning_rate": 6.749107381390761e-06,
      "loss": 0.43416519165039064,
      "memory(GiB)": 72.72,
      "step": 22350,
      "train_speed(iter/s)": 0.251564
    },
    {
      "epoch": 2.0851599664210427,
      "grad_norm": 3.2432703971862793,
      "learning_rate": 6.747662451241728e-06,
      "loss": 0.39493646621704104,
      "memory(GiB)": 72.72,
      "step": 22355,
      "token_acc": 0.49230769230769234,
      "train_speed(iter/s)": 0.251564
    },
    {
      "epoch": 2.0856263408264155,
      "grad_norm": 3.5288262367248535,
      "learning_rate": 6.746217354807998e-06,
      "loss": 0.4242264747619629,
      "memory(GiB)": 72.72,
      "step": 22360,
      "token_acc": 0.3695652173913043,
      "train_speed(iter/s)": 0.251561
    },
    {
      "epoch": 2.0860927152317883,
      "grad_norm": 3.612299680709839,
      "learning_rate": 6.744772092227064e-06,
      "loss": 0.35970654487609866,
      "memory(GiB)": 72.72,
      "step": 22365,
      "train_speed(iter/s)": 0.251564
    },
    {
      "epoch": 2.0865590896371606,
      "grad_norm": 2.6540350914001465,
      "learning_rate": 6.743326663636441e-06,
      "loss": 0.3764496803283691,
      "memory(GiB)": 72.72,
      "step": 22370,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251566
    },
    {
      "epoch": 2.0870254640425334,
      "grad_norm": 4.69877815246582,
      "learning_rate": 6.741881069173657e-06,
      "loss": 0.3793079376220703,
      "memory(GiB)": 72.72,
      "step": 22375,
      "train_speed(iter/s)": 0.251564
    },
    {
      "epoch": 2.0874918384479058,
      "grad_norm": 2.354255199432373,
      "learning_rate": 6.740435308976254e-06,
      "loss": 0.42736520767211916,
      "memory(GiB)": 72.72,
      "step": 22380,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.251561
    },
    {
      "epoch": 2.0879582128532785,
      "grad_norm": 8.776250839233398,
      "learning_rate": 6.738989383181794e-06,
      "loss": 0.44620542526245116,
      "memory(GiB)": 72.72,
      "step": 22385,
      "train_speed(iter/s)": 0.251562
    },
    {
      "epoch": 2.0884245872586513,
      "grad_norm": 4.499826431274414,
      "learning_rate": 6.7375432919278525e-06,
      "loss": 0.3916770458221436,
      "memory(GiB)": 72.72,
      "step": 22390,
      "token_acc": 0.603448275862069,
      "train_speed(iter/s)": 0.251562
    },
    {
      "epoch": 2.088890961664024,
      "grad_norm": 14.835665702819824,
      "learning_rate": 6.7360970353520185e-06,
      "loss": 0.4145662307739258,
      "memory(GiB)": 72.72,
      "step": 22395,
      "train_speed(iter/s)": 0.25156
    },
    {
      "epoch": 2.0893573360693964,
      "grad_norm": 2.9804320335388184,
      "learning_rate": 6.734650613591898e-06,
      "loss": 0.43213567733764646,
      "memory(GiB)": 72.72,
      "step": 22400,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.251559
    },
    {
      "epoch": 2.0898237104747692,
      "grad_norm": 5.950758457183838,
      "learning_rate": 6.7332040267851176e-06,
      "loss": 0.38607332706451414,
      "memory(GiB)": 72.72,
      "step": 22405,
      "train_speed(iter/s)": 0.251559
    },
    {
      "epoch": 2.0902900848801416,
      "grad_norm": 2.995485782623291,
      "learning_rate": 6.731757275069312e-06,
      "loss": 0.39485464096069334,
      "memory(GiB)": 72.72,
      "step": 22410,
      "token_acc": 0.9772727272727273,
      "train_speed(iter/s)": 0.251557
    },
    {
      "epoch": 2.0907564592855143,
      "grad_norm": 3.22975492477417,
      "learning_rate": 6.730310358582137e-06,
      "loss": 0.42372517585754393,
      "memory(GiB)": 72.72,
      "step": 22415,
      "train_speed(iter/s)": 0.251555
    },
    {
      "epoch": 2.091222833690887,
      "grad_norm": 4.705389022827148,
      "learning_rate": 6.728863277461262e-06,
      "loss": 0.40966796875,
      "memory(GiB)": 72.72,
      "step": 22420,
      "train_speed(iter/s)": 0.25155
    },
    {
      "epoch": 2.0916892080962595,
      "grad_norm": 3.3910577297210693,
      "learning_rate": 6.727416031844371e-06,
      "loss": 0.4270409107208252,
      "memory(GiB)": 72.72,
      "step": 22425,
      "train_speed(iter/s)": 0.251552
    },
    {
      "epoch": 2.0921555825016322,
      "grad_norm": 4.242955684661865,
      "learning_rate": 6.725968621869167e-06,
      "loss": 0.382104229927063,
      "memory(GiB)": 72.72,
      "step": 22430,
      "train_speed(iter/s)": 0.25155
    },
    {
      "epoch": 2.092621956907005,
      "grad_norm": 2.674546241760254,
      "learning_rate": 6.7245210476733645e-06,
      "loss": 0.4192031383514404,
      "memory(GiB)": 72.72,
      "step": 22435,
      "token_acc": 0.5189873417721519,
      "train_speed(iter/s)": 0.251551
    },
    {
      "epoch": 2.0930883313123774,
      "grad_norm": 4.156280517578125,
      "learning_rate": 6.723073309394698e-06,
      "loss": 0.3421048641204834,
      "memory(GiB)": 72.72,
      "step": 22440,
      "train_speed(iter/s)": 0.25155
    },
    {
      "epoch": 2.09355470571775,
      "grad_norm": 4.134353160858154,
      "learning_rate": 6.721625407170914e-06,
      "loss": 0.3916254997253418,
      "memory(GiB)": 72.72,
      "step": 22445,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.094021080123123,
      "grad_norm": 3.2655434608459473,
      "learning_rate": 6.720177341139775e-06,
      "loss": 0.4119748115539551,
      "memory(GiB)": 72.72,
      "step": 22450,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.0944874545284953,
      "grad_norm": 4.725271701812744,
      "learning_rate": 6.718729111439062e-06,
      "loss": 0.4240208625793457,
      "memory(GiB)": 72.72,
      "step": 22455,
      "train_speed(iter/s)": 0.251552
    },
    {
      "epoch": 2.094953828933868,
      "grad_norm": 6.2631988525390625,
      "learning_rate": 6.717280718206569e-06,
      "loss": 0.4399690628051758,
      "memory(GiB)": 72.72,
      "step": 22460,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.095420203339241,
      "grad_norm": 5.982556343078613,
      "learning_rate": 6.715832161580106e-06,
      "loss": 0.4033773422241211,
      "memory(GiB)": 72.72,
      "step": 22465,
      "token_acc": 0.6097560975609756,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.095886577744613,
      "grad_norm": 3.2190933227539062,
      "learning_rate": 6.714383441697499e-06,
      "loss": 0.39788568019866943,
      "memory(GiB)": 72.72,
      "step": 22470,
      "token_acc": 0.6444444444444445,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.096352952149986,
      "grad_norm": 3.017085313796997,
      "learning_rate": 6.712934558696586e-06,
      "loss": 0.3877806901931763,
      "memory(GiB)": 72.72,
      "step": 22475,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.251552
    },
    {
      "epoch": 2.0968193265553587,
      "grad_norm": 3.8476462364196777,
      "learning_rate": 6.71148551271523e-06,
      "loss": 0.39277215003967286,
      "memory(GiB)": 72.72,
      "step": 22480,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251549
    },
    {
      "epoch": 2.097285700960731,
      "grad_norm": 2.8746988773345947,
      "learning_rate": 6.7100363038912966e-06,
      "loss": 0.4201931953430176,
      "memory(GiB)": 72.72,
      "step": 22485,
      "token_acc": 0.5806451612903226,
      "train_speed(iter/s)": 0.251548
    },
    {
      "epoch": 2.097752075366104,
      "grad_norm": 6.784633636474609,
      "learning_rate": 6.708586932362679e-06,
      "loss": 0.3834473371505737,
      "memory(GiB)": 72.72,
      "step": 22490,
      "token_acc": 0.5405405405405406,
      "train_speed(iter/s)": 0.25155
    },
    {
      "epoch": 2.0982184497714766,
      "grad_norm": 2.744246006011963,
      "learning_rate": 6.707137398267278e-06,
      "loss": 0.39852521419525144,
      "memory(GiB)": 72.72,
      "step": 22495,
      "token_acc": 0.978021978021978,
      "train_speed(iter/s)": 0.251551
    },
    {
      "epoch": 2.098684824176849,
      "grad_norm": 3.6191139221191406,
      "learning_rate": 6.705687701743012e-06,
      "loss": 0.39557828903198244,
      "memory(GiB)": 72.72,
      "step": 22500,
      "train_speed(iter/s)": 0.25155
    },
    {
      "epoch": 2.0991511985822218,
      "grad_norm": 8.764098167419434,
      "learning_rate": 6.704237842927816e-06,
      "loss": 0.4139088153839111,
      "memory(GiB)": 72.72,
      "step": 22505,
      "train_speed(iter/s)": 0.251551
    },
    {
      "epoch": 2.0996175729875945,
      "grad_norm": 4.1011528968811035,
      "learning_rate": 6.70278782195964e-06,
      "loss": 0.40625600814819335,
      "memory(GiB)": 72.72,
      "step": 22510,
      "train_speed(iter/s)": 0.25155
    },
    {
      "epoch": 2.100083947392967,
      "grad_norm": 3.433201789855957,
      "learning_rate": 6.701337638976449e-06,
      "loss": 0.4483771800994873,
      "memory(GiB)": 72.72,
      "step": 22515,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25155
    },
    {
      "epoch": 2.1005503217983397,
      "grad_norm": 2.0768990516662598,
      "learning_rate": 6.6998872941162196e-06,
      "loss": 0.3967411756515503,
      "memory(GiB)": 72.72,
      "step": 22520,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251549
    },
    {
      "epoch": 2.1010166962037125,
      "grad_norm": 3.20989727973938,
      "learning_rate": 6.698436787516953e-06,
      "loss": 0.3696181297302246,
      "memory(GiB)": 72.72,
      "step": 22525,
      "token_acc": 0.9354838709677419,
      "train_speed(iter/s)": 0.25155
    },
    {
      "epoch": 2.101483070609085,
      "grad_norm": 2.9987335205078125,
      "learning_rate": 6.696986119316657e-06,
      "loss": 0.4093238353729248,
      "memory(GiB)": 72.72,
      "step": 22530,
      "token_acc": 0.4074074074074074,
      "train_speed(iter/s)": 0.251549
    },
    {
      "epoch": 2.1019494450144576,
      "grad_norm": 2.853837490081787,
      "learning_rate": 6.695535289653361e-06,
      "loss": 0.3739457607269287,
      "memory(GiB)": 72.72,
      "step": 22535,
      "train_speed(iter/s)": 0.251551
    },
    {
      "epoch": 2.1024158194198304,
      "grad_norm": 3.0142719745635986,
      "learning_rate": 6.694084298665104e-06,
      "loss": 0.38502187728881837,
      "memory(GiB)": 72.72,
      "step": 22540,
      "train_speed(iter/s)": 0.251549
    },
    {
      "epoch": 2.1028821938252027,
      "grad_norm": 3.381704568862915,
      "learning_rate": 6.6926331464899466e-06,
      "loss": 0.3381354331970215,
      "memory(GiB)": 72.72,
      "step": 22545,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251554
    },
    {
      "epoch": 2.1033485682305755,
      "grad_norm": 3.6558430194854736,
      "learning_rate": 6.6911818332659565e-06,
      "loss": 0.3918455123901367,
      "memory(GiB)": 72.72,
      "step": 22550,
      "token_acc": 0.6506024096385542,
      "train_speed(iter/s)": 0.251554
    },
    {
      "epoch": 2.1038149426359483,
      "grad_norm": 4.019551753997803,
      "learning_rate": 6.689730359131227e-06,
      "loss": 0.42851572036743163,
      "memory(GiB)": 72.72,
      "step": 22555,
      "train_speed(iter/s)": 0.251555
    },
    {
      "epoch": 2.1042813170413206,
      "grad_norm": 3.123352527618408,
      "learning_rate": 6.6882787242238576e-06,
      "loss": 0.42453899383544924,
      "memory(GiB)": 72.72,
      "step": 22560,
      "token_acc": 0.5689655172413793,
      "train_speed(iter/s)": 0.251554
    },
    {
      "epoch": 2.1047476914466934,
      "grad_norm": 3.698106050491333,
      "learning_rate": 6.686826928681972e-06,
      "loss": 0.4293067932128906,
      "memory(GiB)": 72.72,
      "step": 22565,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.251554
    },
    {
      "epoch": 2.105214065852066,
      "grad_norm": 4.470458507537842,
      "learning_rate": 6.685374972643697e-06,
      "loss": 0.36115474700927735,
      "memory(GiB)": 72.72,
      "step": 22570,
      "train_speed(iter/s)": 0.251557
    },
    {
      "epoch": 2.1056804402574385,
      "grad_norm": 4.3506693840026855,
      "learning_rate": 6.683922856247187e-06,
      "loss": 0.412870454788208,
      "memory(GiB)": 72.72,
      "step": 22575,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251558
    },
    {
      "epoch": 2.1061468146628113,
      "grad_norm": 4.434484004974365,
      "learning_rate": 6.682470579630603e-06,
      "loss": 0.3954874753952026,
      "memory(GiB)": 72.72,
      "step": 22580,
      "train_speed(iter/s)": 0.251557
    },
    {
      "epoch": 2.106613189068184,
      "grad_norm": 4.365661144256592,
      "learning_rate": 6.681018142932128e-06,
      "loss": 0.40953726768493653,
      "memory(GiB)": 72.72,
      "step": 22585,
      "token_acc": 0.7371794871794872,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.1070795634735564,
      "grad_norm": 4.419863224029541,
      "learning_rate": 6.679565546289954e-06,
      "loss": 0.39967563152313235,
      "memory(GiB)": 72.72,
      "step": 22590,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.251553
    },
    {
      "epoch": 2.107545937878929,
      "grad_norm": 4.778194904327393,
      "learning_rate": 6.678112789842294e-06,
      "loss": 0.4071479797363281,
      "memory(GiB)": 72.72,
      "step": 22595,
      "train_speed(iter/s)": 0.251555
    },
    {
      "epoch": 2.108012312284302,
      "grad_norm": 3.7065529823303223,
      "learning_rate": 6.676659873727369e-06,
      "loss": 0.4308755874633789,
      "memory(GiB)": 72.72,
      "step": 22600,
      "train_speed(iter/s)": 0.251557
    },
    {
      "epoch": 2.1084786866896743,
      "grad_norm": 3.481978178024292,
      "learning_rate": 6.675206798083425e-06,
      "loss": 0.42159647941589357,
      "memory(GiB)": 72.72,
      "step": 22605,
      "train_speed(iter/s)": 0.251561
    },
    {
      "epoch": 2.108945061095047,
      "grad_norm": 3.553769111633301,
      "learning_rate": 6.673753563048713e-06,
      "loss": 0.42333569526672366,
      "memory(GiB)": 72.72,
      "step": 22610,
      "token_acc": 0.43103448275862066,
      "train_speed(iter/s)": 0.251563
    },
    {
      "epoch": 2.10941143550042,
      "grad_norm": 2.6673552989959717,
      "learning_rate": 6.672300168761507e-06,
      "loss": 0.3820242643356323,
      "memory(GiB)": 72.72,
      "step": 22615,
      "train_speed(iter/s)": 0.25156
    },
    {
      "epoch": 2.109877809905792,
      "grad_norm": 3.648076295852661,
      "learning_rate": 6.670846615360089e-06,
      "loss": 0.3840881586074829,
      "memory(GiB)": 72.72,
      "step": 22620,
      "token_acc": 0.9456521739130435,
      "train_speed(iter/s)": 0.251563
    },
    {
      "epoch": 2.110344184311165,
      "grad_norm": 5.167508602142334,
      "learning_rate": 6.669392902982766e-06,
      "loss": 0.44821672439575194,
      "memory(GiB)": 72.72,
      "step": 22625,
      "train_speed(iter/s)": 0.251565
    },
    {
      "epoch": 2.1108105587165378,
      "grad_norm": 4.47637414932251,
      "learning_rate": 6.667939031767848e-06,
      "loss": 0.42068634033203123,
      "memory(GiB)": 72.72,
      "step": 22630,
      "token_acc": 0.575,
      "train_speed(iter/s)": 0.251567
    },
    {
      "epoch": 2.11127693312191,
      "grad_norm": 3.937185287475586,
      "learning_rate": 6.666485001853671e-06,
      "loss": 0.399308967590332,
      "memory(GiB)": 72.72,
      "step": 22635,
      "train_speed(iter/s)": 0.251567
    },
    {
      "epoch": 2.111743307527283,
      "grad_norm": 3.1199731826782227,
      "learning_rate": 6.665030813378579e-06,
      "loss": 0.41861715316772463,
      "memory(GiB)": 72.72,
      "step": 22640,
      "token_acc": 0.32857142857142857,
      "train_speed(iter/s)": 0.251567
    },
    {
      "epoch": 2.1122096819326557,
      "grad_norm": 3.67110013961792,
      "learning_rate": 6.663576466480935e-06,
      "loss": 0.3697640895843506,
      "memory(GiB)": 72.72,
      "step": 22645,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.251568
    },
    {
      "epoch": 2.112676056338028,
      "grad_norm": 3.9024507999420166,
      "learning_rate": 6.662121961299115e-06,
      "loss": 0.4088407516479492,
      "memory(GiB)": 72.72,
      "step": 22650,
      "train_speed(iter/s)": 0.251569
    },
    {
      "epoch": 2.113142430743401,
      "grad_norm": 4.400877952575684,
      "learning_rate": 6.66066729797151e-06,
      "loss": 0.41144580841064454,
      "memory(GiB)": 72.72,
      "step": 22655,
      "token_acc": 0.958904109589041,
      "train_speed(iter/s)": 0.251569
    },
    {
      "epoch": 2.1136088051487736,
      "grad_norm": 2.9117414951324463,
      "learning_rate": 6.659212476636527e-06,
      "loss": 0.43190641403198243,
      "memory(GiB)": 72.72,
      "step": 22660,
      "token_acc": 0.6578947368421053,
      "train_speed(iter/s)": 0.251571
    },
    {
      "epoch": 2.114075179554146,
      "grad_norm": 8.603376388549805,
      "learning_rate": 6.657757497432591e-06,
      "loss": 0.38296048641204833,
      "memory(GiB)": 72.72,
      "step": 22665,
      "token_acc": 0.9358974358974359,
      "train_speed(iter/s)": 0.251572
    },
    {
      "epoch": 2.1145415539595187,
      "grad_norm": 2.673257827758789,
      "learning_rate": 6.656302360498133e-06,
      "loss": 0.39174637794494627,
      "memory(GiB)": 72.72,
      "step": 22670,
      "token_acc": 0.45588235294117646,
      "train_speed(iter/s)": 0.251573
    },
    {
      "epoch": 2.1150079283648915,
      "grad_norm": 2.4657599925994873,
      "learning_rate": 6.654847065971609e-06,
      "loss": 0.38020246028900145,
      "memory(GiB)": 72.72,
      "step": 22675,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251573
    },
    {
      "epoch": 2.115474302770264,
      "grad_norm": 3.86289644241333,
      "learning_rate": 6.653391613991485e-06,
      "loss": 0.4263926982879639,
      "memory(GiB)": 72.72,
      "step": 22680,
      "train_speed(iter/s)": 0.251576
    },
    {
      "epoch": 2.1159406771756366,
      "grad_norm": 3.871666193008423,
      "learning_rate": 6.651936004696241e-06,
      "loss": 0.3883954048156738,
      "memory(GiB)": 72.72,
      "step": 22685,
      "token_acc": 0.9120879120879121,
      "train_speed(iter/s)": 0.251578
    },
    {
      "epoch": 2.1164070515810094,
      "grad_norm": 3.071246385574341,
      "learning_rate": 6.650480238224376e-06,
      "loss": 0.39115471839904786,
      "memory(GiB)": 72.72,
      "step": 22690,
      "token_acc": 0.6052631578947368,
      "train_speed(iter/s)": 0.251578
    },
    {
      "epoch": 2.1168734259863817,
      "grad_norm": 5.350047588348389,
      "learning_rate": 6.6490243147144e-06,
      "loss": 0.42760453224182127,
      "memory(GiB)": 72.72,
      "step": 22695,
      "token_acc": 0.9306930693069307,
      "train_speed(iter/s)": 0.251582
    },
    {
      "epoch": 2.1173398003917545,
      "grad_norm": 5.141749382019043,
      "learning_rate": 6.647568234304842e-06,
      "loss": 0.3880273103713989,
      "memory(GiB)": 72.72,
      "step": 22700,
      "token_acc": 0.5098039215686274,
      "train_speed(iter/s)": 0.251581
    },
    {
      "epoch": 2.1178061747971273,
      "grad_norm": 4.190982818603516,
      "learning_rate": 6.6461119971342395e-06,
      "loss": 0.4250746726989746,
      "memory(GiB)": 72.72,
      "step": 22705,
      "train_speed(iter/s)": 0.251582
    },
    {
      "epoch": 2.1182725492024996,
      "grad_norm": 6.4636430740356445,
      "learning_rate": 6.644655603341153e-06,
      "loss": 0.4045389175415039,
      "memory(GiB)": 72.72,
      "step": 22710,
      "token_acc": 0.8924731182795699,
      "train_speed(iter/s)": 0.251583
    },
    {
      "epoch": 2.1187389236078724,
      "grad_norm": 4.204786777496338,
      "learning_rate": 6.6431990530641535e-06,
      "loss": 0.4058689594268799,
      "memory(GiB)": 72.72,
      "step": 22715,
      "train_speed(iter/s)": 0.251584
    },
    {
      "epoch": 2.119205298013245,
      "grad_norm": 3.3637826442718506,
      "learning_rate": 6.641742346441824e-06,
      "loss": 0.3945783615112305,
      "memory(GiB)": 72.72,
      "step": 22720,
      "train_speed(iter/s)": 0.251588
    },
    {
      "epoch": 2.1196716724186175,
      "grad_norm": 3.5832314491271973,
      "learning_rate": 6.640285483612769e-06,
      "loss": 0.4346257209777832,
      "memory(GiB)": 72.72,
      "step": 22725,
      "train_speed(iter/s)": 0.251586
    },
    {
      "epoch": 2.1201380468239903,
      "grad_norm": 3.942342519760132,
      "learning_rate": 6.638828464715602e-06,
      "loss": 0.3583800792694092,
      "memory(GiB)": 72.72,
      "step": 22730,
      "train_speed(iter/s)": 0.251585
    },
    {
      "epoch": 2.120604421229363,
      "grad_norm": 2.9153668880462646,
      "learning_rate": 6.6373712898889565e-06,
      "loss": 0.37128491401672364,
      "memory(GiB)": 72.72,
      "step": 22735,
      "token_acc": 0.5852272727272727,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 2.1210707956347354,
      "grad_norm": 4.729592800140381,
      "learning_rate": 6.635913959271476e-06,
      "loss": 0.4271141529083252,
      "memory(GiB)": 72.72,
      "step": 22740,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 2.1215371700401082,
      "grad_norm": 2.7778515815734863,
      "learning_rate": 6.6344564730018225e-06,
      "loss": 0.40102405548095704,
      "memory(GiB)": 72.72,
      "step": 22745,
      "train_speed(iter/s)": 0.251589
    },
    {
      "epoch": 2.122003544445481,
      "grad_norm": 5.072652339935303,
      "learning_rate": 6.632998831218669e-06,
      "loss": 0.3787951946258545,
      "memory(GiB)": 72.72,
      "step": 22750,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 2.1224699188508533,
      "grad_norm": 5.221207618713379,
      "learning_rate": 6.631541034060708e-06,
      "loss": 0.3923765182495117,
      "memory(GiB)": 72.72,
      "step": 22755,
      "train_speed(iter/s)": 0.251592
    },
    {
      "epoch": 2.122936293256226,
      "grad_norm": 4.146644592285156,
      "learning_rate": 6.630083081666644e-06,
      "loss": 0.40781497955322266,
      "memory(GiB)": 72.72,
      "step": 22760,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 2.123402667661599,
      "grad_norm": 2.988199234008789,
      "learning_rate": 6.6286249741751974e-06,
      "loss": 0.3649882793426514,
      "memory(GiB)": 72.72,
      "step": 22765,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 2.1238690420669712,
      "grad_norm": 2.4954047203063965,
      "learning_rate": 6.627166711725101e-06,
      "loss": 0.421820068359375,
      "memory(GiB)": 72.72,
      "step": 22770,
      "token_acc": 0.9746835443037974,
      "train_speed(iter/s)": 0.251588
    },
    {
      "epoch": 2.124335416472344,
      "grad_norm": 2.431098461151123,
      "learning_rate": 6.625708294455105e-06,
      "loss": 0.38677058219909666,
      "memory(GiB)": 72.72,
      "step": 22775,
      "train_speed(iter/s)": 0.251588
    },
    {
      "epoch": 2.124801790877717,
      "grad_norm": 3.8298254013061523,
      "learning_rate": 6.62424972250397e-06,
      "loss": 0.39896090030670167,
      "memory(GiB)": 72.72,
      "step": 22780,
      "token_acc": 0.6939890710382514,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 2.125268165283089,
      "grad_norm": 3.0068063735961914,
      "learning_rate": 6.622790996010481e-06,
      "loss": 0.3991522789001465,
      "memory(GiB)": 72.72,
      "step": 22785,
      "train_speed(iter/s)": 0.251594
    },
    {
      "epoch": 2.125734539688462,
      "grad_norm": 2.244046449661255,
      "learning_rate": 6.621332115113427e-06,
      "loss": 0.3838881731033325,
      "memory(GiB)": 72.72,
      "step": 22790,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.251594
    },
    {
      "epoch": 2.1262009140938347,
      "grad_norm": 3.062922477722168,
      "learning_rate": 6.619873079951616e-06,
      "loss": 0.3499277591705322,
      "memory(GiB)": 72.72,
      "step": 22795,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 2.126667288499207,
      "grad_norm": 3.5343921184539795,
      "learning_rate": 6.6184138906638725e-06,
      "loss": 0.3769944667816162,
      "memory(GiB)": 72.72,
      "step": 22800,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.251589
    },
    {
      "epoch": 2.12713366290458,
      "grad_norm": 5.229489326477051,
      "learning_rate": 6.616954547389032e-06,
      "loss": 0.41646995544433596,
      "memory(GiB)": 72.72,
      "step": 22805,
      "token_acc": 0.5446428571428571,
      "train_speed(iter/s)": 0.251595
    },
    {
      "epoch": 2.1276000373099526,
      "grad_norm": 3.1778054237365723,
      "learning_rate": 6.615495050265949e-06,
      "loss": 0.4061366081237793,
      "memory(GiB)": 72.72,
      "step": 22810,
      "train_speed(iter/s)": 0.251591
    },
    {
      "epoch": 2.128066411715325,
      "grad_norm": 2.8501136302948,
      "learning_rate": 6.614035399433487e-06,
      "loss": 0.3960057258605957,
      "memory(GiB)": 72.72,
      "step": 22815,
      "train_speed(iter/s)": 0.251591
    },
    {
      "epoch": 2.1285327861206977,
      "grad_norm": 3.630704641342163,
      "learning_rate": 6.61257559503053e-06,
      "loss": 0.39305934906005857,
      "memory(GiB)": 72.72,
      "step": 22820,
      "train_speed(iter/s)": 0.251593
    },
    {
      "epoch": 2.1289991605260705,
      "grad_norm": 3.2183802127838135,
      "learning_rate": 6.61111563719597e-06,
      "loss": 0.39004950523376464,
      "memory(GiB)": 72.72,
      "step": 22825,
      "token_acc": 0.5535714285714286,
      "train_speed(iter/s)": 0.251593
    },
    {
      "epoch": 2.129465534931443,
      "grad_norm": 2.743330717086792,
      "learning_rate": 6.609655526068723e-06,
      "loss": 0.3632676601409912,
      "memory(GiB)": 72.72,
      "step": 22830,
      "token_acc": 0.52,
      "train_speed(iter/s)": 0.251596
    },
    {
      "epoch": 2.1299319093368156,
      "grad_norm": 3.517564058303833,
      "learning_rate": 6.608195261787712e-06,
      "loss": 0.41459193229675295,
      "memory(GiB)": 72.72,
      "step": 22835,
      "token_acc": 0.4339622641509434,
      "train_speed(iter/s)": 0.251595
    },
    {
      "epoch": 2.1303982837421884,
      "grad_norm": 3.1994130611419678,
      "learning_rate": 6.606734844491876e-06,
      "loss": 0.41823158264160154,
      "memory(GiB)": 72.72,
      "step": 22840,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.251592
    },
    {
      "epoch": 2.1308646581475608,
      "grad_norm": 3.172530174255371,
      "learning_rate": 6.605274274320167e-06,
      "loss": 0.3487309455871582,
      "memory(GiB)": 72.72,
      "step": 22845,
      "train_speed(iter/s)": 0.251592
    },
    {
      "epoch": 2.1313310325529335,
      "grad_norm": 3.034681558609009,
      "learning_rate": 6.603813551411558e-06,
      "loss": 0.3747739553451538,
      "memory(GiB)": 72.72,
      "step": 22850,
      "token_acc": 0.95,
      "train_speed(iter/s)": 0.251588
    },
    {
      "epoch": 2.1317974069583063,
      "grad_norm": 3.679835557937622,
      "learning_rate": 6.6023526759050285e-06,
      "loss": 0.36700000762939455,
      "memory(GiB)": 72.72,
      "step": 22855,
      "train_speed(iter/s)": 0.251587
    },
    {
      "epoch": 2.1322637813636787,
      "grad_norm": 3.3935961723327637,
      "learning_rate": 6.60089164793958e-06,
      "loss": 0.41390581130981446,
      "memory(GiB)": 72.72,
      "step": 22860,
      "train_speed(iter/s)": 0.251587
    },
    {
      "epoch": 2.1327301557690514,
      "grad_norm": 3.4997427463531494,
      "learning_rate": 6.599430467654222e-06,
      "loss": 0.3719932079315186,
      "memory(GiB)": 72.72,
      "step": 22865,
      "token_acc": 0.52,
      "train_speed(iter/s)": 0.251587
    },
    {
      "epoch": 2.1331965301744242,
      "grad_norm": 2.374866485595703,
      "learning_rate": 6.597969135187982e-06,
      "loss": 0.4068775177001953,
      "memory(GiB)": 72.72,
      "step": 22870,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.25159
    },
    {
      "epoch": 2.1336629045797966,
      "grad_norm": 3.1032073497772217,
      "learning_rate": 6.5965076506799e-06,
      "loss": 0.3774604797363281,
      "memory(GiB)": 72.72,
      "step": 22875,
      "train_speed(iter/s)": 0.251589
    },
    {
      "epoch": 2.1341292789851694,
      "grad_norm": 2.2045347690582275,
      "learning_rate": 6.595046014269035e-06,
      "loss": 0.35489323139190676,
      "memory(GiB)": 72.72,
      "step": 22880,
      "token_acc": 0.24074074074074073,
      "train_speed(iter/s)": 0.251591
    },
    {
      "epoch": 2.1345956533905417,
      "grad_norm": 2.926388740539551,
      "learning_rate": 6.593584226094455e-06,
      "loss": 0.4474353790283203,
      "memory(GiB)": 72.72,
      "step": 22885,
      "train_speed(iter/s)": 0.251589
    },
    {
      "epoch": 2.1350620277959145,
      "grad_norm": 3.5930676460266113,
      "learning_rate": 6.592122286295245e-06,
      "loss": 0.4383441925048828,
      "memory(GiB)": 72.72,
      "step": 22890,
      "train_speed(iter/s)": 0.251587
    },
    {
      "epoch": 2.1355284022012873,
      "grad_norm": 3.665814161300659,
      "learning_rate": 6.590660195010506e-06,
      "loss": 0.39228482246398927,
      "memory(GiB)": 72.72,
      "step": 22895,
      "train_speed(iter/s)": 0.251589
    },
    {
      "epoch": 2.13599477660666,
      "grad_norm": 3.4609286785125732,
      "learning_rate": 6.589197952379347e-06,
      "loss": 0.40604233741760254,
      "memory(GiB)": 72.72,
      "step": 22900,
      "train_speed(iter/s)": 0.251588
    },
    {
      "epoch": 2.1364611510120324,
      "grad_norm": 4.06027364730835,
      "learning_rate": 6.587735558540898e-06,
      "loss": 0.4280858039855957,
      "memory(GiB)": 72.72,
      "step": 22905,
      "token_acc": 0.7346938775510204,
      "train_speed(iter/s)": 0.251586
    },
    {
      "epoch": 2.136927525417405,
      "grad_norm": 3.4590866565704346,
      "learning_rate": 6.586273013634304e-06,
      "loss": 0.430419397354126,
      "memory(GiB)": 72.72,
      "step": 22910,
      "token_acc": 0.543859649122807,
      "train_speed(iter/s)": 0.251585
    },
    {
      "epoch": 2.1373938998227775,
      "grad_norm": 4.643558025360107,
      "learning_rate": 6.584810317798719e-06,
      "loss": 0.3867698907852173,
      "memory(GiB)": 72.72,
      "step": 22915,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.251583
    },
    {
      "epoch": 2.1378602742281503,
      "grad_norm": 3.161226987838745,
      "learning_rate": 6.583347471173314e-06,
      "loss": 0.44124455451965333,
      "memory(GiB)": 72.72,
      "step": 22920,
      "train_speed(iter/s)": 0.251581
    },
    {
      "epoch": 2.138326648633523,
      "grad_norm": 2.9238080978393555,
      "learning_rate": 6.581884473897273e-06,
      "loss": 0.3744850158691406,
      "memory(GiB)": 72.72,
      "step": 22925,
      "token_acc": 0.45614035087719296,
      "train_speed(iter/s)": 0.251579
    },
    {
      "epoch": 2.138793023038896,
      "grad_norm": 2.824993848800659,
      "learning_rate": 6.580421326109799e-06,
      "loss": 0.4339766502380371,
      "memory(GiB)": 72.72,
      "step": 22930,
      "token_acc": 0.4943820224719101,
      "train_speed(iter/s)": 0.251579
    },
    {
      "epoch": 2.139259397444268,
      "grad_norm": 2.711390733718872,
      "learning_rate": 6.5789580279501045e-06,
      "loss": 0.4087514877319336,
      "memory(GiB)": 72.72,
      "step": 22935,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251579
    },
    {
      "epoch": 2.139725771849641,
      "grad_norm": 3.318119764328003,
      "learning_rate": 6.577494579557417e-06,
      "loss": 0.40898523330688474,
      "memory(GiB)": 72.72,
      "step": 22940,
      "train_speed(iter/s)": 0.251578
    },
    {
      "epoch": 2.1401921462550133,
      "grad_norm": 5.113737106323242,
      "learning_rate": 6.576030981070982e-06,
      "loss": 0.38136539459228513,
      "memory(GiB)": 72.72,
      "step": 22945,
      "train_speed(iter/s)": 0.251575
    },
    {
      "epoch": 2.140658520660386,
      "grad_norm": 2.6629114151000977,
      "learning_rate": 6.574567232630052e-06,
      "loss": 0.3888193130493164,
      "memory(GiB)": 72.72,
      "step": 22950,
      "train_speed(iter/s)": 0.251571
    },
    {
      "epoch": 2.141124895065759,
      "grad_norm": 2.5378363132476807,
      "learning_rate": 6.573103334373902e-06,
      "loss": 0.410684871673584,
      "memory(GiB)": 72.72,
      "step": 22955,
      "token_acc": 0.4423076923076923,
      "train_speed(iter/s)": 0.251573
    },
    {
      "epoch": 2.1415912694711317,
      "grad_norm": 7.6860151290893555,
      "learning_rate": 6.571639286441814e-06,
      "loss": 0.41205787658691406,
      "memory(GiB)": 72.72,
      "step": 22960,
      "token_acc": 0.9047619047619048,
      "train_speed(iter/s)": 0.25157
    },
    {
      "epoch": 2.142057643876504,
      "grad_norm": 5.005659580230713,
      "learning_rate": 6.5701750889730906e-06,
      "loss": 0.3754861831665039,
      "memory(GiB)": 72.72,
      "step": 22965,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251572
    },
    {
      "epoch": 2.1425240182818768,
      "grad_norm": 2.487659454345703,
      "learning_rate": 6.568710742107045e-06,
      "loss": 0.3838718175888062,
      "memory(GiB)": 72.72,
      "step": 22970,
      "train_speed(iter/s)": 0.251574
    },
    {
      "epoch": 2.142990392687249,
      "grad_norm": 3.562628984451294,
      "learning_rate": 6.567246245983003e-06,
      "loss": 0.4455247402191162,
      "memory(GiB)": 72.72,
      "step": 22975,
      "token_acc": 0.43137254901960786,
      "train_speed(iter/s)": 0.251576
    },
    {
      "epoch": 2.143456767092622,
      "grad_norm": 2.882124900817871,
      "learning_rate": 6.565781600740309e-06,
      "loss": 0.4219473361968994,
      "memory(GiB)": 72.72,
      "step": 22980,
      "train_speed(iter/s)": 0.251574
    },
    {
      "epoch": 2.1439231414979947,
      "grad_norm": 3.6571240425109863,
      "learning_rate": 6.564316806518321e-06,
      "loss": 0.3891120195388794,
      "memory(GiB)": 72.72,
      "step": 22985,
      "token_acc": 0.9021739130434783,
      "train_speed(iter/s)": 0.251578
    },
    {
      "epoch": 2.144389515903367,
      "grad_norm": 2.882784366607666,
      "learning_rate": 6.5628518634564075e-06,
      "loss": 0.41819348335266116,
      "memory(GiB)": 72.72,
      "step": 22990,
      "token_acc": 0.4318181818181818,
      "train_speed(iter/s)": 0.251579
    },
    {
      "epoch": 2.14485589030874,
      "grad_norm": 5.213832855224609,
      "learning_rate": 6.561386771693953e-06,
      "loss": 0.3986541509628296,
      "memory(GiB)": 72.72,
      "step": 22995,
      "train_speed(iter/s)": 0.251578
    },
    {
      "epoch": 2.1453222647141126,
      "grad_norm": 3.4647984504699707,
      "learning_rate": 6.559921531370357e-06,
      "loss": 0.37767658233642576,
      "memory(GiB)": 72.72,
      "step": 23000,
      "token_acc": 0.9367088607594937,
      "train_speed(iter/s)": 0.251582
    },
    {
      "epoch": 2.145788639119485,
      "grad_norm": 4.025485038757324,
      "learning_rate": 6.5584561426250336e-06,
      "loss": 0.3941590070724487,
      "memory(GiB)": 72.72,
      "step": 23005,
      "train_speed(iter/s)": 0.251583
    },
    {
      "epoch": 2.1462550135248577,
      "grad_norm": 2.7696006298065186,
      "learning_rate": 6.556990605597409e-06,
      "loss": 0.3911121368408203,
      "memory(GiB)": 72.72,
      "step": 23010,
      "train_speed(iter/s)": 0.251584
    },
    {
      "epoch": 2.1467213879302305,
      "grad_norm": 2.2583119869232178,
      "learning_rate": 6.555524920426923e-06,
      "loss": 0.3275377035140991,
      "memory(GiB)": 72.72,
      "step": 23015,
      "token_acc": 0.824,
      "train_speed(iter/s)": 0.251585
    },
    {
      "epoch": 2.147187762335603,
      "grad_norm": 2.9317216873168945,
      "learning_rate": 6.554059087253034e-06,
      "loss": 0.3727119445800781,
      "memory(GiB)": 72.72,
      "step": 23020,
      "token_acc": 0.5277777777777778,
      "train_speed(iter/s)": 0.251583
    },
    {
      "epoch": 2.1476541367409756,
      "grad_norm": 4.156233310699463,
      "learning_rate": 6.552593106215211e-06,
      "loss": 0.38082118034362794,
      "memory(GiB)": 72.72,
      "step": 23025,
      "train_speed(iter/s)": 0.251493
    },
    {
      "epoch": 2.1481205111463484,
      "grad_norm": 6.176276206970215,
      "learning_rate": 6.551126977452935e-06,
      "loss": 0.38779070377349856,
      "memory(GiB)": 72.72,
      "step": 23030,
      "train_speed(iter/s)": 0.25149
    },
    {
      "epoch": 2.1485868855517207,
      "grad_norm": 2.9224274158477783,
      "learning_rate": 6.549660701105707e-06,
      "loss": 0.3912874937057495,
      "memory(GiB)": 72.72,
      "step": 23035,
      "token_acc": 0.7423312883435583,
      "train_speed(iter/s)": 0.251494
    },
    {
      "epoch": 2.1490532599570935,
      "grad_norm": 3.6488280296325684,
      "learning_rate": 6.548194277313037e-06,
      "loss": 0.3937657833099365,
      "memory(GiB)": 72.72,
      "step": 23040,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251496
    },
    {
      "epoch": 2.1495196343624663,
      "grad_norm": 4.561562538146973,
      "learning_rate": 6.54672770621445e-06,
      "loss": 0.3668439626693726,
      "memory(GiB)": 72.72,
      "step": 23045,
      "train_speed(iter/s)": 0.251493
    },
    {
      "epoch": 2.1499860087678386,
      "grad_norm": 2.9806928634643555,
      "learning_rate": 6.5452609879494865e-06,
      "loss": 0.4035759449005127,
      "memory(GiB)": 72.72,
      "step": 23050,
      "token_acc": 0.46938775510204084,
      "train_speed(iter/s)": 0.251494
    },
    {
      "epoch": 2.1504523831732114,
      "grad_norm": 3.1313858032226562,
      "learning_rate": 6.5437941226577e-06,
      "loss": 0.4084358215332031,
      "memory(GiB)": 72.72,
      "step": 23055,
      "token_acc": 0.711864406779661,
      "train_speed(iter/s)": 0.251493
    },
    {
      "epoch": 2.150918757578584,
      "grad_norm": 2.9370040893554688,
      "learning_rate": 6.542327110478661e-06,
      "loss": 0.406024169921875,
      "memory(GiB)": 72.72,
      "step": 23060,
      "token_acc": 0.8125,
      "train_speed(iter/s)": 0.251495
    },
    {
      "epoch": 2.1513851319839565,
      "grad_norm": 2.661123514175415,
      "learning_rate": 6.540859951551947e-06,
      "loss": 0.39268126487731936,
      "memory(GiB)": 72.72,
      "step": 23065,
      "token_acc": 0.7941176470588235,
      "train_speed(iter/s)": 0.251493
    },
    {
      "epoch": 2.1518515063893293,
      "grad_norm": 2.866788387298584,
      "learning_rate": 6.539392646017155e-06,
      "loss": 0.41170148849487304,
      "memory(GiB)": 72.72,
      "step": 23070,
      "train_speed(iter/s)": 0.251492
    },
    {
      "epoch": 2.152317880794702,
      "grad_norm": 6.096746921539307,
      "learning_rate": 6.537925194013894e-06,
      "loss": 0.36736488342285156,
      "memory(GiB)": 72.72,
      "step": 23075,
      "train_speed(iter/s)": 0.251496
    },
    {
      "epoch": 2.1527842552000744,
      "grad_norm": 3.7816410064697266,
      "learning_rate": 6.536457595681791e-06,
      "loss": 0.38775248527526857,
      "memory(GiB)": 72.72,
      "step": 23080,
      "train_speed(iter/s)": 0.251502
    },
    {
      "epoch": 2.153250629605447,
      "grad_norm": 4.506265163421631,
      "learning_rate": 6.53498985116048e-06,
      "loss": 0.4238563537597656,
      "memory(GiB)": 72.72,
      "step": 23085,
      "token_acc": 0.9146341463414634,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.15371700401082,
      "grad_norm": 5.8923211097717285,
      "learning_rate": 6.533521960589614e-06,
      "loss": 0.40578460693359375,
      "memory(GiB)": 72.72,
      "step": 23090,
      "train_speed(iter/s)": 0.251502
    },
    {
      "epoch": 2.1541833784161923,
      "grad_norm": 5.823735237121582,
      "learning_rate": 6.532053924108855e-06,
      "loss": 0.4076572895050049,
      "memory(GiB)": 72.72,
      "step": 23095,
      "token_acc": 0.5405405405405406,
      "train_speed(iter/s)": 0.251505
    },
    {
      "epoch": 2.154649752821565,
      "grad_norm": 2.802072525024414,
      "learning_rate": 6.5305857418578864e-06,
      "loss": 0.37006709575653074,
      "memory(GiB)": 72.72,
      "step": 23100,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.155116127226938,
      "grad_norm": 4.314996719360352,
      "learning_rate": 6.5291174139764005e-06,
      "loss": 0.3797731399536133,
      "memory(GiB)": 72.72,
      "step": 23105,
      "token_acc": 0.76,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.1555825016323102,
      "grad_norm": 4.889324188232422,
      "learning_rate": 6.527648940604102e-06,
      "loss": 0.37975125312805175,
      "memory(GiB)": 72.72,
      "step": 23110,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.156048876037683,
      "grad_norm": 3.9019737243652344,
      "learning_rate": 6.526180321880713e-06,
      "loss": 0.40460977554321287,
      "memory(GiB)": 72.72,
      "step": 23115,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.251504
    },
    {
      "epoch": 2.156515250443056,
      "grad_norm": 3.417574405670166,
      "learning_rate": 6.524711557945969e-06,
      "loss": 0.3967274188995361,
      "memory(GiB)": 72.72,
      "step": 23120,
      "token_acc": 0.6571428571428571,
      "train_speed(iter/s)": 0.251506
    },
    {
      "epoch": 2.156981624848428,
      "grad_norm": 3.6489269733428955,
      "learning_rate": 6.523242648939616e-06,
      "loss": 0.39937529563903806,
      "memory(GiB)": 72.72,
      "step": 23125,
      "train_speed(iter/s)": 0.251507
    },
    {
      "epoch": 2.157447999253801,
      "grad_norm": 2.787926197052002,
      "learning_rate": 6.521773595001416e-06,
      "loss": 0.3831049919128418,
      "memory(GiB)": 72.72,
      "step": 23130,
      "token_acc": 0.9361702127659575,
      "train_speed(iter/s)": 0.251506
    },
    {
      "epoch": 2.1579143736591737,
      "grad_norm": 2.881707191467285,
      "learning_rate": 6.520304396271149e-06,
      "loss": 0.38361177444458006,
      "memory(GiB)": 72.72,
      "step": 23135,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.251511
    },
    {
      "epoch": 2.158380748064546,
      "grad_norm": 4.187047481536865,
      "learning_rate": 6.518835052888601e-06,
      "loss": 0.39805188179016116,
      "memory(GiB)": 72.72,
      "step": 23140,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.25151
    },
    {
      "epoch": 2.158847122469919,
      "grad_norm": 2.898216485977173,
      "learning_rate": 6.517365564993576e-06,
      "loss": 0.3768022060394287,
      "memory(GiB)": 72.72,
      "step": 23145,
      "token_acc": 0.576271186440678,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.1593134968752916,
      "grad_norm": 2.861367702484131,
      "learning_rate": 6.515895932725893e-06,
      "loss": 0.3968052864074707,
      "memory(GiB)": 72.72,
      "step": 23150,
      "token_acc": 0.946236559139785,
      "train_speed(iter/s)": 0.251505
    },
    {
      "epoch": 2.159779871280664,
      "grad_norm": 3.1265077590942383,
      "learning_rate": 6.514426156225382e-06,
      "loss": 0.4031526565551758,
      "memory(GiB)": 72.72,
      "step": 23155,
      "train_speed(iter/s)": 0.251507
    },
    {
      "epoch": 2.1602462456860367,
      "grad_norm": 3.6778669357299805,
      "learning_rate": 6.5129562356318865e-06,
      "loss": 0.3922391653060913,
      "memory(GiB)": 72.72,
      "step": 23160,
      "train_speed(iter/s)": 0.251507
    },
    {
      "epoch": 2.1607126200914095,
      "grad_norm": 3.1398112773895264,
      "learning_rate": 6.511486171085266e-06,
      "loss": 0.40991926193237305,
      "memory(GiB)": 72.72,
      "step": 23165,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.161178994496782,
      "grad_norm": 4.789527893066406,
      "learning_rate": 6.5100159627253935e-06,
      "loss": 0.4087742805480957,
      "memory(GiB)": 72.72,
      "step": 23170,
      "token_acc": 0.4700854700854701,
      "train_speed(iter/s)": 0.251505
    },
    {
      "epoch": 2.1616453689021546,
      "grad_norm": 2.6563720703125,
      "learning_rate": 6.508545610692154e-06,
      "loss": 0.3348264217376709,
      "memory(GiB)": 72.72,
      "step": 23175,
      "train_speed(iter/s)": 0.251504
    },
    {
      "epoch": 2.1621117433075274,
      "grad_norm": 4.401722431182861,
      "learning_rate": 6.507075115125445e-06,
      "loss": 0.40630416870117186,
      "memory(GiB)": 72.72,
      "step": 23180,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.1625781177128998,
      "grad_norm": 3.9769139289855957,
      "learning_rate": 6.505604476165184e-06,
      "loss": 0.36674954891204836,
      "memory(GiB)": 72.72,
      "step": 23185,
      "token_acc": 0.7734375,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.1630444921182725,
      "grad_norm": 4.415688991546631,
      "learning_rate": 6.504133693951294e-06,
      "loss": 0.3472210168838501,
      "memory(GiB)": 72.72,
      "step": 23190,
      "train_speed(iter/s)": 0.2515
    },
    {
      "epoch": 2.1635108665236453,
      "grad_norm": 3.6112029552459717,
      "learning_rate": 6.502662768623715e-06,
      "loss": 0.4330568313598633,
      "memory(GiB)": 72.72,
      "step": 23195,
      "train_speed(iter/s)": 0.251506
    },
    {
      "epoch": 2.1639772409290177,
      "grad_norm": 4.025515556335449,
      "learning_rate": 6.501191700322405e-06,
      "loss": 0.3700343132019043,
      "memory(GiB)": 72.72,
      "step": 23200,
      "train_speed(iter/s)": 0.251507
    },
    {
      "epoch": 2.1644436153343904,
      "grad_norm": 3.6046745777130127,
      "learning_rate": 6.499720489187328e-06,
      "loss": 0.41164188385009765,
      "memory(GiB)": 72.72,
      "step": 23205,
      "train_speed(iter/s)": 0.251509
    },
    {
      "epoch": 2.1649099897397632,
      "grad_norm": 3.269303560256958,
      "learning_rate": 6.498249135358467e-06,
      "loss": 0.4221834659576416,
      "memory(GiB)": 72.72,
      "step": 23210,
      "train_speed(iter/s)": 0.251511
    },
    {
      "epoch": 2.1653763641451356,
      "grad_norm": 2.737046718597412,
      "learning_rate": 6.4967776389758165e-06,
      "loss": 0.39304051399230955,
      "memory(GiB)": 72.72,
      "step": 23215,
      "train_speed(iter/s)": 0.25151
    },
    {
      "epoch": 2.1658427385505084,
      "grad_norm": 3.435554265975952,
      "learning_rate": 6.495306000179385e-06,
      "loss": 0.3646824598312378,
      "memory(GiB)": 72.72,
      "step": 23220,
      "token_acc": 0.4523809523809524,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.166309112955881,
      "grad_norm": 4.2899489402771,
      "learning_rate": 6.493834219109192e-06,
      "loss": 0.3957331895828247,
      "memory(GiB)": 72.72,
      "step": 23225,
      "train_speed(iter/s)": 0.251509
    },
    {
      "epoch": 2.1667754873612535,
      "grad_norm": 2.923534631729126,
      "learning_rate": 6.492362295905275e-06,
      "loss": 0.39254686832427976,
      "memory(GiB)": 72.72,
      "step": 23230,
      "token_acc": 0.5636363636363636,
      "train_speed(iter/s)": 0.251507
    },
    {
      "epoch": 2.1672418617666263,
      "grad_norm": 12.716872215270996,
      "learning_rate": 6.4908902307076845e-06,
      "loss": 0.3915001392364502,
      "memory(GiB)": 72.72,
      "step": 23235,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251505
    },
    {
      "epoch": 2.167708236171999,
      "grad_norm": 7.219106674194336,
      "learning_rate": 6.489418023656482e-06,
      "loss": 0.39212110042572024,
      "memory(GiB)": 72.72,
      "step": 23240,
      "token_acc": 0.6304347826086957,
      "train_speed(iter/s)": 0.251507
    },
    {
      "epoch": 2.1681746105773714,
      "grad_norm": 4.130399703979492,
      "learning_rate": 6.48794567489174e-06,
      "loss": 0.3742202281951904,
      "memory(GiB)": 72.72,
      "step": 23245,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.168640984982744,
      "grad_norm": 3.4047722816467285,
      "learning_rate": 6.486473184553552e-06,
      "loss": 0.3887352466583252,
      "memory(GiB)": 72.72,
      "step": 23250,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.169107359388117,
      "grad_norm": 3.801666021347046,
      "learning_rate": 6.4850005527820215e-06,
      "loss": 0.3791140079498291,
      "memory(GiB)": 72.72,
      "step": 23255,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.1695737337934893,
      "grad_norm": 3.523448944091797,
      "learning_rate": 6.4835277797172615e-06,
      "loss": 0.3941966533660889,
      "memory(GiB)": 72.72,
      "step": 23260,
      "train_speed(iter/s)": 0.251506
    },
    {
      "epoch": 2.170040108198862,
      "grad_norm": 3.1425743103027344,
      "learning_rate": 6.482054865499403e-06,
      "loss": 0.4029101371765137,
      "memory(GiB)": 72.72,
      "step": 23265,
      "token_acc": 0.38461538461538464,
      "train_speed(iter/s)": 0.251509
    },
    {
      "epoch": 2.170506482604235,
      "grad_norm": 3.0845022201538086,
      "learning_rate": 6.48058181026859e-06,
      "loss": 0.42720952033996584,
      "memory(GiB)": 72.72,
      "step": 23270,
      "token_acc": 0.8309859154929577,
      "train_speed(iter/s)": 0.251515
    },
    {
      "epoch": 2.170972857009607,
      "grad_norm": 2.7344284057617188,
      "learning_rate": 6.47910861416498e-06,
      "loss": 0.40204315185546874,
      "memory(GiB)": 72.72,
      "step": 23275,
      "token_acc": 0.45901639344262296,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.17143923141498,
      "grad_norm": 3.489305019378662,
      "learning_rate": 6.477635277328739e-06,
      "loss": 0.39226627349853516,
      "memory(GiB)": 72.72,
      "step": 23280,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.1719056058203527,
      "grad_norm": 4.306792259216309,
      "learning_rate": 6.4761617999000555e-06,
      "loss": 0.3927123546600342,
      "memory(GiB)": 72.72,
      "step": 23285,
      "token_acc": 0.9186046511627907,
      "train_speed(iter/s)": 0.251502
    },
    {
      "epoch": 2.172371980225725,
      "grad_norm": 2.652677297592163,
      "learning_rate": 6.474688182019124e-06,
      "loss": 0.3775832414627075,
      "memory(GiB)": 72.72,
      "step": 23290,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.172838354631098,
      "grad_norm": 2.6460611820220947,
      "learning_rate": 6.473214423826155e-06,
      "loss": 0.3972172260284424,
      "memory(GiB)": 72.72,
      "step": 23295,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.251501
    },
    {
      "epoch": 2.1733047290364707,
      "grad_norm": 2.612461805343628,
      "learning_rate": 6.471740525461371e-06,
      "loss": 0.4048511505126953,
      "memory(GiB)": 72.72,
      "step": 23300,
      "train_speed(iter/s)": 0.251502
    },
    {
      "epoch": 2.173771103441843,
      "grad_norm": 3.5480103492736816,
      "learning_rate": 6.470266487065011e-06,
      "loss": 0.3926872730255127,
      "memory(GiB)": 72.72,
      "step": 23305,
      "train_speed(iter/s)": 0.251505
    },
    {
      "epoch": 2.1742374778472158,
      "grad_norm": 3.1553399562835693,
      "learning_rate": 6.468792308777324e-06,
      "loss": 0.38831634521484376,
      "memory(GiB)": 72.72,
      "step": 23310,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.1747038522525886,
      "grad_norm": 2.6942286491394043,
      "learning_rate": 6.467317990738572e-06,
      "loss": 0.3923290729522705,
      "memory(GiB)": 72.72,
      "step": 23315,
      "token_acc": 0.4153846153846154,
      "train_speed(iter/s)": 0.251499
    },
    {
      "epoch": 2.175170226657961,
      "grad_norm": 2.4428040981292725,
      "learning_rate": 6.4658435330890344e-06,
      "loss": 0.45323810577392576,
      "memory(GiB)": 72.72,
      "step": 23320,
      "token_acc": 0.5847953216374269,
      "train_speed(iter/s)": 0.251499
    },
    {
      "epoch": 2.1756366010633337,
      "grad_norm": 3.4633166790008545,
      "learning_rate": 6.4643689359690006e-06,
      "loss": 0.3808131694793701,
      "memory(GiB)": 72.72,
      "step": 23325,
      "train_speed(iter/s)": 0.251494
    },
    {
      "epoch": 2.1761029754687065,
      "grad_norm": 3.224447011947632,
      "learning_rate": 6.462894199518772e-06,
      "loss": 0.33424715995788573,
      "memory(GiB)": 72.72,
      "step": 23330,
      "token_acc": 0.5964912280701754,
      "train_speed(iter/s)": 0.251493
    },
    {
      "epoch": 2.176569349874079,
      "grad_norm": 2.844285488128662,
      "learning_rate": 6.461419323878669e-06,
      "loss": 0.402028751373291,
      "memory(GiB)": 72.72,
      "step": 23335,
      "token_acc": 0.38,
      "train_speed(iter/s)": 0.251492
    },
    {
      "epoch": 2.1770357242794516,
      "grad_norm": 3.0924344062805176,
      "learning_rate": 6.459944309189019e-06,
      "loss": 0.37728061676025393,
      "memory(GiB)": 72.72,
      "step": 23340,
      "token_acc": 0.5221238938053098,
      "train_speed(iter/s)": 0.251495
    },
    {
      "epoch": 2.1775020986848244,
      "grad_norm": 2.5842912197113037,
      "learning_rate": 6.458469155590164e-06,
      "loss": 0.40534076690673826,
      "memory(GiB)": 72.72,
      "step": 23345,
      "token_acc": 0.6842105263157895,
      "train_speed(iter/s)": 0.251502
    },
    {
      "epoch": 2.1779684730901967,
      "grad_norm": 3.1877431869506836,
      "learning_rate": 6.456993863222463e-06,
      "loss": 0.3882730007171631,
      "memory(GiB)": 72.72,
      "step": 23350,
      "train_speed(iter/s)": 0.251501
    },
    {
      "epoch": 2.1784348474955695,
      "grad_norm": 4.068724155426025,
      "learning_rate": 6.455518432226284e-06,
      "loss": 0.3710016250610352,
      "memory(GiB)": 72.72,
      "step": 23355,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.1789012219009423,
      "grad_norm": 4.097326755523682,
      "learning_rate": 6.454042862742011e-06,
      "loss": 0.379132080078125,
      "memory(GiB)": 72.72,
      "step": 23360,
      "train_speed(iter/s)": 0.251503
    },
    {
      "epoch": 2.1793675963063146,
      "grad_norm": 2.698212146759033,
      "learning_rate": 6.452567154910037e-06,
      "loss": 0.37563304901123046,
      "memory(GiB)": 72.72,
      "step": 23365,
      "token_acc": 0.5346534653465347,
      "train_speed(iter/s)": 0.251502
    },
    {
      "epoch": 2.1798339707116874,
      "grad_norm": 4.002720355987549,
      "learning_rate": 6.451091308870774e-06,
      "loss": 0.4101369857788086,
      "memory(GiB)": 72.72,
      "step": 23370,
      "train_speed(iter/s)": 0.251501
    },
    {
      "epoch": 2.18030034511706,
      "grad_norm": 5.195778846740723,
      "learning_rate": 6.449615324764643e-06,
      "loss": 0.3939943790435791,
      "memory(GiB)": 72.72,
      "step": 23375,
      "token_acc": 0.62,
      "train_speed(iter/s)": 0.251504
    },
    {
      "epoch": 2.1807667195224325,
      "grad_norm": 2.693260431289673,
      "learning_rate": 6.44813920273208e-06,
      "loss": 0.3793654203414917,
      "memory(GiB)": 72.72,
      "step": 23380,
      "train_speed(iter/s)": 0.251506
    },
    {
      "epoch": 2.1812330939278053,
      "grad_norm": 3.3022878170013428,
      "learning_rate": 6.446662942913532e-06,
      "loss": 0.3800344467163086,
      "memory(GiB)": 72.72,
      "step": 23385,
      "token_acc": 0.5409836065573771,
      "train_speed(iter/s)": 0.251506
    },
    {
      "epoch": 2.181699468333178,
      "grad_norm": 4.513761043548584,
      "learning_rate": 6.445186545449462e-06,
      "loss": 0.4134199142456055,
      "memory(GiB)": 72.72,
      "step": 23390,
      "train_speed(iter/s)": 0.251505
    },
    {
      "epoch": 2.1821658427385504,
      "grad_norm": 8.119892120361328,
      "learning_rate": 6.443710010480344e-06,
      "loss": 0.41701269149780273,
      "memory(GiB)": 72.72,
      "step": 23395,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.251506
    },
    {
      "epoch": 2.182632217143923,
      "grad_norm": 3.740673542022705,
      "learning_rate": 6.442233338146666e-06,
      "loss": 0.39530253410339355,
      "memory(GiB)": 72.72,
      "step": 23400,
      "token_acc": 0.5517241379310345,
      "train_speed(iter/s)": 0.251509
    },
    {
      "epoch": 2.183098591549296,
      "grad_norm": 2.952760934829712,
      "learning_rate": 6.4407565285889285e-06,
      "loss": 0.41083440780639646,
      "memory(GiB)": 72.72,
      "step": 23405,
      "train_speed(iter/s)": 0.251512
    },
    {
      "epoch": 2.1835649659546683,
      "grad_norm": 4.629777908325195,
      "learning_rate": 6.439279581947648e-06,
      "loss": 0.3648515224456787,
      "memory(GiB)": 72.72,
      "step": 23410,
      "token_acc": 0.6265060240963856,
      "train_speed(iter/s)": 0.251512
    },
    {
      "epoch": 2.184031340360041,
      "grad_norm": 3.4875729084014893,
      "learning_rate": 6.437802498363346e-06,
      "loss": 0.3676342725753784,
      "memory(GiB)": 72.72,
      "step": 23415,
      "token_acc": 0.5178571428571429,
      "train_speed(iter/s)": 0.251511
    },
    {
      "epoch": 2.184497714765414,
      "grad_norm": 3.774212598800659,
      "learning_rate": 6.436325277976566e-06,
      "loss": 0.42201709747314453,
      "memory(GiB)": 72.72,
      "step": 23420,
      "token_acc": 0.5434782608695652,
      "train_speed(iter/s)": 0.251514
    },
    {
      "epoch": 2.184964089170786,
      "grad_norm": 2.932032346725464,
      "learning_rate": 6.434847920927863e-06,
      "loss": 0.3938558578491211,
      "memory(GiB)": 72.72,
      "step": 23425,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.185430463576159,
      "grad_norm": 7.002200126647949,
      "learning_rate": 6.433370427357798e-06,
      "loss": 0.4000705718994141,
      "memory(GiB)": 72.72,
      "step": 23430,
      "train_speed(iter/s)": 0.251512
    },
    {
      "epoch": 2.185896837981532,
      "grad_norm": 3.822831153869629,
      "learning_rate": 6.431892797406953e-06,
      "loss": 0.4005455493927002,
      "memory(GiB)": 72.72,
      "step": 23435,
      "token_acc": 0.3684210526315789,
      "train_speed(iter/s)": 0.251517
    },
    {
      "epoch": 2.186363212386904,
      "grad_norm": 4.341678619384766,
      "learning_rate": 6.43041503121592e-06,
      "loss": 0.36373748779296877,
      "memory(GiB)": 72.72,
      "step": 23440,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251514
    },
    {
      "epoch": 2.186829586792277,
      "grad_norm": 3.972754716873169,
      "learning_rate": 6.428937128925303e-06,
      "loss": 0.3896059274673462,
      "memory(GiB)": 72.72,
      "step": 23445,
      "train_speed(iter/s)": 0.251514
    },
    {
      "epoch": 2.1872959611976492,
      "grad_norm": 3.613703966140747,
      "learning_rate": 6.427459090675718e-06,
      "loss": 0.356852388381958,
      "memory(GiB)": 72.72,
      "step": 23450,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.251514
    },
    {
      "epoch": 2.187762335603022,
      "grad_norm": 4.623002052307129,
      "learning_rate": 6.4259809166078e-06,
      "loss": 0.34732646942138673,
      "memory(GiB)": 72.72,
      "step": 23455,
      "token_acc": 0.5873015873015873,
      "train_speed(iter/s)": 0.25151
    },
    {
      "epoch": 2.188228710008395,
      "grad_norm": 2.9739744663238525,
      "learning_rate": 6.424502606862192e-06,
      "loss": 0.40027341842651365,
      "memory(GiB)": 72.72,
      "step": 23460,
      "token_acc": 0.4878048780487805,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.1886950844137676,
      "grad_norm": 4.073622703552246,
      "learning_rate": 6.423024161579548e-06,
      "loss": 0.3880605220794678,
      "memory(GiB)": 72.72,
      "step": 23465,
      "train_speed(iter/s)": 0.251507
    },
    {
      "epoch": 2.18916145881914,
      "grad_norm": 3.0396528244018555,
      "learning_rate": 6.4215455809005375e-06,
      "loss": 0.40275940895080564,
      "memory(GiB)": 72.72,
      "step": 23470,
      "train_speed(iter/s)": 0.251504
    },
    {
      "epoch": 2.1896278332245127,
      "grad_norm": 2.898125410079956,
      "learning_rate": 6.420066864965846e-06,
      "loss": 0.4055582046508789,
      "memory(GiB)": 72.72,
      "step": 23475,
      "token_acc": 0.5098039215686274,
      "train_speed(iter/s)": 0.251504
    },
    {
      "epoch": 2.190094207629885,
      "grad_norm": 3.9405364990234375,
      "learning_rate": 6.418588013916165e-06,
      "loss": 0.37662386894226074,
      "memory(GiB)": 72.72,
      "step": 23480,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.190560582035258,
      "grad_norm": 4.770843029022217,
      "learning_rate": 6.417109027892207e-06,
      "loss": 0.3432615756988525,
      "memory(GiB)": 72.72,
      "step": 23485,
      "train_speed(iter/s)": 0.251511
    },
    {
      "epoch": 2.1910269564406306,
      "grad_norm": 3.0209288597106934,
      "learning_rate": 6.415629907034689e-06,
      "loss": 0.4052574634552002,
      "memory(GiB)": 72.72,
      "step": 23490,
      "train_speed(iter/s)": 0.251509
    },
    {
      "epoch": 2.1914933308460034,
      "grad_norm": 4.010460376739502,
      "learning_rate": 6.4141506514843455e-06,
      "loss": 0.3864633083343506,
      "memory(GiB)": 72.72,
      "step": 23495,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.251512
    },
    {
      "epoch": 2.1919597052513757,
      "grad_norm": 3.4962048530578613,
      "learning_rate": 6.412671261381924e-06,
      "loss": 0.4313179016113281,
      "memory(GiB)": 72.72,
      "step": 23500,
      "token_acc": 0.5526315789473685,
      "train_speed(iter/s)": 0.25151
    },
    {
      "epoch": 2.1924260796567485,
      "grad_norm": 9.788919448852539,
      "learning_rate": 6.411191736868185e-06,
      "loss": 0.4188258171081543,
      "memory(GiB)": 72.72,
      "step": 23505,
      "train_speed(iter/s)": 0.251512
    },
    {
      "epoch": 2.192892454062121,
      "grad_norm": 2.6096458435058594,
      "learning_rate": 6.409712078083901e-06,
      "loss": 0.4095175743103027,
      "memory(GiB)": 72.72,
      "step": 23510,
      "token_acc": 0.7804878048780488,
      "train_speed(iter/s)": 0.25151
    },
    {
      "epoch": 2.1933588284674936,
      "grad_norm": 4.0296454429626465,
      "learning_rate": 6.408232285169853e-06,
      "loss": 0.408259916305542,
      "memory(GiB)": 72.72,
      "step": 23515,
      "token_acc": 0.5434782608695652,
      "train_speed(iter/s)": 0.251512
    },
    {
      "epoch": 2.1938252028728664,
      "grad_norm": 3.542818546295166,
      "learning_rate": 6.406752358266841e-06,
      "loss": 0.38358616828918457,
      "memory(GiB)": 72.72,
      "step": 23520,
      "train_speed(iter/s)": 0.251515
    },
    {
      "epoch": 2.194291577278239,
      "grad_norm": 4.317922115325928,
      "learning_rate": 6.405272297515676e-06,
      "loss": 0.3912552833557129,
      "memory(GiB)": 72.72,
      "step": 23525,
      "train_speed(iter/s)": 0.251516
    },
    {
      "epoch": 2.1947579516836115,
      "grad_norm": 3.2466890811920166,
      "learning_rate": 6.403792103057183e-06,
      "loss": 0.4131801128387451,
      "memory(GiB)": 72.72,
      "step": 23530,
      "token_acc": 0.4927536231884058,
      "train_speed(iter/s)": 0.251515
    },
    {
      "epoch": 2.1952243260889843,
      "grad_norm": 3.142531633377075,
      "learning_rate": 6.4023117750321954e-06,
      "loss": 0.42441959381103517,
      "memory(GiB)": 72.72,
      "step": 23535,
      "token_acc": 0.8319327731092437,
      "train_speed(iter/s)": 0.251517
    },
    {
      "epoch": 2.1956907004943567,
      "grad_norm": 3.703861713409424,
      "learning_rate": 6.40083131358156e-06,
      "loss": 0.4595780372619629,
      "memory(GiB)": 72.72,
      "step": 23540,
      "train_speed(iter/s)": 0.251516
    },
    {
      "epoch": 2.1961570748997294,
      "grad_norm": 3.475644826889038,
      "learning_rate": 6.399350718846142e-06,
      "loss": 0.3824204921722412,
      "memory(GiB)": 72.72,
      "step": 23545,
      "train_speed(iter/s)": 0.251518
    },
    {
      "epoch": 2.1966234493051022,
      "grad_norm": 3.459724187850952,
      "learning_rate": 6.397869990966814e-06,
      "loss": 0.4096981048583984,
      "memory(GiB)": 72.72,
      "step": 23550,
      "token_acc": 0.6486486486486487,
      "train_speed(iter/s)": 0.251519
    },
    {
      "epoch": 2.1970898237104746,
      "grad_norm": 3.3162965774536133,
      "learning_rate": 6.3963891300844615e-06,
      "loss": 0.37261099815368653,
      "memory(GiB)": 72.72,
      "step": 23555,
      "train_speed(iter/s)": 0.25152
    },
    {
      "epoch": 2.1975561981158473,
      "grad_norm": 2.6984851360321045,
      "learning_rate": 6.394908136339988e-06,
      "loss": 0.4022003173828125,
      "memory(GiB)": 72.72,
      "step": 23560,
      "token_acc": 0.5576923076923077,
      "train_speed(iter/s)": 0.251526
    },
    {
      "epoch": 2.19802257252122,
      "grad_norm": 2.785808563232422,
      "learning_rate": 6.3934270098743e-06,
      "loss": 0.3971081733703613,
      "memory(GiB)": 72.72,
      "step": 23565,
      "train_speed(iter/s)": 0.251525
    },
    {
      "epoch": 2.1984889469265925,
      "grad_norm": 2.519869089126587,
      "learning_rate": 6.3919457508283236e-06,
      "loss": 0.3548917531967163,
      "memory(GiB)": 72.72,
      "step": 23570,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.251522
    },
    {
      "epoch": 2.1989553213319653,
      "grad_norm": 2.538468360900879,
      "learning_rate": 6.390464359342998e-06,
      "loss": 0.3779124736785889,
      "memory(GiB)": 72.72,
      "step": 23575,
      "train_speed(iter/s)": 0.251525
    },
    {
      "epoch": 2.199421695737338,
      "grad_norm": 3.3954789638519287,
      "learning_rate": 6.388982835559273e-06,
      "loss": 0.37539947032928467,
      "memory(GiB)": 72.72,
      "step": 23580,
      "train_speed(iter/s)": 0.251522
    },
    {
      "epoch": 2.1998880701427104,
      "grad_norm": 4.185987949371338,
      "learning_rate": 6.38750117961811e-06,
      "loss": 0.398451042175293,
      "memory(GiB)": 72.72,
      "step": 23585,
      "train_speed(iter/s)": 0.251525
    },
    {
      "epoch": 2.200354444548083,
      "grad_norm": 2.593282699584961,
      "learning_rate": 6.3860193916604825e-06,
      "loss": 0.39226536750793456,
      "memory(GiB)": 72.72,
      "step": 23590,
      "train_speed(iter/s)": 0.251526
    },
    {
      "epoch": 2.200820818953456,
      "grad_norm": 3.8154959678649902,
      "learning_rate": 6.3845374718273815e-06,
      "loss": 0.40746417045593264,
      "memory(GiB)": 72.72,
      "step": 23595,
      "train_speed(iter/s)": 0.251523
    },
    {
      "epoch": 2.2012871933588283,
      "grad_norm": 2.044318675994873,
      "learning_rate": 6.383055420259804e-06,
      "loss": 0.3848233699798584,
      "memory(GiB)": 72.72,
      "step": 23600,
      "token_acc": 0.7588652482269503,
      "train_speed(iter/s)": 0.251522
    },
    {
      "epoch": 2.201753567764201,
      "grad_norm": 2.2989869117736816,
      "learning_rate": 6.3815732370987634e-06,
      "loss": 0.35376873016357424,
      "memory(GiB)": 72.72,
      "step": 23605,
      "train_speed(iter/s)": 0.251519
    },
    {
      "epoch": 2.202219942169574,
      "grad_norm": 2.6158134937286377,
      "learning_rate": 6.380090922485287e-06,
      "loss": 0.41059112548828125,
      "memory(GiB)": 72.72,
      "step": 23610,
      "train_speed(iter/s)": 0.251518
    },
    {
      "epoch": 2.202686316574946,
      "grad_norm": 2.955695390701294,
      "learning_rate": 6.378608476560411e-06,
      "loss": 0.42243032455444335,
      "memory(GiB)": 72.72,
      "step": 23615,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.251518
    },
    {
      "epoch": 2.203152690980319,
      "grad_norm": 3.361851930618286,
      "learning_rate": 6.3771258994651815e-06,
      "loss": 0.37361726760864256,
      "memory(GiB)": 72.72,
      "step": 23620,
      "train_speed(iter/s)": 0.251516
    },
    {
      "epoch": 2.2036190653856917,
      "grad_norm": 3.2031126022338867,
      "learning_rate": 6.375643191340668e-06,
      "loss": 0.379440450668335,
      "memory(GiB)": 72.72,
      "step": 23625,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.204085439791064,
      "grad_norm": 3.464188814163208,
      "learning_rate": 6.374160352327942e-06,
      "loss": 0.4130085945129395,
      "memory(GiB)": 72.72,
      "step": 23630,
      "token_acc": 0.4166666666666667,
      "train_speed(iter/s)": 0.251514
    },
    {
      "epoch": 2.204551814196437,
      "grad_norm": 2.9481399059295654,
      "learning_rate": 6.3726773825680935e-06,
      "loss": 0.38233113288879395,
      "memory(GiB)": 72.72,
      "step": 23635,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.251514
    },
    {
      "epoch": 2.2050181886018096,
      "grad_norm": 4.171154975891113,
      "learning_rate": 6.371194282202218e-06,
      "loss": 0.3550222396850586,
      "memory(GiB)": 72.72,
      "step": 23640,
      "token_acc": 0.68,
      "train_speed(iter/s)": 0.251512
    },
    {
      "epoch": 2.205484563007182,
      "grad_norm": 3.610492467880249,
      "learning_rate": 6.369711051371433e-06,
      "loss": 0.3612156629562378,
      "memory(GiB)": 72.72,
      "step": 23645,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.2059509374125548,
      "grad_norm": 2.3253540992736816,
      "learning_rate": 6.36822769021686e-06,
      "loss": 0.39182438850402834,
      "memory(GiB)": 72.72,
      "step": 23650,
      "train_speed(iter/s)": 0.251514
    },
    {
      "epoch": 2.2064173118179276,
      "grad_norm": 3.1417675018310547,
      "learning_rate": 6.366744198879638e-06,
      "loss": 0.3869946479797363,
      "memory(GiB)": 72.72,
      "step": 23655,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.2068836862233,
      "grad_norm": 6.005561351776123,
      "learning_rate": 6.365260577500914e-06,
      "loss": 0.3738333463668823,
      "memory(GiB)": 72.72,
      "step": 23660,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.2073500606286727,
      "grad_norm": 3.2048919200897217,
      "learning_rate": 6.363776826221853e-06,
      "loss": 0.38341240882873534,
      "memory(GiB)": 72.72,
      "step": 23665,
      "token_acc": 0.4915254237288136,
      "train_speed(iter/s)": 0.251511
    },
    {
      "epoch": 2.2078164350340455,
      "grad_norm": 3.6893277168273926,
      "learning_rate": 6.362292945183627e-06,
      "loss": 0.3531951427459717,
      "memory(GiB)": 72.72,
      "step": 23670,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.208282809439418,
      "grad_norm": 3.955328941345215,
      "learning_rate": 6.360808934527425e-06,
      "loss": 0.4090592384338379,
      "memory(GiB)": 72.72,
      "step": 23675,
      "token_acc": 0.6538461538461539,
      "train_speed(iter/s)": 0.251508
    },
    {
      "epoch": 2.2087491838447906,
      "grad_norm": 3.3450515270233154,
      "learning_rate": 6.359324794394445e-06,
      "loss": 0.3857861042022705,
      "memory(GiB)": 72.72,
      "step": 23680,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.2092155582501634,
      "grad_norm": 4.384006500244141,
      "learning_rate": 6.357840524925899e-06,
      "loss": 0.375752592086792,
      "memory(GiB)": 72.72,
      "step": 23685,
      "train_speed(iter/s)": 0.251515
    },
    {
      "epoch": 2.2096819326555357,
      "grad_norm": 3.1805057525634766,
      "learning_rate": 6.356356126263008e-06,
      "loss": 0.3755582332611084,
      "memory(GiB)": 72.72,
      "step": 23690,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.2101483070609085,
      "grad_norm": 2.653137683868408,
      "learning_rate": 6.354871598547011e-06,
      "loss": 0.373801589012146,
      "memory(GiB)": 72.72,
      "step": 23695,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.251518
    },
    {
      "epoch": 2.2106146814662813,
      "grad_norm": 11.287257194519043,
      "learning_rate": 6.353386941919155e-06,
      "loss": 0.4011682510375977,
      "memory(GiB)": 72.72,
      "step": 23700,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25152
    },
    {
      "epoch": 2.2110810558716536,
      "grad_norm": 2.4211554527282715,
      "learning_rate": 6.3519021565207015e-06,
      "loss": 0.37437076568603517,
      "memory(GiB)": 72.72,
      "step": 23705,
      "token_acc": 0.76875,
      "train_speed(iter/s)": 0.251518
    },
    {
      "epoch": 2.2115474302770264,
      "grad_norm": 4.741170406341553,
      "learning_rate": 6.350417242492922e-06,
      "loss": 0.403721284866333,
      "memory(GiB)": 72.72,
      "step": 23710,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.212013804682399,
      "grad_norm": 3.267691135406494,
      "learning_rate": 6.3489321999771015e-06,
      "loss": 0.36374077796936033,
      "memory(GiB)": 72.72,
      "step": 23715,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.251513
    },
    {
      "epoch": 2.2124801790877715,
      "grad_norm": 5.830296516418457,
      "learning_rate": 6.347447029114537e-06,
      "loss": 0.4277674674987793,
      "memory(GiB)": 72.72,
      "step": 23720,
      "train_speed(iter/s)": 0.251514
    },
    {
      "epoch": 2.2129465534931443,
      "grad_norm": 28.884090423583984,
      "learning_rate": 6.345961730046539e-06,
      "loss": 0.42861080169677734,
      "memory(GiB)": 72.72,
      "step": 23725,
      "train_speed(iter/s)": 0.251517
    },
    {
      "epoch": 2.213412927898517,
      "grad_norm": 3.420780897140503,
      "learning_rate": 6.344476302914431e-06,
      "loss": 0.39140305519104,
      "memory(GiB)": 72.72,
      "step": 23730,
      "train_speed(iter/s)": 0.251517
    },
    {
      "epoch": 2.2138793023038894,
      "grad_norm": 3.5954062938690186,
      "learning_rate": 6.342990747859543e-06,
      "loss": 0.3595465660095215,
      "memory(GiB)": 72.72,
      "step": 23735,
      "train_speed(iter/s)": 0.251515
    },
    {
      "epoch": 2.214345676709262,
      "grad_norm": 3.890807628631592,
      "learning_rate": 6.341505065023222e-06,
      "loss": 0.3582282066345215,
      "memory(GiB)": 72.72,
      "step": 23740,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251515
    },
    {
      "epoch": 2.214812051114635,
      "grad_norm": 4.025689125061035,
      "learning_rate": 6.340019254546827e-06,
      "loss": 0.3952972888946533,
      "memory(GiB)": 72.72,
      "step": 23745,
      "train_speed(iter/s)": 0.251519
    },
    {
      "epoch": 2.2152784255200073,
      "grad_norm": 3.46016263961792,
      "learning_rate": 6.3385333165717274e-06,
      "loss": 0.36876592636108396,
      "memory(GiB)": 72.72,
      "step": 23750,
      "token_acc": 0.45,
      "train_speed(iter/s)": 0.251518
    },
    {
      "epoch": 2.21574479992538,
      "grad_norm": 3.819565534591675,
      "learning_rate": 6.337047251239308e-06,
      "loss": 0.38153948783874514,
      "memory(GiB)": 72.72,
      "step": 23755,
      "token_acc": 0.8108108108108109,
      "train_speed(iter/s)": 0.251516
    },
    {
      "epoch": 2.216211174330753,
      "grad_norm": 5.009091377258301,
      "learning_rate": 6.33556105869096e-06,
      "loss": 0.4006455421447754,
      "memory(GiB)": 72.72,
      "step": 23760,
      "token_acc": 0.4032258064516129,
      "train_speed(iter/s)": 0.251519
    },
    {
      "epoch": 2.216677548736125,
      "grad_norm": 4.050997734069824,
      "learning_rate": 6.334074739068091e-06,
      "loss": 0.3838978290557861,
      "memory(GiB)": 72.72,
      "step": 23765,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 2.217143923141498,
      "grad_norm": 3.0675911903381348,
      "learning_rate": 6.332588292512121e-06,
      "loss": 0.34388508796691897,
      "memory(GiB)": 72.72,
      "step": 23770,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.217610297546871,
      "grad_norm": 2.488705635070801,
      "learning_rate": 6.33110171916448e-06,
      "loss": 0.3822488784790039,
      "memory(GiB)": 72.72,
      "step": 23775,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 2.218076671952243,
      "grad_norm": 3.054419994354248,
      "learning_rate": 6.32961501916661e-06,
      "loss": 0.3836113929748535,
      "memory(GiB)": 72.72,
      "step": 23780,
      "token_acc": 0.3333333333333333,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 2.218543046357616,
      "grad_norm": 3.821241855621338,
      "learning_rate": 6.32812819265997e-06,
      "loss": 0.3613192796707153,
      "memory(GiB)": 72.72,
      "step": 23785,
      "token_acc": 0.9204545454545454,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 2.2190094207629887,
      "grad_norm": 4.613398551940918,
      "learning_rate": 6.326641239786022e-06,
      "loss": 0.35655765533447265,
      "memory(GiB)": 72.72,
      "step": 23790,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 2.219475795168361,
      "grad_norm": 4.5491461753845215,
      "learning_rate": 6.325154160686246e-06,
      "loss": 0.3600744724273682,
      "memory(GiB)": 72.72,
      "step": 23795,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 2.219942169573734,
      "grad_norm": 4.337228775024414,
      "learning_rate": 6.3236669555021345e-06,
      "loss": 0.34350013732910156,
      "memory(GiB)": 72.72,
      "step": 23800,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.2204085439791066,
      "grad_norm": 6.147457599639893,
      "learning_rate": 6.322179624375191e-06,
      "loss": 0.4069826126098633,
      "memory(GiB)": 72.72,
      "step": 23805,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.220874918384479,
      "grad_norm": 3.4668405055999756,
      "learning_rate": 6.320692167446928e-06,
      "loss": 0.39012622833251953,
      "memory(GiB)": 72.72,
      "step": 23810,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 2.2213412927898517,
      "grad_norm": 3.214320182800293,
      "learning_rate": 6.3192045848588746e-06,
      "loss": 0.35806803703308104,
      "memory(GiB)": 72.72,
      "step": 23815,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.2218076671952245,
      "grad_norm": 4.892267227172852,
      "learning_rate": 6.317716876752569e-06,
      "loss": 0.3594757080078125,
      "memory(GiB)": 72.72,
      "step": 23820,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.222274041600597,
      "grad_norm": 3.5854406356811523,
      "learning_rate": 6.316229043269559e-06,
      "loss": 0.40229177474975586,
      "memory(GiB)": 72.72,
      "step": 23825,
      "token_acc": 0.5945945945945946,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.2227404160059696,
      "grad_norm": 7.261283874511719,
      "learning_rate": 6.314741084551414e-06,
      "loss": 0.3823865413665771,
      "memory(GiB)": 72.72,
      "step": 23830,
      "token_acc": 0.4126984126984127,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 2.2232067904113424,
      "grad_norm": 4.702671051025391,
      "learning_rate": 6.3132530007397045e-06,
      "loss": 0.38747055530548097,
      "memory(GiB)": 72.72,
      "step": 23835,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.2236731648167147,
      "grad_norm": 2.383819341659546,
      "learning_rate": 6.311764791976015e-06,
      "loss": 0.3900845289230347,
      "memory(GiB)": 72.72,
      "step": 23840,
      "token_acc": 0.3333333333333333,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.2241395392220875,
      "grad_norm": 3.899550676345825,
      "learning_rate": 6.310276458401948e-06,
      "loss": 0.38977980613708496,
      "memory(GiB)": 72.72,
      "step": 23845,
      "token_acc": 0.9690721649484536,
      "train_speed(iter/s)": 0.251441
    },
    {
      "epoch": 2.2246059136274603,
      "grad_norm": 3.371126890182495,
      "learning_rate": 6.308788000159113e-06,
      "loss": 0.3796891212463379,
      "memory(GiB)": 72.72,
      "step": 23850,
      "token_acc": 0.7323943661971831,
      "train_speed(iter/s)": 0.251445
    },
    {
      "epoch": 2.2250722880328326,
      "grad_norm": 2.9178407192230225,
      "learning_rate": 6.307299417389131e-06,
      "loss": 0.38554885387420657,
      "memory(GiB)": 72.72,
      "step": 23855,
      "token_acc": 0.4772727272727273,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 2.2255386624382054,
      "grad_norm": 3.5438382625579834,
      "learning_rate": 6.305810710233637e-06,
      "loss": 0.3575286388397217,
      "memory(GiB)": 72.72,
      "step": 23860,
      "train_speed(iter/s)": 0.251444
    },
    {
      "epoch": 2.226005036843578,
      "grad_norm": 4.665938854217529,
      "learning_rate": 6.3043218788342765e-06,
      "loss": 0.4153785228729248,
      "memory(GiB)": 72.72,
      "step": 23865,
      "token_acc": 0.5473684210526316,
      "train_speed(iter/s)": 0.251448
    },
    {
      "epoch": 2.2264714112489505,
      "grad_norm": 4.314459323883057,
      "learning_rate": 6.302832923332707e-06,
      "loss": 0.37873144149780275,
      "memory(GiB)": 72.72,
      "step": 23870,
      "train_speed(iter/s)": 0.251446
    },
    {
      "epoch": 2.2269377856543233,
      "grad_norm": 3.9708542823791504,
      "learning_rate": 6.3013438438705974e-06,
      "loss": 0.4073692798614502,
      "memory(GiB)": 72.72,
      "step": 23875,
      "train_speed(iter/s)": 0.251446
    },
    {
      "epoch": 2.227404160059696,
      "grad_norm": 3.8779397010803223,
      "learning_rate": 6.299854640589631e-06,
      "loss": 0.385072135925293,
      "memory(GiB)": 72.72,
      "step": 23880,
      "token_acc": 0.9518072289156626,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 2.2278705344650684,
      "grad_norm": 2.0594043731689453,
      "learning_rate": 6.298365313631502e-06,
      "loss": 0.3736839294433594,
      "memory(GiB)": 72.72,
      "step": 23885,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 2.2283369088704412,
      "grad_norm": 2.8705124855041504,
      "learning_rate": 6.296875863137909e-06,
      "loss": 0.38119056224823,
      "memory(GiB)": 72.72,
      "step": 23890,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.228803283275814,
      "grad_norm": 4.262256622314453,
      "learning_rate": 6.295386289250575e-06,
      "loss": 0.3847893238067627,
      "memory(GiB)": 72.72,
      "step": 23895,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.2292696576811863,
      "grad_norm": 2.3412704467773438,
      "learning_rate": 6.293896592111226e-06,
      "loss": 0.3413534164428711,
      "memory(GiB)": 72.72,
      "step": 23900,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.229736032086559,
      "grad_norm": 4.452507019042969,
      "learning_rate": 6.292406771861602e-06,
      "loss": 0.39434428215026857,
      "memory(GiB)": 72.72,
      "step": 23905,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 2.230202406491932,
      "grad_norm": 3.376206874847412,
      "learning_rate": 6.290916828643455e-06,
      "loss": 0.36457324028015137,
      "memory(GiB)": 72.72,
      "step": 23910,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.2306687808973042,
      "grad_norm": 3.083834171295166,
      "learning_rate": 6.28942676259855e-06,
      "loss": 0.37348761558532717,
      "memory(GiB)": 72.72,
      "step": 23915,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 2.231135155302677,
      "grad_norm": 3.686241626739502,
      "learning_rate": 6.2879365738686585e-06,
      "loss": 0.40633211135864256,
      "memory(GiB)": 72.72,
      "step": 23920,
      "token_acc": 0.4634146341463415,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.23160152970805,
      "grad_norm": 2.6931042671203613,
      "learning_rate": 6.286446262595569e-06,
      "loss": 0.3769895792007446,
      "memory(GiB)": 72.72,
      "step": 23925,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 2.232067904113422,
      "grad_norm": 4.531794548034668,
      "learning_rate": 6.284955828921083e-06,
      "loss": 0.39091308116912843,
      "memory(GiB)": 72.72,
      "step": 23930,
      "token_acc": 0.7321428571428571,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.232534278518795,
      "grad_norm": 8.807003021240234,
      "learning_rate": 6.283465272987008e-06,
      "loss": 0.378359055519104,
      "memory(GiB)": 72.72,
      "step": 23935,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.2330006529241677,
      "grad_norm": 4.5099263191223145,
      "learning_rate": 6.281974594935164e-06,
      "loss": 0.35723721981048584,
      "memory(GiB)": 72.72,
      "step": 23940,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.23346702732954,
      "grad_norm": 8.896658897399902,
      "learning_rate": 6.280483794907388e-06,
      "loss": 0.3805071353912354,
      "memory(GiB)": 72.72,
      "step": 23945,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.233933401734913,
      "grad_norm": 5.0655598640441895,
      "learning_rate": 6.278992873045524e-06,
      "loss": 0.4088758945465088,
      "memory(GiB)": 72.72,
      "step": 23950,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.2343997761402856,
      "grad_norm": 3.3064823150634766,
      "learning_rate": 6.277501829491427e-06,
      "loss": 0.37891082763671874,
      "memory(GiB)": 72.72,
      "step": 23955,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.234866150545658,
      "grad_norm": 4.056874752044678,
      "learning_rate": 6.2760106643869664e-06,
      "loss": 0.39183950424194336,
      "memory(GiB)": 72.72,
      "step": 23960,
      "token_acc": 0.525,
      "train_speed(iter/s)": 0.251465
    },
    {
      "epoch": 2.2353325249510307,
      "grad_norm": 3.1201045513153076,
      "learning_rate": 6.274519377874023e-06,
      "loss": 0.35591444969177244,
      "memory(GiB)": 72.72,
      "step": 23965,
      "token_acc": 0.6226415094339622,
      "train_speed(iter/s)": 0.251468
    },
    {
      "epoch": 2.2357988993564035,
      "grad_norm": 4.547382831573486,
      "learning_rate": 6.273027970094488e-06,
      "loss": 0.3414137601852417,
      "memory(GiB)": 72.72,
      "step": 23970,
      "train_speed(iter/s)": 0.251468
    },
    {
      "epoch": 2.236265273761776,
      "grad_norm": 3.775211811065674,
      "learning_rate": 6.27153644119026e-06,
      "loss": 0.36993296146392823,
      "memory(GiB)": 72.72,
      "step": 23975,
      "train_speed(iter/s)": 0.251469
    },
    {
      "epoch": 2.2367316481671486,
      "grad_norm": 3.5090768337249756,
      "learning_rate": 6.2700447913032595e-06,
      "loss": 0.37233519554138184,
      "memory(GiB)": 72.72,
      "step": 23980,
      "token_acc": 0.8875,
      "train_speed(iter/s)": 0.251467
    },
    {
      "epoch": 2.2371980225725214,
      "grad_norm": 3.806431293487549,
      "learning_rate": 6.268553020575409e-06,
      "loss": 0.35724506378173826,
      "memory(GiB)": 72.72,
      "step": 23985,
      "train_speed(iter/s)": 0.251465
    },
    {
      "epoch": 2.2376643969778938,
      "grad_norm": 2.9882125854492188,
      "learning_rate": 6.267061129148646e-06,
      "loss": 0.40744752883911134,
      "memory(GiB)": 72.72,
      "step": 23990,
      "token_acc": 0.8223684210526315,
      "train_speed(iter/s)": 0.251467
    },
    {
      "epoch": 2.2381307713832665,
      "grad_norm": 5.230030536651611,
      "learning_rate": 6.265569117164918e-06,
      "loss": 0.41646585464477537,
      "memory(GiB)": 72.72,
      "step": 23995,
      "token_acc": 0.5344827586206896,
      "train_speed(iter/s)": 0.251471
    },
    {
      "epoch": 2.2385971457886393,
      "grad_norm": 3.4144530296325684,
      "learning_rate": 6.26407698476619e-06,
      "loss": 0.3777130126953125,
      "memory(GiB)": 72.72,
      "step": 24000,
      "train_speed(iter/s)": 0.251472
    },
    {
      "epoch": 2.2390635201940117,
      "grad_norm": 3.9539201259613037,
      "learning_rate": 6.26258473209443e-06,
      "loss": 0.3766310214996338,
      "memory(GiB)": 72.72,
      "step": 24005,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.2395298945993845,
      "grad_norm": 3.801915407180786,
      "learning_rate": 6.2610923592916224e-06,
      "loss": 0.35783236026763915,
      "memory(GiB)": 72.72,
      "step": 24010,
      "token_acc": 0.6371681415929203,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.239996269004757,
      "grad_norm": 4.482061386108398,
      "learning_rate": 6.259599866499762e-06,
      "loss": 0.39587204456329345,
      "memory(GiB)": 72.72,
      "step": 24015,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.2404626434101296,
      "grad_norm": 4.918038845062256,
      "learning_rate": 6.258107253860854e-06,
      "loss": 0.3470447540283203,
      "memory(GiB)": 72.72,
      "step": 24020,
      "token_acc": 0.87248322147651,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 2.2409290178155024,
      "grad_norm": 2.8281102180480957,
      "learning_rate": 6.2566145215169146e-06,
      "loss": 0.37875449657440186,
      "memory(GiB)": 72.72,
      "step": 24025,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.241395392220875,
      "grad_norm": 2.500471830368042,
      "learning_rate": 6.255121669609978e-06,
      "loss": 0.33710718154907227,
      "memory(GiB)": 72.72,
      "step": 24030,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.2418617666262475,
      "grad_norm": 6.644637107849121,
      "learning_rate": 6.25362869828208e-06,
      "loss": 0.39168739318847656,
      "memory(GiB)": 72.72,
      "step": 24035,
      "token_acc": 0.8246753246753247,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.2423281410316203,
      "grad_norm": 4.439964771270752,
      "learning_rate": 6.252135607675274e-06,
      "loss": 0.38095736503601074,
      "memory(GiB)": 72.72,
      "step": 24040,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.251409
    },
    {
      "epoch": 2.2427945154369926,
      "grad_norm": 3.447209119796753,
      "learning_rate": 6.25064239793162e-06,
      "loss": 0.370637845993042,
      "memory(GiB)": 72.72,
      "step": 24045,
      "train_speed(iter/s)": 0.251411
    },
    {
      "epoch": 2.2432608898423654,
      "grad_norm": 10.37330150604248,
      "learning_rate": 6.2491490691931955e-06,
      "loss": 0.380535888671875,
      "memory(GiB)": 72.72,
      "step": 24050,
      "train_speed(iter/s)": 0.251411
    },
    {
      "epoch": 2.243727264247738,
      "grad_norm": 7.993093013763428,
      "learning_rate": 6.247655621602086e-06,
      "loss": 0.3660349130630493,
      "memory(GiB)": 72.72,
      "step": 24055,
      "token_acc": 0.375,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 2.244193638653111,
      "grad_norm": 4.943540573120117,
      "learning_rate": 6.246162055300386e-06,
      "loss": 0.4332289695739746,
      "memory(GiB)": 72.72,
      "step": 24060,
      "token_acc": 0.5964912280701754,
      "train_speed(iter/s)": 0.251409
    },
    {
      "epoch": 2.2446600130584833,
      "grad_norm": 3.2449698448181152,
      "learning_rate": 6.244668370430207e-06,
      "loss": 0.3743577003479004,
      "memory(GiB)": 72.72,
      "step": 24065,
      "train_speed(iter/s)": 0.251411
    },
    {
      "epoch": 2.245126387463856,
      "grad_norm": 4.353517055511475,
      "learning_rate": 6.243174567133666e-06,
      "loss": 0.42545485496520996,
      "memory(GiB)": 72.72,
      "step": 24070,
      "token_acc": 0.5967741935483871,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 2.2455927618692284,
      "grad_norm": 5.137841701507568,
      "learning_rate": 6.2416806455528955e-06,
      "loss": 0.39606385231018065,
      "memory(GiB)": 72.72,
      "step": 24075,
      "train_speed(iter/s)": 0.251411
    },
    {
      "epoch": 2.246059136274601,
      "grad_norm": 7.717497825622559,
      "learning_rate": 6.240186605830035e-06,
      "loss": 0.36566736698150637,
      "memory(GiB)": 72.72,
      "step": 24080,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 2.246525510679974,
      "grad_norm": 5.348331928253174,
      "learning_rate": 6.238692448107241e-06,
      "loss": 0.39587337970733644,
      "memory(GiB)": 72.72,
      "step": 24085,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 2.2469918850853468,
      "grad_norm": 3.995189666748047,
      "learning_rate": 6.2371981725266765e-06,
      "loss": 0.3594110727310181,
      "memory(GiB)": 72.72,
      "step": 24090,
      "token_acc": 0.9473684210526315,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 2.247458259490719,
      "grad_norm": 3.0130679607391357,
      "learning_rate": 6.2357037792305155e-06,
      "loss": 0.4056978225708008,
      "memory(GiB)": 72.72,
      "step": 24095,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 2.247924633896092,
      "grad_norm": 4.966856002807617,
      "learning_rate": 6.234209268360947e-06,
      "loss": 0.3804177284240723,
      "memory(GiB)": 72.72,
      "step": 24100,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 2.248391008301464,
      "grad_norm": 4.7831315994262695,
      "learning_rate": 6.23271464006017e-06,
      "loss": 0.40242643356323243,
      "memory(GiB)": 72.72,
      "step": 24105,
      "token_acc": 0.7549668874172185,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 2.248857382706837,
      "grad_norm": 9.080172538757324,
      "learning_rate": 6.231219894470391e-06,
      "loss": 0.36125478744506834,
      "memory(GiB)": 72.72,
      "step": 24110,
      "token_acc": 0.98,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.2493237571122098,
      "grad_norm": 5.473299503326416,
      "learning_rate": 6.2297250317338335e-06,
      "loss": 0.4003488540649414,
      "memory(GiB)": 72.72,
      "step": 24115,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 2.249790131517582,
      "grad_norm": 12.364551544189453,
      "learning_rate": 6.228230051992727e-06,
      "loss": 0.37652029991149905,
      "memory(GiB)": 72.72,
      "step": 24120,
      "token_acc": 0.4576271186440678,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 2.250256505922955,
      "grad_norm": 7.4431281089782715,
      "learning_rate": 6.226734955389314e-06,
      "loss": 0.3731751680374146,
      "memory(GiB)": 72.72,
      "step": 24125,
      "token_acc": 0.4426229508196721,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 2.2507228803283277,
      "grad_norm": 3.987823247909546,
      "learning_rate": 6.22523974206585e-06,
      "loss": 0.3688085079193115,
      "memory(GiB)": 72.72,
      "step": 24130,
      "token_acc": 0.42105263157894735,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 2.2511892547337,
      "grad_norm": 27.21814727783203,
      "learning_rate": 6.223744412164599e-06,
      "loss": 0.37950997352600097,
      "memory(GiB)": 72.72,
      "step": 24135,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 2.251655629139073,
      "grad_norm": 3.61934494972229,
      "learning_rate": 6.222248965827835e-06,
      "loss": 0.35476956367492674,
      "memory(GiB)": 72.72,
      "step": 24140,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 2.2521220035444456,
      "grad_norm": 4.3787689208984375,
      "learning_rate": 6.220753403197848e-06,
      "loss": 0.4005854606628418,
      "memory(GiB)": 72.72,
      "step": 24145,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.252588377949818,
      "grad_norm": 2.962306261062622,
      "learning_rate": 6.219257724416936e-06,
      "loss": 0.41922383308410643,
      "memory(GiB)": 72.72,
      "step": 24150,
      "token_acc": 0.9298245614035088,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 2.2530547523551907,
      "grad_norm": 36.91365432739258,
      "learning_rate": 6.217761929627407e-06,
      "loss": 0.36768715381622313,
      "memory(GiB)": 72.72,
      "step": 24155,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 2.2535211267605635,
      "grad_norm": 3.1563467979431152,
      "learning_rate": 6.216266018971583e-06,
      "loss": 0.3558650016784668,
      "memory(GiB)": 72.72,
      "step": 24160,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 2.253987501165936,
      "grad_norm": 4.615761756896973,
      "learning_rate": 6.214769992591794e-06,
      "loss": 0.376821231842041,
      "memory(GiB)": 72.72,
      "step": 24165,
      "token_acc": 0.5230769230769231,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.2544538755713086,
      "grad_norm": 6.0791015625,
      "learning_rate": 6.2132738506303815e-06,
      "loss": 0.40737037658691405,
      "memory(GiB)": 72.72,
      "step": 24170,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.2549202499766814,
      "grad_norm": 6.33790397644043,
      "learning_rate": 6.2117775932297e-06,
      "loss": 0.3754455089569092,
      "memory(GiB)": 72.72,
      "step": 24175,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.2553866243820537,
      "grad_norm": 2.6206777095794678,
      "learning_rate": 6.210281220532113e-06,
      "loss": 0.3709465980529785,
      "memory(GiB)": 72.72,
      "step": 24180,
      "token_acc": 0.9438202247191011,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 2.2558529987874265,
      "grad_norm": 3.5260424613952637,
      "learning_rate": 6.208784732679996e-06,
      "loss": 0.3440942525863647,
      "memory(GiB)": 72.72,
      "step": 24185,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.2563193731927993,
      "grad_norm": 3.817927837371826,
      "learning_rate": 6.207288129815737e-06,
      "loss": 0.38037848472595215,
      "memory(GiB)": 72.72,
      "step": 24190,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.2567857475981716,
      "grad_norm": 3.0774645805358887,
      "learning_rate": 6.20579141208173e-06,
      "loss": 0.377396821975708,
      "memory(GiB)": 72.72,
      "step": 24195,
      "token_acc": 0.9625668449197861,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 2.2572521220035444,
      "grad_norm": 3.0927348136901855,
      "learning_rate": 6.204294579620385e-06,
      "loss": 0.35828485488891604,
      "memory(GiB)": 72.72,
      "step": 24200,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.257718496408917,
      "grad_norm": 3.0320470333099365,
      "learning_rate": 6.202797632574122e-06,
      "loss": 0.3487353563308716,
      "memory(GiB)": 72.72,
      "step": 24205,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.251439
    },
    {
      "epoch": 2.2581848708142895,
      "grad_norm": 4.103635311126709,
      "learning_rate": 6.201300571085369e-06,
      "loss": 0.3754248857498169,
      "memory(GiB)": 72.72,
      "step": 24210,
      "token_acc": 0.6435643564356436,
      "train_speed(iter/s)": 0.251439
    },
    {
      "epoch": 2.2586512452196623,
      "grad_norm": 3.9394044876098633,
      "learning_rate": 6.199803395296565e-06,
      "loss": 0.3602506160736084,
      "memory(GiB)": 72.72,
      "step": 24215,
      "token_acc": 0.4523809523809524,
      "train_speed(iter/s)": 0.251439
    },
    {
      "epoch": 2.259117619625035,
      "grad_norm": 3.0477817058563232,
      "learning_rate": 6.198306105350167e-06,
      "loss": 0.40311241149902344,
      "memory(GiB)": 72.72,
      "step": 24220,
      "token_acc": 0.4745762711864407,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 2.2595839940304074,
      "grad_norm": 9.237998008728027,
      "learning_rate": 6.196808701388634e-06,
      "loss": 0.3664107322692871,
      "memory(GiB)": 72.72,
      "step": 24225,
      "token_acc": 0.6458333333333334,
      "train_speed(iter/s)": 0.25144
    },
    {
      "epoch": 2.26005036843578,
      "grad_norm": 3.8358404636383057,
      "learning_rate": 6.195311183554439e-06,
      "loss": 0.34931039810180664,
      "memory(GiB)": 72.72,
      "step": 24230,
      "train_speed(iter/s)": 0.251441
    },
    {
      "epoch": 2.260516742841153,
      "grad_norm": 3.0366599559783936,
      "learning_rate": 6.193813551990068e-06,
      "loss": 0.3798878908157349,
      "memory(GiB)": 72.72,
      "step": 24235,
      "train_speed(iter/s)": 0.251441
    },
    {
      "epoch": 2.2609831172465253,
      "grad_norm": 3.551917552947998,
      "learning_rate": 6.192315806838014e-06,
      "loss": 0.37057530879974365,
      "memory(GiB)": 72.72,
      "step": 24240,
      "token_acc": 0.9423076923076923,
      "train_speed(iter/s)": 0.251445
    },
    {
      "epoch": 2.261449491651898,
      "grad_norm": 5.64119291305542,
      "learning_rate": 6.190817948240784e-06,
      "loss": 0.4124629020690918,
      "memory(GiB)": 72.72,
      "step": 24245,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 2.261915866057271,
      "grad_norm": 4.525860786437988,
      "learning_rate": 6.189319976340895e-06,
      "loss": 0.37593300342559816,
      "memory(GiB)": 72.72,
      "step": 24250,
      "token_acc": 0.6046511627906976,
      "train_speed(iter/s)": 0.251449
    },
    {
      "epoch": 2.2623822404626432,
      "grad_norm": 31.2204532623291,
      "learning_rate": 6.187821891280876e-06,
      "loss": 0.36607396602630615,
      "memory(GiB)": 72.72,
      "step": 24255,
      "train_speed(iter/s)": 0.251449
    },
    {
      "epoch": 2.262848614868016,
      "grad_norm": 32.0152473449707,
      "learning_rate": 6.1863236932032615e-06,
      "loss": 0.4342369556427002,
      "memory(GiB)": 72.72,
      "step": 24260,
      "token_acc": 0.44642857142857145,
      "train_speed(iter/s)": 0.25145
    },
    {
      "epoch": 2.263314989273389,
      "grad_norm": 7.374209880828857,
      "learning_rate": 6.184825382250601e-06,
      "loss": 0.4042488098144531,
      "memory(GiB)": 72.72,
      "step": 24265,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 2.263781363678761,
      "grad_norm": 7.883458614349365,
      "learning_rate": 6.183326958565457e-06,
      "loss": 0.3616783618927002,
      "memory(GiB)": 72.72,
      "step": 24270,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 2.264247738084134,
      "grad_norm": 6.609732627868652,
      "learning_rate": 6.181828422290398e-06,
      "loss": 0.36200432777404784,
      "memory(GiB)": 72.72,
      "step": 24275,
      "token_acc": 0.33962264150943394,
      "train_speed(iter/s)": 0.251458
    },
    {
      "epoch": 2.2647141124895067,
      "grad_norm": 5.098463535308838,
      "learning_rate": 6.1803297735680045e-06,
      "loss": 0.35338711738586426,
      "memory(GiB)": 72.72,
      "step": 24280,
      "token_acc": 0.7413793103448276,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.265180486894879,
      "grad_norm": 4.476007461547852,
      "learning_rate": 6.17883101254087e-06,
      "loss": 0.35349221229553224,
      "memory(GiB)": 72.72,
      "step": 24285,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 2.265646861300252,
      "grad_norm": 3.9157469272613525,
      "learning_rate": 6.1773321393515965e-06,
      "loss": 0.3991786003112793,
      "memory(GiB)": 72.72,
      "step": 24290,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.2661132357056246,
      "grad_norm": 4.743109226226807,
      "learning_rate": 6.175833154142796e-06,
      "loss": 0.3568383455276489,
      "memory(GiB)": 72.72,
      "step": 24295,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.266579610110997,
      "grad_norm": 5.434849739074707,
      "learning_rate": 6.174334057057092e-06,
      "loss": 0.383988094329834,
      "memory(GiB)": 72.72,
      "step": 24300,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.2670459845163697,
      "grad_norm": 3.7089245319366455,
      "learning_rate": 6.172834848237123e-06,
      "loss": 0.39123923778533937,
      "memory(GiB)": 72.72,
      "step": 24305,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.2675123589217425,
      "grad_norm": 2.7678613662719727,
      "learning_rate": 6.17133552782553e-06,
      "loss": 0.394632625579834,
      "memory(GiB)": 72.72,
      "step": 24310,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 2.267978733327115,
      "grad_norm": 5.034566402435303,
      "learning_rate": 6.169836095964969e-06,
      "loss": 0.39952280521392824,
      "memory(GiB)": 72.72,
      "step": 24315,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.2684451077324876,
      "grad_norm": 4.102349281311035,
      "learning_rate": 6.168336552798108e-06,
      "loss": 0.3780202865600586,
      "memory(GiB)": 72.72,
      "step": 24320,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.2689114821378604,
      "grad_norm": 5.570070743560791,
      "learning_rate": 6.166836898467622e-06,
      "loss": 0.39392781257629395,
      "memory(GiB)": 72.72,
      "step": 24325,
      "token_acc": 0.6382978723404256,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.2693778565432328,
      "grad_norm": 6.053173542022705,
      "learning_rate": 6.1653371331162e-06,
      "loss": 0.40242867469787597,
      "memory(GiB)": 72.72,
      "step": 24330,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.2698442309486055,
      "grad_norm": 5.088960647583008,
      "learning_rate": 6.163837256886541e-06,
      "loss": 0.3770256996154785,
      "memory(GiB)": 72.72,
      "step": 24335,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.2703106053539783,
      "grad_norm": 6.003449440002441,
      "learning_rate": 6.1623372699213515e-06,
      "loss": 0.3722879648208618,
      "memory(GiB)": 72.72,
      "step": 24340,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.2707769797593507,
      "grad_norm": 3.124953269958496,
      "learning_rate": 6.160837172363352e-06,
      "loss": 0.36899518966674805,
      "memory(GiB)": 72.72,
      "step": 24345,
      "token_acc": 0.9354838709677419,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.2712433541647234,
      "grad_norm": 3.8212225437164307,
      "learning_rate": 6.1593369643552705e-06,
      "loss": 0.36967997550964354,
      "memory(GiB)": 72.72,
      "step": 24350,
      "token_acc": 0.7651515151515151,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.2717097285700962,
      "grad_norm": 5.357364177703857,
      "learning_rate": 6.157836646039849e-06,
      "loss": 0.3626563310623169,
      "memory(GiB)": 72.72,
      "step": 24355,
      "token_acc": 0.8620689655172413,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.2721761029754686,
      "grad_norm": 3.0540459156036377,
      "learning_rate": 6.156336217559837e-06,
      "loss": 0.4040683269500732,
      "memory(GiB)": 72.72,
      "step": 24360,
      "train_speed(iter/s)": 0.251457
    },
    {
      "epoch": 2.2726424773808414,
      "grad_norm": 6.956780910491943,
      "learning_rate": 6.154835679057997e-06,
      "loss": 0.3557556629180908,
      "memory(GiB)": 72.72,
      "step": 24365,
      "token_acc": 0.6037735849056604,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 2.273108851786214,
      "grad_norm": 5.355518817901611,
      "learning_rate": 6.153335030677099e-06,
      "loss": 0.3920925140380859,
      "memory(GiB)": 72.72,
      "step": 24370,
      "token_acc": 0.9746835443037974,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.2735752261915865,
      "grad_norm": 3.7016801834106445,
      "learning_rate": 6.151834272559926e-06,
      "loss": 0.38938825130462645,
      "memory(GiB)": 72.72,
      "step": 24375,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.2740416005969593,
      "grad_norm": 3.6903154850006104,
      "learning_rate": 6.150333404849269e-06,
      "loss": 0.3604844570159912,
      "memory(GiB)": 72.72,
      "step": 24380,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.274507975002332,
      "grad_norm": 2.9527366161346436,
      "learning_rate": 6.148832427687934e-06,
      "loss": 0.36486477851867677,
      "memory(GiB)": 72.72,
      "step": 24385,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.2749743494077044,
      "grad_norm": 5.653296947479248,
      "learning_rate": 6.1473313412187315e-06,
      "loss": 0.3774324893951416,
      "memory(GiB)": 72.72,
      "step": 24390,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.275440723813077,
      "grad_norm": 3.7511467933654785,
      "learning_rate": 6.145830145584487e-06,
      "loss": 0.342630672454834,
      "memory(GiB)": 72.72,
      "step": 24395,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.27590709821845,
      "grad_norm": 5.76817512512207,
      "learning_rate": 6.144328840928033e-06,
      "loss": 0.40187931060791016,
      "memory(GiB)": 72.72,
      "step": 24400,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.2763734726238223,
      "grad_norm": 3.4280831813812256,
      "learning_rate": 6.142827427392217e-06,
      "loss": 0.3608280658721924,
      "memory(GiB)": 72.72,
      "step": 24405,
      "train_speed(iter/s)": 0.251466
    },
    {
      "epoch": 2.276839847029195,
      "grad_norm": 4.195070266723633,
      "learning_rate": 6.14132590511989e-06,
      "loss": 0.3774670124053955,
      "memory(GiB)": 72.72,
      "step": 24410,
      "train_speed(iter/s)": 0.251467
    },
    {
      "epoch": 2.277306221434568,
      "grad_norm": 3.5474534034729004,
      "learning_rate": 6.139824274253919e-06,
      "loss": 0.3682876110076904,
      "memory(GiB)": 72.72,
      "step": 24415,
      "train_speed(iter/s)": 0.251468
    },
    {
      "epoch": 2.27777259583994,
      "grad_norm": 2.9198615550994873,
      "learning_rate": 6.13832253493718e-06,
      "loss": 0.37124297618865965,
      "memory(GiB)": 72.72,
      "step": 24420,
      "token_acc": 0.509090909090909,
      "train_speed(iter/s)": 0.251475
    },
    {
      "epoch": 2.278238970245313,
      "grad_norm": 6.825139045715332,
      "learning_rate": 6.136820687312559e-06,
      "loss": 0.37613298892974856,
      "memory(GiB)": 72.72,
      "step": 24425,
      "train_speed(iter/s)": 0.251473
    },
    {
      "epoch": 2.2787053446506857,
      "grad_norm": 4.741691589355469,
      "learning_rate": 6.135318731522951e-06,
      "loss": 0.3820199489593506,
      "memory(GiB)": 72.72,
      "step": 24430,
      "train_speed(iter/s)": 0.251474
    },
    {
      "epoch": 2.279171719056058,
      "grad_norm": 19.312519073486328,
      "learning_rate": 6.133816667711265e-06,
      "loss": 0.3276803016662598,
      "memory(GiB)": 72.72,
      "step": 24435,
      "token_acc": 0.849624060150376,
      "train_speed(iter/s)": 0.251475
    },
    {
      "epoch": 2.279638093461431,
      "grad_norm": 4.54908561706543,
      "learning_rate": 6.1323144960204124e-06,
      "loss": 0.40281028747558595,
      "memory(GiB)": 72.72,
      "step": 24440,
      "train_speed(iter/s)": 0.251474
    },
    {
      "epoch": 2.2801044678668037,
      "grad_norm": 4.157515048980713,
      "learning_rate": 6.130812216593327e-06,
      "loss": 0.3797978162765503,
      "memory(GiB)": 72.72,
      "step": 24445,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.25148
    },
    {
      "epoch": 2.280570842272176,
      "grad_norm": 3.7105793952941895,
      "learning_rate": 6.129309829572941e-06,
      "loss": 0.40322022438049315,
      "memory(GiB)": 72.72,
      "step": 24450,
      "token_acc": 0.9487179487179487,
      "train_speed(iter/s)": 0.251477
    },
    {
      "epoch": 2.2810372166775488,
      "grad_norm": 3.8817977905273438,
      "learning_rate": 6.127807335102205e-06,
      "loss": 0.3699950218200684,
      "memory(GiB)": 72.72,
      "step": 24455,
      "train_speed(iter/s)": 0.251478
    },
    {
      "epoch": 2.2815035910829216,
      "grad_norm": 5.261909484863281,
      "learning_rate": 6.126304733324073e-06,
      "loss": 0.3714857816696167,
      "memory(GiB)": 72.72,
      "step": 24460,
      "train_speed(iter/s)": 0.251477
    },
    {
      "epoch": 2.281969965488294,
      "grad_norm": 3.234509229660034,
      "learning_rate": 6.124802024381518e-06,
      "loss": 0.33139562606811523,
      "memory(GiB)": 72.72,
      "step": 24465,
      "token_acc": 0.4576271186440678,
      "train_speed(iter/s)": 0.251473
    },
    {
      "epoch": 2.2824363398936667,
      "grad_norm": 4.155924320220947,
      "learning_rate": 6.123299208417513e-06,
      "loss": 0.39055767059326174,
      "memory(GiB)": 72.72,
      "step": 24470,
      "train_speed(iter/s)": 0.251475
    },
    {
      "epoch": 2.2829027142990395,
      "grad_norm": 4.160336971282959,
      "learning_rate": 6.12179628557505e-06,
      "loss": 0.3827256202697754,
      "memory(GiB)": 72.72,
      "step": 24475,
      "token_acc": 0.9702970297029703,
      "train_speed(iter/s)": 0.251478
    },
    {
      "epoch": 2.283369088704412,
      "grad_norm": 5.3990888595581055,
      "learning_rate": 6.1202932559971275e-06,
      "loss": 0.37853820323944093,
      "memory(GiB)": 72.72,
      "step": 24480,
      "train_speed(iter/s)": 0.251478
    },
    {
      "epoch": 2.2838354631097846,
      "grad_norm": 6.097723960876465,
      "learning_rate": 6.11879011982675e-06,
      "loss": 0.3734076976776123,
      "memory(GiB)": 72.72,
      "step": 24485,
      "train_speed(iter/s)": 0.251482
    },
    {
      "epoch": 2.284301837515157,
      "grad_norm": 5.055305004119873,
      "learning_rate": 6.117286877206941e-06,
      "loss": 0.3673620939254761,
      "memory(GiB)": 72.72,
      "step": 24490,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251484
    },
    {
      "epoch": 2.2847682119205297,
      "grad_norm": 3.6054623126983643,
      "learning_rate": 6.1157835282807265e-06,
      "loss": 0.3830269336700439,
      "memory(GiB)": 72.72,
      "step": 24495,
      "train_speed(iter/s)": 0.251485
    },
    {
      "epoch": 2.2852345863259025,
      "grad_norm": 4.758448123931885,
      "learning_rate": 6.114280073191146e-06,
      "loss": 0.3619096755981445,
      "memory(GiB)": 72.72,
      "step": 24500,
      "train_speed(iter/s)": 0.251482
    },
    {
      "epoch": 2.2857009607312753,
      "grad_norm": 2.793562412261963,
      "learning_rate": 6.112776512081251e-06,
      "loss": 0.35993332862854005,
      "memory(GiB)": 72.72,
      "step": 24505,
      "token_acc": 0.8686868686868687,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.2861673351366476,
      "grad_norm": 4.443504810333252,
      "learning_rate": 6.1112728450940985e-06,
      "loss": 0.38926851749420166,
      "memory(GiB)": 72.72,
      "step": 24510,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 2.2866337095420204,
      "grad_norm": 3.501924991607666,
      "learning_rate": 6.109769072372758e-06,
      "loss": 0.3634109258651733,
      "memory(GiB)": 72.72,
      "step": 24515,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 2.2871000839473927,
      "grad_norm": 3.9718844890594482,
      "learning_rate": 6.108265194060308e-06,
      "loss": 0.3600612163543701,
      "memory(GiB)": 72.72,
      "step": 24520,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.2875664583527655,
      "grad_norm": 3.861260175704956,
      "learning_rate": 6.10676121029984e-06,
      "loss": 0.35429704189300537,
      "memory(GiB)": 72.72,
      "step": 24525,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.2880328327581383,
      "grad_norm": 4.454816818237305,
      "learning_rate": 6.105257121234452e-06,
      "loss": 0.33958845138549804,
      "memory(GiB)": 72.72,
      "step": 24530,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.288499207163511,
      "grad_norm": 12.566139221191406,
      "learning_rate": 6.103752927007254e-06,
      "loss": 0.34446077346801757,
      "memory(GiB)": 72.72,
      "step": 24535,
      "token_acc": 0.9375,
      "train_speed(iter/s)": 0.251392
    },
    {
      "epoch": 2.2889655815688834,
      "grad_norm": 4.3300089836120605,
      "learning_rate": 6.102248627761365e-06,
      "loss": 0.3742605924606323,
      "memory(GiB)": 72.72,
      "step": 24540,
      "token_acc": 0.9456521739130435,
      "train_speed(iter/s)": 0.251395
    },
    {
      "epoch": 2.289431955974256,
      "grad_norm": 3.496903657913208,
      "learning_rate": 6.100744223639914e-06,
      "loss": 0.3796722412109375,
      "memory(GiB)": 72.72,
      "step": 24545,
      "train_speed(iter/s)": 0.251394
    },
    {
      "epoch": 2.2898983303796285,
      "grad_norm": 6.904290199279785,
      "learning_rate": 6.099239714786041e-06,
      "loss": 0.38871767520904543,
      "memory(GiB)": 72.72,
      "step": 24550,
      "token_acc": 0.5526315789473685,
      "train_speed(iter/s)": 0.251393
    },
    {
      "epoch": 2.2903647047850013,
      "grad_norm": 4.8443708419799805,
      "learning_rate": 6.097735101342896e-06,
      "loss": 0.3560131549835205,
      "memory(GiB)": 72.72,
      "step": 24555,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 2.290831079190374,
      "grad_norm": 3.7370893955230713,
      "learning_rate": 6.096230383453639e-06,
      "loss": 0.35244388580322267,
      "memory(GiB)": 72.72,
      "step": 24560,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 2.291297453595747,
      "grad_norm": 8.20132827758789,
      "learning_rate": 6.094725561261436e-06,
      "loss": 0.3121603727340698,
      "memory(GiB)": 72.72,
      "step": 24565,
      "train_speed(iter/s)": 0.251394
    },
    {
      "epoch": 2.291763828001119,
      "grad_norm": 4.242281913757324,
      "learning_rate": 6.093220634909468e-06,
      "loss": 0.4182119369506836,
      "memory(GiB)": 72.72,
      "step": 24570,
      "train_speed(iter/s)": 0.251393
    },
    {
      "epoch": 2.292230202406492,
      "grad_norm": 2.9838178157806396,
      "learning_rate": 6.091715604540925e-06,
      "loss": 0.37290515899658205,
      "memory(GiB)": 72.72,
      "step": 24575,
      "token_acc": 0.9523809523809523,
      "train_speed(iter/s)": 0.251391
    },
    {
      "epoch": 2.2926965768118643,
      "grad_norm": 4.790142059326172,
      "learning_rate": 6.0902104702990075e-06,
      "loss": 0.36800360679626465,
      "memory(GiB)": 72.72,
      "step": 24580,
      "train_speed(iter/s)": 0.251392
    },
    {
      "epoch": 2.293162951217237,
      "grad_norm": 4.5011677742004395,
      "learning_rate": 6.088705232326919e-06,
      "loss": 0.3881897687911987,
      "memory(GiB)": 72.72,
      "step": 24585,
      "token_acc": 0.5645161290322581,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 2.29362932562261,
      "grad_norm": 7.730616092681885,
      "learning_rate": 6.087199890767883e-06,
      "loss": 0.42649011611938475,
      "memory(GiB)": 72.72,
      "step": 24590,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 2.2940957000279827,
      "grad_norm": 4.204687595367432,
      "learning_rate": 6.085694445765127e-06,
      "loss": 0.3648822784423828,
      "memory(GiB)": 72.72,
      "step": 24595,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 2.294562074433355,
      "grad_norm": 3.6219770908355713,
      "learning_rate": 6.084188897461888e-06,
      "loss": 0.4028327941894531,
      "memory(GiB)": 72.72,
      "step": 24600,
      "token_acc": 0.9518072289156626,
      "train_speed(iter/s)": 0.251391
    },
    {
      "epoch": 2.295028448838728,
      "grad_norm": 5.587934494018555,
      "learning_rate": 6.082683246001416e-06,
      "loss": 0.4064475059509277,
      "memory(GiB)": 72.72,
      "step": 24605,
      "token_acc": 0.7344632768361582,
      "train_speed(iter/s)": 0.251392
    },
    {
      "epoch": 2.2954948232441,
      "grad_norm": 4.075558662414551,
      "learning_rate": 6.081177491526968e-06,
      "loss": 0.3728791236877441,
      "memory(GiB)": 72.72,
      "step": 24610,
      "token_acc": 0.9578947368421052,
      "train_speed(iter/s)": 0.251393
    },
    {
      "epoch": 2.295961197649473,
      "grad_norm": 4.644834518432617,
      "learning_rate": 6.079671634181813e-06,
      "loss": 0.35773253440856934,
      "memory(GiB)": 72.72,
      "step": 24615,
      "train_speed(iter/s)": 0.251399
    },
    {
      "epoch": 2.2964275720548457,
      "grad_norm": 4.007647514343262,
      "learning_rate": 6.078165674109227e-06,
      "loss": 0.3931555271148682,
      "memory(GiB)": 72.72,
      "step": 24620,
      "train_speed(iter/s)": 0.251403
    },
    {
      "epoch": 2.2968939464602185,
      "grad_norm": 5.292603492736816,
      "learning_rate": 6.076659611452499e-06,
      "loss": 0.3461765289306641,
      "memory(GiB)": 72.72,
      "step": 24625,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 2.297360320865591,
      "grad_norm": 5.951736927032471,
      "learning_rate": 6.075153446354927e-06,
      "loss": 0.371514892578125,
      "memory(GiB)": 72.72,
      "step": 24630,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 2.2978266952709636,
      "grad_norm": 3.717827558517456,
      "learning_rate": 6.073647178959814e-06,
      "loss": 0.39082722663879393,
      "memory(GiB)": 72.72,
      "step": 24635,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 2.298293069676336,
      "grad_norm": 4.467624664306641,
      "learning_rate": 6.0721408094104815e-06,
      "loss": 0.3793971061706543,
      "memory(GiB)": 72.72,
      "step": 24640,
      "train_speed(iter/s)": 0.251399
    },
    {
      "epoch": 2.2987594440817087,
      "grad_norm": 2.8848142623901367,
      "learning_rate": 6.070634337850253e-06,
      "loss": 0.3596106767654419,
      "memory(GiB)": 72.72,
      "step": 24645,
      "train_speed(iter/s)": 0.251401
    },
    {
      "epoch": 2.2992258184870815,
      "grad_norm": 3.574506998062134,
      "learning_rate": 6.069127764422466e-06,
      "loss": 0.3511203289031982,
      "memory(GiB)": 72.72,
      "step": 24650,
      "train_speed(iter/s)": 0.251401
    },
    {
      "epoch": 2.2996921928924543,
      "grad_norm": 4.064139366149902,
      "learning_rate": 6.067621089270466e-06,
      "loss": 0.3788685083389282,
      "memory(GiB)": 72.72,
      "step": 24655,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 2.3001585672978266,
      "grad_norm": 3.600525140762329,
      "learning_rate": 6.066114312537606e-06,
      "loss": 0.3754345178604126,
      "memory(GiB)": 72.72,
      "step": 24660,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 2.3006249417031994,
      "grad_norm": 103.21420288085938,
      "learning_rate": 6.064607434367256e-06,
      "loss": 0.3645038604736328,
      "memory(GiB)": 72.72,
      "step": 24665,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.3010913161085718,
      "grad_norm": 10.45992660522461,
      "learning_rate": 6.063100454902786e-06,
      "loss": 0.34116902351379397,
      "memory(GiB)": 72.72,
      "step": 24670,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.3015576905139445,
      "grad_norm": 2.761906147003174,
      "learning_rate": 6.061593374287584e-06,
      "loss": 0.37693703174591064,
      "memory(GiB)": 72.72,
      "step": 24675,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.3020240649193173,
      "grad_norm": 4.872417449951172,
      "learning_rate": 6.060086192665044e-06,
      "loss": 0.3500129222869873,
      "memory(GiB)": 72.72,
      "step": 24680,
      "token_acc": 0.5957446808510638,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 2.30249043932469,
      "grad_norm": 8.43531608581543,
      "learning_rate": 6.058578910178567e-06,
      "loss": 0.3799978494644165,
      "memory(GiB)": 72.72,
      "step": 24685,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 2.3029568137300624,
      "grad_norm": 4.689176559448242,
      "learning_rate": 6.057071526971567e-06,
      "loss": 0.373881196975708,
      "memory(GiB)": 72.72,
      "step": 24690,
      "token_acc": 0.8188405797101449,
      "train_speed(iter/s)": 0.251409
    },
    {
      "epoch": 2.3034231881354352,
      "grad_norm": 4.5829362869262695,
      "learning_rate": 6.055564043187468e-06,
      "loss": 0.41156826019287107,
      "memory(GiB)": 72.72,
      "step": 24695,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.3038895625408076,
      "grad_norm": 4.877379417419434,
      "learning_rate": 6.054056458969702e-06,
      "loss": 0.38498334884643554,
      "memory(GiB)": 72.72,
      "step": 24700,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 2.3043559369461803,
      "grad_norm": 4.592807292938232,
      "learning_rate": 6.052548774461713e-06,
      "loss": 0.4173145294189453,
      "memory(GiB)": 72.72,
      "step": 24705,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.304822311351553,
      "grad_norm": 3.348630428314209,
      "learning_rate": 6.0510409898069485e-06,
      "loss": 0.4010148048400879,
      "memory(GiB)": 72.72,
      "step": 24710,
      "token_acc": 0.9375,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.3052886857569255,
      "grad_norm": 4.496835231781006,
      "learning_rate": 6.049533105148872e-06,
      "loss": 0.405714225769043,
      "memory(GiB)": 72.72,
      "step": 24715,
      "token_acc": 0.9655172413793104,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.3057550601622983,
      "grad_norm": 4.672304153442383,
      "learning_rate": 6.048025120630954e-06,
      "loss": 0.39061741828918456,
      "memory(GiB)": 72.72,
      "step": 24720,
      "token_acc": 0.6444444444444445,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.306221434567671,
      "grad_norm": 3.3125321865081787,
      "learning_rate": 6.046517036396673e-06,
      "loss": 0.37997748851776125,
      "memory(GiB)": 72.72,
      "step": 24725,
      "train_speed(iter/s)": 0.251404
    },
    {
      "epoch": 2.3066878089730434,
      "grad_norm": 4.677615165710449,
      "learning_rate": 6.045008852589522e-06,
      "loss": 0.39676029682159425,
      "memory(GiB)": 72.72,
      "step": 24730,
      "token_acc": 0.4690265486725664,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.307154183378416,
      "grad_norm": 13.83735466003418,
      "learning_rate": 6.043500569352998e-06,
      "loss": 0.3992058753967285,
      "memory(GiB)": 72.72,
      "step": 24735,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 2.307620557783789,
      "grad_norm": 5.403492450714111,
      "learning_rate": 6.0419921868306074e-06,
      "loss": 0.36292004585266113,
      "memory(GiB)": 72.72,
      "step": 24740,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.3080869321891613,
      "grad_norm": 5.852347373962402,
      "learning_rate": 6.040483705165871e-06,
      "loss": 0.35503363609313965,
      "memory(GiB)": 72.72,
      "step": 24745,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.308553306594534,
      "grad_norm": 6.837181091308594,
      "learning_rate": 6.038975124502315e-06,
      "loss": 0.4086167812347412,
      "memory(GiB)": 72.72,
      "step": 24750,
      "train_speed(iter/s)": 0.251409
    },
    {
      "epoch": 2.309019680999907,
      "grad_norm": 4.75803279876709,
      "learning_rate": 6.037466444983477e-06,
      "loss": 0.39027113914489747,
      "memory(GiB)": 72.72,
      "step": 24755,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 2.309486055405279,
      "grad_norm": 3.9183595180511475,
      "learning_rate": 6.035957666752903e-06,
      "loss": 0.374521803855896,
      "memory(GiB)": 72.72,
      "step": 24760,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251413
    },
    {
      "epoch": 2.309952429810652,
      "grad_norm": 4.569921970367432,
      "learning_rate": 6.034448789954148e-06,
      "loss": 0.3354924201965332,
      "memory(GiB)": 72.72,
      "step": 24765,
      "token_acc": 0.8308823529411765,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 2.3104188042160247,
      "grad_norm": 4.52277946472168,
      "learning_rate": 6.032939814730779e-06,
      "loss": 0.38803720474243164,
      "memory(GiB)": 72.72,
      "step": 24770,
      "token_acc": 0.5955056179775281,
      "train_speed(iter/s)": 0.251413
    },
    {
      "epoch": 2.310885178621397,
      "grad_norm": 4.37896728515625,
      "learning_rate": 6.031430741226366e-06,
      "loss": 0.4181669235229492,
      "memory(GiB)": 72.72,
      "step": 24775,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 2.31135155302677,
      "grad_norm": 8.252737998962402,
      "learning_rate": 6.029921569584497e-06,
      "loss": 0.37597131729125977,
      "memory(GiB)": 72.72,
      "step": 24780,
      "train_speed(iter/s)": 0.251413
    },
    {
      "epoch": 2.3118179274321426,
      "grad_norm": 4.522150039672852,
      "learning_rate": 6.028412299948763e-06,
      "loss": 0.37122306823730467,
      "memory(GiB)": 72.72,
      "step": 24785,
      "token_acc": 0.42,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 2.312284301837515,
      "grad_norm": 3.609869956970215,
      "learning_rate": 6.026902932462766e-06,
      "loss": 0.3595024585723877,
      "memory(GiB)": 72.72,
      "step": 24790,
      "token_acc": 0.4957983193277311,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 2.3127506762428878,
      "grad_norm": 6.2301249504089355,
      "learning_rate": 6.025393467270119e-06,
      "loss": 0.37301197052001955,
      "memory(GiB)": 72.72,
      "step": 24795,
      "token_acc": 0.7428571428571429,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 2.3132170506482606,
      "grad_norm": 4.70496940612793,
      "learning_rate": 6.023883904514443e-06,
      "loss": 0.3876327991485596,
      "memory(GiB)": 72.72,
      "step": 24800,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 2.313683425053633,
      "grad_norm": 4.355003356933594,
      "learning_rate": 6.022374244339367e-06,
      "loss": 0.3406780958175659,
      "memory(GiB)": 72.72,
      "step": 24805,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 2.3141497994590057,
      "grad_norm": 3.7439093589782715,
      "learning_rate": 6.020864486888531e-06,
      "loss": 0.39785444736480713,
      "memory(GiB)": 72.72,
      "step": 24810,
      "token_acc": 0.946236559139785,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 2.3146161738643785,
      "grad_norm": 3.208106279373169,
      "learning_rate": 6.019354632305584e-06,
      "loss": 0.3541595935821533,
      "memory(GiB)": 72.72,
      "step": 24815,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 2.315082548269751,
      "grad_norm": 4.4288763999938965,
      "learning_rate": 6.017844680734184e-06,
      "loss": 0.38292107582092283,
      "memory(GiB)": 72.72,
      "step": 24820,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 2.3155489226751236,
      "grad_norm": 3.6506595611572266,
      "learning_rate": 6.016334632317998e-06,
      "loss": 0.3659297227859497,
      "memory(GiB)": 72.72,
      "step": 24825,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.251424
    },
    {
      "epoch": 2.3160152970804964,
      "grad_norm": 4.407897472381592,
      "learning_rate": 6.014824487200704e-06,
      "loss": 0.4146708965301514,
      "memory(GiB)": 72.72,
      "step": 24830,
      "token_acc": 0.5957446808510638,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 2.3164816714858687,
      "grad_norm": 4.100198268890381,
      "learning_rate": 6.013314245525985e-06,
      "loss": 0.3522042989730835,
      "memory(GiB)": 72.72,
      "step": 24835,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.3169480458912415,
      "grad_norm": 9.421786308288574,
      "learning_rate": 6.011803907437537e-06,
      "loss": 0.39466769695281984,
      "memory(GiB)": 72.72,
      "step": 24840,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 2.3174144202966143,
      "grad_norm": 4.669751167297363,
      "learning_rate": 6.010293473079064e-06,
      "loss": 0.34382498264312744,
      "memory(GiB)": 72.72,
      "step": 24845,
      "token_acc": 0.7755102040816326,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 2.3178807947019866,
      "grad_norm": 6.253143310546875,
      "learning_rate": 6.00878294259428e-06,
      "loss": 0.3675406455993652,
      "memory(GiB)": 72.72,
      "step": 24850,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 2.3183471691073594,
      "grad_norm": 4.257294654846191,
      "learning_rate": 6.0072723161269076e-06,
      "loss": 0.3315820932388306,
      "memory(GiB)": 72.72,
      "step": 24855,
      "token_acc": 0.8270676691729323,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 2.318813543512732,
      "grad_norm": 3.6106510162353516,
      "learning_rate": 6.005761593820675e-06,
      "loss": 0.39078965187072756,
      "memory(GiB)": 72.72,
      "step": 24860,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 2.3192799179181045,
      "grad_norm": 4.332106113433838,
      "learning_rate": 6.004250775819327e-06,
      "loss": 0.3832305192947388,
      "memory(GiB)": 72.72,
      "step": 24865,
      "token_acc": 0.9431818181818182,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 2.3197462923234773,
      "grad_norm": 7.226354598999023,
      "learning_rate": 6.00273986226661e-06,
      "loss": 0.3608452796936035,
      "memory(GiB)": 72.72,
      "step": 24870,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.32021266672885,
      "grad_norm": 13.077296257019043,
      "learning_rate": 6.001228853306284e-06,
      "loss": 0.38077991008758544,
      "memory(GiB)": 72.72,
      "step": 24875,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 2.3206790411342224,
      "grad_norm": 3.8116326332092285,
      "learning_rate": 5.999717749082119e-06,
      "loss": 0.41322712898254393,
      "memory(GiB)": 72.72,
      "step": 24880,
      "token_acc": 0.3983739837398374,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 2.321145415539595,
      "grad_norm": 4.8405046463012695,
      "learning_rate": 5.998206549737888e-06,
      "loss": 0.355318546295166,
      "memory(GiB)": 72.72,
      "step": 24885,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 2.321611789944968,
      "grad_norm": 3.26552677154541,
      "learning_rate": 5.996695255417379e-06,
      "loss": 0.3332526206970215,
      "memory(GiB)": 72.72,
      "step": 24890,
      "train_speed(iter/s)": 0.251441
    },
    {
      "epoch": 2.3220781643503403,
      "grad_norm": 3.331247329711914,
      "learning_rate": 5.995183866264387e-06,
      "loss": 0.3474684953689575,
      "memory(GiB)": 72.72,
      "step": 24895,
      "token_acc": 0.5961538461538461,
      "train_speed(iter/s)": 0.25144
    },
    {
      "epoch": 2.322544538755713,
      "grad_norm": 16.65996551513672,
      "learning_rate": 5.993672382422716e-06,
      "loss": 0.3879899024963379,
      "memory(GiB)": 72.72,
      "step": 24900,
      "token_acc": 0.4838709677419355,
      "train_speed(iter/s)": 0.251444
    },
    {
      "epoch": 2.323010913161086,
      "grad_norm": 7.871509075164795,
      "learning_rate": 5.99216080403618e-06,
      "loss": 0.36212868690490724,
      "memory(GiB)": 72.72,
      "step": 24905,
      "train_speed(iter/s)": 0.251446
    },
    {
      "epoch": 2.323477287566458,
      "grad_norm": 3.7030069828033447,
      "learning_rate": 5.9906491312485986e-06,
      "loss": 0.351090145111084,
      "memory(GiB)": 72.72,
      "step": 24910,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 2.323943661971831,
      "grad_norm": 3.237881898880005,
      "learning_rate": 5.989137364203804e-06,
      "loss": 0.37859477996826174,
      "memory(GiB)": 72.72,
      "step": 24915,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251446
    },
    {
      "epoch": 2.324410036377204,
      "grad_norm": 3.980841875076294,
      "learning_rate": 5.987625503045637e-06,
      "loss": 0.39490485191345215,
      "memory(GiB)": 72.72,
      "step": 24920,
      "token_acc": 0.4492753623188406,
      "train_speed(iter/s)": 0.251446
    },
    {
      "epoch": 2.324876410782576,
      "grad_norm": 4.892118453979492,
      "learning_rate": 5.986113547917945e-06,
      "loss": 0.3722022771835327,
      "memory(GiB)": 72.72,
      "step": 24925,
      "train_speed(iter/s)": 0.251446
    },
    {
      "epoch": 2.325342785187949,
      "grad_norm": 5.500353813171387,
      "learning_rate": 5.984601498964589e-06,
      "loss": 0.36319398880004883,
      "memory(GiB)": 72.72,
      "step": 24930,
      "train_speed(iter/s)": 0.251448
    },
    {
      "epoch": 2.3258091595933217,
      "grad_norm": 5.601923942565918,
      "learning_rate": 5.983089356329431e-06,
      "loss": 0.35791668891906736,
      "memory(GiB)": 72.72,
      "step": 24935,
      "train_speed(iter/s)": 0.251448
    },
    {
      "epoch": 2.326275533998694,
      "grad_norm": 10.127636909484863,
      "learning_rate": 5.981577120156349e-06,
      "loss": 0.3824849843978882,
      "memory(GiB)": 72.72,
      "step": 24940,
      "token_acc": 0.48484848484848486,
      "train_speed(iter/s)": 0.25145
    },
    {
      "epoch": 2.326741908404067,
      "grad_norm": 4.657347679138184,
      "learning_rate": 5.980064790589229e-06,
      "loss": 0.3810982942581177,
      "memory(GiB)": 72.72,
      "step": 24945,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 2.3272082828094396,
      "grad_norm": 4.866530418395996,
      "learning_rate": 5.978552367771963e-06,
      "loss": 0.3936636209487915,
      "memory(GiB)": 72.72,
      "step": 24950,
      "token_acc": 0.9340659340659341,
      "train_speed(iter/s)": 0.251458
    },
    {
      "epoch": 2.327674657214812,
      "grad_norm": 3.248652696609497,
      "learning_rate": 5.977039851848456e-06,
      "loss": 0.38354408740997314,
      "memory(GiB)": 72.72,
      "step": 24955,
      "token_acc": 0.5350877192982456,
      "train_speed(iter/s)": 0.251457
    },
    {
      "epoch": 2.3281410316201847,
      "grad_norm": 4.281142711639404,
      "learning_rate": 5.975527242962613e-06,
      "loss": 0.3889946699142456,
      "memory(GiB)": 72.72,
      "step": 24960,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 2.3286074060255575,
      "grad_norm": 5.005202293395996,
      "learning_rate": 5.97401454125836e-06,
      "loss": 0.3569707632064819,
      "memory(GiB)": 72.72,
      "step": 24965,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.32907378043093,
      "grad_norm": 5.320195198059082,
      "learning_rate": 5.972501746879624e-06,
      "loss": 0.40659098625183104,
      "memory(GiB)": 72.72,
      "step": 24970,
      "train_speed(iter/s)": 0.251465
    },
    {
      "epoch": 2.3295401548363026,
      "grad_norm": 5.238564491271973,
      "learning_rate": 5.970988859970344e-06,
      "loss": 0.3414619445800781,
      "memory(GiB)": 72.72,
      "step": 24975,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.3300065292416754,
      "grad_norm": 4.1053571701049805,
      "learning_rate": 5.969475880674463e-06,
      "loss": 0.39843020439147947,
      "memory(GiB)": 72.72,
      "step": 24980,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.3304729036470477,
      "grad_norm": 18.653213500976562,
      "learning_rate": 5.967962809135939e-06,
      "loss": 0.36075263023376464,
      "memory(GiB)": 72.72,
      "step": 24985,
      "token_acc": 0.8979591836734694,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.3309392780524205,
      "grad_norm": 5.7734785079956055,
      "learning_rate": 5.966449645498736e-06,
      "loss": 0.3742120981216431,
      "memory(GiB)": 72.72,
      "step": 24990,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.3314056524577933,
      "grad_norm": 4.186585903167725,
      "learning_rate": 5.964936389906826e-06,
      "loss": 0.395078706741333,
      "memory(GiB)": 72.72,
      "step": 24995,
      "train_speed(iter/s)": 0.251465
    },
    {
      "epoch": 2.3318720268631656,
      "grad_norm": 12.93120002746582,
      "learning_rate": 5.96342304250419e-06,
      "loss": 0.38372747898101806,
      "memory(GiB)": 72.72,
      "step": 25000,
      "token_acc": 0.5288461538461539,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.3323384012685384,
      "grad_norm": 3.684008836746216,
      "learning_rate": 5.9619096034348225e-06,
      "loss": 0.33941528797149656,
      "memory(GiB)": 72.72,
      "step": 25005,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 2.332804775673911,
      "grad_norm": 15.800797462463379,
      "learning_rate": 5.960396072842717e-06,
      "loss": 0.38645305633544924,
      "memory(GiB)": 72.72,
      "step": 25010,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 2.3332711500792835,
      "grad_norm": 6.518582820892334,
      "learning_rate": 5.958882450871884e-06,
      "loss": 0.3575774669647217,
      "memory(GiB)": 72.72,
      "step": 25015,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 2.3337375244846563,
      "grad_norm": 5.445771217346191,
      "learning_rate": 5.95736873766634e-06,
      "loss": 0.341897988319397,
      "memory(GiB)": 72.72,
      "step": 25020,
      "token_acc": 0.5689655172413793,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 2.334203898890029,
      "grad_norm": 22.225446701049805,
      "learning_rate": 5.95585493337011e-06,
      "loss": 0.3912321090698242,
      "memory(GiB)": 72.72,
      "step": 25025,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 2.3346702732954014,
      "grad_norm": 4.822511672973633,
      "learning_rate": 5.9543410381272285e-06,
      "loss": 0.39304842948913576,
      "memory(GiB)": 72.72,
      "step": 25030,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 2.3351366477007742,
      "grad_norm": 3.1376302242279053,
      "learning_rate": 5.952827052081736e-06,
      "loss": 0.36697189807891845,
      "memory(GiB)": 72.72,
      "step": 25035,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 2.335603022106147,
      "grad_norm": 4.950666904449463,
      "learning_rate": 5.9513129753776855e-06,
      "loss": 0.39845187664031984,
      "memory(GiB)": 72.72,
      "step": 25040,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 2.3360693965115193,
      "grad_norm": 5.166136264801025,
      "learning_rate": 5.949798808159134e-06,
      "loss": 0.3605672836303711,
      "memory(GiB)": 72.72,
      "step": 25045,
      "train_speed(iter/s)": 0.251451
    },
    {
      "epoch": 2.336535770916892,
      "grad_norm": 9.247791290283203,
      "learning_rate": 5.948284550570154e-06,
      "loss": 0.3960346460342407,
      "memory(GiB)": 72.72,
      "step": 25050,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 2.3370021453222645,
      "grad_norm": 4.675581455230713,
      "learning_rate": 5.94677020275482e-06,
      "loss": 0.3997817039489746,
      "memory(GiB)": 72.72,
      "step": 25055,
      "token_acc": 0.9405940594059405,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 2.3374685197276373,
      "grad_norm": 7.78815221786499,
      "learning_rate": 5.9452557648572165e-06,
      "loss": 0.40064401626586915,
      "memory(GiB)": 72.72,
      "step": 25060,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 2.33793489413301,
      "grad_norm": 3.515141248703003,
      "learning_rate": 5.94374123702144e-06,
      "loss": 0.3724795341491699,
      "memory(GiB)": 72.72,
      "step": 25065,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 2.338401268538383,
      "grad_norm": 5.967958450317383,
      "learning_rate": 5.942226619391592e-06,
      "loss": 0.4207813262939453,
      "memory(GiB)": 72.72,
      "step": 25070,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 2.338867642943755,
      "grad_norm": 4.881235122680664,
      "learning_rate": 5.940711912111784e-06,
      "loss": 0.3821688652038574,
      "memory(GiB)": 72.72,
      "step": 25075,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 2.339334017349128,
      "grad_norm": 11.062458992004395,
      "learning_rate": 5.939197115326135e-06,
      "loss": 0.4129852294921875,
      "memory(GiB)": 72.72,
      "step": 25080,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.251458
    },
    {
      "epoch": 2.3398003917545003,
      "grad_norm": 6.5676445960998535,
      "learning_rate": 5.937682229178774e-06,
      "loss": 0.3610007047653198,
      "memory(GiB)": 72.72,
      "step": 25085,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 2.340266766159873,
      "grad_norm": 5.45519495010376,
      "learning_rate": 5.9361672538138374e-06,
      "loss": 0.38083672523498535,
      "memory(GiB)": 72.72,
      "step": 25090,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.340733140565246,
      "grad_norm": 5.2590742111206055,
      "learning_rate": 5.93465218937547e-06,
      "loss": 0.36626691818237306,
      "memory(GiB)": 72.72,
      "step": 25095,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.3411995149706186,
      "grad_norm": 4.34017276763916,
      "learning_rate": 5.9331370360078275e-06,
      "loss": 0.37938656806945803,
      "memory(GiB)": 72.72,
      "step": 25100,
      "token_acc": 0.9239130434782609,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.341665889375991,
      "grad_norm": 7.413193702697754,
      "learning_rate": 5.93162179385507e-06,
      "loss": 0.39967167377471924,
      "memory(GiB)": 72.72,
      "step": 25105,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.3421322637813637,
      "grad_norm": 4.086280822753906,
      "learning_rate": 5.930106463061367e-06,
      "loss": 0.3825075149536133,
      "memory(GiB)": 72.72,
      "step": 25110,
      "token_acc": 0.5526315789473685,
      "train_speed(iter/s)": 0.251464
    },
    {
      "epoch": 2.342598638186736,
      "grad_norm": 3.533877372741699,
      "learning_rate": 5.928591043770902e-06,
      "loss": 0.36415600776672363,
      "memory(GiB)": 72.72,
      "step": 25115,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.343065012592109,
      "grad_norm": 4.790225028991699,
      "learning_rate": 5.927075536127858e-06,
      "loss": 0.3605152130126953,
      "memory(GiB)": 72.72,
      "step": 25120,
      "token_acc": 0.5283018867924528,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.3435313869974816,
      "grad_norm": 5.7339396476745605,
      "learning_rate": 5.925559940276433e-06,
      "loss": 0.39565577507019045,
      "memory(GiB)": 72.72,
      "step": 25125,
      "train_speed(iter/s)": 0.251466
    },
    {
      "epoch": 2.3439977614028544,
      "grad_norm": 8.619668960571289,
      "learning_rate": 5.924044256360832e-06,
      "loss": 0.34392604827880857,
      "memory(GiB)": 72.72,
      "step": 25130,
      "token_acc": 0.8280254777070064,
      "train_speed(iter/s)": 0.25147
    },
    {
      "epoch": 2.3444641358082268,
      "grad_norm": 4.518521308898926,
      "learning_rate": 5.9225284845252655e-06,
      "loss": 0.3521115779876709,
      "memory(GiB)": 72.72,
      "step": 25135,
      "train_speed(iter/s)": 0.251471
    },
    {
      "epoch": 2.3449305102135996,
      "grad_norm": 9.632718086242676,
      "learning_rate": 5.921012624913955e-06,
      "loss": 0.3741601467132568,
      "memory(GiB)": 72.72,
      "step": 25140,
      "train_speed(iter/s)": 0.251469
    },
    {
      "epoch": 2.345396884618972,
      "grad_norm": 5.108825206756592,
      "learning_rate": 5.919496677671131e-06,
      "loss": 0.36975123882293703,
      "memory(GiB)": 72.72,
      "step": 25145,
      "train_speed(iter/s)": 0.251466
    },
    {
      "epoch": 2.3458632590243447,
      "grad_norm": 4.213815689086914,
      "learning_rate": 5.917980642941032e-06,
      "loss": 0.3738798379898071,
      "memory(GiB)": 72.72,
      "step": 25150,
      "token_acc": 0.5955056179775281,
      "train_speed(iter/s)": 0.251469
    },
    {
      "epoch": 2.3463296334297175,
      "grad_norm": 4.317080497741699,
      "learning_rate": 5.916464520867901e-06,
      "loss": 0.3846604347229004,
      "memory(GiB)": 72.72,
      "step": 25155,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25147
    },
    {
      "epoch": 2.3467960078350902,
      "grad_norm": 4.64582633972168,
      "learning_rate": 5.9149483115959964e-06,
      "loss": 0.39170212745666505,
      "memory(GiB)": 72.72,
      "step": 25160,
      "train_speed(iter/s)": 0.251469
    },
    {
      "epoch": 2.3472623822404626,
      "grad_norm": 4.061405181884766,
      "learning_rate": 5.913432015269576e-06,
      "loss": 0.35850048065185547,
      "memory(GiB)": 72.72,
      "step": 25165,
      "train_speed(iter/s)": 0.251469
    },
    {
      "epoch": 2.3477287566458354,
      "grad_norm": 7.029292106628418,
      "learning_rate": 5.911915632032914e-06,
      "loss": 0.3474377155303955,
      "memory(GiB)": 72.72,
      "step": 25170,
      "train_speed(iter/s)": 0.251466
    },
    {
      "epoch": 2.3481951310512077,
      "grad_norm": 7.5581231117248535,
      "learning_rate": 5.910399162030289e-06,
      "loss": 0.3869169235229492,
      "memory(GiB)": 72.72,
      "step": 25175,
      "token_acc": 0.9583333333333334,
      "train_speed(iter/s)": 0.251467
    },
    {
      "epoch": 2.3486615054565805,
      "grad_norm": 6.176352024078369,
      "learning_rate": 5.908882605405988e-06,
      "loss": 0.37438833713531494,
      "memory(GiB)": 72.72,
      "step": 25180,
      "train_speed(iter/s)": 0.251468
    },
    {
      "epoch": 2.3491278798619533,
      "grad_norm": 8.872058868408203,
      "learning_rate": 5.907365962304308e-06,
      "loss": 0.36611011028289797,
      "memory(GiB)": 72.72,
      "step": 25185,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251467
    },
    {
      "epoch": 2.349594254267326,
      "grad_norm": 4.135873794555664,
      "learning_rate": 5.905849232869551e-06,
      "loss": 0.41229424476623533,
      "memory(GiB)": 72.72,
      "step": 25190,
      "train_speed(iter/s)": 0.251465
    },
    {
      "epoch": 2.3500606286726984,
      "grad_norm": 3.9611074924468994,
      "learning_rate": 5.904332417246029e-06,
      "loss": 0.39526567459106443,
      "memory(GiB)": 72.72,
      "step": 25195,
      "token_acc": 0.6391752577319587,
      "train_speed(iter/s)": 0.251469
    },
    {
      "epoch": 2.350527003078071,
      "grad_norm": 4.709146022796631,
      "learning_rate": 5.902815515578066e-06,
      "loss": 0.3889012336730957,
      "memory(GiB)": 72.72,
      "step": 25200,
      "train_speed(iter/s)": 0.251469
    },
    {
      "epoch": 2.3509933774834435,
      "grad_norm": 5.577944278717041,
      "learning_rate": 5.901298528009987e-06,
      "loss": 0.3453520774841309,
      "memory(GiB)": 72.72,
      "step": 25205,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.251471
    },
    {
      "epoch": 2.3514597518888163,
      "grad_norm": 5.840417385101318,
      "learning_rate": 5.8997814546861286e-06,
      "loss": 0.35108489990234376,
      "memory(GiB)": 72.72,
      "step": 25210,
      "train_speed(iter/s)": 0.25147
    },
    {
      "epoch": 2.351926126294189,
      "grad_norm": 4.019093036651611,
      "learning_rate": 5.898264295750836e-06,
      "loss": 0.39055547714233396,
      "memory(GiB)": 72.72,
      "step": 25215,
      "train_speed(iter/s)": 0.251471
    },
    {
      "epoch": 2.352392500699562,
      "grad_norm": 4.582101821899414,
      "learning_rate": 5.896747051348464e-06,
      "loss": 0.3981461763381958,
      "memory(GiB)": 72.72,
      "step": 25220,
      "train_speed(iter/s)": 0.251472
    },
    {
      "epoch": 2.352858875104934,
      "grad_norm": 4.473864555358887,
      "learning_rate": 5.895229721623373e-06,
      "loss": 0.3737491130828857,
      "memory(GiB)": 72.72,
      "step": 25225,
      "token_acc": 0.6764705882352942,
      "train_speed(iter/s)": 0.251472
    },
    {
      "epoch": 2.353325249510307,
      "grad_norm": 3.4111039638519287,
      "learning_rate": 5.893712306719931e-06,
      "loss": 0.36168670654296875,
      "memory(GiB)": 72.72,
      "step": 25230,
      "token_acc": 0.5754716981132075,
      "train_speed(iter/s)": 0.251472
    },
    {
      "epoch": 2.3537916239156793,
      "grad_norm": 18.766395568847656,
      "learning_rate": 5.892194806782516e-06,
      "loss": 0.3520609617233276,
      "memory(GiB)": 72.72,
      "step": 25235,
      "token_acc": 0.6486486486486487,
      "train_speed(iter/s)": 0.251472
    },
    {
      "epoch": 2.354257998321052,
      "grad_norm": 3.895003080368042,
      "learning_rate": 5.8906772219555155e-06,
      "loss": 0.3674121856689453,
      "memory(GiB)": 72.72,
      "step": 25240,
      "train_speed(iter/s)": 0.251472
    },
    {
      "epoch": 2.354724372726425,
      "grad_norm": 4.043837547302246,
      "learning_rate": 5.889159552383319e-06,
      "loss": 0.3714489459991455,
      "memory(GiB)": 72.72,
      "step": 25245,
      "train_speed(iter/s)": 0.251473
    },
    {
      "epoch": 2.355190747131797,
      "grad_norm": 3.9367902278900146,
      "learning_rate": 5.8876417982103305e-06,
      "loss": 0.3917471647262573,
      "memory(GiB)": 72.72,
      "step": 25250,
      "token_acc": 0.5102040816326531,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 2.35565712153717,
      "grad_norm": 4.343338489532471,
      "learning_rate": 5.886123959580961e-06,
      "loss": 0.35095987319946287,
      "memory(GiB)": 72.72,
      "step": 25255,
      "token_acc": 0.576271186440678,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 2.356123495942543,
      "grad_norm": 3.5371220111846924,
      "learning_rate": 5.884606036639625e-06,
      "loss": 0.4022824287414551,
      "memory(GiB)": 72.72,
      "step": 25260,
      "token_acc": 0.8482758620689655,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.356589870347915,
      "grad_norm": 4.756450653076172,
      "learning_rate": 5.883088029530749e-06,
      "loss": 0.3779132843017578,
      "memory(GiB)": 72.72,
      "step": 25265,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 2.357056244753288,
      "grad_norm": 5.085392951965332,
      "learning_rate": 5.881569938398768e-06,
      "loss": 0.39848761558532714,
      "memory(GiB)": 72.72,
      "step": 25270,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 2.3575226191586607,
      "grad_norm": 2.367429494857788,
      "learning_rate": 5.8800517633881235e-06,
      "loss": 0.33263959884643557,
      "memory(GiB)": 72.72,
      "step": 25275,
      "token_acc": 0.9010989010989011,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 2.357988993564033,
      "grad_norm": 4.5771164894104,
      "learning_rate": 5.878533504643266e-06,
      "loss": 0.40504040718078616,
      "memory(GiB)": 72.72,
      "step": 25280,
      "token_acc": 0.9680851063829787,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 2.358455367969406,
      "grad_norm": 3.8429579734802246,
      "learning_rate": 5.87701516230865e-06,
      "loss": 0.37977824211120603,
      "memory(GiB)": 72.72,
      "step": 25285,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 2.3589217423747786,
      "grad_norm": 3.109851837158203,
      "learning_rate": 5.875496736528744e-06,
      "loss": 0.3662321329116821,
      "memory(GiB)": 72.72,
      "step": 25290,
      "token_acc": 0.8130081300813008,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.359388116780151,
      "grad_norm": 3.213526964187622,
      "learning_rate": 5.87397822744802e-06,
      "loss": 0.3599182367324829,
      "memory(GiB)": 72.72,
      "step": 25295,
      "token_acc": 0.6702127659574468,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 2.3598544911855237,
      "grad_norm": 4.102874755859375,
      "learning_rate": 5.872459635210961e-06,
      "loss": 0.3834676265716553,
      "memory(GiB)": 72.72,
      "step": 25300,
      "token_acc": 0.8823529411764706,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.3603208655908965,
      "grad_norm": 2.840095043182373,
      "learning_rate": 5.870940959962055e-06,
      "loss": 0.3628129005432129,
      "memory(GiB)": 72.72,
      "step": 25305,
      "token_acc": 0.5125,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.360787239996269,
      "grad_norm": 8.877532005310059,
      "learning_rate": 5.869422201845799e-06,
      "loss": 0.4420443534851074,
      "memory(GiB)": 72.72,
      "step": 25310,
      "token_acc": 0.6585365853658537,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.3612536144016416,
      "grad_norm": 3.7345669269561768,
      "learning_rate": 5.867903361006698e-06,
      "loss": 0.3250291347503662,
      "memory(GiB)": 72.72,
      "step": 25315,
      "train_speed(iter/s)": 0.251377
    },
    {
      "epoch": 2.3617199888070144,
      "grad_norm": 3.6200308799743652,
      "learning_rate": 5.866384437589268e-06,
      "loss": 0.3223036050796509,
      "memory(GiB)": 72.72,
      "step": 25320,
      "token_acc": 0.6037735849056604,
      "train_speed(iter/s)": 0.251377
    },
    {
      "epoch": 2.3621863632123867,
      "grad_norm": 6.879279136657715,
      "learning_rate": 5.8648654317380275e-06,
      "loss": 0.34307861328125,
      "memory(GiB)": 72.72,
      "step": 25325,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 2.3626527376177595,
      "grad_norm": 4.539209365844727,
      "learning_rate": 5.863346343597503e-06,
      "loss": 0.3486682415008545,
      "memory(GiB)": 72.72,
      "step": 25330,
      "token_acc": 0.8538461538461538,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 2.3631191120231323,
      "grad_norm": 4.383313179016113,
      "learning_rate": 5.8618271733122355e-06,
      "loss": 0.40006232261657715,
      "memory(GiB)": 72.72,
      "step": 25335,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.3635854864285046,
      "grad_norm": 3.884870767593384,
      "learning_rate": 5.860307921026768e-06,
      "loss": 0.37803001403808595,
      "memory(GiB)": 72.72,
      "step": 25340,
      "token_acc": 0.875,
      "train_speed(iter/s)": 0.251377
    },
    {
      "epoch": 2.3640518608338774,
      "grad_norm": 3.200854539871216,
      "learning_rate": 5.8587885868856505e-06,
      "loss": 0.40004701614379884,
      "memory(GiB)": 72.72,
      "step": 25345,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 2.36451823523925,
      "grad_norm": 2.898676633834839,
      "learning_rate": 5.857269171033445e-06,
      "loss": 0.3534806251525879,
      "memory(GiB)": 72.72,
      "step": 25350,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 2.3649846096446225,
      "grad_norm": 4.9994683265686035,
      "learning_rate": 5.855749673614719e-06,
      "loss": 0.35358757972717286,
      "memory(GiB)": 72.72,
      "step": 25355,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 2.3654509840499953,
      "grad_norm": 3.249460220336914,
      "learning_rate": 5.854230094774048e-06,
      "loss": 0.36844778060913086,
      "memory(GiB)": 72.72,
      "step": 25360,
      "token_acc": 0.68,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 2.365917358455368,
      "grad_norm": 10.334063529968262,
      "learning_rate": 5.852710434656014e-06,
      "loss": 0.3662543296813965,
      "memory(GiB)": 72.72,
      "step": 25365,
      "token_acc": 0.7740112994350282,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.3663837328607404,
      "grad_norm": 4.037467002868652,
      "learning_rate": 5.8511906934052095e-06,
      "loss": 0.354305362701416,
      "memory(GiB)": 72.72,
      "step": 25370,
      "token_acc": 0.9532710280373832,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.3668501072661132,
      "grad_norm": 2.9273128509521484,
      "learning_rate": 5.8496708711662344e-06,
      "loss": 0.35591607093811034,
      "memory(GiB)": 72.72,
      "step": 25375,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.367316481671486,
      "grad_norm": 13.523844718933105,
      "learning_rate": 5.848150968083691e-06,
      "loss": 0.39808125495910646,
      "memory(GiB)": 72.72,
      "step": 25380,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.251377
    },
    {
      "epoch": 2.3677828560768583,
      "grad_norm": 3.3472328186035156,
      "learning_rate": 5.846630984302197e-06,
      "loss": 0.3910839557647705,
      "memory(GiB)": 72.72,
      "step": 25385,
      "token_acc": 0.6888888888888889,
      "train_speed(iter/s)": 0.251377
    },
    {
      "epoch": 2.368249230482231,
      "grad_norm": 5.580090045928955,
      "learning_rate": 5.845110919966371e-06,
      "loss": 0.3974813461303711,
      "memory(GiB)": 72.72,
      "step": 25390,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 2.368715604887604,
      "grad_norm": 4.634658336639404,
      "learning_rate": 5.843590775220846e-06,
      "loss": 0.34271488189697263,
      "memory(GiB)": 72.72,
      "step": 25395,
      "token_acc": 0.5888888888888889,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 2.3691819792929762,
      "grad_norm": 4.070404052734375,
      "learning_rate": 5.842070550210258e-06,
      "loss": 0.3631966829299927,
      "memory(GiB)": 72.72,
      "step": 25400,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 2.369648353698349,
      "grad_norm": 3.664635181427002,
      "learning_rate": 5.84055024507925e-06,
      "loss": 0.3768965005874634,
      "memory(GiB)": 72.72,
      "step": 25405,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.370114728103722,
      "grad_norm": 3.708986520767212,
      "learning_rate": 5.839029859972477e-06,
      "loss": 0.36256070137023927,
      "memory(GiB)": 72.72,
      "step": 25410,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 2.370581102509094,
      "grad_norm": 3.0620951652526855,
      "learning_rate": 5.837509395034596e-06,
      "loss": 0.3617525577545166,
      "memory(GiB)": 72.72,
      "step": 25415,
      "token_acc": 0.935064935064935,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.371047476914467,
      "grad_norm": 4.5341973304748535,
      "learning_rate": 5.835988850410277e-06,
      "loss": 0.3737316608428955,
      "memory(GiB)": 72.72,
      "step": 25420,
      "token_acc": 0.5568181818181818,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.3715138513198397,
      "grad_norm": 6.892753601074219,
      "learning_rate": 5.834468226244196e-06,
      "loss": 0.3564124584197998,
      "memory(GiB)": 72.72,
      "step": 25425,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.371980225725212,
      "grad_norm": 3.70768666267395,
      "learning_rate": 5.832947522681031e-06,
      "loss": 0.33691604137420655,
      "memory(GiB)": 72.72,
      "step": 25430,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.372446600130585,
      "grad_norm": 7.5676093101501465,
      "learning_rate": 5.831426739865476e-06,
      "loss": 0.36816842555999757,
      "memory(GiB)": 72.72,
      "step": 25435,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.3729129745359576,
      "grad_norm": 3.403858184814453,
      "learning_rate": 5.829905877942228e-06,
      "loss": 0.3760477781295776,
      "memory(GiB)": 72.72,
      "step": 25440,
      "token_acc": 0.8366013071895425,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.37337934894133,
      "grad_norm": 3.5698108673095703,
      "learning_rate": 5.828384937055992e-06,
      "loss": 0.3812380313873291,
      "memory(GiB)": 72.72,
      "step": 25445,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.3738457233467027,
      "grad_norm": 3.60162615776062,
      "learning_rate": 5.826863917351482e-06,
      "loss": 0.3566253185272217,
      "memory(GiB)": 72.72,
      "step": 25450,
      "token_acc": 0.45,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.3743120977520755,
      "grad_norm": 5.393113613128662,
      "learning_rate": 5.825342818973416e-06,
      "loss": 0.37802441120147706,
      "memory(GiB)": 72.72,
      "step": 25455,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 2.374778472157448,
      "grad_norm": 4.051112651824951,
      "learning_rate": 5.823821642066525e-06,
      "loss": 0.3613369703292847,
      "memory(GiB)": 72.72,
      "step": 25460,
      "train_speed(iter/s)": 0.251392
    },
    {
      "epoch": 2.3752448465628206,
      "grad_norm": 3.699615716934204,
      "learning_rate": 5.822300386775542e-06,
      "loss": 0.3586263179779053,
      "memory(GiB)": 72.72,
      "step": 25465,
      "train_speed(iter/s)": 0.251393
    },
    {
      "epoch": 2.3757112209681934,
      "grad_norm": 3.919900417327881,
      "learning_rate": 5.820779053245209e-06,
      "loss": 0.36286101341247556,
      "memory(GiB)": 72.72,
      "step": 25470,
      "train_speed(iter/s)": 0.251392
    },
    {
      "epoch": 2.3761775953735658,
      "grad_norm": 3.552325487136841,
      "learning_rate": 5.819257641620281e-06,
      "loss": 0.3572295427322388,
      "memory(GiB)": 72.72,
      "step": 25475,
      "token_acc": 0.5510204081632653,
      "train_speed(iter/s)": 0.251395
    },
    {
      "epoch": 2.3766439697789385,
      "grad_norm": 4.194581031799316,
      "learning_rate": 5.81773615204551e-06,
      "loss": 0.4105769157409668,
      "memory(GiB)": 72.72,
      "step": 25480,
      "token_acc": 0.7450980392156863,
      "train_speed(iter/s)": 0.251395
    },
    {
      "epoch": 2.3771103441843113,
      "grad_norm": 3.686800479888916,
      "learning_rate": 5.816214584665662e-06,
      "loss": 0.3600032329559326,
      "memory(GiB)": 72.72,
      "step": 25485,
      "token_acc": 0.6101694915254238,
      "train_speed(iter/s)": 0.251397
    },
    {
      "epoch": 2.3775767185896837,
      "grad_norm": 3.917792558670044,
      "learning_rate": 5.814692939625511e-06,
      "loss": 0.34570975303649903,
      "memory(GiB)": 72.72,
      "step": 25490,
      "token_acc": 0.6607142857142857,
      "train_speed(iter/s)": 0.251397
    },
    {
      "epoch": 2.3780430929950565,
      "grad_norm": 3.997610092163086,
      "learning_rate": 5.8131712170698385e-06,
      "loss": 0.36301488876342775,
      "memory(GiB)": 72.72,
      "step": 25495,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.251395
    },
    {
      "epoch": 2.3785094674004292,
      "grad_norm": 3.676957845687866,
      "learning_rate": 5.811649417143428e-06,
      "loss": 0.3388508796691895,
      "memory(GiB)": 72.72,
      "step": 25500,
      "token_acc": 0.3793103448275862,
      "train_speed(iter/s)": 0.251396
    },
    {
      "epoch": 2.3789758418058016,
      "grad_norm": 3.8171546459198,
      "learning_rate": 5.810127539991077e-06,
      "loss": 0.3642692804336548,
      "memory(GiB)": 72.72,
      "step": 25505,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.251395
    },
    {
      "epoch": 2.3794422162111744,
      "grad_norm": 3.7940590381622314,
      "learning_rate": 5.808605585757586e-06,
      "loss": 0.3863035202026367,
      "memory(GiB)": 72.72,
      "step": 25510,
      "train_speed(iter/s)": 0.251394
    },
    {
      "epoch": 2.379908590616547,
      "grad_norm": 3.768395185470581,
      "learning_rate": 5.807083554587765e-06,
      "loss": 0.35576767921447755,
      "memory(GiB)": 72.72,
      "step": 25515,
      "train_speed(iter/s)": 0.251395
    },
    {
      "epoch": 2.3803749650219195,
      "grad_norm": 4.715306758880615,
      "learning_rate": 5.8055614466264275e-06,
      "loss": 0.39781694412231444,
      "memory(GiB)": 72.72,
      "step": 25520,
      "token_acc": 0.4838709677419355,
      "train_speed(iter/s)": 0.251396
    },
    {
      "epoch": 2.3808413394272923,
      "grad_norm": 2.7770638465881348,
      "learning_rate": 5.804039262018403e-06,
      "loss": 0.36087841987609864,
      "memory(GiB)": 72.72,
      "step": 25525,
      "token_acc": 0.6885245901639344,
      "train_speed(iter/s)": 0.2514
    },
    {
      "epoch": 2.381307713832665,
      "grad_norm": 4.370469570159912,
      "learning_rate": 5.802517000908519e-06,
      "loss": 0.3804766178131104,
      "memory(GiB)": 72.72,
      "step": 25530,
      "token_acc": 0.5409836065573771,
      "train_speed(iter/s)": 0.251399
    },
    {
      "epoch": 2.3817740882380374,
      "grad_norm": 4.791949272155762,
      "learning_rate": 5.800994663441612e-06,
      "loss": 0.3839688777923584,
      "memory(GiB)": 72.72,
      "step": 25535,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 2.38224046264341,
      "grad_norm": 10.56550407409668,
      "learning_rate": 5.799472249762532e-06,
      "loss": 0.43054561614990233,
      "memory(GiB)": 72.72,
      "step": 25540,
      "token_acc": 0.5957446808510638,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 2.382706837048783,
      "grad_norm": 4.065779209136963,
      "learning_rate": 5.79794976001613e-06,
      "loss": 0.35946044921875,
      "memory(GiB)": 72.72,
      "step": 25545,
      "token_acc": 0.9574468085106383,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 2.3831732114541553,
      "grad_norm": 4.2824225425720215,
      "learning_rate": 5.7964271943472685e-06,
      "loss": 0.34869043827056884,
      "memory(GiB)": 72.72,
      "step": 25550,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.383639585859528,
      "grad_norm": 2.8070969581604004,
      "learning_rate": 5.794904552900811e-06,
      "loss": 0.3612831592559814,
      "memory(GiB)": 72.72,
      "step": 25555,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251409
    },
    {
      "epoch": 2.384105960264901,
      "grad_norm": 4.90032958984375,
      "learning_rate": 5.793381835821634e-06,
      "loss": 0.3674276351928711,
      "memory(GiB)": 72.72,
      "step": 25560,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 2.384572334670273,
      "grad_norm": 6.530603885650635,
      "learning_rate": 5.791859043254621e-06,
      "loss": 0.3846395015716553,
      "memory(GiB)": 72.72,
      "step": 25565,
      "token_acc": 0.9418604651162791,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 2.385038709075646,
      "grad_norm": 3.7745327949523926,
      "learning_rate": 5.790336175344656e-06,
      "loss": 0.3737197399139404,
      "memory(GiB)": 72.72,
      "step": 25570,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 2.3855050834810188,
      "grad_norm": 3.9551234245300293,
      "learning_rate": 5.788813232236643e-06,
      "loss": 0.3710984230041504,
      "memory(GiB)": 72.72,
      "step": 25575,
      "token_acc": 0.91,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 2.385971457886391,
      "grad_norm": 30.96811294555664,
      "learning_rate": 5.787290214075478e-06,
      "loss": 0.36456377506256105,
      "memory(GiB)": 72.72,
      "step": 25580,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 2.386437832291764,
      "grad_norm": 8.650910377502441,
      "learning_rate": 5.785767121006075e-06,
      "loss": 0.3969250679016113,
      "memory(GiB)": 72.72,
      "step": 25585,
      "train_speed(iter/s)": 0.251411
    },
    {
      "epoch": 2.3869042066971367,
      "grad_norm": 3.451890230178833,
      "learning_rate": 5.7842439531733505e-06,
      "loss": 0.3544299602508545,
      "memory(GiB)": 72.72,
      "step": 25590,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 2.387370581102509,
      "grad_norm": 4.78316068649292,
      "learning_rate": 5.782720710722232e-06,
      "loss": 0.34363484382629395,
      "memory(GiB)": 72.72,
      "step": 25595,
      "token_acc": 0.6739130434782609,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 2.3878369555078818,
      "grad_norm": 3.4742515087127686,
      "learning_rate": 5.781197393797648e-06,
      "loss": 0.3321193218231201,
      "memory(GiB)": 72.72,
      "step": 25600,
      "token_acc": 0.8590604026845637,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 2.3883033299132546,
      "grad_norm": 4.842090606689453,
      "learning_rate": 5.779674002544537e-06,
      "loss": 0.3776871681213379,
      "memory(GiB)": 72.72,
      "step": 25605,
      "token_acc": 0.5757575757575758,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 2.388769704318627,
      "grad_norm": 4.0153398513793945,
      "learning_rate": 5.778150537107848e-06,
      "loss": 0.3593364477157593,
      "memory(GiB)": 72.72,
      "step": 25610,
      "token_acc": 0.589041095890411,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 2.3892360787239997,
      "grad_norm": 3.201812744140625,
      "learning_rate": 5.776626997632533e-06,
      "loss": 0.3645341873168945,
      "memory(GiB)": 72.72,
      "step": 25615,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 2.389702453129372,
      "grad_norm": 5.880755424499512,
      "learning_rate": 5.77510338426355e-06,
      "loss": 0.37883954048156737,
      "memory(GiB)": 72.72,
      "step": 25620,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 2.390168827534745,
      "grad_norm": 3.77303147315979,
      "learning_rate": 5.773579697145869e-06,
      "loss": 0.3750662326812744,
      "memory(GiB)": 72.72,
      "step": 25625,
      "token_acc": 0.5773195876288659,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 2.3906352019401176,
      "grad_norm": 7.7209086418151855,
      "learning_rate": 5.772055936424462e-06,
      "loss": 0.390437650680542,
      "memory(GiB)": 72.72,
      "step": 25630,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 2.3911015763454904,
      "grad_norm": 3.427398443222046,
      "learning_rate": 5.770532102244313e-06,
      "loss": 0.366316032409668,
      "memory(GiB)": 72.72,
      "step": 25635,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 2.3915679507508627,
      "grad_norm": 6.442559242248535,
      "learning_rate": 5.769008194750405e-06,
      "loss": 0.4090126037597656,
      "memory(GiB)": 72.72,
      "step": 25640,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 2.3920343251562355,
      "grad_norm": 3.6925418376922607,
      "learning_rate": 5.767484214087737e-06,
      "loss": 0.3636601686477661,
      "memory(GiB)": 72.72,
      "step": 25645,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 2.392500699561608,
      "grad_norm": 5.307289123535156,
      "learning_rate": 5.765960160401314e-06,
      "loss": 0.3725444316864014,
      "memory(GiB)": 72.72,
      "step": 25650,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.3929670739669806,
      "grad_norm": 3.0771079063415527,
      "learning_rate": 5.7644360338361375e-06,
      "loss": 0.36256349086761475,
      "memory(GiB)": 72.72,
      "step": 25655,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.3934334483723534,
      "grad_norm": 4.434755325317383,
      "learning_rate": 5.762911834537228e-06,
      "loss": 0.38674376010894773,
      "memory(GiB)": 72.72,
      "step": 25660,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 2.393899822777726,
      "grad_norm": 3.729370594024658,
      "learning_rate": 5.761387562649608e-06,
      "loss": 0.4054121017456055,
      "memory(GiB)": 72.72,
      "step": 25665,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.3943661971830985,
      "grad_norm": 3.0028553009033203,
      "learning_rate": 5.759863218318306e-06,
      "loss": 0.38652811050415037,
      "memory(GiB)": 72.72,
      "step": 25670,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 2.3948325715884713,
      "grad_norm": 3.2760977745056152,
      "learning_rate": 5.758338801688361e-06,
      "loss": 0.35811772346496584,
      "memory(GiB)": 72.72,
      "step": 25675,
      "token_acc": 0.5447154471544715,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 2.3952989459938436,
      "grad_norm": 5.267429828643799,
      "learning_rate": 5.756814312904816e-06,
      "loss": 0.35738577842712405,
      "memory(GiB)": 72.72,
      "step": 25680,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 2.3957653203992164,
      "grad_norm": 4.174643516540527,
      "learning_rate": 5.75528975211272e-06,
      "loss": 0.3194388151168823,
      "memory(GiB)": 72.72,
      "step": 25685,
      "token_acc": 0.6491228070175439,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.396231694804589,
      "grad_norm": 4.476850509643555,
      "learning_rate": 5.753765119457128e-06,
      "loss": 0.392165207862854,
      "memory(GiB)": 72.72,
      "step": 25690,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 2.396698069209962,
      "grad_norm": 8.433201789855957,
      "learning_rate": 5.752240415083109e-06,
      "loss": 0.4230180740356445,
      "memory(GiB)": 72.72,
      "step": 25695,
      "token_acc": 0.8163265306122449,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 2.3971644436153343,
      "grad_norm": 5.384060859680176,
      "learning_rate": 5.750715639135733e-06,
      "loss": 0.3736705303192139,
      "memory(GiB)": 72.72,
      "step": 25700,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 2.397630818020707,
      "grad_norm": 4.1526198387146,
      "learning_rate": 5.749190791760074e-06,
      "loss": 0.42274227142333987,
      "memory(GiB)": 72.72,
      "step": 25705,
      "token_acc": 0.47619047619047616,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 2.3980971924260794,
      "grad_norm": 3.996767044067383,
      "learning_rate": 5.7476658731012215e-06,
      "loss": 0.36894104480743406,
      "memory(GiB)": 72.72,
      "step": 25710,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 2.398563566831452,
      "grad_norm": 3.362401247024536,
      "learning_rate": 5.746140883304263e-06,
      "loss": 0.3781136512756348,
      "memory(GiB)": 72.72,
      "step": 25715,
      "token_acc": 0.9135802469135802,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 2.399029941236825,
      "grad_norm": 12.190298080444336,
      "learning_rate": 5.744615822514299e-06,
      "loss": 0.35847461223602295,
      "memory(GiB)": 72.72,
      "step": 25720,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 2.399496315642198,
      "grad_norm": 4.843387126922607,
      "learning_rate": 5.743090690876433e-06,
      "loss": 0.37014408111572267,
      "memory(GiB)": 72.72,
      "step": 25725,
      "token_acc": 0.48672566371681414,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 2.39996269004757,
      "grad_norm": 2.892737627029419,
      "learning_rate": 5.741565488535777e-06,
      "loss": 0.3648526668548584,
      "memory(GiB)": 72.72,
      "step": 25730,
      "token_acc": 0.5431472081218274,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 2.400429064452943,
      "grad_norm": 5.701290130615234,
      "learning_rate": 5.740040215637448e-06,
      "loss": 0.3643254995346069,
      "memory(GiB)": 72.72,
      "step": 25735,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 2.4008954388583152,
      "grad_norm": 5.011953353881836,
      "learning_rate": 5.738514872326573e-06,
      "loss": 0.36523966789245604,
      "memory(GiB)": 72.72,
      "step": 25740,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 2.401361813263688,
      "grad_norm": 4.526570796966553,
      "learning_rate": 5.736989458748282e-06,
      "loss": 0.35160830020904543,
      "memory(GiB)": 72.72,
      "step": 25745,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 2.401828187669061,
      "grad_norm": 5.693222522735596,
      "learning_rate": 5.735463975047717e-06,
      "loss": 0.3534053325653076,
      "memory(GiB)": 72.72,
      "step": 25750,
      "token_acc": 0.6258992805755396,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 2.4022945620744336,
      "grad_norm": 4.7576093673706055,
      "learning_rate": 5.733938421370018e-06,
      "loss": 0.33890523910522463,
      "memory(GiB)": 72.72,
      "step": 25755,
      "token_acc": 0.5862068965517241,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.402760936479806,
      "grad_norm": 4.059952735900879,
      "learning_rate": 5.732412797860339e-06,
      "loss": 0.3286741256713867,
      "memory(GiB)": 72.72,
      "step": 25760,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.4032273108851787,
      "grad_norm": 4.130782127380371,
      "learning_rate": 5.73088710466384e-06,
      "loss": 0.35677366256713866,
      "memory(GiB)": 72.72,
      "step": 25765,
      "token_acc": 0.5698924731182796,
      "train_speed(iter/s)": 0.251439
    },
    {
      "epoch": 2.403693685290551,
      "grad_norm": 4.955039024353027,
      "learning_rate": 5.729361341925684e-06,
      "loss": 0.390470552444458,
      "memory(GiB)": 72.72,
      "step": 25770,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 2.404160059695924,
      "grad_norm": 4.6141180992126465,
      "learning_rate": 5.7278355097910445e-06,
      "loss": 0.3460658073425293,
      "memory(GiB)": 72.72,
      "step": 25775,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.251441
    },
    {
      "epoch": 2.4046264341012966,
      "grad_norm": 3.8754093647003174,
      "learning_rate": 5.726309608405096e-06,
      "loss": 0.3975371360778809,
      "memory(GiB)": 72.72,
      "step": 25780,
      "train_speed(iter/s)": 0.251439
    },
    {
      "epoch": 2.4050928085066694,
      "grad_norm": 3.829883575439453,
      "learning_rate": 5.7247836379130275e-06,
      "loss": 0.3718850612640381,
      "memory(GiB)": 72.72,
      "step": 25785,
      "token_acc": 0.45614035087719296,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.4055591829120417,
      "grad_norm": 3.8541901111602783,
      "learning_rate": 5.723257598460027e-06,
      "loss": 0.38542282581329346,
      "memory(GiB)": 72.72,
      "step": 25790,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 2.4060255573174145,
      "grad_norm": 2.538616180419922,
      "learning_rate": 5.721731490191294e-06,
      "loss": 0.3891444683074951,
      "memory(GiB)": 72.72,
      "step": 25795,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.406491931722787,
      "grad_norm": 6.2320685386657715,
      "learning_rate": 5.720205313252036e-06,
      "loss": 0.3388509273529053,
      "memory(GiB)": 72.72,
      "step": 25800,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.4069583061281596,
      "grad_norm": 4.664113521575928,
      "learning_rate": 5.718679067787458e-06,
      "loss": 0.3645111799240112,
      "memory(GiB)": 72.72,
      "step": 25805,
      "token_acc": 0.4943820224719101,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.4074246805335324,
      "grad_norm": 4.510435581207275,
      "learning_rate": 5.717152753942782e-06,
      "loss": 0.3828381061553955,
      "memory(GiB)": 72.72,
      "step": 25810,
      "train_speed(iter/s)": 0.251439
    },
    {
      "epoch": 2.4078910549389048,
      "grad_norm": 3.1274938583374023,
      "learning_rate": 5.715626371863231e-06,
      "loss": 0.3595918655395508,
      "memory(GiB)": 72.72,
      "step": 25815,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.251442
    },
    {
      "epoch": 2.4083574293442775,
      "grad_norm": 3.0529677867889404,
      "learning_rate": 5.714099921694035e-06,
      "loss": 0.35863494873046875,
      "memory(GiB)": 72.72,
      "step": 25820,
      "token_acc": 0.47761194029850745,
      "train_speed(iter/s)": 0.251443
    },
    {
      "epoch": 2.4088238037496503,
      "grad_norm": 3.5619733333587646,
      "learning_rate": 5.7125734035804305e-06,
      "loss": 0.36439154148101804,
      "memory(GiB)": 72.72,
      "step": 25825,
      "token_acc": 0.6862745098039216,
      "train_speed(iter/s)": 0.251443
    },
    {
      "epoch": 2.4092901781550227,
      "grad_norm": 4.545880317687988,
      "learning_rate": 5.711046817667663e-06,
      "loss": 0.3370778560638428,
      "memory(GiB)": 72.72,
      "step": 25830,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.251443
    },
    {
      "epoch": 2.4097565525603954,
      "grad_norm": 2.605966329574585,
      "learning_rate": 5.70952016410098e-06,
      "loss": 0.37218222618103025,
      "memory(GiB)": 72.72,
      "step": 25835,
      "train_speed(iter/s)": 0.251443
    },
    {
      "epoch": 2.4102229269657682,
      "grad_norm": 6.152155876159668,
      "learning_rate": 5.707993443025639e-06,
      "loss": 0.3797096014022827,
      "memory(GiB)": 72.72,
      "step": 25840,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251444
    },
    {
      "epoch": 2.4106893013711406,
      "grad_norm": 5.231029033660889,
      "learning_rate": 5.706466654586904e-06,
      "loss": 0.3645652770996094,
      "memory(GiB)": 72.72,
      "step": 25845,
      "token_acc": 0.47959183673469385,
      "train_speed(iter/s)": 0.251444
    },
    {
      "epoch": 2.4111556757765134,
      "grad_norm": 3.178196430206299,
      "learning_rate": 5.704939798930044e-06,
      "loss": 0.3581530094146729,
      "memory(GiB)": 72.72,
      "step": 25850,
      "train_speed(iter/s)": 0.251442
    },
    {
      "epoch": 2.411622050181886,
      "grad_norm": 5.602252960205078,
      "learning_rate": 5.703412876200333e-06,
      "loss": 0.37319581508636473,
      "memory(GiB)": 72.72,
      "step": 25855,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.251443
    },
    {
      "epoch": 2.4120884245872585,
      "grad_norm": 5.237931251525879,
      "learning_rate": 5.701885886543052e-06,
      "loss": 0.39225804805755615,
      "memory(GiB)": 72.72,
      "step": 25860,
      "token_acc": 0.4696969696969697,
      "train_speed(iter/s)": 0.251445
    },
    {
      "epoch": 2.4125547989926313,
      "grad_norm": 4.321573257446289,
      "learning_rate": 5.700358830103492e-06,
      "loss": 0.3758021354675293,
      "memory(GiB)": 72.72,
      "step": 25865,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 2.413021173398004,
      "grad_norm": 3.1891286373138428,
      "learning_rate": 5.698831707026947e-06,
      "loss": 0.35657467842102053,
      "memory(GiB)": 72.72,
      "step": 25870,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.4134875478033764,
      "grad_norm": 4.321958065032959,
      "learning_rate": 5.697304517458718e-06,
      "loss": 0.353157114982605,
      "memory(GiB)": 72.72,
      "step": 25875,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 2.413953922208749,
      "grad_norm": 2.8294641971588135,
      "learning_rate": 5.695777261544113e-06,
      "loss": 0.35596599578857424,
      "memory(GiB)": 72.72,
      "step": 25880,
      "token_acc": 0.6285714285714286,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 2.414420296614122,
      "grad_norm": 3.360572099685669,
      "learning_rate": 5.694249939428444e-06,
      "loss": 0.35905089378356936,
      "memory(GiB)": 72.72,
      "step": 25885,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 2.4148866710194943,
      "grad_norm": 4.777055263519287,
      "learning_rate": 5.692722551257032e-06,
      "loss": 0.3585456609725952,
      "memory(GiB)": 72.72,
      "step": 25890,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 2.415353045424867,
      "grad_norm": 4.021737098693848,
      "learning_rate": 5.691195097175204e-06,
      "loss": 0.37679615020751955,
      "memory(GiB)": 72.72,
      "step": 25895,
      "token_acc": 0.9565217391304348,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 2.41581941983024,
      "grad_norm": 3.2263360023498535,
      "learning_rate": 5.689667577328292e-06,
      "loss": 0.32039453983306887,
      "memory(GiB)": 72.72,
      "step": 25900,
      "train_speed(iter/s)": 0.25144
    },
    {
      "epoch": 2.416285794235612,
      "grad_norm": 6.233006954193115,
      "learning_rate": 5.688139991861633e-06,
      "loss": 0.3575682401657104,
      "memory(GiB)": 72.72,
      "step": 25905,
      "token_acc": 0.4626865671641791,
      "train_speed(iter/s)": 0.251439
    },
    {
      "epoch": 2.416752168640985,
      "grad_norm": 3.1779720783233643,
      "learning_rate": 5.686612340920574e-06,
      "loss": 0.46529569625854494,
      "memory(GiB)": 72.72,
      "step": 25910,
      "token_acc": 0.5436893203883495,
      "train_speed(iter/s)": 0.251441
    },
    {
      "epoch": 2.4172185430463577,
      "grad_norm": 5.269570827484131,
      "learning_rate": 5.685084624650466e-06,
      "loss": 0.38454465866088866,
      "memory(GiB)": 72.72,
      "step": 25915,
      "train_speed(iter/s)": 0.251443
    },
    {
      "epoch": 2.41768491745173,
      "grad_norm": 3.227200984954834,
      "learning_rate": 5.683556843196667e-06,
      "loss": 0.3444788932800293,
      "memory(GiB)": 72.72,
      "step": 25920,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 2.418151291857103,
      "grad_norm": 4.1066107749938965,
      "learning_rate": 5.6820289967045405e-06,
      "loss": 0.3851128816604614,
      "memory(GiB)": 72.72,
      "step": 25925,
      "token_acc": 0.34615384615384615,
      "train_speed(iter/s)": 0.251448
    },
    {
      "epoch": 2.4186176662624757,
      "grad_norm": 4.686700344085693,
      "learning_rate": 5.680501085319456e-06,
      "loss": 0.3572384834289551,
      "memory(GiB)": 72.72,
      "step": 25930,
      "token_acc": 0.8355263157894737,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 2.419084040667848,
      "grad_norm": 4.833330154418945,
      "learning_rate": 5.6789731091867885e-06,
      "loss": 0.36131882667541504,
      "memory(GiB)": 72.72,
      "step": 25935,
      "token_acc": 0.5737704918032787,
      "train_speed(iter/s)": 0.25145
    },
    {
      "epoch": 2.4195504150732208,
      "grad_norm": 16.635639190673828,
      "learning_rate": 5.677445068451922e-06,
      "loss": 0.35259332656860354,
      "memory(GiB)": 72.72,
      "step": 25940,
      "train_speed(iter/s)": 0.251451
    },
    {
      "epoch": 2.4200167894785936,
      "grad_norm": 3.771686553955078,
      "learning_rate": 5.675916963260244e-06,
      "loss": 0.3869942188262939,
      "memory(GiB)": 72.72,
      "step": 25945,
      "token_acc": 0.8012820512820513,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 2.420483163883966,
      "grad_norm": 7.9295973777771,
      "learning_rate": 5.67438879375715e-06,
      "loss": 0.3866246700286865,
      "memory(GiB)": 72.72,
      "step": 25950,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 2.4209495382893387,
      "grad_norm": 3.373274326324463,
      "learning_rate": 5.6728605600880385e-06,
      "loss": 0.35169072151184083,
      "memory(GiB)": 72.72,
      "step": 25955,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.4214159126947115,
      "grad_norm": 3.918849468231201,
      "learning_rate": 5.671332262398317e-06,
      "loss": 0.430879020690918,
      "memory(GiB)": 72.72,
      "step": 25960,
      "token_acc": 0.6470588235294118,
      "train_speed(iter/s)": 0.251465
    },
    {
      "epoch": 2.421882287100084,
      "grad_norm": 4.639570236206055,
      "learning_rate": 5.6698039008334e-06,
      "loss": 0.3523365259170532,
      "memory(GiB)": 72.72,
      "step": 25965,
      "token_acc": 0.5423728813559322,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 2.4223486615054566,
      "grad_norm": 4.006880760192871,
      "learning_rate": 5.668275475538705e-06,
      "loss": 0.3553260326385498,
      "memory(GiB)": 72.72,
      "step": 25970,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.4228150359108294,
      "grad_norm": 4.447886943817139,
      "learning_rate": 5.666746986659657e-06,
      "loss": 0.38397674560546874,
      "memory(GiB)": 72.72,
      "step": 25975,
      "token_acc": 0.5304347826086957,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.4232814103162017,
      "grad_norm": 6.379453659057617,
      "learning_rate": 5.665218434341687e-06,
      "loss": 0.39895317554473875,
      "memory(GiB)": 72.72,
      "step": 25980,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 2.4237477847215745,
      "grad_norm": 4.603277683258057,
      "learning_rate": 5.663689818730233e-06,
      "loss": 0.39385280609130857,
      "memory(GiB)": 72.72,
      "step": 25985,
      "token_acc": 0.5116279069767442,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 2.4242141591269473,
      "grad_norm": 3.2667384147644043,
      "learning_rate": 5.6621611399707365e-06,
      "loss": 0.40521831512451173,
      "memory(GiB)": 72.72,
      "step": 25990,
      "token_acc": 0.9797979797979798,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 2.4246805335323196,
      "grad_norm": 3.4587724208831787,
      "learning_rate": 5.6606323982086476e-06,
      "loss": 0.3723621845245361,
      "memory(GiB)": 72.72,
      "step": 25995,
      "train_speed(iter/s)": 0.251374
    },
    {
      "epoch": 2.4251469079376924,
      "grad_norm": 3.917386770248413,
      "learning_rate": 5.659103593589421e-06,
      "loss": 0.37241616249084475,
      "memory(GiB)": 72.72,
      "step": 26000,
      "token_acc": 0.6756756756756757,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.425613282343065,
      "grad_norm": 2.494502305984497,
      "learning_rate": 5.657574726258519e-06,
      "loss": 0.40950427055358884,
      "memory(GiB)": 72.72,
      "step": 26005,
      "token_acc": 0.6744186046511628,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.4260796567484375,
      "grad_norm": 6.157377243041992,
      "learning_rate": 5.6560457963614055e-06,
      "loss": 0.33752806186676027,
      "memory(GiB)": 72.72,
      "step": 26010,
      "token_acc": 0.64,
      "train_speed(iter/s)": 0.251301
    },
    {
      "epoch": 2.4265460311538103,
      "grad_norm": 3.3980257511138916,
      "learning_rate": 5.654516804043557e-06,
      "loss": 0.3876137971878052,
      "memory(GiB)": 72.72,
      "step": 26015,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.427012405559183,
      "grad_norm": 4.939496994018555,
      "learning_rate": 5.652987749450451e-06,
      "loss": 0.3855570077896118,
      "memory(GiB)": 72.72,
      "step": 26020,
      "token_acc": 0.37383177570093457,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.4274787799645554,
      "grad_norm": 3.613621473312378,
      "learning_rate": 5.651458632727572e-06,
      "loss": 0.3879511594772339,
      "memory(GiB)": 72.72,
      "step": 26025,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.427945154369928,
      "grad_norm": 4.489452362060547,
      "learning_rate": 5.6499294540204095e-06,
      "loss": 0.3479179859161377,
      "memory(GiB)": 72.72,
      "step": 26030,
      "token_acc": 0.5705521472392638,
      "train_speed(iter/s)": 0.251301
    },
    {
      "epoch": 2.428411528775301,
      "grad_norm": 3.8012335300445557,
      "learning_rate": 5.648400213474463e-06,
      "loss": 0.3737748146057129,
      "memory(GiB)": 72.72,
      "step": 26035,
      "train_speed(iter/s)": 0.2513
    },
    {
      "epoch": 2.4288779031806733,
      "grad_norm": 6.115479946136475,
      "learning_rate": 5.646870911235234e-06,
      "loss": 0.36511566638946535,
      "memory(GiB)": 72.72,
      "step": 26040,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.2513
    },
    {
      "epoch": 2.429344277586046,
      "grad_norm": 2.927708148956299,
      "learning_rate": 5.6453415474482295e-06,
      "loss": 0.3622847557067871,
      "memory(GiB)": 72.72,
      "step": 26045,
      "token_acc": 0.536,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.429810651991419,
      "grad_norm": 4.599658966064453,
      "learning_rate": 5.643812122258966e-06,
      "loss": 0.3727912425994873,
      "memory(GiB)": 72.72,
      "step": 26050,
      "token_acc": 0.7021276595744681,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.430277026396791,
      "grad_norm": 5.089081287384033,
      "learning_rate": 5.642282635812961e-06,
      "loss": 0.3592959403991699,
      "memory(GiB)": 72.72,
      "step": 26055,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.430743400802164,
      "grad_norm": 4.106836318969727,
      "learning_rate": 5.640753088255742e-06,
      "loss": 0.36757373809814453,
      "memory(GiB)": 72.72,
      "step": 26060,
      "train_speed(iter/s)": 0.2513
    },
    {
      "epoch": 2.431209775207537,
      "grad_norm": 4.110750675201416,
      "learning_rate": 5.6392234797328405e-06,
      "loss": 0.3544189453125,
      "memory(GiB)": 72.72,
      "step": 26065,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.431676149612909,
      "grad_norm": 4.672807216644287,
      "learning_rate": 5.637693810389795e-06,
      "loss": 0.3493464708328247,
      "memory(GiB)": 72.72,
      "step": 26070,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.432142524018282,
      "grad_norm": 8.606574058532715,
      "learning_rate": 5.636164080372149e-06,
      "loss": 0.39827871322631836,
      "memory(GiB)": 72.72,
      "step": 26075,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.4326088984236547,
      "grad_norm": 5.35292387008667,
      "learning_rate": 5.634634289825448e-06,
      "loss": 0.36377243995666503,
      "memory(GiB)": 72.72,
      "step": 26080,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.433075272829027,
      "grad_norm": 5.741961479187012,
      "learning_rate": 5.633104438895249e-06,
      "loss": 0.30327801704406737,
      "memory(GiB)": 72.72,
      "step": 26085,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.4335416472344,
      "grad_norm": 3.2281482219696045,
      "learning_rate": 5.631574527727115e-06,
      "loss": 0.3410632610321045,
      "memory(GiB)": 72.72,
      "step": 26090,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.4340080216397726,
      "grad_norm": 4.447279453277588,
      "learning_rate": 5.63004455646661e-06,
      "loss": 0.35645341873168945,
      "memory(GiB)": 72.72,
      "step": 26095,
      "token_acc": 0.5945945945945946,
      "train_speed(iter/s)": 0.251301
    },
    {
      "epoch": 2.434474396045145,
      "grad_norm": 3.408946990966797,
      "learning_rate": 5.628514525259307e-06,
      "loss": 0.36101350784301756,
      "memory(GiB)": 72.72,
      "step": 26100,
      "token_acc": 0.8407643312101911,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.4349407704505177,
      "grad_norm": 5.30133581161499,
      "learning_rate": 5.626984434250782e-06,
      "loss": 0.3733679294586182,
      "memory(GiB)": 72.72,
      "step": 26105,
      "token_acc": 0.9238095238095239,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.4354071448558905,
      "grad_norm": 5.473303318023682,
      "learning_rate": 5.625454283586618e-06,
      "loss": 0.3809375524520874,
      "memory(GiB)": 72.72,
      "step": 26110,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.435873519261263,
      "grad_norm": 4.787716388702393,
      "learning_rate": 5.623924073412407e-06,
      "loss": 0.3923700571060181,
      "memory(GiB)": 72.72,
      "step": 26115,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.4363398936666356,
      "grad_norm": 10.418121337890625,
      "learning_rate": 5.622393803873743e-06,
      "loss": 0.3839062213897705,
      "memory(GiB)": 72.72,
      "step": 26120,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.4368062680720084,
      "grad_norm": 3.8695011138916016,
      "learning_rate": 5.620863475116227e-06,
      "loss": 0.393553352355957,
      "memory(GiB)": 72.72,
      "step": 26125,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.4372726424773807,
      "grad_norm": 4.981108665466309,
      "learning_rate": 5.619333087285461e-06,
      "loss": 0.3506136894226074,
      "memory(GiB)": 72.72,
      "step": 26130,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.251312
    },
    {
      "epoch": 2.4377390168827535,
      "grad_norm": 2.766199827194214,
      "learning_rate": 5.617802640527061e-06,
      "loss": 0.3740601301193237,
      "memory(GiB)": 72.72,
      "step": 26135,
      "token_acc": 0.5147058823529411,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.4382053912881263,
      "grad_norm": 5.846426486968994,
      "learning_rate": 5.616272134986644e-06,
      "loss": 0.3843498945236206,
      "memory(GiB)": 72.72,
      "step": 26140,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.4386717656934986,
      "grad_norm": 3.166368246078491,
      "learning_rate": 5.614741570809831e-06,
      "loss": 0.39910283088684084,
      "memory(GiB)": 72.72,
      "step": 26145,
      "token_acc": 0.6521739130434783,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 2.4391381400988714,
      "grad_norm": 3.337700366973877,
      "learning_rate": 5.613210948142252e-06,
      "loss": 0.35704469680786133,
      "memory(GiB)": 72.72,
      "step": 26150,
      "token_acc": 0.9342105263157895,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.4396045145042438,
      "grad_norm": 17.136417388916016,
      "learning_rate": 5.611680267129539e-06,
      "loss": 0.358510947227478,
      "memory(GiB)": 72.72,
      "step": 26155,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.4400708889096165,
      "grad_norm": 3.2952916622161865,
      "learning_rate": 5.610149527917334e-06,
      "loss": 0.3475378751754761,
      "memory(GiB)": 72.72,
      "step": 26160,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.4405372633149893,
      "grad_norm": 2.74969482421875,
      "learning_rate": 5.608618730651279e-06,
      "loss": 0.3340057611465454,
      "memory(GiB)": 72.72,
      "step": 26165,
      "token_acc": 0.9056603773584906,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.441003637720362,
      "grad_norm": 4.87815523147583,
      "learning_rate": 5.60708787547703e-06,
      "loss": 0.3475171089172363,
      "memory(GiB)": 72.72,
      "step": 26170,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.4414700121257344,
      "grad_norm": 3.4329640865325928,
      "learning_rate": 5.605556962540238e-06,
      "loss": 0.36138062477111815,
      "memory(GiB)": 72.72,
      "step": 26175,
      "token_acc": 0.4489795918367347,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.4419363865311072,
      "grad_norm": 7.542819976806641,
      "learning_rate": 5.6040259919865655e-06,
      "loss": 0.381540584564209,
      "memory(GiB)": 72.72,
      "step": 26180,
      "token_acc": 0.4090909090909091,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.4424027609364796,
      "grad_norm": 4.384064197540283,
      "learning_rate": 5.602494963961682e-06,
      "loss": 0.33043441772460935,
      "memory(GiB)": 72.72,
      "step": 26185,
      "token_acc": 0.6981132075471698,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.4428691353418523,
      "grad_norm": 2.8107645511627197,
      "learning_rate": 5.600963878611259e-06,
      "loss": 0.33755395412445066,
      "memory(GiB)": 72.72,
      "step": 26190,
      "train_speed(iter/s)": 0.251299
    },
    {
      "epoch": 2.443335509747225,
      "grad_norm": 3.162938117980957,
      "learning_rate": 5.599432736080973e-06,
      "loss": 0.3644170045852661,
      "memory(GiB)": 72.72,
      "step": 26195,
      "token_acc": 0.6938775510204082,
      "train_speed(iter/s)": 0.2513
    },
    {
      "epoch": 2.443801884152598,
      "grad_norm": 8.328413963317871,
      "learning_rate": 5.597901536516509e-06,
      "loss": 0.40123958587646485,
      "memory(GiB)": 72.72,
      "step": 26200,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.4442682585579703,
      "grad_norm": 4.970666885375977,
      "learning_rate": 5.596370280063556e-06,
      "loss": 0.36224026679992677,
      "memory(GiB)": 72.72,
      "step": 26205,
      "token_acc": 0.6041666666666666,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.444734632963343,
      "grad_norm": 2.9593827724456787,
      "learning_rate": 5.5948389668678084e-06,
      "loss": 0.3896637439727783,
      "memory(GiB)": 72.72,
      "step": 26210,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.4452010073687154,
      "grad_norm": 4.945718765258789,
      "learning_rate": 5.593307597074964e-06,
      "loss": 0.3768659830093384,
      "memory(GiB)": 72.72,
      "step": 26215,
      "token_acc": 0.6097560975609756,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.445667381774088,
      "grad_norm": 3.9243099689483643,
      "learning_rate": 5.591776170830733e-06,
      "loss": 0.3403537511825562,
      "memory(GiB)": 72.72,
      "step": 26220,
      "token_acc": 0.9484536082474226,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.446133756179461,
      "grad_norm": 3.75325345993042,
      "learning_rate": 5.590244688280819e-06,
      "loss": 0.33568997383117677,
      "memory(GiB)": 72.72,
      "step": 26225,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.4466001305848337,
      "grad_norm": 4.379051685333252,
      "learning_rate": 5.588713149570942e-06,
      "loss": 0.3738661766052246,
      "memory(GiB)": 72.72,
      "step": 26230,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.447066504990206,
      "grad_norm": 4.201237678527832,
      "learning_rate": 5.587181554846822e-06,
      "loss": 0.40485401153564454,
      "memory(GiB)": 72.72,
      "step": 26235,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 2.447532879395579,
      "grad_norm": 3.2055187225341797,
      "learning_rate": 5.585649904254187e-06,
      "loss": 0.34795901775360105,
      "memory(GiB)": 72.72,
      "step": 26240,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.447999253800951,
      "grad_norm": 2.887500762939453,
      "learning_rate": 5.584118197938769e-06,
      "loss": 0.34816746711730956,
      "memory(GiB)": 72.72,
      "step": 26245,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.448465628206324,
      "grad_norm": 4.42522668838501,
      "learning_rate": 5.582586436046301e-06,
      "loss": 0.3540958404541016,
      "memory(GiB)": 72.72,
      "step": 26250,
      "train_speed(iter/s)": 0.251312
    },
    {
      "epoch": 2.4489320026116967,
      "grad_norm": 2.8935816287994385,
      "learning_rate": 5.58105461872253e-06,
      "loss": 0.3321674346923828,
      "memory(GiB)": 72.72,
      "step": 26255,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.4493983770170695,
      "grad_norm": 10.792097091674805,
      "learning_rate": 5.5795227461132015e-06,
      "loss": 0.36820383071899415,
      "memory(GiB)": 72.72,
      "step": 26260,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.449864751422442,
      "grad_norm": 4.380990505218506,
      "learning_rate": 5.577990818364068e-06,
      "loss": 0.34643566608428955,
      "memory(GiB)": 72.72,
      "step": 26265,
      "token_acc": 0.4716981132075472,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4503311258278146,
      "grad_norm": 4.684345722198486,
      "learning_rate": 5.57645883562089e-06,
      "loss": 0.3718485116958618,
      "memory(GiB)": 72.72,
      "step": 26270,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 2.450797500233187,
      "grad_norm": 3.991797924041748,
      "learning_rate": 5.57492679802943e-06,
      "loss": 0.3639978885650635,
      "memory(GiB)": 72.72,
      "step": 26275,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251315
    },
    {
      "epoch": 2.4512638746385598,
      "grad_norm": 4.536759376525879,
      "learning_rate": 5.573394705735455e-06,
      "loss": 0.360717248916626,
      "memory(GiB)": 72.72,
      "step": 26280,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.4517302490439326,
      "grad_norm": 7.304858207702637,
      "learning_rate": 5.571862558884741e-06,
      "loss": 0.3317031621932983,
      "memory(GiB)": 72.72,
      "step": 26285,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4521966234493053,
      "grad_norm": 2.753688097000122,
      "learning_rate": 5.570330357623065e-06,
      "loss": 0.3597417831420898,
      "memory(GiB)": 72.72,
      "step": 26290,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.4526629978546777,
      "grad_norm": 7.79125452041626,
      "learning_rate": 5.568798102096214e-06,
      "loss": 0.3971599340438843,
      "memory(GiB)": 72.72,
      "step": 26295,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4531293722600505,
      "grad_norm": 3.1090707778930664,
      "learning_rate": 5.567265792449975e-06,
      "loss": 0.36939144134521484,
      "memory(GiB)": 72.72,
      "step": 26300,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.453595746665423,
      "grad_norm": 3.6082611083984375,
      "learning_rate": 5.565733428830144e-06,
      "loss": 0.32224092483520506,
      "memory(GiB)": 72.72,
      "step": 26305,
      "token_acc": 0.941747572815534,
      "train_speed(iter/s)": 0.251312
    },
    {
      "epoch": 2.4540621210707956,
      "grad_norm": 6.24039888381958,
      "learning_rate": 5.56420101138252e-06,
      "loss": 0.28925299644470215,
      "memory(GiB)": 72.72,
      "step": 26310,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4545284954761684,
      "grad_norm": 2.4590771198272705,
      "learning_rate": 5.562668540252905e-06,
      "loss": 0.34131679534912107,
      "memory(GiB)": 72.72,
      "step": 26315,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 2.454994869881541,
      "grad_norm": 4.429184436798096,
      "learning_rate": 5.5611360155871165e-06,
      "loss": 0.3840935707092285,
      "memory(GiB)": 72.72,
      "step": 26320,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 2.4554612442869135,
      "grad_norm": 2.9415907859802246,
      "learning_rate": 5.5596034375309615e-06,
      "loss": 0.34556193351745607,
      "memory(GiB)": 72.72,
      "step": 26325,
      "token_acc": 0.5663716814159292,
      "train_speed(iter/s)": 0.25132
    },
    {
      "epoch": 2.4559276186922863,
      "grad_norm": 6.664435863494873,
      "learning_rate": 5.558070806230265e-06,
      "loss": 0.37731099128723145,
      "memory(GiB)": 72.72,
      "step": 26330,
      "token_acc": 0.5869565217391305,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.4563939930976586,
      "grad_norm": 3.6411919593811035,
      "learning_rate": 5.556538121830848e-06,
      "loss": 0.38582921028137207,
      "memory(GiB)": 72.72,
      "step": 26335,
      "token_acc": 0.532258064516129,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 2.4568603675030314,
      "grad_norm": 3.311577320098877,
      "learning_rate": 5.555005384478544e-06,
      "loss": 0.32529644966125487,
      "memory(GiB)": 72.72,
      "step": 26340,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.457326741908404,
      "grad_norm": 4.80769681930542,
      "learning_rate": 5.553472594319189e-06,
      "loss": 0.3552315473556519,
      "memory(GiB)": 72.72,
      "step": 26345,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.457793116313777,
      "grad_norm": 3.058340549468994,
      "learning_rate": 5.55193975149862e-06,
      "loss": 0.3732140064239502,
      "memory(GiB)": 72.72,
      "step": 26350,
      "token_acc": 0.4117647058823529,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.4582594907191493,
      "grad_norm": 3.8082668781280518,
      "learning_rate": 5.550406856162686e-06,
      "loss": 0.36097400188446044,
      "memory(GiB)": 72.72,
      "step": 26355,
      "token_acc": 0.5370370370370371,
      "train_speed(iter/s)": 0.251315
    },
    {
      "epoch": 2.458725865124522,
      "grad_norm": 3.7381415367126465,
      "learning_rate": 5.5488739084572345e-06,
      "loss": 0.40929574966430665,
      "memory(GiB)": 72.72,
      "step": 26360,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 2.4591922395298944,
      "grad_norm": 3.434598207473755,
      "learning_rate": 5.547340908528119e-06,
      "loss": 0.4128657341003418,
      "memory(GiB)": 72.72,
      "step": 26365,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.459658613935267,
      "grad_norm": 3.7537600994110107,
      "learning_rate": 5.545807856521206e-06,
      "loss": 0.3921947956085205,
      "memory(GiB)": 72.72,
      "step": 26370,
      "token_acc": 0.6833333333333333,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.46012498834064,
      "grad_norm": 4.88997745513916,
      "learning_rate": 5.544274752582355e-06,
      "loss": 0.3869555711746216,
      "memory(GiB)": 72.72,
      "step": 26375,
      "token_acc": 0.9345794392523364,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.4605913627460123,
      "grad_norm": 5.885376453399658,
      "learning_rate": 5.542741596857438e-06,
      "loss": 0.3406060218811035,
      "memory(GiB)": 72.72,
      "step": 26380,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.461057737151385,
      "grad_norm": 3.8209171295166016,
      "learning_rate": 5.541208389492329e-06,
      "loss": 0.34897189140319823,
      "memory(GiB)": 72.72,
      "step": 26385,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.461524111556758,
      "grad_norm": 3.3961055278778076,
      "learning_rate": 5.53967513063291e-06,
      "loss": 0.35451905727386473,
      "memory(GiB)": 72.72,
      "step": 26390,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.46199048596213,
      "grad_norm": 3.3531181812286377,
      "learning_rate": 5.538141820425065e-06,
      "loss": 0.3723714828491211,
      "memory(GiB)": 72.72,
      "step": 26395,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.462456860367503,
      "grad_norm": 6.909706115722656,
      "learning_rate": 5.536608459014683e-06,
      "loss": 0.3849784374237061,
      "memory(GiB)": 72.72,
      "step": 26400,
      "token_acc": 0.509090909090909,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.462923234772876,
      "grad_norm": 3.236386775970459,
      "learning_rate": 5.53507504654766e-06,
      "loss": 0.366090726852417,
      "memory(GiB)": 72.72,
      "step": 26405,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.463389609178248,
      "grad_norm": 4.102263450622559,
      "learning_rate": 5.533541583169894e-06,
      "loss": 0.3591389894485474,
      "memory(GiB)": 72.72,
      "step": 26410,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.463855983583621,
      "grad_norm": 3.815232515335083,
      "learning_rate": 5.532008069027291e-06,
      "loss": 0.3422490358352661,
      "memory(GiB)": 72.72,
      "step": 26415,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.4643223579889937,
      "grad_norm": 5.03139591217041,
      "learning_rate": 5.530474504265758e-06,
      "loss": 0.348099684715271,
      "memory(GiB)": 72.72,
      "step": 26420,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.464788732394366,
      "grad_norm": 3.616427421569824,
      "learning_rate": 5.52894088903121e-06,
      "loss": 0.37513909339904783,
      "memory(GiB)": 72.72,
      "step": 26425,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.465255106799739,
      "grad_norm": 4.67113733291626,
      "learning_rate": 5.5274072234695665e-06,
      "loss": 0.32780234813690184,
      "memory(GiB)": 72.72,
      "step": 26430,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.4657214812051116,
      "grad_norm": 7.427613735198975,
      "learning_rate": 5.525873507726749e-06,
      "loss": 0.322414493560791,
      "memory(GiB)": 72.72,
      "step": 26435,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.466187855610484,
      "grad_norm": 3.8850817680358887,
      "learning_rate": 5.524339741948689e-06,
      "loss": 0.3503121376037598,
      "memory(GiB)": 72.72,
      "step": 26440,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4666542300158567,
      "grad_norm": 5.338908672332764,
      "learning_rate": 5.522805926281319e-06,
      "loss": 0.361745023727417,
      "memory(GiB)": 72.72,
      "step": 26445,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 2.4671206044212295,
      "grad_norm": 3.2010252475738525,
      "learning_rate": 5.521272060870572e-06,
      "loss": 0.3478137969970703,
      "memory(GiB)": 72.72,
      "step": 26450,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 2.467586978826602,
      "grad_norm": 3.4606783390045166,
      "learning_rate": 5.519738145862395e-06,
      "loss": 0.3798661708831787,
      "memory(GiB)": 72.72,
      "step": 26455,
      "token_acc": 0.5606060606060606,
      "train_speed(iter/s)": 0.251315
    },
    {
      "epoch": 2.4680533532319746,
      "grad_norm": 3.74086332321167,
      "learning_rate": 5.518204181402737e-06,
      "loss": 0.37301363945007326,
      "memory(GiB)": 72.72,
      "step": 26460,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 2.4685197276373474,
      "grad_norm": 3.224034309387207,
      "learning_rate": 5.5166701676375455e-06,
      "loss": 0.3789651870727539,
      "memory(GiB)": 72.72,
      "step": 26465,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 2.4689861020427197,
      "grad_norm": 3.0525379180908203,
      "learning_rate": 5.51513610471278e-06,
      "loss": 0.35774621963500974,
      "memory(GiB)": 72.72,
      "step": 26470,
      "token_acc": 0.5925925925925926,
      "train_speed(iter/s)": 0.251315
    },
    {
      "epoch": 2.4694524764480925,
      "grad_norm": 3.4419541358947754,
      "learning_rate": 5.513601992774401e-06,
      "loss": 0.33705744743347166,
      "memory(GiB)": 72.72,
      "step": 26475,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.4699188508534653,
      "grad_norm": 4.082568645477295,
      "learning_rate": 5.5120678319683755e-06,
      "loss": 0.38361401557922364,
      "memory(GiB)": 72.72,
      "step": 26480,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4703852252588376,
      "grad_norm": 4.172462463378906,
      "learning_rate": 5.51053362244067e-06,
      "loss": 0.3703007698059082,
      "memory(GiB)": 72.72,
      "step": 26485,
      "token_acc": 0.7258883248730964,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.4708515996642104,
      "grad_norm": 3.246612310409546,
      "learning_rate": 5.5089993643372656e-06,
      "loss": 0.33305559158325193,
      "memory(GiB)": 72.72,
      "step": 26490,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.471317974069583,
      "grad_norm": 22.529827117919922,
      "learning_rate": 5.50746505780414e-06,
      "loss": 0.3695554256439209,
      "memory(GiB)": 72.72,
      "step": 26495,
      "token_acc": 0.95,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4717843484749555,
      "grad_norm": 3.760101079940796,
      "learning_rate": 5.505930702987277e-06,
      "loss": 0.3534067630767822,
      "memory(GiB)": 72.72,
      "step": 26500,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.4722507228803283,
      "grad_norm": 4.02763557434082,
      "learning_rate": 5.504396300032665e-06,
      "loss": 0.38853042125701903,
      "memory(GiB)": 72.72,
      "step": 26505,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.472717097285701,
      "grad_norm": 3.350524663925171,
      "learning_rate": 5.5028618490863e-06,
      "loss": 0.3633481502532959,
      "memory(GiB)": 72.72,
      "step": 26510,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4731834716910734,
      "grad_norm": 3.2555134296417236,
      "learning_rate": 5.501327350294179e-06,
      "loss": 0.3464795112609863,
      "memory(GiB)": 72.72,
      "step": 26515,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 2.4736498460964462,
      "grad_norm": 2.7875781059265137,
      "learning_rate": 5.499792803802305e-06,
      "loss": 0.35042319297790525,
      "memory(GiB)": 72.72,
      "step": 26520,
      "token_acc": 0.48936170212765956,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.474116220501819,
      "grad_norm": 2.7154831886291504,
      "learning_rate": 5.498258209756686e-06,
      "loss": 0.3422723293304443,
      "memory(GiB)": 72.72,
      "step": 26525,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.4745825949071913,
      "grad_norm": 3.467818260192871,
      "learning_rate": 5.496723568303333e-06,
      "loss": 0.35399818420410156,
      "memory(GiB)": 72.72,
      "step": 26530,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.475048969312564,
      "grad_norm": 3.481151580810547,
      "learning_rate": 5.4951888795882605e-06,
      "loss": 0.33108565807342527,
      "memory(GiB)": 72.72,
      "step": 26535,
      "token_acc": 0.8014184397163121,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.475515343717937,
      "grad_norm": 3.412313938140869,
      "learning_rate": 5.493654143757495e-06,
      "loss": 0.3569627285003662,
      "memory(GiB)": 72.72,
      "step": 26540,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.4759817181233092,
      "grad_norm": 3.11531662940979,
      "learning_rate": 5.492119360957057e-06,
      "loss": 0.3531392812728882,
      "memory(GiB)": 72.72,
      "step": 26545,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.476448092528682,
      "grad_norm": 5.333922386169434,
      "learning_rate": 5.4905845313329774e-06,
      "loss": 0.366689395904541,
      "memory(GiB)": 72.72,
      "step": 26550,
      "train_speed(iter/s)": 0.251315
    },
    {
      "epoch": 2.476914466934055,
      "grad_norm": 7.4879631996154785,
      "learning_rate": 5.48904965503129e-06,
      "loss": 0.35648987293243406,
      "memory(GiB)": 72.72,
      "step": 26555,
      "token_acc": 0.4864864864864865,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 2.477380841339427,
      "grad_norm": 6.334369659423828,
      "learning_rate": 5.487514732198036e-06,
      "loss": 0.3175319194793701,
      "memory(GiB)": 72.72,
      "step": 26560,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 2.4778472157448,
      "grad_norm": 5.008772373199463,
      "learning_rate": 5.485979762979256e-06,
      "loss": 0.38855302333831787,
      "memory(GiB)": 72.72,
      "step": 26565,
      "token_acc": 0.6046511627906976,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.4783135901501727,
      "grad_norm": 4.811733722686768,
      "learning_rate": 5.484444747521001e-06,
      "loss": 0.3860083341598511,
      "memory(GiB)": 72.72,
      "step": 26570,
      "token_acc": 0.6170212765957447,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.478779964555545,
      "grad_norm": 3.6414735317230225,
      "learning_rate": 5.482909685969317e-06,
      "loss": 0.37420854568481443,
      "memory(GiB)": 72.72,
      "step": 26575,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 2.479246338960918,
      "grad_norm": 2.677172899246216,
      "learning_rate": 5.481374578470267e-06,
      "loss": 0.35284910202026365,
      "memory(GiB)": 72.72,
      "step": 26580,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.4797127133662906,
      "grad_norm": 9.476076126098633,
      "learning_rate": 5.479839425169907e-06,
      "loss": 0.3584174633026123,
      "memory(GiB)": 72.72,
      "step": 26585,
      "token_acc": 0.3877551020408163,
      "train_speed(iter/s)": 0.25132
    },
    {
      "epoch": 2.480179087771663,
      "grad_norm": 3.877551794052124,
      "learning_rate": 5.478304226214305e-06,
      "loss": 0.3214855670928955,
      "memory(GiB)": 72.72,
      "step": 26590,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 2.4806454621770357,
      "grad_norm": 3.0985913276672363,
      "learning_rate": 5.476768981749529e-06,
      "loss": 0.36364963054656985,
      "memory(GiB)": 72.72,
      "step": 26595,
      "token_acc": 0.5471698113207547,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 2.4811118365824085,
      "grad_norm": 3.2284634113311768,
      "learning_rate": 5.475233691921654e-06,
      "loss": 0.3648935079574585,
      "memory(GiB)": 72.72,
      "step": 26600,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.251322
    },
    {
      "epoch": 2.481578210987781,
      "grad_norm": 2.6925570964813232,
      "learning_rate": 5.4736983568767555e-06,
      "loss": 0.33181071281433105,
      "memory(GiB)": 72.72,
      "step": 26605,
      "train_speed(iter/s)": 0.251323
    },
    {
      "epoch": 2.4820445853931536,
      "grad_norm": 4.244992733001709,
      "learning_rate": 5.472162976760919e-06,
      "loss": 0.3725146770477295,
      "memory(GiB)": 72.72,
      "step": 26610,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 2.4825109597985264,
      "grad_norm": 2.604750394821167,
      "learning_rate": 5.470627551720229e-06,
      "loss": 0.38210067749023435,
      "memory(GiB)": 72.72,
      "step": 26615,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 2.4829773342038988,
      "grad_norm": 2.7358696460723877,
      "learning_rate": 5.4690920819007774e-06,
      "loss": 0.3834853649139404,
      "memory(GiB)": 72.72,
      "step": 26620,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 2.4834437086092715,
      "grad_norm": 9.039226531982422,
      "learning_rate": 5.467556567448659e-06,
      "loss": 0.3432264804840088,
      "memory(GiB)": 72.72,
      "step": 26625,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 2.4839100830146443,
      "grad_norm": 6.064852714538574,
      "learning_rate": 5.466021008509974e-06,
      "loss": 0.3412592649459839,
      "memory(GiB)": 72.72,
      "step": 26630,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 2.4843764574200167,
      "grad_norm": 3.3510704040527344,
      "learning_rate": 5.464485405230826e-06,
      "loss": 0.36267406940460206,
      "memory(GiB)": 72.72,
      "step": 26635,
      "token_acc": 0.5471698113207547,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 2.4848428318253895,
      "grad_norm": 5.223333835601807,
      "learning_rate": 5.462949757757321e-06,
      "loss": 0.3619281768798828,
      "memory(GiB)": 72.72,
      "step": 26640,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 2.4853092062307622,
      "grad_norm": 3.5218820571899414,
      "learning_rate": 5.461414066235575e-06,
      "loss": 0.33639819622039796,
      "memory(GiB)": 72.72,
      "step": 26645,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 2.4857755806361346,
      "grad_norm": 4.203180313110352,
      "learning_rate": 5.459878330811701e-06,
      "loss": 0.3593593120574951,
      "memory(GiB)": 72.72,
      "step": 26650,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 2.4862419550415074,
      "grad_norm": 4.56793737411499,
      "learning_rate": 5.458342551631819e-06,
      "loss": 0.36893301010131835,
      "memory(GiB)": 72.72,
      "step": 26655,
      "token_acc": 0.6481481481481481,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 2.48670832944688,
      "grad_norm": 2.740879774093628,
      "learning_rate": 5.4568067288420565e-06,
      "loss": 0.34495768547058103,
      "memory(GiB)": 72.72,
      "step": 26660,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 2.4871747038522525,
      "grad_norm": 3.423063039779663,
      "learning_rate": 5.455270862588541e-06,
      "loss": 0.3592651844024658,
      "memory(GiB)": 72.72,
      "step": 26665,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 2.4876410782576253,
      "grad_norm": 3.3230903148651123,
      "learning_rate": 5.453734953017406e-06,
      "loss": 0.3667969942092896,
      "memory(GiB)": 72.72,
      "step": 26670,
      "token_acc": 0.6721311475409836,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 2.488107452662998,
      "grad_norm": 2.437441110610962,
      "learning_rate": 5.4521990002747875e-06,
      "loss": 0.3511666774749756,
      "memory(GiB)": 72.72,
      "step": 26675,
      "token_acc": 0.6166666666666667,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 2.4885738270683704,
      "grad_norm": 2.6880881786346436,
      "learning_rate": 5.450663004506827e-06,
      "loss": 0.3061189651489258,
      "memory(GiB)": 72.72,
      "step": 26680,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.489040201473743,
      "grad_norm": 3.7536416053771973,
      "learning_rate": 5.44912696585967e-06,
      "loss": 0.3472015857696533,
      "memory(GiB)": 72.72,
      "step": 26685,
      "train_speed(iter/s)": 0.251331
    },
    {
      "epoch": 2.489506575879116,
      "grad_norm": 4.495577335357666,
      "learning_rate": 5.447590884479464e-06,
      "loss": 0.36009228229522705,
      "memory(GiB)": 72.72,
      "step": 26690,
      "token_acc": 0.6862745098039216,
      "train_speed(iter/s)": 0.251332
    },
    {
      "epoch": 2.4899729502844883,
      "grad_norm": 3.5106897354125977,
      "learning_rate": 5.446054760512368e-06,
      "loss": 0.3672311782836914,
      "memory(GiB)": 72.72,
      "step": 26695,
      "token_acc": 0.7659574468085106,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 2.490439324689861,
      "grad_norm": 3.757380485534668,
      "learning_rate": 5.444518594104533e-06,
      "loss": 0.34407529830932615,
      "memory(GiB)": 72.72,
      "step": 26700,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.490905699095234,
      "grad_norm": 3.579981803894043,
      "learning_rate": 5.442982385402123e-06,
      "loss": 0.3268117904663086,
      "memory(GiB)": 72.72,
      "step": 26705,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.491372073500606,
      "grad_norm": 3.7674317359924316,
      "learning_rate": 5.441446134551305e-06,
      "loss": 0.3635705471038818,
      "memory(GiB)": 72.72,
      "step": 26710,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.491838447905979,
      "grad_norm": 3.4241955280303955,
      "learning_rate": 5.439909841698246e-06,
      "loss": 0.3762415647506714,
      "memory(GiB)": 72.72,
      "step": 26715,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 2.4923048223113513,
      "grad_norm": 5.6204094886779785,
      "learning_rate": 5.438373506989123e-06,
      "loss": 0.39125473499298097,
      "memory(GiB)": 72.72,
      "step": 26720,
      "token_acc": 0.5233644859813084,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 2.492771196716724,
      "grad_norm": 3.2480249404907227,
      "learning_rate": 5.436837130570108e-06,
      "loss": 0.37269253730773927,
      "memory(GiB)": 72.72,
      "step": 26725,
      "token_acc": 0.4230769230769231,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 2.493237571122097,
      "grad_norm": 4.643887042999268,
      "learning_rate": 5.435300712587388e-06,
      "loss": 0.3989137887954712,
      "memory(GiB)": 72.72,
      "step": 26730,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.4937039455274697,
      "grad_norm": 3.513852119445801,
      "learning_rate": 5.433764253187146e-06,
      "loss": 0.3899538993835449,
      "memory(GiB)": 72.72,
      "step": 26735,
      "token_acc": 0.4594594594594595,
      "train_speed(iter/s)": 0.251255
    },
    {
      "epoch": 2.494170319932842,
      "grad_norm": 2.685669183731079,
      "learning_rate": 5.43222775251557e-06,
      "loss": 0.337699294090271,
      "memory(GiB)": 72.72,
      "step": 26740,
      "token_acc": 0.6818181818181818,
      "train_speed(iter/s)": 0.251255
    },
    {
      "epoch": 2.4946366943382148,
      "grad_norm": 2.691178321838379,
      "learning_rate": 5.430691210718857e-06,
      "loss": 0.333988094329834,
      "memory(GiB)": 72.72,
      "step": 26745,
      "train_speed(iter/s)": 0.251256
    },
    {
      "epoch": 2.495103068743587,
      "grad_norm": 3.041227340698242,
      "learning_rate": 5.4291546279432e-06,
      "loss": 0.3788933277130127,
      "memory(GiB)": 72.72,
      "step": 26750,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.49556944314896,
      "grad_norm": 2.518852949142456,
      "learning_rate": 5.4276180043348025e-06,
      "loss": 0.35599939823150634,
      "memory(GiB)": 72.72,
      "step": 26755,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.4960358175543327,
      "grad_norm": 2.8060336112976074,
      "learning_rate": 5.426081340039871e-06,
      "loss": 0.35820798873901366,
      "memory(GiB)": 72.72,
      "step": 26760,
      "token_acc": 0.8869565217391304,
      "train_speed(iter/s)": 0.251252
    },
    {
      "epoch": 2.4965021919597055,
      "grad_norm": 2.774855852127075,
      "learning_rate": 5.424544635204611e-06,
      "loss": 0.3537945032119751,
      "memory(GiB)": 72.72,
      "step": 26765,
      "train_speed(iter/s)": 0.25125
    },
    {
      "epoch": 2.496968566365078,
      "grad_norm": 3.821669101715088,
      "learning_rate": 5.423007889975238e-06,
      "loss": 0.34003520011901855,
      "memory(GiB)": 72.72,
      "step": 26770,
      "train_speed(iter/s)": 0.251249
    },
    {
      "epoch": 2.4974349407704506,
      "grad_norm": 3.1271064281463623,
      "learning_rate": 5.421471104497966e-06,
      "loss": 0.36168408393859863,
      "memory(GiB)": 72.72,
      "step": 26775,
      "train_speed(iter/s)": 0.251251
    },
    {
      "epoch": 2.497901315175823,
      "grad_norm": 4.484077453613281,
      "learning_rate": 5.419934278919017e-06,
      "loss": 0.37106075286865237,
      "memory(GiB)": 72.72,
      "step": 26780,
      "token_acc": 0.631578947368421,
      "train_speed(iter/s)": 0.251252
    },
    {
      "epoch": 2.4983676895811957,
      "grad_norm": 3.005337715148926,
      "learning_rate": 5.418397413384616e-06,
      "loss": 0.3318017959594727,
      "memory(GiB)": 72.72,
      "step": 26785,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.4988340639865685,
      "grad_norm": 6.203769683837891,
      "learning_rate": 5.41686050804099e-06,
      "loss": 0.38120326995849607,
      "memory(GiB)": 72.72,
      "step": 26790,
      "token_acc": 0.4074074074074074,
      "train_speed(iter/s)": 0.251255
    },
    {
      "epoch": 2.4993004383919413,
      "grad_norm": 17.77885627746582,
      "learning_rate": 5.415323563034369e-06,
      "loss": 0.37624320983886717,
      "memory(GiB)": 72.72,
      "step": 26795,
      "token_acc": 0.5225225225225225,
      "train_speed(iter/s)": 0.251252
    },
    {
      "epoch": 2.4997668127973136,
      "grad_norm": 5.314587116241455,
      "learning_rate": 5.413786578510992e-06,
      "loss": 0.3947760105133057,
      "memory(GiB)": 72.72,
      "step": 26800,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251256
    },
    {
      "epoch": 2.5002331872026864,
      "grad_norm": 4.5467729568481445,
      "learning_rate": 5.412249554617097e-06,
      "loss": 0.3641338348388672,
      "memory(GiB)": 72.72,
      "step": 26805,
      "token_acc": 0.9649122807017544,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.5006995616080587,
      "grad_norm": 2.850437641143799,
      "learning_rate": 5.410712491498925e-06,
      "loss": 0.3499929904937744,
      "memory(GiB)": 72.72,
      "step": 26810,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.5011659360134315,
      "grad_norm": 4.0149312019348145,
      "learning_rate": 5.409175389302726e-06,
      "loss": 0.3784456729888916,
      "memory(GiB)": 72.72,
      "step": 26815,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.5016323104188043,
      "grad_norm": 4.001642227172852,
      "learning_rate": 5.40763824817475e-06,
      "loss": 0.38546299934387207,
      "memory(GiB)": 72.72,
      "step": 26820,
      "token_acc": 0.4777777777777778,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.502098684824177,
      "grad_norm": 3.935690402984619,
      "learning_rate": 5.406101068261249e-06,
      "loss": 0.37939000129699707,
      "memory(GiB)": 72.72,
      "step": 26825,
      "token_acc": 0.9642857142857143,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.5025650592295494,
      "grad_norm": 3.6422641277313232,
      "learning_rate": 5.404563849708483e-06,
      "loss": 0.37174282073974607,
      "memory(GiB)": 72.72,
      "step": 26830,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.503031433634922,
      "grad_norm": 5.136044025421143,
      "learning_rate": 5.403026592662713e-06,
      "loss": 0.37535967826843264,
      "memory(GiB)": 72.72,
      "step": 26835,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.5034978080402945,
      "grad_norm": 3.976038932800293,
      "learning_rate": 5.401489297270205e-06,
      "loss": 0.3670384407043457,
      "memory(GiB)": 72.72,
      "step": 26840,
      "token_acc": 0.9203539823008849,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.5039641824456673,
      "grad_norm": 3.7709193229675293,
      "learning_rate": 5.399951963677226e-06,
      "loss": 0.3690935611724854,
      "memory(GiB)": 72.72,
      "step": 26845,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.50443055685104,
      "grad_norm": 5.13720703125,
      "learning_rate": 5.3984145920300505e-06,
      "loss": 0.35723400115966797,
      "memory(GiB)": 72.72,
      "step": 26850,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.504896931256413,
      "grad_norm": 2.507704257965088,
      "learning_rate": 5.396877182474953e-06,
      "loss": 0.3601247310638428,
      "memory(GiB)": 72.72,
      "step": 26855,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.5053633056617852,
      "grad_norm": 7.596055030822754,
      "learning_rate": 5.3953397351582135e-06,
      "loss": 0.3809858560562134,
      "memory(GiB)": 72.72,
      "step": 26860,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.505829680067158,
      "grad_norm": 3.5323574542999268,
      "learning_rate": 5.393802250226117e-06,
      "loss": 0.3677567720413208,
      "memory(GiB)": 72.72,
      "step": 26865,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.5062960544725303,
      "grad_norm": 3.503754138946533,
      "learning_rate": 5.392264727824952e-06,
      "loss": 0.3559291362762451,
      "memory(GiB)": 72.72,
      "step": 26870,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.506762428877903,
      "grad_norm": 3.04081130027771,
      "learning_rate": 5.390727168101003e-06,
      "loss": 0.34519176483154296,
      "memory(GiB)": 72.72,
      "step": 26875,
      "token_acc": 0.43283582089552236,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.507228803283276,
      "grad_norm": 6.736630916595459,
      "learning_rate": 5.389189571200569e-06,
      "loss": 0.3248758792877197,
      "memory(GiB)": 72.72,
      "step": 26880,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.5076951776886487,
      "grad_norm": 6.351902961730957,
      "learning_rate": 5.3876519372699466e-06,
      "loss": 0.3565832614898682,
      "memory(GiB)": 72.72,
      "step": 26885,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.508161552094021,
      "grad_norm": 8.11312198638916,
      "learning_rate": 5.386114266455437e-06,
      "loss": 0.35733304023742674,
      "memory(GiB)": 72.72,
      "step": 26890,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.508627926499394,
      "grad_norm": 11.216914176940918,
      "learning_rate": 5.384576558903344e-06,
      "loss": 0.37385215759277346,
      "memory(GiB)": 72.72,
      "step": 26895,
      "token_acc": 0.6515151515151515,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.509094300904766,
      "grad_norm": 3.6203341484069824,
      "learning_rate": 5.383038814759975e-06,
      "loss": 0.3341132402420044,
      "memory(GiB)": 72.72,
      "step": 26900,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.509560675310139,
      "grad_norm": 5.071950912475586,
      "learning_rate": 5.381501034171643e-06,
      "loss": 0.32968523502349856,
      "memory(GiB)": 72.72,
      "step": 26905,
      "token_acc": 0.7317073170731707,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.5100270497155117,
      "grad_norm": 4.430066108703613,
      "learning_rate": 5.379963217284662e-06,
      "loss": 0.3666216850280762,
      "memory(GiB)": 72.72,
      "step": 26910,
      "token_acc": 0.8260869565217391,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.5104934241208845,
      "grad_norm": 3.578997850418091,
      "learning_rate": 5.378425364245354e-06,
      "loss": 0.37996063232421873,
      "memory(GiB)": 72.72,
      "step": 26915,
      "token_acc": 0.5370370370370371,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.510959798526257,
      "grad_norm": 3.877894878387451,
      "learning_rate": 5.376887475200039e-06,
      "loss": 0.310977578163147,
      "memory(GiB)": 72.72,
      "step": 26920,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.5114261729316296,
      "grad_norm": 3.10722017288208,
      "learning_rate": 5.375349550295038e-06,
      "loss": 0.32146825790405276,
      "memory(GiB)": 72.72,
      "step": 26925,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.511892547337002,
      "grad_norm": 5.509044170379639,
      "learning_rate": 5.373811589676685e-06,
      "loss": 0.36360836029052734,
      "memory(GiB)": 72.72,
      "step": 26930,
      "token_acc": 0.6818181818181818,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.5123589217423747,
      "grad_norm": 4.188267707824707,
      "learning_rate": 5.372273593491312e-06,
      "loss": 0.36164867877960205,
      "memory(GiB)": 72.72,
      "step": 26935,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.5128252961477475,
      "grad_norm": 3.7255911827087402,
      "learning_rate": 5.3707355618852534e-06,
      "loss": 0.36474266052246096,
      "memory(GiB)": 72.72,
      "step": 26940,
      "token_acc": 0.96875,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.5132916705531203,
      "grad_norm": 7.597148418426514,
      "learning_rate": 5.369197495004847e-06,
      "loss": 0.3675715684890747,
      "memory(GiB)": 72.72,
      "step": 26945,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.5137580449584926,
      "grad_norm": 3.7874464988708496,
      "learning_rate": 5.367659392996436e-06,
      "loss": 0.37677512168884275,
      "memory(GiB)": 72.72,
      "step": 26950,
      "token_acc": 0.5211267605633803,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 2.5142244193638654,
      "grad_norm": 3.6947991847991943,
      "learning_rate": 5.366121256006368e-06,
      "loss": 0.3708821773529053,
      "memory(GiB)": 72.72,
      "step": 26955,
      "token_acc": 0.52,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 2.5146907937692378,
      "grad_norm": 3.7839770317077637,
      "learning_rate": 5.3645830841809875e-06,
      "loss": 0.37976274490356443,
      "memory(GiB)": 72.72,
      "step": 26960,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 2.5151571681746105,
      "grad_norm": 3.005706310272217,
      "learning_rate": 5.363044877666652e-06,
      "loss": 0.3396642208099365,
      "memory(GiB)": 72.72,
      "step": 26965,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 2.5156235425799833,
      "grad_norm": 3.127312421798706,
      "learning_rate": 5.361506636609716e-06,
      "loss": 0.356510853767395,
      "memory(GiB)": 72.72,
      "step": 26970,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 2.516089916985356,
      "grad_norm": 4.455442428588867,
      "learning_rate": 5.3599683611565345e-06,
      "loss": 0.31426224708557127,
      "memory(GiB)": 72.72,
      "step": 26975,
      "token_acc": 0.3541666666666667,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.5165562913907285,
      "grad_norm": 3.4385006427764893,
      "learning_rate": 5.3584300514534736e-06,
      "loss": 0.37288286685943606,
      "memory(GiB)": 72.72,
      "step": 26980,
      "token_acc": 0.5673076923076923,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 2.5170226657961012,
      "grad_norm": 3.030277729034424,
      "learning_rate": 5.356891707646898e-06,
      "loss": 0.3915034055709839,
      "memory(GiB)": 72.72,
      "step": 26985,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.5174890402014736,
      "grad_norm": 2.8947293758392334,
      "learning_rate": 5.355353329883174e-06,
      "loss": 0.3434908390045166,
      "memory(GiB)": 72.72,
      "step": 26990,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 2.5179554146068464,
      "grad_norm": 8.405805587768555,
      "learning_rate": 5.353814918308676e-06,
      "loss": 0.353134822845459,
      "memory(GiB)": 72.72,
      "step": 26995,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.518421789012219,
      "grad_norm": 2.9475386142730713,
      "learning_rate": 5.3522764730697795e-06,
      "loss": 0.3271827220916748,
      "memory(GiB)": 72.72,
      "step": 27000,
      "token_acc": 0.9120879120879121,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.518888163417592,
      "grad_norm": 2.4472696781158447,
      "learning_rate": 5.350737994312862e-06,
      "loss": 0.3527217864990234,
      "memory(GiB)": 72.72,
      "step": 27005,
      "token_acc": 0.76,
      "train_speed(iter/s)": 0.251223
    },
    {
      "epoch": 2.5193545378229643,
      "grad_norm": 3.737199068069458,
      "learning_rate": 5.349199482184303e-06,
      "loss": 0.372542142868042,
      "memory(GiB)": 72.72,
      "step": 27010,
      "token_acc": 0.5043478260869565,
      "train_speed(iter/s)": 0.251221
    },
    {
      "epoch": 2.519820912228337,
      "grad_norm": 2.5297768115997314,
      "learning_rate": 5.34766093683049e-06,
      "loss": 0.358621883392334,
      "memory(GiB)": 72.72,
      "step": 27015,
      "train_speed(iter/s)": 0.251224
    },
    {
      "epoch": 2.5202872866337094,
      "grad_norm": 2.9530560970306396,
      "learning_rate": 5.34612235839781e-06,
      "loss": 0.3618112564086914,
      "memory(GiB)": 72.72,
      "step": 27020,
      "train_speed(iter/s)": 0.251223
    },
    {
      "epoch": 2.520753661039082,
      "grad_norm": 3.4375545978546143,
      "learning_rate": 5.344583747032655e-06,
      "loss": 0.37006535530090334,
      "memory(GiB)": 72.72,
      "step": 27025,
      "train_speed(iter/s)": 0.251223
    },
    {
      "epoch": 2.521220035444455,
      "grad_norm": 3.895556688308716,
      "learning_rate": 5.3430451028814155e-06,
      "loss": 0.3925835847854614,
      "memory(GiB)": 72.72,
      "step": 27030,
      "token_acc": 0.5862068965517241,
      "train_speed(iter/s)": 0.251223
    },
    {
      "epoch": 2.5216864098498273,
      "grad_norm": 2.8651504516601562,
      "learning_rate": 5.341506426090493e-06,
      "loss": 0.3653378486633301,
      "memory(GiB)": 72.72,
      "step": 27035,
      "token_acc": 0.631578947368421,
      "train_speed(iter/s)": 0.251222
    },
    {
      "epoch": 2.5221527842552,
      "grad_norm": 3.4354424476623535,
      "learning_rate": 5.339967716806285e-06,
      "loss": 0.3715400695800781,
      "memory(GiB)": 72.72,
      "step": 27040,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.251221
    },
    {
      "epoch": 2.522619158660573,
      "grad_norm": 4.177384376525879,
      "learning_rate": 5.338428975175197e-06,
      "loss": 0.35105228424072266,
      "memory(GiB)": 72.72,
      "step": 27045,
      "train_speed(iter/s)": 0.251222
    },
    {
      "epoch": 2.523085533065945,
      "grad_norm": 3.5041000843048096,
      "learning_rate": 5.3368902013436345e-06,
      "loss": 0.3297667741775513,
      "memory(GiB)": 72.72,
      "step": 27050,
      "token_acc": 0.47540983606557374,
      "train_speed(iter/s)": 0.251226
    },
    {
      "epoch": 2.523551907471318,
      "grad_norm": 3.204981803894043,
      "learning_rate": 5.335351395458006e-06,
      "loss": 0.3605639457702637,
      "memory(GiB)": 72.72,
      "step": 27055,
      "train_speed(iter/s)": 0.251222
    },
    {
      "epoch": 2.5240182818766908,
      "grad_norm": 5.291533946990967,
      "learning_rate": 5.333812557664726e-06,
      "loss": 0.36541223526000977,
      "memory(GiB)": 72.72,
      "step": 27060,
      "token_acc": 0.6181818181818182,
      "train_speed(iter/s)": 0.251225
    },
    {
      "epoch": 2.524484656282063,
      "grad_norm": 5.313027381896973,
      "learning_rate": 5.33227368811021e-06,
      "loss": 0.3676201820373535,
      "memory(GiB)": 72.72,
      "step": 27065,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.251225
    },
    {
      "epoch": 2.524951030687436,
      "grad_norm": 5.6290106773376465,
      "learning_rate": 5.330734786940877e-06,
      "loss": 0.3251523971557617,
      "memory(GiB)": 72.72,
      "step": 27070,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251225
    },
    {
      "epoch": 2.5254174050928087,
      "grad_norm": 4.689949035644531,
      "learning_rate": 5.3291958543031465e-06,
      "loss": 0.3526925086975098,
      "memory(GiB)": 72.72,
      "step": 27075,
      "train_speed(iter/s)": 0.251224
    },
    {
      "epoch": 2.525883779498181,
      "grad_norm": 4.974355697631836,
      "learning_rate": 5.327656890343443e-06,
      "loss": 0.3640429496765137,
      "memory(GiB)": 72.72,
      "step": 27080,
      "train_speed(iter/s)": 0.251227
    },
    {
      "epoch": 2.5263501539035538,
      "grad_norm": 3.1528615951538086,
      "learning_rate": 5.326117895208198e-06,
      "loss": 0.3535308361053467,
      "memory(GiB)": 72.72,
      "step": 27085,
      "train_speed(iter/s)": 0.251227
    },
    {
      "epoch": 2.5268165283089266,
      "grad_norm": 3.5482513904571533,
      "learning_rate": 5.324578869043839e-06,
      "loss": 0.34206175804138184,
      "memory(GiB)": 72.72,
      "step": 27090,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.527282902714299,
      "grad_norm": 4.273407459259033,
      "learning_rate": 5.323039811996802e-06,
      "loss": 0.3841505527496338,
      "memory(GiB)": 72.72,
      "step": 27095,
      "token_acc": 0.9012345679012346,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.5277492771196717,
      "grad_norm": 3.373281955718994,
      "learning_rate": 5.321500724213521e-06,
      "loss": 0.3260213851928711,
      "memory(GiB)": 72.72,
      "step": 27100,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.5282156515250445,
      "grad_norm": 3.2787976264953613,
      "learning_rate": 5.319961605840436e-06,
      "loss": 0.37164475917816164,
      "memory(GiB)": 72.72,
      "step": 27105,
      "train_speed(iter/s)": 0.251225
    },
    {
      "epoch": 2.528682025930417,
      "grad_norm": 3.210860013961792,
      "learning_rate": 5.318422457023991e-06,
      "loss": 0.36660423278808596,
      "memory(GiB)": 72.72,
      "step": 27110,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.5291484003357896,
      "grad_norm": 12.705860137939453,
      "learning_rate": 5.316883277910629e-06,
      "loss": 0.3208495616912842,
      "memory(GiB)": 72.72,
      "step": 27115,
      "train_speed(iter/s)": 0.251227
    },
    {
      "epoch": 2.5296147747411624,
      "grad_norm": 5.882896900177002,
      "learning_rate": 5.315344068646799e-06,
      "loss": 0.34535698890686034,
      "memory(GiB)": 72.72,
      "step": 27120,
      "train_speed(iter/s)": 0.25123
    },
    {
      "epoch": 2.5300811491465347,
      "grad_norm": 4.14792013168335,
      "learning_rate": 5.3138048293789535e-06,
      "loss": 0.363727331161499,
      "memory(GiB)": 72.72,
      "step": 27125,
      "token_acc": 0.5178571428571429,
      "train_speed(iter/s)": 0.251233
    },
    {
      "epoch": 2.5305475235519075,
      "grad_norm": 3.899608612060547,
      "learning_rate": 5.3122655602535444e-06,
      "loss": 0.36813840866088865,
      "memory(GiB)": 72.72,
      "step": 27130,
      "train_speed(iter/s)": 0.251234
    },
    {
      "epoch": 2.5310138979572803,
      "grad_norm": 3.6844091415405273,
      "learning_rate": 5.31072626141703e-06,
      "loss": 0.34308757781982424,
      "memory(GiB)": 72.72,
      "step": 27135,
      "token_acc": 0.4696969696969697,
      "train_speed(iter/s)": 0.251238
    },
    {
      "epoch": 2.5314802723626526,
      "grad_norm": 3.7079031467437744,
      "learning_rate": 5.309186933015868e-06,
      "loss": 0.3521381378173828,
      "memory(GiB)": 72.72,
      "step": 27140,
      "token_acc": 0.43902439024390244,
      "train_speed(iter/s)": 0.251238
    },
    {
      "epoch": 2.5319466467680254,
      "grad_norm": 16.2844181060791,
      "learning_rate": 5.307647575196523e-06,
      "loss": 0.37094113826751707,
      "memory(GiB)": 72.72,
      "step": 27145,
      "train_speed(iter/s)": 0.25123
    },
    {
      "epoch": 2.532413021173398,
      "grad_norm": 3.452350616455078,
      "learning_rate": 5.306108188105458e-06,
      "loss": 0.37749533653259276,
      "memory(GiB)": 72.72,
      "step": 27150,
      "token_acc": 0.49166666666666664,
      "train_speed(iter/s)": 0.251229
    },
    {
      "epoch": 2.5328793955787705,
      "grad_norm": 2.896265983581543,
      "learning_rate": 5.304568771889143e-06,
      "loss": 0.35964412689208985,
      "memory(GiB)": 72.72,
      "step": 27155,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251226
    },
    {
      "epoch": 2.5333457699841433,
      "grad_norm": 3.6058807373046875,
      "learning_rate": 5.303029326694046e-06,
      "loss": 0.35927705764770507,
      "memory(GiB)": 72.72,
      "step": 27160,
      "train_speed(iter/s)": 0.251227
    },
    {
      "epoch": 2.5338121443895156,
      "grad_norm": 3.161120653152466,
      "learning_rate": 5.301489852666643e-06,
      "loss": 0.36615695953369143,
      "memory(GiB)": 72.72,
      "step": 27165,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.5342785187948884,
      "grad_norm": 2.5969815254211426,
      "learning_rate": 5.299950349953409e-06,
      "loss": 0.3793602228164673,
      "memory(GiB)": 72.72,
      "step": 27170,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.534744893200261,
      "grad_norm": 3.964184522628784,
      "learning_rate": 5.298410818700823e-06,
      "loss": 0.34425690174102785,
      "memory(GiB)": 72.72,
      "step": 27175,
      "train_speed(iter/s)": 0.251229
    },
    {
      "epoch": 2.535211267605634,
      "grad_norm": 3.2492778301239014,
      "learning_rate": 5.296871259055367e-06,
      "loss": 0.37359418869018557,
      "memory(GiB)": 72.72,
      "step": 27180,
      "token_acc": 0.6382978723404256,
      "train_speed(iter/s)": 0.25123
    },
    {
      "epoch": 2.5356776420110063,
      "grad_norm": 3.0932810306549072,
      "learning_rate": 5.295331671163526e-06,
      "loss": 0.322402811050415,
      "memory(GiB)": 72.72,
      "step": 27185,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.536144016416379,
      "grad_norm": 2.964348077774048,
      "learning_rate": 5.293792055171786e-06,
      "loss": 0.36017560958862305,
      "memory(GiB)": 72.72,
      "step": 27190,
      "token_acc": 0.9404761904761905,
      "train_speed(iter/s)": 0.251224
    },
    {
      "epoch": 2.5366103908217514,
      "grad_norm": 2.2220804691314697,
      "learning_rate": 5.292252411226637e-06,
      "loss": 0.3180384635925293,
      "memory(GiB)": 72.72,
      "step": 27195,
      "token_acc": 0.9240506329113924,
      "train_speed(iter/s)": 0.251223
    },
    {
      "epoch": 2.537076765227124,
      "grad_norm": 3.2415964603424072,
      "learning_rate": 5.29071273947457e-06,
      "loss": 0.35776629447937014,
      "memory(GiB)": 72.72,
      "step": 27200,
      "train_speed(iter/s)": 0.25122
    },
    {
      "epoch": 2.537543139632497,
      "grad_norm": 2.4413340091705322,
      "learning_rate": 5.289173040062083e-06,
      "loss": 0.3867171764373779,
      "memory(GiB)": 72.72,
      "step": 27205,
      "token_acc": 0.6935483870967742,
      "train_speed(iter/s)": 0.251219
    },
    {
      "epoch": 2.53800951403787,
      "grad_norm": 3.557159423828125,
      "learning_rate": 5.287633313135672e-06,
      "loss": 0.3591611385345459,
      "memory(GiB)": 72.72,
      "step": 27210,
      "train_speed(iter/s)": 0.251219
    },
    {
      "epoch": 2.538475888443242,
      "grad_norm": 4.026412487030029,
      "learning_rate": 5.286093558841837e-06,
      "loss": 0.36096508502960206,
      "memory(GiB)": 72.72,
      "step": 27215,
      "train_speed(iter/s)": 0.25122
    },
    {
      "epoch": 2.538942262848615,
      "grad_norm": 3.4639627933502197,
      "learning_rate": 5.2845537773270815e-06,
      "loss": 0.3577666997909546,
      "memory(GiB)": 72.72,
      "step": 27220,
      "train_speed(iter/s)": 0.251219
    },
    {
      "epoch": 2.5394086372539872,
      "grad_norm": 3.435271739959717,
      "learning_rate": 5.2830139687379105e-06,
      "loss": 0.35070726871490476,
      "memory(GiB)": 72.72,
      "step": 27225,
      "train_speed(iter/s)": 0.251222
    },
    {
      "epoch": 2.53987501165936,
      "grad_norm": 2.925651788711548,
      "learning_rate": 5.281474133220831e-06,
      "loss": 0.3769673347473145,
      "memory(GiB)": 72.72,
      "step": 27230,
      "token_acc": 0.5945945945945946,
      "train_speed(iter/s)": 0.251221
    },
    {
      "epoch": 2.540341386064733,
      "grad_norm": 5.428627014160156,
      "learning_rate": 5.279934270922355e-06,
      "loss": 0.3797614574432373,
      "memory(GiB)": 72.72,
      "step": 27235,
      "train_speed(iter/s)": 0.25122
    },
    {
      "epoch": 2.5408077604701056,
      "grad_norm": 3.261014699935913,
      "learning_rate": 5.278394381988997e-06,
      "loss": 0.37334885597229006,
      "memory(GiB)": 72.72,
      "step": 27240,
      "train_speed(iter/s)": 0.251223
    },
    {
      "epoch": 2.541274134875478,
      "grad_norm": 2.815805673599243,
      "learning_rate": 5.2768544665672716e-06,
      "loss": 0.377885627746582,
      "memory(GiB)": 72.72,
      "step": 27245,
      "token_acc": 0.6904761904761905,
      "train_speed(iter/s)": 0.251223
    },
    {
      "epoch": 2.5417405092808507,
      "grad_norm": 9.793866157531738,
      "learning_rate": 5.275314524803694e-06,
      "loss": 0.3690223693847656,
      "memory(GiB)": 72.72,
      "step": 27250,
      "token_acc": 0.9157894736842105,
      "train_speed(iter/s)": 0.251227
    },
    {
      "epoch": 2.542206883686223,
      "grad_norm": 2.438011646270752,
      "learning_rate": 5.27377455684479e-06,
      "loss": 0.3762176036834717,
      "memory(GiB)": 72.72,
      "step": 27255,
      "token_acc": 0.5172413793103449,
      "train_speed(iter/s)": 0.251231
    },
    {
      "epoch": 2.542673258091596,
      "grad_norm": 2.6454081535339355,
      "learning_rate": 5.2722345628370785e-06,
      "loss": 0.3734732151031494,
      "memory(GiB)": 72.72,
      "step": 27260,
      "token_acc": 0.9438202247191011,
      "train_speed(iter/s)": 0.25123
    },
    {
      "epoch": 2.5431396324969686,
      "grad_norm": 3.0569279193878174,
      "learning_rate": 5.270694542927089e-06,
      "loss": 0.3881413221359253,
      "memory(GiB)": 72.72,
      "step": 27265,
      "train_speed(iter/s)": 0.251227
    },
    {
      "epoch": 2.5436060069023414,
      "grad_norm": 3.0916733741760254,
      "learning_rate": 5.269154497261346e-06,
      "loss": 0.34912109375,
      "memory(GiB)": 72.72,
      "step": 27270,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.5440723813077137,
      "grad_norm": 5.439239978790283,
      "learning_rate": 5.267614425986383e-06,
      "loss": 0.3687638282775879,
      "memory(GiB)": 72.72,
      "step": 27275,
      "train_speed(iter/s)": 0.251229
    },
    {
      "epoch": 2.5445387557130865,
      "grad_norm": 3.0128557682037354,
      "learning_rate": 5.266074329248729e-06,
      "loss": 0.3588722705841064,
      "memory(GiB)": 72.72,
      "step": 27280,
      "token_acc": 0.6511627906976745,
      "train_speed(iter/s)": 0.251227
    },
    {
      "epoch": 2.545005130118459,
      "grad_norm": 5.2500529289245605,
      "learning_rate": 5.2645342071949246e-06,
      "loss": 0.36714982986450195,
      "memory(GiB)": 72.72,
      "step": 27285,
      "train_speed(iter/s)": 0.251228
    },
    {
      "epoch": 2.5454715045238316,
      "grad_norm": 3.796949863433838,
      "learning_rate": 5.262994059971505e-06,
      "loss": 0.3413818120956421,
      "memory(GiB)": 72.72,
      "step": 27290,
      "train_speed(iter/s)": 0.251231
    },
    {
      "epoch": 2.5459378789292044,
      "grad_norm": 5.426999092102051,
      "learning_rate": 5.261453887725012e-06,
      "loss": 0.3533756732940674,
      "memory(GiB)": 72.72,
      "step": 27295,
      "train_speed(iter/s)": 0.251233
    },
    {
      "epoch": 2.546404253334577,
      "grad_norm": 3.891389846801758,
      "learning_rate": 5.259913690601984e-06,
      "loss": 0.3647559642791748,
      "memory(GiB)": 72.72,
      "step": 27300,
      "train_speed(iter/s)": 0.251234
    },
    {
      "epoch": 2.5468706277399495,
      "grad_norm": 4.081057548522949,
      "learning_rate": 5.2583734687489705e-06,
      "loss": 0.39501826763153075,
      "memory(GiB)": 72.72,
      "step": 27305,
      "train_speed(iter/s)": 0.251236
    },
    {
      "epoch": 2.5473370021453223,
      "grad_norm": 4.352865219116211,
      "learning_rate": 5.2568332223125186e-06,
      "loss": 0.37546982765197756,
      "memory(GiB)": 72.72,
      "step": 27310,
      "token_acc": 0.5225225225225225,
      "train_speed(iter/s)": 0.251238
    },
    {
      "epoch": 2.5478033765506947,
      "grad_norm": 3.7628016471862793,
      "learning_rate": 5.2552929514391746e-06,
      "loss": 0.34567625522613527,
      "memory(GiB)": 72.72,
      "step": 27315,
      "train_speed(iter/s)": 0.251236
    },
    {
      "epoch": 2.5482697509560674,
      "grad_norm": 4.923162937164307,
      "learning_rate": 5.253752656275495e-06,
      "loss": 0.39849014282226564,
      "memory(GiB)": 72.72,
      "step": 27320,
      "train_speed(iter/s)": 0.251237
    },
    {
      "epoch": 2.5487361253614402,
      "grad_norm": 4.861449718475342,
      "learning_rate": 5.25221233696803e-06,
      "loss": 0.37220587730407717,
      "memory(GiB)": 72.72,
      "step": 27325,
      "train_speed(iter/s)": 0.251239
    },
    {
      "epoch": 2.549202499766813,
      "grad_norm": 2.8129427433013916,
      "learning_rate": 5.25067199366334e-06,
      "loss": 0.33966922760009766,
      "memory(GiB)": 72.72,
      "step": 27330,
      "token_acc": 0.4696969696969697,
      "train_speed(iter/s)": 0.251242
    },
    {
      "epoch": 2.5496688741721854,
      "grad_norm": 3.3143250942230225,
      "learning_rate": 5.24913162650798e-06,
      "loss": 0.37648730278015136,
      "memory(GiB)": 72.72,
      "step": 27335,
      "train_speed(iter/s)": 0.251241
    },
    {
      "epoch": 2.550135248577558,
      "grad_norm": 6.1428422927856445,
      "learning_rate": 5.247591235648515e-06,
      "loss": 0.33500237464904786,
      "memory(GiB)": 72.72,
      "step": 27340,
      "token_acc": 0.6938775510204082,
      "train_speed(iter/s)": 0.251243
    },
    {
      "epoch": 2.5506016229829305,
      "grad_norm": 2.6885547637939453,
      "learning_rate": 5.246050821231505e-06,
      "loss": 0.33437376022338866,
      "memory(GiB)": 72.72,
      "step": 27345,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251244
    },
    {
      "epoch": 2.5510679973883033,
      "grad_norm": 7.9755377769470215,
      "learning_rate": 5.244510383403517e-06,
      "loss": 0.3413811922073364,
      "memory(GiB)": 72.72,
      "step": 27350,
      "token_acc": 0.7945205479452054,
      "train_speed(iter/s)": 0.251245
    },
    {
      "epoch": 2.551534371793676,
      "grad_norm": 2.881969928741455,
      "learning_rate": 5.242969922311121e-06,
      "loss": 0.36453914642333984,
      "memory(GiB)": 72.72,
      "step": 27355,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251243
    },
    {
      "epoch": 2.552000746199049,
      "grad_norm": 3.4628071784973145,
      "learning_rate": 5.241429438100885e-06,
      "loss": 0.3823453426361084,
      "memory(GiB)": 72.72,
      "step": 27360,
      "token_acc": 0.6274509803921569,
      "train_speed(iter/s)": 0.251245
    },
    {
      "epoch": 2.552467120604421,
      "grad_norm": 3.8328440189361572,
      "learning_rate": 5.239888930919381e-06,
      "loss": 0.3635897159576416,
      "memory(GiB)": 72.72,
      "step": 27365,
      "token_acc": 0.6949152542372882,
      "train_speed(iter/s)": 0.251247
    },
    {
      "epoch": 2.552933495009794,
      "grad_norm": 3.1477816104888916,
      "learning_rate": 5.238348400913184e-06,
      "loss": 0.34523012638092043,
      "memory(GiB)": 72.72,
      "step": 27370,
      "train_speed(iter/s)": 0.251245
    },
    {
      "epoch": 2.5533998694151663,
      "grad_norm": 3.654942274093628,
      "learning_rate": 5.236807848228872e-06,
      "loss": 0.33745107650756834,
      "memory(GiB)": 72.72,
      "step": 27375,
      "train_speed(iter/s)": 0.251249
    },
    {
      "epoch": 2.553866243820539,
      "grad_norm": 2.9488139152526855,
      "learning_rate": 5.235267273013023e-06,
      "loss": 0.36736350059509276,
      "memory(GiB)": 72.72,
      "step": 27380,
      "token_acc": 0.5423728813559322,
      "train_speed(iter/s)": 0.251247
    },
    {
      "epoch": 2.554332618225912,
      "grad_norm": 2.2869951725006104,
      "learning_rate": 5.233726675412215e-06,
      "loss": 0.2971800327301025,
      "memory(GiB)": 72.72,
      "step": 27385,
      "train_speed(iter/s)": 0.251247
    },
    {
      "epoch": 2.5547989926312846,
      "grad_norm": 2.818462610244751,
      "learning_rate": 5.232186055573038e-06,
      "loss": 0.34698288440704345,
      "memory(GiB)": 72.72,
      "step": 27390,
      "token_acc": 0.948339483394834,
      "train_speed(iter/s)": 0.251244
    },
    {
      "epoch": 2.555265367036657,
      "grad_norm": 3.785033941268921,
      "learning_rate": 5.23064541364207e-06,
      "loss": 0.33568587303161623,
      "memory(GiB)": 72.72,
      "step": 27395,
      "train_speed(iter/s)": 0.251245
    },
    {
      "epoch": 2.5557317414420297,
      "grad_norm": 4.23923921585083,
      "learning_rate": 5.229104749765902e-06,
      "loss": 0.38145225048065184,
      "memory(GiB)": 72.72,
      "step": 27400,
      "token_acc": 0.46808510638297873,
      "train_speed(iter/s)": 0.251243
    },
    {
      "epoch": 2.556198115847402,
      "grad_norm": 5.828202247619629,
      "learning_rate": 5.227564064091123e-06,
      "loss": 0.3563809871673584,
      "memory(GiB)": 72.72,
      "step": 27405,
      "token_acc": 0.8734177215189873,
      "train_speed(iter/s)": 0.251243
    },
    {
      "epoch": 2.556664490252775,
      "grad_norm": 2.8317172527313232,
      "learning_rate": 5.2260233567643245e-06,
      "loss": 0.31259000301361084,
      "memory(GiB)": 72.72,
      "step": 27410,
      "train_speed(iter/s)": 0.251244
    },
    {
      "epoch": 2.5571308646581477,
      "grad_norm": 2.5535025596618652,
      "learning_rate": 5.224482627932101e-06,
      "loss": 0.3180056571960449,
      "memory(GiB)": 72.72,
      "step": 27415,
      "train_speed(iter/s)": 0.251244
    },
    {
      "epoch": 2.5575972390635204,
      "grad_norm": 2.8524951934814453,
      "learning_rate": 5.222941877741044e-06,
      "loss": 0.3936798334121704,
      "memory(GiB)": 72.72,
      "step": 27420,
      "train_speed(iter/s)": 0.251245
    },
    {
      "epoch": 2.5580636134688928,
      "grad_norm": 6.294812202453613,
      "learning_rate": 5.221401106337757e-06,
      "loss": 0.36203536987304685,
      "memory(GiB)": 72.72,
      "step": 27425,
      "train_speed(iter/s)": 0.251246
    },
    {
      "epoch": 2.5585299878742656,
      "grad_norm": 4.140127182006836,
      "learning_rate": 5.2198603138688365e-06,
      "loss": 0.3203533887863159,
      "memory(GiB)": 72.72,
      "step": 27430,
      "train_speed(iter/s)": 0.251246
    },
    {
      "epoch": 2.558996362279638,
      "grad_norm": 2.8249106407165527,
      "learning_rate": 5.2183195004808814e-06,
      "loss": 0.3859849214553833,
      "memory(GiB)": 72.72,
      "step": 27435,
      "token_acc": 0.7213114754098361,
      "train_speed(iter/s)": 0.251248
    },
    {
      "epoch": 2.5594627366850107,
      "grad_norm": 4.073904991149902,
      "learning_rate": 5.216778666320502e-06,
      "loss": 0.3688396215438843,
      "memory(GiB)": 72.72,
      "step": 27440,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.251253
    },
    {
      "epoch": 2.5599291110903835,
      "grad_norm": 3.5248186588287354,
      "learning_rate": 5.2152378115343e-06,
      "loss": 0.3626726150512695,
      "memory(GiB)": 72.72,
      "step": 27445,
      "train_speed(iter/s)": 0.251252
    },
    {
      "epoch": 2.5603954854957562,
      "grad_norm": 5.083754062652588,
      "learning_rate": 5.213696936268881e-06,
      "loss": 0.36497223377227783,
      "memory(GiB)": 72.72,
      "step": 27450,
      "train_speed(iter/s)": 0.251252
    },
    {
      "epoch": 2.5608618599011286,
      "grad_norm": 3.5281412601470947,
      "learning_rate": 5.212156040670858e-06,
      "loss": 0.34462857246398926,
      "memory(GiB)": 72.72,
      "step": 27455,
      "train_speed(iter/s)": 0.251253
    },
    {
      "epoch": 2.5613282343065014,
      "grad_norm": 3.3653039932250977,
      "learning_rate": 5.210615124886841e-06,
      "loss": 0.35939028263092043,
      "memory(GiB)": 72.72,
      "step": 27460,
      "token_acc": 0.9425287356321839,
      "train_speed(iter/s)": 0.251253
    },
    {
      "epoch": 2.5617946087118737,
      "grad_norm": 8.368986129760742,
      "learning_rate": 5.2090741890634446e-06,
      "loss": 0.4107199668884277,
      "memory(GiB)": 72.72,
      "step": 27465,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251255
    },
    {
      "epoch": 2.5622609831172465,
      "grad_norm": 37.766265869140625,
      "learning_rate": 5.207533233347283e-06,
      "loss": 0.3588909149169922,
      "memory(GiB)": 72.72,
      "step": 27470,
      "train_speed(iter/s)": 0.251256
    },
    {
      "epoch": 2.5627273575226193,
      "grad_norm": 9.054694175720215,
      "learning_rate": 5.205992257884973e-06,
      "loss": 0.3478551864624023,
      "memory(GiB)": 72.72,
      "step": 27475,
      "token_acc": 0.7083333333333334,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.563193731927992,
      "grad_norm": 5.827840805053711,
      "learning_rate": 5.204451262823135e-06,
      "loss": 0.3667425632476807,
      "memory(GiB)": 72.72,
      "step": 27480,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.5636601063333644,
      "grad_norm": 5.231960296630859,
      "learning_rate": 5.2029102483083874e-06,
      "loss": 0.334291672706604,
      "memory(GiB)": 72.72,
      "step": 27485,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.564126480738737,
      "grad_norm": 3.8858418464660645,
      "learning_rate": 5.2013692144873576e-06,
      "loss": 0.3405157089233398,
      "memory(GiB)": 72.72,
      "step": 27490,
      "token_acc": 0.7535211267605634,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.5645928551441095,
      "grad_norm": 3.700580596923828,
      "learning_rate": 5.199828161506665e-06,
      "loss": 0.34490351676940917,
      "memory(GiB)": 72.72,
      "step": 27495,
      "train_speed(iter/s)": 0.251256
    },
    {
      "epoch": 2.5650592295494823,
      "grad_norm": 3.845548629760742,
      "learning_rate": 5.1982870895129385e-06,
      "loss": 0.32698979377746584,
      "memory(GiB)": 72.72,
      "step": 27500,
      "train_speed(iter/s)": 0.251257
    },
    {
      "epoch": 2.565525603954855,
      "grad_norm": 2.702523708343506,
      "learning_rate": 5.1967459986528065e-06,
      "loss": 0.33763506412506106,
      "memory(GiB)": 72.72,
      "step": 27505,
      "train_speed(iter/s)": 0.251257
    },
    {
      "epoch": 2.565991978360228,
      "grad_norm": 8.118956565856934,
      "learning_rate": 5.195204889072899e-06,
      "loss": 0.37338719367980955,
      "memory(GiB)": 72.72,
      "step": 27510,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.5664583527656,
      "grad_norm": 14.05575180053711,
      "learning_rate": 5.193663760919848e-06,
      "loss": 0.36255741119384766,
      "memory(GiB)": 72.72,
      "step": 27515,
      "train_speed(iter/s)": 0.251257
    },
    {
      "epoch": 2.566924727170973,
      "grad_norm": 4.644525051116943,
      "learning_rate": 5.192122614340287e-06,
      "loss": 0.3535335540771484,
      "memory(GiB)": 72.72,
      "step": 27520,
      "train_speed(iter/s)": 0.251256
    },
    {
      "epoch": 2.5673911015763453,
      "grad_norm": 3.728425979614258,
      "learning_rate": 5.190581449480851e-06,
      "loss": 0.37038936614990237,
      "memory(GiB)": 72.72,
      "step": 27525,
      "train_speed(iter/s)": 0.251257
    },
    {
      "epoch": 2.567857475981718,
      "grad_norm": 4.105545520782471,
      "learning_rate": 5.189040266488176e-06,
      "loss": 0.31522645950317385,
      "memory(GiB)": 72.72,
      "step": 27530,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.568323850387091,
      "grad_norm": 3.244204521179199,
      "learning_rate": 5.187499065508903e-06,
      "loss": 0.3511899471282959,
      "memory(GiB)": 72.72,
      "step": 27535,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.5687902247924637,
      "grad_norm": 3.911841869354248,
      "learning_rate": 5.185957846689672e-06,
      "loss": 0.3311484336853027,
      "memory(GiB)": 72.72,
      "step": 27540,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.569256599197836,
      "grad_norm": 3.523205041885376,
      "learning_rate": 5.184416610177125e-06,
      "loss": 0.36894443035125735,
      "memory(GiB)": 72.72,
      "step": 27545,
      "token_acc": 0.6615384615384615,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.569722973603209,
      "grad_norm": 3.3400208950042725,
      "learning_rate": 5.182875356117904e-06,
      "loss": 0.3332512378692627,
      "memory(GiB)": 72.72,
      "step": 27550,
      "token_acc": 0.5420560747663551,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.570189348008581,
      "grad_norm": 3.3573760986328125,
      "learning_rate": 5.1813340846586564e-06,
      "loss": 0.3413561820983887,
      "memory(GiB)": 72.72,
      "step": 27555,
      "token_acc": 0.6346153846153846,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.570655722413954,
      "grad_norm": 3.7242770195007324,
      "learning_rate": 5.17979279594603e-06,
      "loss": 0.3507404327392578,
      "memory(GiB)": 72.72,
      "step": 27560,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.5711220968193267,
      "grad_norm": 4.647815704345703,
      "learning_rate": 5.178251490126675e-06,
      "loss": 0.35676255226135256,
      "memory(GiB)": 72.72,
      "step": 27565,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.571588471224699,
      "grad_norm": 4.319308280944824,
      "learning_rate": 5.176710167347236e-06,
      "loss": 0.38813440799713134,
      "memory(GiB)": 72.72,
      "step": 27570,
      "token_acc": 0.9444444444444444,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.572054845630072,
      "grad_norm": 3.4461381435394287,
      "learning_rate": 5.175168827754371e-06,
      "loss": 0.34272644519805906,
      "memory(GiB)": 72.72,
      "step": 27575,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.5725212200354446,
      "grad_norm": 5.0230607986450195,
      "learning_rate": 5.173627471494731e-06,
      "loss": 0.35454626083374025,
      "memory(GiB)": 72.72,
      "step": 27580,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.572987594440817,
      "grad_norm": 5.013324737548828,
      "learning_rate": 5.172086098714972e-06,
      "loss": 0.33033313751220705,
      "memory(GiB)": 72.72,
      "step": 27585,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.5734539688461897,
      "grad_norm": 2.723104953765869,
      "learning_rate": 5.170544709561751e-06,
      "loss": 0.35878400802612304,
      "memory(GiB)": 72.72,
      "step": 27590,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.5739203432515625,
      "grad_norm": 3.290689706802368,
      "learning_rate": 5.169003304181727e-06,
      "loss": 0.3317599296569824,
      "memory(GiB)": 72.72,
      "step": 27595,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.574386717656935,
      "grad_norm": 3.8675057888031006,
      "learning_rate": 5.167461882721558e-06,
      "loss": 0.3404886722564697,
      "memory(GiB)": 72.72,
      "step": 27600,
      "token_acc": 0.5212765957446809,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.5748530920623076,
      "grad_norm": 6.27183723449707,
      "learning_rate": 5.165920445327906e-06,
      "loss": 0.3669186353683472,
      "memory(GiB)": 72.72,
      "step": 27605,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.5753194664676804,
      "grad_norm": 3.1955723762512207,
      "learning_rate": 5.164378992147437e-06,
      "loss": 0.3131136417388916,
      "memory(GiB)": 72.72,
      "step": 27610,
      "token_acc": 0.631578947368421,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.5757858408730527,
      "grad_norm": 10.380060195922852,
      "learning_rate": 5.162837523326814e-06,
      "loss": 0.32539966106414797,
      "memory(GiB)": 72.72,
      "step": 27615,
      "token_acc": 0.7735849056603774,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.5762522152784255,
      "grad_norm": 5.6890082359313965,
      "learning_rate": 5.1612960390127e-06,
      "loss": 0.3714164733886719,
      "memory(GiB)": 72.72,
      "step": 27620,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.5767185896837983,
      "grad_norm": 5.1225175857543945,
      "learning_rate": 5.159754539351765e-06,
      "loss": 0.3583188772201538,
      "memory(GiB)": 72.72,
      "step": 27625,
      "token_acc": 0.4793388429752066,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.5771849640891706,
      "grad_norm": 3.810513734817505,
      "learning_rate": 5.158213024490678e-06,
      "loss": 0.36475262641906736,
      "memory(GiB)": 72.72,
      "step": 27630,
      "token_acc": 0.8854961832061069,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.5776513384945434,
      "grad_norm": 3.612565517425537,
      "learning_rate": 5.15667149457611e-06,
      "loss": 0.3658111572265625,
      "memory(GiB)": 72.72,
      "step": 27635,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.578117712899916,
      "grad_norm": 5.699498176574707,
      "learning_rate": 5.15512994975473e-06,
      "loss": 0.3422654628753662,
      "memory(GiB)": 72.72,
      "step": 27640,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.5785840873052885,
      "grad_norm": 5.72313117980957,
      "learning_rate": 5.153588390173215e-06,
      "loss": 0.40180306434631347,
      "memory(GiB)": 72.72,
      "step": 27645,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.5790504617106613,
      "grad_norm": 4.590900421142578,
      "learning_rate": 5.1520468159782376e-06,
      "loss": 0.35130624771118163,
      "memory(GiB)": 72.72,
      "step": 27650,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.579516836116034,
      "grad_norm": 4.797340393066406,
      "learning_rate": 5.150505227316472e-06,
      "loss": 0.3803263664245605,
      "memory(GiB)": 72.72,
      "step": 27655,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.5799832105214064,
      "grad_norm": 3.2673897743225098,
      "learning_rate": 5.1489636243345995e-06,
      "loss": 0.3703291893005371,
      "memory(GiB)": 72.72,
      "step": 27660,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.5804495849267792,
      "grad_norm": 2.611320972442627,
      "learning_rate": 5.147422007179298e-06,
      "loss": 0.3284801244735718,
      "memory(GiB)": 72.72,
      "step": 27665,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.580915959332152,
      "grad_norm": 3.934575080871582,
      "learning_rate": 5.145880375997244e-06,
      "loss": 0.3212618827819824,
      "memory(GiB)": 72.72,
      "step": 27670,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.5813823337375243,
      "grad_norm": 4.538372039794922,
      "learning_rate": 5.144338730935123e-06,
      "loss": 0.33495163917541504,
      "memory(GiB)": 72.72,
      "step": 27675,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.581848708142897,
      "grad_norm": 4.836432933807373,
      "learning_rate": 5.142797072139617e-06,
      "loss": 0.36026849746704104,
      "memory(GiB)": 72.72,
      "step": 27680,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.58231508254827,
      "grad_norm": 4.194894790649414,
      "learning_rate": 5.141255399757409e-06,
      "loss": 0.3738051414489746,
      "memory(GiB)": 72.72,
      "step": 27685,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.5827814569536423,
      "grad_norm": 4.9250640869140625,
      "learning_rate": 5.139713713935185e-06,
      "loss": 0.3585636138916016,
      "memory(GiB)": 72.72,
      "step": 27690,
      "token_acc": 0.5043478260869565,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.583247831359015,
      "grad_norm": 4.995268821716309,
      "learning_rate": 5.138172014819631e-06,
      "loss": 0.35069732666015624,
      "memory(GiB)": 72.72,
      "step": 27695,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.583714205764388,
      "grad_norm": 4.122838973999023,
      "learning_rate": 5.136630302557436e-06,
      "loss": 0.3438581466674805,
      "memory(GiB)": 72.72,
      "step": 27700,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.58418058016976,
      "grad_norm": 6.022170543670654,
      "learning_rate": 5.135088577295287e-06,
      "loss": 0.3674268960952759,
      "memory(GiB)": 72.72,
      "step": 27705,
      "token_acc": 0.9354838709677419,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.584646954575133,
      "grad_norm": 2.942682981491089,
      "learning_rate": 5.133546839179878e-06,
      "loss": 0.3411713123321533,
      "memory(GiB)": 72.72,
      "step": 27710,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.5851133289805057,
      "grad_norm": 3.4812123775482178,
      "learning_rate": 5.1320050883579e-06,
      "loss": 0.34912848472595215,
      "memory(GiB)": 72.72,
      "step": 27715,
      "train_speed(iter/s)": 0.251277
    },
    {
      "epoch": 2.585579703385878,
      "grad_norm": 4.595036506652832,
      "learning_rate": 5.130463324976043e-06,
      "loss": 0.3355611801147461,
      "memory(GiB)": 72.72,
      "step": 27720,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 2.586046077791251,
      "grad_norm": 4.596334457397461,
      "learning_rate": 5.128921549181001e-06,
      "loss": 0.3387602806091309,
      "memory(GiB)": 72.72,
      "step": 27725,
      "token_acc": 0.9333333333333333,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 2.586512452196623,
      "grad_norm": 6.3678765296936035,
      "learning_rate": 5.127379761119471e-06,
      "loss": 0.40963263511657716,
      "memory(GiB)": 72.72,
      "step": 27730,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 2.586978826601996,
      "grad_norm": 11.204764366149902,
      "learning_rate": 5.1258379609381506e-06,
      "loss": 0.3772132873535156,
      "memory(GiB)": 72.72,
      "step": 27735,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 2.5874452010073687,
      "grad_norm": 5.4358439445495605,
      "learning_rate": 5.124296148783735e-06,
      "loss": 0.3364726066589355,
      "memory(GiB)": 72.72,
      "step": 27740,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 2.5879115754127415,
      "grad_norm": 3.025501012802124,
      "learning_rate": 5.122754324802924e-06,
      "loss": 0.36318149566650393,
      "memory(GiB)": 72.72,
      "step": 27745,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.588377949818114,
      "grad_norm": 5.573935031890869,
      "learning_rate": 5.121212489142418e-06,
      "loss": 0.3173773765563965,
      "memory(GiB)": 72.72,
      "step": 27750,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 2.5888443242234866,
      "grad_norm": 5.117720603942871,
      "learning_rate": 5.119670641948915e-06,
      "loss": 0.35187320709228515,
      "memory(GiB)": 72.72,
      "step": 27755,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 2.589310698628859,
      "grad_norm": 8.226658821105957,
      "learning_rate": 5.118128783369119e-06,
      "loss": 0.3199183940887451,
      "memory(GiB)": 72.72,
      "step": 27760,
      "token_acc": 0.9908256880733946,
      "train_speed(iter/s)": 0.25129
    },
    {
      "epoch": 2.5897770730342318,
      "grad_norm": 2.986253023147583,
      "learning_rate": 5.116586913549737e-06,
      "loss": 0.3462449312210083,
      "memory(GiB)": 72.72,
      "step": 27765,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 2.5902434474396046,
      "grad_norm": 4.775956153869629,
      "learning_rate": 5.115045032637467e-06,
      "loss": 0.350831127166748,
      "memory(GiB)": 72.72,
      "step": 27770,
      "token_acc": 0.6853146853146853,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.5907098218449773,
      "grad_norm": 3.485038995742798,
      "learning_rate": 5.113503140779015e-06,
      "loss": 0.3496320962905884,
      "memory(GiB)": 72.72,
      "step": 27775,
      "token_acc": 0.7818181818181819,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.5911761962503497,
      "grad_norm": 9.765310287475586,
      "learning_rate": 5.111961238121091e-06,
      "loss": 0.3694671392440796,
      "memory(GiB)": 72.72,
      "step": 27780,
      "token_acc": 0.9090909090909091,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 2.5916425706557225,
      "grad_norm": 15.385077476501465,
      "learning_rate": 5.110419324810398e-06,
      "loss": 0.35770440101623535,
      "memory(GiB)": 72.72,
      "step": 27785,
      "token_acc": 0.9102564102564102,
      "train_speed(iter/s)": 0.251292
    },
    {
      "epoch": 2.592108945061095,
      "grad_norm": 3.551022529602051,
      "learning_rate": 5.108877400993648e-06,
      "loss": 0.35175917148590086,
      "memory(GiB)": 72.72,
      "step": 27790,
      "token_acc": 0.9438202247191011,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.5925753194664676,
      "grad_norm": 4.681175231933594,
      "learning_rate": 5.107335466817548e-06,
      "loss": 0.3298440933227539,
      "memory(GiB)": 72.72,
      "step": 27795,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.5930416938718404,
      "grad_norm": 6.303700923919678,
      "learning_rate": 5.10579352242881e-06,
      "loss": 0.3593559503555298,
      "memory(GiB)": 72.72,
      "step": 27800,
      "token_acc": 0.6796116504854369,
      "train_speed(iter/s)": 0.251298
    },
    {
      "epoch": 2.593508068277213,
      "grad_norm": 3.7863898277282715,
      "learning_rate": 5.1042515679741435e-06,
      "loss": 0.352459716796875,
      "memory(GiB)": 72.72,
      "step": 27805,
      "token_acc": 0.9615384615384616,
      "train_speed(iter/s)": 0.251299
    },
    {
      "epoch": 2.5939744426825855,
      "grad_norm": 4.950374603271484,
      "learning_rate": 5.102709603600261e-06,
      "loss": 0.33620951175689695,
      "memory(GiB)": 72.72,
      "step": 27810,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.5944408170879583,
      "grad_norm": 3.908257484436035,
      "learning_rate": 5.101167629453877e-06,
      "loss": 0.3561567783355713,
      "memory(GiB)": 72.72,
      "step": 27815,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.5949071914933306,
      "grad_norm": 3.1715853214263916,
      "learning_rate": 5.099625645681705e-06,
      "loss": 0.346217679977417,
      "memory(GiB)": 72.72,
      "step": 27820,
      "token_acc": 0.5846153846153846,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 2.5953735658987034,
      "grad_norm": 4.174473762512207,
      "learning_rate": 5.098083652430458e-06,
      "loss": 0.3630736589431763,
      "memory(GiB)": 72.72,
      "step": 27825,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.595839940304076,
      "grad_norm": 5.285023212432861,
      "learning_rate": 5.096541649846854e-06,
      "loss": 0.3616217613220215,
      "memory(GiB)": 72.72,
      "step": 27830,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.596306314709449,
      "grad_norm": 5.784619331359863,
      "learning_rate": 5.094999638077611e-06,
      "loss": 0.3630536556243896,
      "memory(GiB)": 72.72,
      "step": 27835,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.5967726891148213,
      "grad_norm": 4.46017599105835,
      "learning_rate": 5.093457617269444e-06,
      "loss": 0.37318878173828124,
      "memory(GiB)": 72.72,
      "step": 27840,
      "token_acc": 0.9111111111111111,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.597239063520194,
      "grad_norm": 3.7364063262939453,
      "learning_rate": 5.0919155875690725e-06,
      "loss": 0.33537452220916747,
      "memory(GiB)": 72.72,
      "step": 27845,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.5977054379255664,
      "grad_norm": 3.126025438308716,
      "learning_rate": 5.090373549123216e-06,
      "loss": 0.3404244422912598,
      "memory(GiB)": 72.72,
      "step": 27850,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.598171812330939,
      "grad_norm": 3.7626254558563232,
      "learning_rate": 5.088831502078596e-06,
      "loss": 0.32221662998199463,
      "memory(GiB)": 72.72,
      "step": 27855,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.598638186736312,
      "grad_norm": 4.118236064910889,
      "learning_rate": 5.08728944658193e-06,
      "loss": 0.3349200010299683,
      "memory(GiB)": 72.72,
      "step": 27860,
      "token_acc": 0.6607142857142857,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.5991045611416848,
      "grad_norm": 8.385191917419434,
      "learning_rate": 5.085747382779945e-06,
      "loss": 0.3726224899291992,
      "memory(GiB)": 72.72,
      "step": 27865,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.599570935547057,
      "grad_norm": 3.366363286972046,
      "learning_rate": 5.084205310819359e-06,
      "loss": 0.3697225093841553,
      "memory(GiB)": 72.72,
      "step": 27870,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.60003730995243,
      "grad_norm": 5.163361549377441,
      "learning_rate": 5.082663230846896e-06,
      "loss": 0.36016838550567626,
      "memory(GiB)": 72.72,
      "step": 27875,
      "train_speed(iter/s)": 0.251292
    },
    {
      "epoch": 2.600503684357802,
      "grad_norm": 4.462796688079834,
      "learning_rate": 5.081121143009282e-06,
      "loss": 0.3462869644165039,
      "memory(GiB)": 72.72,
      "step": 27880,
      "token_acc": 0.9615384615384616,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.600970058763175,
      "grad_norm": 9.034547805786133,
      "learning_rate": 5.079579047453243e-06,
      "loss": 0.36495094299316405,
      "memory(GiB)": 72.72,
      "step": 27885,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.601436433168548,
      "grad_norm": 4.180849552154541,
      "learning_rate": 5.078036944325502e-06,
      "loss": 0.36453537940979003,
      "memory(GiB)": 72.72,
      "step": 27890,
      "token_acc": 0.7037037037037037,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 2.6019028075739206,
      "grad_norm": 3.478013038635254,
      "learning_rate": 5.0764948337727835e-06,
      "loss": 0.37122647762298583,
      "memory(GiB)": 72.72,
      "step": 27895,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 2.602369181979293,
      "grad_norm": 3.244189977645874,
      "learning_rate": 5.0749527159418195e-06,
      "loss": 0.32872681617736815,
      "memory(GiB)": 72.72,
      "step": 27900,
      "token_acc": 0.9666666666666667,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.6028355563846657,
      "grad_norm": 3.5496208667755127,
      "learning_rate": 5.073410590979335e-06,
      "loss": 0.33144166469573977,
      "memory(GiB)": 72.72,
      "step": 27905,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.603301930790038,
      "grad_norm": 4.739102363586426,
      "learning_rate": 5.071868459032059e-06,
      "loss": 0.3664799690246582,
      "memory(GiB)": 72.72,
      "step": 27910,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.603768305195411,
      "grad_norm": 6.444648265838623,
      "learning_rate": 5.070326320246721e-06,
      "loss": 0.3239551544189453,
      "memory(GiB)": 72.72,
      "step": 27915,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.6042346796007836,
      "grad_norm": 3.235306978225708,
      "learning_rate": 5.0687841747700496e-06,
      "loss": 0.3659056186676025,
      "memory(GiB)": 72.72,
      "step": 27920,
      "token_acc": 0.9206349206349206,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.6047010540061564,
      "grad_norm": 2.8750743865966797,
      "learning_rate": 5.067242022748775e-06,
      "loss": 0.3757073640823364,
      "memory(GiB)": 72.72,
      "step": 27925,
      "token_acc": 0.7027027027027027,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.6051674284115287,
      "grad_norm": 5.104614734649658,
      "learning_rate": 5.0656998643296305e-06,
      "loss": 0.374387788772583,
      "memory(GiB)": 72.72,
      "step": 27930,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.6056338028169015,
      "grad_norm": 6.761939525604248,
      "learning_rate": 5.064157699659345e-06,
      "loss": 0.3567039966583252,
      "memory(GiB)": 72.72,
      "step": 27935,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.606100177222274,
      "grad_norm": 4.463676929473877,
      "learning_rate": 5.062615528884655e-06,
      "loss": 0.36888091564178466,
      "memory(GiB)": 72.72,
      "step": 27940,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.6065665516276466,
      "grad_norm": 5.903026103973389,
      "learning_rate": 5.061073352152287e-06,
      "loss": 0.3429375171661377,
      "memory(GiB)": 72.72,
      "step": 27945,
      "token_acc": 0.6203703703703703,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.6070329260330194,
      "grad_norm": 3.180833101272583,
      "learning_rate": 5.059531169608979e-06,
      "loss": 0.33882551193237304,
      "memory(GiB)": 72.72,
      "step": 27950,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.607499300438392,
      "grad_norm": 3.93296217918396,
      "learning_rate": 5.057988981401463e-06,
      "loss": 0.3316348552703857,
      "memory(GiB)": 72.72,
      "step": 27955,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251312
    },
    {
      "epoch": 2.6079656748437645,
      "grad_norm": 2.910088062286377,
      "learning_rate": 5.056446787676475e-06,
      "loss": 0.3734561920166016,
      "memory(GiB)": 72.72,
      "step": 27960,
      "token_acc": 0.576271186440678,
      "train_speed(iter/s)": 0.251315
    },
    {
      "epoch": 2.6084320492491373,
      "grad_norm": 6.140575408935547,
      "learning_rate": 5.054904588580749e-06,
      "loss": 0.3719186544418335,
      "memory(GiB)": 72.72,
      "step": 27965,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.6088984236545096,
      "grad_norm": 3.1209206581115723,
      "learning_rate": 5.0533623842610205e-06,
      "loss": 0.300557804107666,
      "memory(GiB)": 72.72,
      "step": 27970,
      "token_acc": 0.7619047619047619,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 2.6093647980598824,
      "grad_norm": 3.718864917755127,
      "learning_rate": 5.051820174864025e-06,
      "loss": 0.2963711738586426,
      "memory(GiB)": 72.72,
      "step": 27975,
      "token_acc": 0.9305555555555556,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 2.609831172465255,
      "grad_norm": 3.314770221710205,
      "learning_rate": 5.050277960536499e-06,
      "loss": 0.40654425621032714,
      "memory(GiB)": 72.72,
      "step": 27980,
      "token_acc": 0.5046728971962616,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 2.610297546870628,
      "grad_norm": 2.9851839542388916,
      "learning_rate": 5.0487357414251805e-06,
      "loss": 0.34360513687133787,
      "memory(GiB)": 72.72,
      "step": 27985,
      "token_acc": 0.5604395604395604,
      "train_speed(iter/s)": 0.251318
    },
    {
      "epoch": 2.6107639212760003,
      "grad_norm": 2.8470702171325684,
      "learning_rate": 5.047193517676808e-06,
      "loss": 0.3815379858016968,
      "memory(GiB)": 72.72,
      "step": 27990,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.25132
    },
    {
      "epoch": 2.611230295681373,
      "grad_norm": 3.9397149085998535,
      "learning_rate": 5.045651289438115e-06,
      "loss": 0.34590873718261717,
      "memory(GiB)": 72.72,
      "step": 27995,
      "token_acc": 0.8620689655172413,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 2.6116966700867454,
      "grad_norm": 4.116610527038574,
      "learning_rate": 5.044109056855844e-06,
      "loss": 0.383345627784729,
      "memory(GiB)": 72.72,
      "step": 28000,
      "train_speed(iter/s)": 0.25132
    },
    {
      "epoch": 2.6121630444921182,
      "grad_norm": 3.499648332595825,
      "learning_rate": 5.042566820076732e-06,
      "loss": 0.3757671356201172,
      "memory(GiB)": 72.72,
      "step": 28005,
      "token_acc": 0.5617977528089888,
      "train_speed(iter/s)": 0.251256
    },
    {
      "epoch": 2.612629418897491,
      "grad_norm": 3.449284315109253,
      "learning_rate": 5.0410245792475174e-06,
      "loss": 0.3146329879760742,
      "memory(GiB)": 72.72,
      "step": 28010,
      "train_speed(iter/s)": 0.251255
    },
    {
      "epoch": 2.613095793302864,
      "grad_norm": 3.139633893966675,
      "learning_rate": 5.039482334514941e-06,
      "loss": 0.37613282203674314,
      "memory(GiB)": 72.72,
      "step": 28015,
      "token_acc": 0.611764705882353,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.613562167708236,
      "grad_norm": 5.439028739929199,
      "learning_rate": 5.037940086025742e-06,
      "loss": 0.3824112892150879,
      "memory(GiB)": 72.72,
      "step": 28020,
      "token_acc": 0.5692307692307692,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.614028542113609,
      "grad_norm": 3.69868540763855,
      "learning_rate": 5.0363978339266615e-06,
      "loss": 0.34669458866119385,
      "memory(GiB)": 72.72,
      "step": 28025,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.6144949165189812,
      "grad_norm": 2.288869619369507,
      "learning_rate": 5.034855578364437e-06,
      "loss": 0.36281046867370603,
      "memory(GiB)": 72.72,
      "step": 28030,
      "token_acc": 0.7380952380952381,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.614961290924354,
      "grad_norm": 5.524386882781982,
      "learning_rate": 5.033313319485814e-06,
      "loss": 0.35624032020568847,
      "memory(GiB)": 72.72,
      "step": 28035,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.615427665329727,
      "grad_norm": 3.565202236175537,
      "learning_rate": 5.031771057437531e-06,
      "loss": 0.36749184131622314,
      "memory(GiB)": 72.72,
      "step": 28040,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6158940397350996,
      "grad_norm": 4.8746724128723145,
      "learning_rate": 5.030228792366328e-06,
      "loss": 0.36585533618927,
      "memory(GiB)": 72.72,
      "step": 28045,
      "token_acc": 0.9292929292929293,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.616360414140472,
      "grad_norm": 3.2665531635284424,
      "learning_rate": 5.02868652441895e-06,
      "loss": 0.3296764850616455,
      "memory(GiB)": 72.72,
      "step": 28050,
      "token_acc": 0.7777777777777778,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6168267885458447,
      "grad_norm": 3.9867875576019287,
      "learning_rate": 5.027144253742138e-06,
      "loss": 0.3407605648040771,
      "memory(GiB)": 72.72,
      "step": 28055,
      "token_acc": 0.9479166666666666,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.617293162951217,
      "grad_norm": 3.1096251010894775,
      "learning_rate": 5.025601980482633e-06,
      "loss": 0.34210910797119143,
      "memory(GiB)": 72.72,
      "step": 28060,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.61775953735659,
      "grad_norm": 6.532179832458496,
      "learning_rate": 5.0240597047871785e-06,
      "loss": 0.3559743881225586,
      "memory(GiB)": 72.72,
      "step": 28065,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.6182259117619626,
      "grad_norm": 5.6167893409729,
      "learning_rate": 5.022517426802516e-06,
      "loss": 0.3440000295639038,
      "memory(GiB)": 72.72,
      "step": 28070,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.6186922861673354,
      "grad_norm": 3.4414544105529785,
      "learning_rate": 5.020975146675392e-06,
      "loss": 0.3621237277984619,
      "memory(GiB)": 72.72,
      "step": 28075,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.6191586605727077,
      "grad_norm": 3.724590539932251,
      "learning_rate": 5.019432864552546e-06,
      "loss": 0.3939627408981323,
      "memory(GiB)": 72.72,
      "step": 28080,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.6196250349780805,
      "grad_norm": 3.335655689239502,
      "learning_rate": 5.017890580580723e-06,
      "loss": 0.3684843063354492,
      "memory(GiB)": 72.72,
      "step": 28085,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.620091409383453,
      "grad_norm": 3.3551414012908936,
      "learning_rate": 5.016348294906668e-06,
      "loss": 0.3697450399398804,
      "memory(GiB)": 72.72,
      "step": 28090,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.6205577837888256,
      "grad_norm": 4.677495002746582,
      "learning_rate": 5.01480600767712e-06,
      "loss": 0.3338754177093506,
      "memory(GiB)": 72.72,
      "step": 28095,
      "token_acc": 0.9367088607594937,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.6210241581941984,
      "grad_norm": 2.6223886013031006,
      "learning_rate": 5.013263719038828e-06,
      "loss": 0.31158080101013186,
      "memory(GiB)": 72.72,
      "step": 28100,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.621490532599571,
      "grad_norm": 4.8108978271484375,
      "learning_rate": 5.011721429138534e-06,
      "loss": 0.37481255531311036,
      "memory(GiB)": 72.72,
      "step": 28105,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6219569070049435,
      "grad_norm": 6.36808443069458,
      "learning_rate": 5.010179138122982e-06,
      "loss": 0.3481929063796997,
      "memory(GiB)": 72.72,
      "step": 28110,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6224232814103163,
      "grad_norm": 15.727982521057129,
      "learning_rate": 5.008636846138916e-06,
      "loss": 0.3462106227874756,
      "memory(GiB)": 72.72,
      "step": 28115,
      "token_acc": 0.7021276595744681,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6228896558156887,
      "grad_norm": 3.4390408992767334,
      "learning_rate": 5.00709455333308e-06,
      "loss": 0.36914429664611814,
      "memory(GiB)": 72.72,
      "step": 28120,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6233560302210615,
      "grad_norm": 2.662102460861206,
      "learning_rate": 5.00555225985222e-06,
      "loss": 0.35782771110534667,
      "memory(GiB)": 72.72,
      "step": 28125,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6238224046264342,
      "grad_norm": 2.868180513381958,
      "learning_rate": 5.0040099658430785e-06,
      "loss": 0.33498897552490237,
      "memory(GiB)": 72.72,
      "step": 28130,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6242887790318066,
      "grad_norm": 3.1576974391937256,
      "learning_rate": 5.002467671452402e-06,
      "loss": 0.3541330575942993,
      "memory(GiB)": 72.72,
      "step": 28135,
      "token_acc": 0.5166666666666667,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6247551534371794,
      "grad_norm": 3.012065887451172,
      "learning_rate": 5.000925376826936e-06,
      "loss": 0.40776705741882324,
      "memory(GiB)": 72.72,
      "step": 28140,
      "token_acc": 0.989247311827957,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.625221527842552,
      "grad_norm": 3.731933116912842,
      "learning_rate": 4.999383082113421e-06,
      "loss": 0.34347000122070315,
      "memory(GiB)": 72.72,
      "step": 28145,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6256879022479245,
      "grad_norm": 2.5233187675476074,
      "learning_rate": 4.997840787458605e-06,
      "loss": 0.3535500764846802,
      "memory(GiB)": 72.72,
      "step": 28150,
      "token_acc": 0.6274509803921569,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6261542766532973,
      "grad_norm": 4.413775444030762,
      "learning_rate": 4.996298493009229e-06,
      "loss": 0.33069000244140623,
      "memory(GiB)": 72.72,
      "step": 28155,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.62662065105867,
      "grad_norm": 2.5067615509033203,
      "learning_rate": 4.9947561989120425e-06,
      "loss": 0.3324641466140747,
      "memory(GiB)": 72.72,
      "step": 28160,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6270870254640424,
      "grad_norm": 2.7137515544891357,
      "learning_rate": 4.993213905313787e-06,
      "loss": 0.3167571544647217,
      "memory(GiB)": 72.72,
      "step": 28165,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.627553399869415,
      "grad_norm": 2.69443678855896,
      "learning_rate": 4.991671612361208e-06,
      "loss": 0.36959936618804934,
      "memory(GiB)": 72.72,
      "step": 28170,
      "token_acc": 0.6415094339622641,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.628019774274788,
      "grad_norm": 3.566162347793579,
      "learning_rate": 4.990129320201048e-06,
      "loss": 0.34166076183319094,
      "memory(GiB)": 72.72,
      "step": 28175,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6284861486801603,
      "grad_norm": 10.459961891174316,
      "learning_rate": 4.9885870289800535e-06,
      "loss": 0.3380588531494141,
      "memory(GiB)": 72.72,
      "step": 28180,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.628952523085533,
      "grad_norm": 2.323625326156616,
      "learning_rate": 4.987044738844968e-06,
      "loss": 0.37006411552429197,
      "memory(GiB)": 72.72,
      "step": 28185,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.629418897490906,
      "grad_norm": 3.167013645172119,
      "learning_rate": 4.985502449942535e-06,
      "loss": 0.3775314807891846,
      "memory(GiB)": 72.72,
      "step": 28190,
      "token_acc": 0.5689655172413793,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.629885271896278,
      "grad_norm": 2.96920108795166,
      "learning_rate": 4.9839601624195e-06,
      "loss": 0.33514363765716554,
      "memory(GiB)": 72.72,
      "step": 28195,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.630351646301651,
      "grad_norm": 4.044088840484619,
      "learning_rate": 4.982417876422606e-06,
      "loss": 0.3558499336242676,
      "memory(GiB)": 72.72,
      "step": 28200,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6308180207070238,
      "grad_norm": 2.8214590549468994,
      "learning_rate": 4.980875592098598e-06,
      "loss": 0.3788822412490845,
      "memory(GiB)": 72.72,
      "step": 28205,
      "token_acc": 0.9803921568627451,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.631284395112396,
      "grad_norm": 2.799461603164673,
      "learning_rate": 4.979333309594217e-06,
      "loss": 0.331544828414917,
      "memory(GiB)": 72.72,
      "step": 28210,
      "token_acc": 0.8163265306122449,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.631750769517769,
      "grad_norm": 3.5567386150360107,
      "learning_rate": 4.9777910290562095e-06,
      "loss": 0.38236312866210936,
      "memory(GiB)": 72.72,
      "step": 28215,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6322171439231417,
      "grad_norm": 5.239508628845215,
      "learning_rate": 4.9762487506313164e-06,
      "loss": 0.37383108139038085,
      "memory(GiB)": 72.72,
      "step": 28220,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.632683518328514,
      "grad_norm": 3.5267038345336914,
      "learning_rate": 4.9747064744662785e-06,
      "loss": 0.3963192939758301,
      "memory(GiB)": 72.72,
      "step": 28225,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6331498927338868,
      "grad_norm": 2.525869131088257,
      "learning_rate": 4.973164200707845e-06,
      "loss": 0.34582903385162356,
      "memory(GiB)": 72.72,
      "step": 28230,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6336162671392596,
      "grad_norm": 3.5200247764587402,
      "learning_rate": 4.971621929502755e-06,
      "loss": 0.31633772850036623,
      "memory(GiB)": 72.72,
      "step": 28235,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.634082641544632,
      "grad_norm": 70.19467163085938,
      "learning_rate": 4.97007966099775e-06,
      "loss": 0.3621891975402832,
      "memory(GiB)": 72.72,
      "step": 28240,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6345490159500047,
      "grad_norm": 3.3920180797576904,
      "learning_rate": 4.968537395339574e-06,
      "loss": 0.34711883068084715,
      "memory(GiB)": 72.72,
      "step": 28245,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6350153903553775,
      "grad_norm": 3.6280691623687744,
      "learning_rate": 4.966995132674967e-06,
      "loss": 0.35357184410095216,
      "memory(GiB)": 72.72,
      "step": 28250,
      "token_acc": 0.9479166666666666,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.63548176476075,
      "grad_norm": 3.0785529613494873,
      "learning_rate": 4.965452873150672e-06,
      "loss": 0.3209641933441162,
      "memory(GiB)": 72.72,
      "step": 28255,
      "token_acc": 0.46551724137931033,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6359481391661226,
      "grad_norm": 7.178168296813965,
      "learning_rate": 4.96391061691343e-06,
      "loss": 0.3228419780731201,
      "memory(GiB)": 72.72,
      "step": 28260,
      "token_acc": 0.4714285714285714,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.636414513571495,
      "grad_norm": 3.5849852561950684,
      "learning_rate": 4.96236836410998e-06,
      "loss": 0.3540530204772949,
      "memory(GiB)": 72.72,
      "step": 28265,
      "token_acc": 0.5362318840579711,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6368808879768677,
      "grad_norm": 3.100587844848633,
      "learning_rate": 4.960826114887066e-06,
      "loss": 0.32871341705322266,
      "memory(GiB)": 72.72,
      "step": 28270,
      "token_acc": 0.5818181818181818,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6373472623822405,
      "grad_norm": 2.990591526031494,
      "learning_rate": 4.959283869391426e-06,
      "loss": 0.34475834369659425,
      "memory(GiB)": 72.72,
      "step": 28275,
      "token_acc": 0.6041666666666666,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6378136367876133,
      "grad_norm": 4.526302814483643,
      "learning_rate": 4.957741627769801e-06,
      "loss": 0.36248900890350344,
      "memory(GiB)": 72.72,
      "step": 28280,
      "token_acc": 0.7021276595744681,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6382800111929856,
      "grad_norm": 2.6063356399536133,
      "learning_rate": 4.956199390168929e-06,
      "loss": 0.3527212142944336,
      "memory(GiB)": 72.72,
      "step": 28285,
      "token_acc": 0.6052631578947368,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6387463855983584,
      "grad_norm": 3.409780263900757,
      "learning_rate": 4.954657156735549e-06,
      "loss": 0.3468358278274536,
      "memory(GiB)": 72.72,
      "step": 28290,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6392127600037307,
      "grad_norm": 2.6835098266601562,
      "learning_rate": 4.953114927616402e-06,
      "loss": 0.36539716720581056,
      "memory(GiB)": 72.72,
      "step": 28295,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6396791344091035,
      "grad_norm": 2.971437454223633,
      "learning_rate": 4.951572702958226e-06,
      "loss": 0.37862381935119627,
      "memory(GiB)": 72.72,
      "step": 28300,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6401455088144763,
      "grad_norm": 3.1345834732055664,
      "learning_rate": 4.950030482907757e-06,
      "loss": 0.3141034603118896,
      "memory(GiB)": 72.72,
      "step": 28305,
      "token_acc": 0.4673913043478261,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.640611883219849,
      "grad_norm": 3.487361192703247,
      "learning_rate": 4.948488267611735e-06,
      "loss": 0.3231735944747925,
      "memory(GiB)": 72.72,
      "step": 28310,
      "token_acc": 0.532258064516129,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6410782576252214,
      "grad_norm": 2.9919252395629883,
      "learning_rate": 4.946946057216895e-06,
      "loss": 0.3513899803161621,
      "memory(GiB)": 72.72,
      "step": 28315,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.641544632030594,
      "grad_norm": 4.174492835998535,
      "learning_rate": 4.945403851869975e-06,
      "loss": 0.36432838439941406,
      "memory(GiB)": 72.72,
      "step": 28320,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6420110064359665,
      "grad_norm": 4.063701152801514,
      "learning_rate": 4.943861651717707e-06,
      "loss": 0.35509064197540285,
      "memory(GiB)": 72.72,
      "step": 28325,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6424773808413393,
      "grad_norm": 5.007852077484131,
      "learning_rate": 4.942319456906832e-06,
      "loss": 0.31669325828552247,
      "memory(GiB)": 72.72,
      "step": 28330,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.642943755246712,
      "grad_norm": 5.0003461837768555,
      "learning_rate": 4.940777267584084e-06,
      "loss": 0.35421361923217776,
      "memory(GiB)": 72.72,
      "step": 28335,
      "token_acc": 0.8382352941176471,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.643410129652085,
      "grad_norm": 3.317754030227661,
      "learning_rate": 4.939235083896196e-06,
      "loss": 0.36605427265167234,
      "memory(GiB)": 72.72,
      "step": 28340,
      "token_acc": 0.9375,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.643876504057457,
      "grad_norm": 19.722469329833984,
      "learning_rate": 4.937692905989903e-06,
      "loss": 0.34516756534576415,
      "memory(GiB)": 72.72,
      "step": 28345,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.64434287846283,
      "grad_norm": 4.151440143585205,
      "learning_rate": 4.936150734011937e-06,
      "loss": 0.341182541847229,
      "memory(GiB)": 72.72,
      "step": 28350,
      "token_acc": 0.8523489932885906,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.6448092528682023,
      "grad_norm": 3.300103187561035,
      "learning_rate": 4.9346085681090325e-06,
      "loss": 0.3480972766876221,
      "memory(GiB)": 72.72,
      "step": 28355,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.645275627273575,
      "grad_norm": 2.851375102996826,
      "learning_rate": 4.93306640842792e-06,
      "loss": 0.36011548042297364,
      "memory(GiB)": 72.72,
      "step": 28360,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.645742001678948,
      "grad_norm": 3.5305707454681396,
      "learning_rate": 4.931524255115334e-06,
      "loss": 0.33865952491760254,
      "memory(GiB)": 72.72,
      "step": 28365,
      "token_acc": 0.9433962264150944,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.6462083760843207,
      "grad_norm": 2.9879283905029297,
      "learning_rate": 4.929982108318004e-06,
      "loss": 0.36852593421936036,
      "memory(GiB)": 72.72,
      "step": 28370,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.646674750489693,
      "grad_norm": 3.4584968090057373,
      "learning_rate": 4.92843996818266e-06,
      "loss": 0.3332176923751831,
      "memory(GiB)": 72.72,
      "step": 28375,
      "token_acc": 0.8866666666666667,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.647141124895066,
      "grad_norm": 4.640471458435059,
      "learning_rate": 4.926897834856033e-06,
      "loss": 0.37147057056427,
      "memory(GiB)": 72.72,
      "step": 28380,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.647607499300438,
      "grad_norm": 2.567225933074951,
      "learning_rate": 4.925355708484853e-06,
      "loss": 0.3465023756027222,
      "memory(GiB)": 72.72,
      "step": 28385,
      "token_acc": 0.5147058823529411,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.648073873705811,
      "grad_norm": 2.3049516677856445,
      "learning_rate": 4.923813589215847e-06,
      "loss": 0.32541134357452395,
      "memory(GiB)": 72.72,
      "step": 28390,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6485402481111837,
      "grad_norm": 3.538160800933838,
      "learning_rate": 4.922271477195741e-06,
      "loss": 0.35231082439422606,
      "memory(GiB)": 72.72,
      "step": 28395,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.6490066225165565,
      "grad_norm": 3.367065191268921,
      "learning_rate": 4.9207293725712665e-06,
      "loss": 0.39086127281188965,
      "memory(GiB)": 72.72,
      "step": 28400,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.649472996921929,
      "grad_norm": 3.049984931945801,
      "learning_rate": 4.919187275489147e-06,
      "loss": 0.34406237602233886,
      "memory(GiB)": 72.72,
      "step": 28405,
      "token_acc": 0.9866666666666667,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6499393713273016,
      "grad_norm": 3.4917728900909424,
      "learning_rate": 4.917645186096111e-06,
      "loss": 0.33559794425964357,
      "memory(GiB)": 72.72,
      "step": 28410,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.650405745732674,
      "grad_norm": 3.9478185176849365,
      "learning_rate": 4.916103104538881e-06,
      "loss": 0.3808882236480713,
      "memory(GiB)": 72.72,
      "step": 28415,
      "token_acc": 0.4722222222222222,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6508721201380467,
      "grad_norm": 9.215660095214844,
      "learning_rate": 4.9145610309641825e-06,
      "loss": 0.36551318168640134,
      "memory(GiB)": 72.72,
      "step": 28420,
      "token_acc": 0.9285714285714286,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6513384945434195,
      "grad_norm": 3.403024911880493,
      "learning_rate": 4.913018965518736e-06,
      "loss": 0.32338454723358157,
      "memory(GiB)": 72.72,
      "step": 28425,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6518048689487923,
      "grad_norm": 3.7394988536834717,
      "learning_rate": 4.911476908349269e-06,
      "loss": 0.34866244792938234,
      "memory(GiB)": 72.72,
      "step": 28430,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.6522712433541646,
      "grad_norm": 3.3806731700897217,
      "learning_rate": 4.909934859602503e-06,
      "loss": 0.36930346488952637,
      "memory(GiB)": 72.72,
      "step": 28435,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.6527376177595374,
      "grad_norm": 2.5634870529174805,
      "learning_rate": 4.908392819425156e-06,
      "loss": 0.3545365333557129,
      "memory(GiB)": 72.72,
      "step": 28440,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.6532039921649098,
      "grad_norm": 6.947004318237305,
      "learning_rate": 4.9068507879639505e-06,
      "loss": 0.33481540679931643,
      "memory(GiB)": 72.72,
      "step": 28445,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6536703665702825,
      "grad_norm": 4.71972131729126,
      "learning_rate": 4.9053087653656055e-06,
      "loss": 0.3704623460769653,
      "memory(GiB)": 72.72,
      "step": 28450,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.6541367409756553,
      "grad_norm": 3.080613374710083,
      "learning_rate": 4.903766751776839e-06,
      "loss": 0.3065149784088135,
      "memory(GiB)": 72.72,
      "step": 28455,
      "token_acc": 0.5694444444444444,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.654603115381028,
      "grad_norm": 3.277480125427246,
      "learning_rate": 4.902224747344369e-06,
      "loss": 0.3776232719421387,
      "memory(GiB)": 72.72,
      "step": 28460,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6550694897864004,
      "grad_norm": 2.6014835834503174,
      "learning_rate": 4.900682752214916e-06,
      "loss": 0.33684477806091306,
      "memory(GiB)": 72.72,
      "step": 28465,
      "token_acc": 0.49019607843137253,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6555358641917732,
      "grad_norm": 3.2791335582733154,
      "learning_rate": 4.899140766535191e-06,
      "loss": 0.3479227304458618,
      "memory(GiB)": 72.72,
      "step": 28470,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6560022385971456,
      "grad_norm": 3.0796892642974854,
      "learning_rate": 4.897598790451912e-06,
      "loss": 0.31403517723083496,
      "memory(GiB)": 72.72,
      "step": 28475,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6564686130025184,
      "grad_norm": 2.6897716522216797,
      "learning_rate": 4.896056824111792e-06,
      "loss": 0.35478963851928713,
      "memory(GiB)": 72.72,
      "step": 28480,
      "token_acc": 0.5116279069767442,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.656934987407891,
      "grad_norm": 39.1817512512207,
      "learning_rate": 4.894514867661546e-06,
      "loss": 0.38525614738464353,
      "memory(GiB)": 72.72,
      "step": 28485,
      "token_acc": 0.8562091503267973,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.657401361813264,
      "grad_norm": 3.887849807739258,
      "learning_rate": 4.892972921247886e-06,
      "loss": 0.36157498359680174,
      "memory(GiB)": 72.72,
      "step": 28490,
      "token_acc": 0.4915254237288136,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6578677362186363,
      "grad_norm": 2.8841404914855957,
      "learning_rate": 4.891430985017519e-06,
      "loss": 0.3791168689727783,
      "memory(GiB)": 72.72,
      "step": 28495,
      "token_acc": 0.5964912280701754,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.658334110624009,
      "grad_norm": 2.8331260681152344,
      "learning_rate": 4.889889059117162e-06,
      "loss": 0.40005693435668943,
      "memory(GiB)": 72.72,
      "step": 28500,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.6588004850293814,
      "grad_norm": 3.043117046356201,
      "learning_rate": 4.888347143693522e-06,
      "loss": 0.3618258714675903,
      "memory(GiB)": 72.72,
      "step": 28505,
      "token_acc": 0.7862068965517242,
      "train_speed(iter/s)": 0.251258
    },
    {
      "epoch": 2.659266859434754,
      "grad_norm": 3.4955708980560303,
      "learning_rate": 4.886805238893308e-06,
      "loss": 0.3534481763839722,
      "memory(GiB)": 72.72,
      "step": 28510,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.659733233840127,
      "grad_norm": 3.373486042022705,
      "learning_rate": 4.885263344863226e-06,
      "loss": 0.3632262468338013,
      "memory(GiB)": 72.72,
      "step": 28515,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.6601996082454997,
      "grad_norm": 4.956743240356445,
      "learning_rate": 4.883721461749984e-06,
      "loss": 0.3466343879699707,
      "memory(GiB)": 72.72,
      "step": 28520,
      "token_acc": 0.9714285714285714,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.660665982650872,
      "grad_norm": 3.471749782562256,
      "learning_rate": 4.882179589700286e-06,
      "loss": 0.3152095556259155,
      "memory(GiB)": 72.72,
      "step": 28525,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.661132357056245,
      "grad_norm": 3.6055145263671875,
      "learning_rate": 4.880637728860836e-06,
      "loss": 0.3542806625366211,
      "memory(GiB)": 72.72,
      "step": 28530,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.661598731461617,
      "grad_norm": 8.632137298583984,
      "learning_rate": 4.8790958793783395e-06,
      "loss": 0.30912320613861083,
      "memory(GiB)": 72.72,
      "step": 28535,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.66206510586699,
      "grad_norm": 3.8345282077789307,
      "learning_rate": 4.877554041399497e-06,
      "loss": 0.3369431734085083,
      "memory(GiB)": 72.72,
      "step": 28540,
      "token_acc": 0.5252525252525253,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.6625314802723627,
      "grad_norm": 2.4910106658935547,
      "learning_rate": 4.876012215071011e-06,
      "loss": 0.3107755661010742,
      "memory(GiB)": 72.72,
      "step": 28545,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6629978546777355,
      "grad_norm": 2.99363112449646,
      "learning_rate": 4.874470400539581e-06,
      "loss": 0.36382412910461426,
      "memory(GiB)": 72.72,
      "step": 28550,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.663464229083108,
      "grad_norm": 3.1759450435638428,
      "learning_rate": 4.872928597951906e-06,
      "loss": 0.3198843240737915,
      "memory(GiB)": 72.72,
      "step": 28555,
      "token_acc": 0.7482014388489209,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6639306034884807,
      "grad_norm": 3.524963617324829,
      "learning_rate": 4.871386807454682e-06,
      "loss": 0.3460808753967285,
      "memory(GiB)": 72.72,
      "step": 28560,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.664396977893853,
      "grad_norm": 4.2201642990112305,
      "learning_rate": 4.869845029194607e-06,
      "loss": 0.3645210266113281,
      "memory(GiB)": 72.72,
      "step": 28565,
      "token_acc": 0.5370370370370371,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6648633522992258,
      "grad_norm": 2.2312378883361816,
      "learning_rate": 4.868303263318378e-06,
      "loss": 0.32022411823272706,
      "memory(GiB)": 72.72,
      "step": 28570,
      "token_acc": 0.5945945945945946,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6653297267045986,
      "grad_norm": 4.153147220611572,
      "learning_rate": 4.866761509972687e-06,
      "loss": 0.38546137809753417,
      "memory(GiB)": 72.72,
      "step": 28575,
      "token_acc": 0.7692307692307693,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6657961011099713,
      "grad_norm": 2.5794405937194824,
      "learning_rate": 4.865219769304228e-06,
      "loss": 0.3342101812362671,
      "memory(GiB)": 72.72,
      "step": 28580,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6662624755153437,
      "grad_norm": 3.852384328842163,
      "learning_rate": 4.863678041459692e-06,
      "loss": 0.35713944435119627,
      "memory(GiB)": 72.72,
      "step": 28585,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6667288499207165,
      "grad_norm": 2.9650509357452393,
      "learning_rate": 4.862136326585773e-06,
      "loss": 0.3885044097900391,
      "memory(GiB)": 72.72,
      "step": 28590,
      "token_acc": 0.6415094339622641,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.667195224326089,
      "grad_norm": 2.8523380756378174,
      "learning_rate": 4.8605946248291534e-06,
      "loss": 0.33987865447998045,
      "memory(GiB)": 72.72,
      "step": 28595,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6676615987314616,
      "grad_norm": 3.553227424621582,
      "learning_rate": 4.859052936336529e-06,
      "loss": 0.3121935844421387,
      "memory(GiB)": 72.72,
      "step": 28600,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6681279731368344,
      "grad_norm": 5.113133907318115,
      "learning_rate": 4.857511261254583e-06,
      "loss": 0.3414178371429443,
      "memory(GiB)": 72.72,
      "step": 28605,
      "token_acc": 0.5576923076923077,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.668594347542207,
      "grad_norm": 4.024399280548096,
      "learning_rate": 4.855969599730002e-06,
      "loss": 0.3603882074356079,
      "memory(GiB)": 72.72,
      "step": 28610,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.6690607219475795,
      "grad_norm": 2.706406593322754,
      "learning_rate": 4.854427951909469e-06,
      "loss": 0.3427037000656128,
      "memory(GiB)": 72.72,
      "step": 28615,
      "token_acc": 0.5609756097560976,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6695270963529523,
      "grad_norm": 7.39807653427124,
      "learning_rate": 4.852886317939669e-06,
      "loss": 0.3515156269073486,
      "memory(GiB)": 72.72,
      "step": 28620,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.6699934707583246,
      "grad_norm": 2.871155261993408,
      "learning_rate": 4.851344697967281e-06,
      "loss": 0.36675314903259276,
      "memory(GiB)": 72.72,
      "step": 28625,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.6704598451636974,
      "grad_norm": 2.5994627475738525,
      "learning_rate": 4.8498030921389874e-06,
      "loss": 0.34475982189178467,
      "memory(GiB)": 72.72,
      "step": 28630,
      "token_acc": 0.7258064516129032,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.67092621956907,
      "grad_norm": 3.9084115028381348,
      "learning_rate": 4.848261500601467e-06,
      "loss": 0.37254886627197265,
      "memory(GiB)": 72.72,
      "step": 28635,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.671392593974443,
      "grad_norm": 3.837507486343384,
      "learning_rate": 4.846719923501399e-06,
      "loss": 0.3336927890777588,
      "memory(GiB)": 72.72,
      "step": 28640,
      "token_acc": 0.9620253164556962,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6718589683798153,
      "grad_norm": 3.1578023433685303,
      "learning_rate": 4.845178360985457e-06,
      "loss": 0.34740524291992186,
      "memory(GiB)": 72.72,
      "step": 28645,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.672325342785188,
      "grad_norm": 3.7315773963928223,
      "learning_rate": 4.843636813200317e-06,
      "loss": 0.3478370666503906,
      "memory(GiB)": 72.72,
      "step": 28650,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.6727917171905604,
      "grad_norm": 2.626002311706543,
      "learning_rate": 4.842095280292652e-06,
      "loss": 0.3162530422210693,
      "memory(GiB)": 72.72,
      "step": 28655,
      "token_acc": 0.8787878787878788,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.673258091595933,
      "grad_norm": 5.304835319519043,
      "learning_rate": 4.840553762409135e-06,
      "loss": 0.32570533752441405,
      "memory(GiB)": 72.72,
      "step": 28660,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.673724466001306,
      "grad_norm": 4.087857723236084,
      "learning_rate": 4.839012259696436e-06,
      "loss": 0.35503125190734863,
      "memory(GiB)": 72.72,
      "step": 28665,
      "token_acc": 0.5730337078651685,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6741908404066783,
      "grad_norm": 3.613487720489502,
      "learning_rate": 4.8374707723012245e-06,
      "loss": 0.35208835601806643,
      "memory(GiB)": 72.72,
      "step": 28670,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.674657214812051,
      "grad_norm": 2.340452194213867,
      "learning_rate": 4.835929300370169e-06,
      "loss": 0.32132444381713865,
      "memory(GiB)": 72.72,
      "step": 28675,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.675123589217424,
      "grad_norm": 3.822610378265381,
      "learning_rate": 4.834387844049935e-06,
      "loss": 0.3615370035171509,
      "memory(GiB)": 72.72,
      "step": 28680,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.675589963622796,
      "grad_norm": 5.298736095428467,
      "learning_rate": 4.832846403487188e-06,
      "loss": 0.3387298583984375,
      "memory(GiB)": 72.72,
      "step": 28685,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.676056338028169,
      "grad_norm": 4.251531600952148,
      "learning_rate": 4.831304978828591e-06,
      "loss": 0.3469900131225586,
      "memory(GiB)": 72.72,
      "step": 28690,
      "token_acc": 0.5784313725490197,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.676522712433542,
      "grad_norm": 2.625537157058716,
      "learning_rate": 4.829763570220804e-06,
      "loss": 0.3635148525238037,
      "memory(GiB)": 72.72,
      "step": 28695,
      "token_acc": 0.5490196078431373,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.676989086838914,
      "grad_norm": 5.439349174499512,
      "learning_rate": 4.828222177810488e-06,
      "loss": 0.35399665832519533,
      "memory(GiB)": 72.72,
      "step": 28700,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.677455461244287,
      "grad_norm": 2.917536735534668,
      "learning_rate": 4.826680801744305e-06,
      "loss": 0.3257133007049561,
      "memory(GiB)": 72.72,
      "step": 28705,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.6779218356496597,
      "grad_norm": 3.112482786178589,
      "learning_rate": 4.82513944216891e-06,
      "loss": 0.3760094165802002,
      "memory(GiB)": 72.72,
      "step": 28710,
      "token_acc": 0.5128205128205128,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.678388210055032,
      "grad_norm": 5.78458309173584,
      "learning_rate": 4.823598099230957e-06,
      "loss": 0.31003775596618655,
      "memory(GiB)": 72.72,
      "step": 28715,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.678854584460405,
      "grad_norm": 3.3530807495117188,
      "learning_rate": 4.822056773077103e-06,
      "loss": 0.34270663261413575,
      "memory(GiB)": 72.72,
      "step": 28720,
      "token_acc": 0.6885245901639344,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.6793209588657776,
      "grad_norm": 3.4910905361175537,
      "learning_rate": 4.820515463853997e-06,
      "loss": 0.3541125774383545,
      "memory(GiB)": 72.72,
      "step": 28725,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.67978733327115,
      "grad_norm": 2.632760763168335,
      "learning_rate": 4.818974171708292e-06,
      "loss": 0.34357438087463377,
      "memory(GiB)": 72.72,
      "step": 28730,
      "token_acc": 0.7090909090909091,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.6802537076765227,
      "grad_norm": 4.5149688720703125,
      "learning_rate": 4.817432896786637e-06,
      "loss": 0.36423935890197756,
      "memory(GiB)": 72.72,
      "step": 28735,
      "token_acc": 0.6792452830188679,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.6807200820818955,
      "grad_norm": 1.8903436660766602,
      "learning_rate": 4.81589163923568e-06,
      "loss": 0.3487250328063965,
      "memory(GiB)": 72.72,
      "step": 28740,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251275
    },
    {
      "epoch": 2.681186456487268,
      "grad_norm": 3.70906662940979,
      "learning_rate": 4.814350399202066e-06,
      "loss": 0.3611703872680664,
      "memory(GiB)": 72.72,
      "step": 28745,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.6816528308926406,
      "grad_norm": 3.724912166595459,
      "learning_rate": 4.8128091768324396e-06,
      "loss": 0.30563380718231203,
      "memory(GiB)": 72.72,
      "step": 28750,
      "token_acc": 0.9295774647887324,
      "train_speed(iter/s)": 0.251277
    },
    {
      "epoch": 2.6821192052980134,
      "grad_norm": 5.358823299407959,
      "learning_rate": 4.811267972273444e-06,
      "loss": 0.3576495170593262,
      "memory(GiB)": 72.72,
      "step": 28755,
      "token_acc": 0.9666666666666667,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.6825855797033857,
      "grad_norm": 4.225455284118652,
      "learning_rate": 4.809726785671719e-06,
      "loss": 0.3851360082626343,
      "memory(GiB)": 72.72,
      "step": 28760,
      "token_acc": 0.475,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.6830519541087585,
      "grad_norm": 3.3559088706970215,
      "learning_rate": 4.8081856171739024e-06,
      "loss": 0.35540432929992677,
      "memory(GiB)": 72.72,
      "step": 28765,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.6835183285141313,
      "grad_norm": 2.7849035263061523,
      "learning_rate": 4.806644466926636e-06,
      "loss": 0.3310649871826172,
      "memory(GiB)": 72.72,
      "step": 28770,
      "token_acc": 0.6341463414634146,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.6839847029195036,
      "grad_norm": 3.2278621196746826,
      "learning_rate": 4.805103335076552e-06,
      "loss": 0.3431707382202148,
      "memory(GiB)": 72.72,
      "step": 28775,
      "token_acc": 0.5391304347826087,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.6844510773248764,
      "grad_norm": 3.42612624168396,
      "learning_rate": 4.803562221770285e-06,
      "loss": 0.3718018770217896,
      "memory(GiB)": 72.72,
      "step": 28780,
      "token_acc": 0.6779661016949152,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.684917451730249,
      "grad_norm": 5.126622676849365,
      "learning_rate": 4.802021127154469e-06,
      "loss": 0.3658599376678467,
      "memory(GiB)": 72.72,
      "step": 28785,
      "token_acc": 0.574468085106383,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6853838261356215,
      "grad_norm": 2.8914310932159424,
      "learning_rate": 4.800480051375732e-06,
      "loss": 0.30593719482421877,
      "memory(GiB)": 72.72,
      "step": 28790,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6858502005409943,
      "grad_norm": 5.143190383911133,
      "learning_rate": 4.7989389945807035e-06,
      "loss": 0.32868740558624265,
      "memory(GiB)": 72.72,
      "step": 28795,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.686316574946367,
      "grad_norm": 2.8756346702575684,
      "learning_rate": 4.7973979569160075e-06,
      "loss": 0.3217083215713501,
      "memory(GiB)": 72.72,
      "step": 28800,
      "token_acc": 0.6086956521739131,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6867829493517394,
      "grad_norm": 3.0476016998291016,
      "learning_rate": 4.795856938528275e-06,
      "loss": 0.36119871139526366,
      "memory(GiB)": 72.72,
      "step": 28805,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6872493237571122,
      "grad_norm": 2.4290339946746826,
      "learning_rate": 4.794315939564126e-06,
      "loss": 0.3229130744934082,
      "memory(GiB)": 72.72,
      "step": 28810,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.687715698162485,
      "grad_norm": 3.2852532863616943,
      "learning_rate": 4.7927749601701815e-06,
      "loss": 0.34540328979492185,
      "memory(GiB)": 72.72,
      "step": 28815,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6881820725678574,
      "grad_norm": 3.3827900886535645,
      "learning_rate": 4.79123400049306e-06,
      "loss": 0.33189101219177247,
      "memory(GiB)": 72.72,
      "step": 28820,
      "token_acc": 0.8435374149659864,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.68864844697323,
      "grad_norm": 5.0900654792785645,
      "learning_rate": 4.7896930606793804e-06,
      "loss": 0.31784934997558595,
      "memory(GiB)": 72.72,
      "step": 28825,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.6891148213786025,
      "grad_norm": 3.8847858905792236,
      "learning_rate": 4.788152140875759e-06,
      "loss": 0.34812374114990235,
      "memory(GiB)": 72.72,
      "step": 28830,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6895811957839753,
      "grad_norm": 2.9866719245910645,
      "learning_rate": 4.786611241228808e-06,
      "loss": 0.3085388422012329,
      "memory(GiB)": 72.72,
      "step": 28835,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.690047570189348,
      "grad_norm": 8.335684776306152,
      "learning_rate": 4.78507036188514e-06,
      "loss": 0.37935695648193357,
      "memory(GiB)": 72.72,
      "step": 28840,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.690513944594721,
      "grad_norm": 3.520237922668457,
      "learning_rate": 4.783529502991365e-06,
      "loss": 0.3673680782318115,
      "memory(GiB)": 72.72,
      "step": 28845,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.690980319000093,
      "grad_norm": 3.4807069301605225,
      "learning_rate": 4.7819886646940915e-06,
      "loss": 0.36903972625732423,
      "memory(GiB)": 72.72,
      "step": 28850,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.691446693405466,
      "grad_norm": 5.1457929611206055,
      "learning_rate": 4.780447847139925e-06,
      "loss": 0.3290992736816406,
      "memory(GiB)": 72.72,
      "step": 28855,
      "token_acc": 0.9879518072289156,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.6919130678108383,
      "grad_norm": 7.441924571990967,
      "learning_rate": 4.778907050475469e-06,
      "loss": 0.35058107376098635,
      "memory(GiB)": 72.72,
      "step": 28860,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.692379442216211,
      "grad_norm": 3.052260398864746,
      "learning_rate": 4.777366274847328e-06,
      "loss": 0.3296924114227295,
      "memory(GiB)": 72.72,
      "step": 28865,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.692845816621584,
      "grad_norm": 2.848439931869507,
      "learning_rate": 4.775825520402096e-06,
      "loss": 0.3707315444946289,
      "memory(GiB)": 72.72,
      "step": 28870,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.6933121910269566,
      "grad_norm": 2.8677194118499756,
      "learning_rate": 4.774284787286378e-06,
      "loss": 0.34185209274291994,
      "memory(GiB)": 72.72,
      "step": 28875,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.693778565432329,
      "grad_norm": 4.887576580047607,
      "learning_rate": 4.772744075646767e-06,
      "loss": 0.3687190294265747,
      "memory(GiB)": 72.72,
      "step": 28880,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6942449398377017,
      "grad_norm": 4.9458794593811035,
      "learning_rate": 4.771203385629858e-06,
      "loss": 0.3696089744567871,
      "memory(GiB)": 72.72,
      "step": 28885,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.694711314243074,
      "grad_norm": 6.096247673034668,
      "learning_rate": 4.769662717382241e-06,
      "loss": 0.34424452781677245,
      "memory(GiB)": 72.72,
      "step": 28890,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.695177688648447,
      "grad_norm": 3.550487995147705,
      "learning_rate": 4.768122071050506e-06,
      "loss": 0.3258349895477295,
      "memory(GiB)": 72.72,
      "step": 28895,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.6956440630538197,
      "grad_norm": 2.9683072566986084,
      "learning_rate": 4.7665814467812406e-06,
      "loss": 0.3311488628387451,
      "memory(GiB)": 72.72,
      "step": 28900,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6961104374591924,
      "grad_norm": 4.473496437072754,
      "learning_rate": 4.765040844721035e-06,
      "loss": 0.35422601699829104,
      "memory(GiB)": 72.72,
      "step": 28905,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.6965768118645648,
      "grad_norm": 5.575683116912842,
      "learning_rate": 4.763500265016467e-06,
      "loss": 0.3257183790206909,
      "memory(GiB)": 72.72,
      "step": 28910,
      "token_acc": 0.8235294117647058,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6970431862699376,
      "grad_norm": 3.279550552368164,
      "learning_rate": 4.761959707814121e-06,
      "loss": 0.324539041519165,
      "memory(GiB)": 72.72,
      "step": 28915,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.69750956067531,
      "grad_norm": 2.860412359237671,
      "learning_rate": 4.760419173260575e-06,
      "loss": 0.38524560928344725,
      "memory(GiB)": 72.72,
      "step": 28920,
      "token_acc": 0.5771812080536913,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.6979759350806827,
      "grad_norm": 3.7047266960144043,
      "learning_rate": 4.7588786615024064e-06,
      "loss": 0.37690072059631347,
      "memory(GiB)": 72.72,
      "step": 28925,
      "token_acc": 0.6129032258064516,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.6984423094860555,
      "grad_norm": 7.67147159576416,
      "learning_rate": 4.757338172686191e-06,
      "loss": 0.3479252576828003,
      "memory(GiB)": 72.72,
      "step": 28930,
      "token_acc": 0.954954954954955,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.6989086838914282,
      "grad_norm": 3.5946450233459473,
      "learning_rate": 4.7557977069585e-06,
      "loss": 0.36586856842041016,
      "memory(GiB)": 72.72,
      "step": 28935,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.6993750582968006,
      "grad_norm": 4.7031707763671875,
      "learning_rate": 4.754257264465906e-06,
      "loss": 0.3349276304244995,
      "memory(GiB)": 72.72,
      "step": 28940,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.6998414327021734,
      "grad_norm": 3.071720600128174,
      "learning_rate": 4.752716845354976e-06,
      "loss": 0.32791297435760497,
      "memory(GiB)": 72.72,
      "step": 28945,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.7003078071075457,
      "grad_norm": 4.526431560516357,
      "learning_rate": 4.7511764497722755e-06,
      "loss": 0.35101373195648194,
      "memory(GiB)": 72.72,
      "step": 28950,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.7007741815129185,
      "grad_norm": 3.324653387069702,
      "learning_rate": 4.7496360778643706e-06,
      "loss": 0.35979652404785156,
      "memory(GiB)": 72.72,
      "step": 28955,
      "token_acc": 0.8283582089552238,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7012405559182913,
      "grad_norm": 4.747137069702148,
      "learning_rate": 4.748095729777822e-06,
      "loss": 0.32268471717834474,
      "memory(GiB)": 72.72,
      "step": 28960,
      "token_acc": 0.7788461538461539,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.701706930323664,
      "grad_norm": 3.117583751678467,
      "learning_rate": 4.746555405659188e-06,
      "loss": 0.3834064483642578,
      "memory(GiB)": 72.72,
      "step": 28965,
      "token_acc": 0.6326530612244898,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.7021733047290364,
      "grad_norm": 2.976773738861084,
      "learning_rate": 4.7450151056550245e-06,
      "loss": 0.32358741760253906,
      "memory(GiB)": 72.72,
      "step": 28970,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.702639679134409,
      "grad_norm": 4.2724409103393555,
      "learning_rate": 4.743474829911889e-06,
      "loss": 0.3942937612533569,
      "memory(GiB)": 72.72,
      "step": 28975,
      "token_acc": 0.6595744680851063,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.7031060535397815,
      "grad_norm": 2.951286554336548,
      "learning_rate": 4.741934578576334e-06,
      "loss": 0.37899277210235593,
      "memory(GiB)": 72.72,
      "step": 28980,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.7035724279451543,
      "grad_norm": 3.506361722946167,
      "learning_rate": 4.740394351794911e-06,
      "loss": 0.3520380973815918,
      "memory(GiB)": 72.72,
      "step": 28985,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.704038802350527,
      "grad_norm": 3.278433084487915,
      "learning_rate": 4.738854149714163e-06,
      "loss": 0.36473560333251953,
      "memory(GiB)": 72.72,
      "step": 28990,
      "token_acc": 0.5851063829787234,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7045051767559,
      "grad_norm": 6.221900463104248,
      "learning_rate": 4.737313972480639e-06,
      "loss": 0.3518786907196045,
      "memory(GiB)": 72.72,
      "step": 28995,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.704971551161272,
      "grad_norm": 3.4697468280792236,
      "learning_rate": 4.735773820240882e-06,
      "loss": 0.3552470445632935,
      "memory(GiB)": 72.72,
      "step": 29000,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.705437925566645,
      "grad_norm": 2.8182482719421387,
      "learning_rate": 4.73423369314143e-06,
      "loss": 0.3201132774353027,
      "memory(GiB)": 72.72,
      "step": 29005,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.7059042999720173,
      "grad_norm": 2.950511932373047,
      "learning_rate": 4.732693591328824e-06,
      "loss": 0.35539519786834717,
      "memory(GiB)": 72.72,
      "step": 29010,
      "token_acc": 0.9222222222222223,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.70637067437739,
      "grad_norm": 4.753400802612305,
      "learning_rate": 4.7311535149496e-06,
      "loss": 0.3329742193222046,
      "memory(GiB)": 72.72,
      "step": 29015,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.706837048782763,
      "grad_norm": 4.236701965332031,
      "learning_rate": 4.729613464150291e-06,
      "loss": 0.3529062271118164,
      "memory(GiB)": 72.72,
      "step": 29020,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.7073034231881357,
      "grad_norm": 3.496657609939575,
      "learning_rate": 4.728073439077427e-06,
      "loss": 0.34985995292663574,
      "memory(GiB)": 72.72,
      "step": 29025,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.707769797593508,
      "grad_norm": 3.07631778717041,
      "learning_rate": 4.726533439877538e-06,
      "loss": 0.347731876373291,
      "memory(GiB)": 72.72,
      "step": 29030,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.708236171998881,
      "grad_norm": 2.6015849113464355,
      "learning_rate": 4.724993466697149e-06,
      "loss": 0.34134063720703123,
      "memory(GiB)": 72.72,
      "step": 29035,
      "token_acc": 0.6605166051660517,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.708702546404253,
      "grad_norm": 3.1408329010009766,
      "learning_rate": 4.723453519682786e-06,
      "loss": 0.36329352855682373,
      "memory(GiB)": 72.72,
      "step": 29040,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.709168920809626,
      "grad_norm": 2.9475157260894775,
      "learning_rate": 4.7219135989809675e-06,
      "loss": 0.37326502799987793,
      "memory(GiB)": 72.72,
      "step": 29045,
      "token_acc": 0.42592592592592593,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7096352952149987,
      "grad_norm": 3.237273693084717,
      "learning_rate": 4.720373704738214e-06,
      "loss": 0.3723649501800537,
      "memory(GiB)": 72.72,
      "step": 29050,
      "token_acc": 0.5348837209302325,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.7101016696203715,
      "grad_norm": 10.954689979553223,
      "learning_rate": 4.718833837101042e-06,
      "loss": 0.33523025512695315,
      "memory(GiB)": 72.72,
      "step": 29055,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.710568044025744,
      "grad_norm": 3.749258041381836,
      "learning_rate": 4.717293996215964e-06,
      "loss": 0.3585398197174072,
      "memory(GiB)": 72.72,
      "step": 29060,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.7110344184311166,
      "grad_norm": 3.3040449619293213,
      "learning_rate": 4.715754182229491e-06,
      "loss": 0.3341970682144165,
      "memory(GiB)": 72.72,
      "step": 29065,
      "token_acc": 0.49206349206349204,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.711500792836489,
      "grad_norm": 3.1529178619384766,
      "learning_rate": 4.714214395288129e-06,
      "loss": 0.3853811502456665,
      "memory(GiB)": 72.72,
      "step": 29070,
      "token_acc": 0.64,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.7119671672418617,
      "grad_norm": 3.3397293090820312,
      "learning_rate": 4.7126746355383904e-06,
      "loss": 0.3232858180999756,
      "memory(GiB)": 72.72,
      "step": 29075,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.7124335416472345,
      "grad_norm": 2.1557164192199707,
      "learning_rate": 4.711134903126775e-06,
      "loss": 0.32785544395446775,
      "memory(GiB)": 72.72,
      "step": 29080,
      "token_acc": 0.8163265306122449,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.7128999160526073,
      "grad_norm": 2.6360244750976562,
      "learning_rate": 4.709595198199783e-06,
      "loss": 0.32494866847991943,
      "memory(GiB)": 72.72,
      "step": 29085,
      "token_acc": 0.6333333333333333,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.7133662904579796,
      "grad_norm": 2.470193386077881,
      "learning_rate": 4.708055520903913e-06,
      "loss": 0.30798044204711916,
      "memory(GiB)": 72.72,
      "step": 29090,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.7138326648633524,
      "grad_norm": 2.927065134048462,
      "learning_rate": 4.706515871385661e-06,
      "loss": 0.37670102119445803,
      "memory(GiB)": 72.72,
      "step": 29095,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.7142990392687247,
      "grad_norm": 5.92868185043335,
      "learning_rate": 4.70497624979152e-06,
      "loss": 0.341052770614624,
      "memory(GiB)": 72.72,
      "step": 29100,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7147654136740975,
      "grad_norm": 4.009463310241699,
      "learning_rate": 4.703436656267978e-06,
      "loss": 0.3494894504547119,
      "memory(GiB)": 72.72,
      "step": 29105,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.7152317880794703,
      "grad_norm": 3.55031418800354,
      "learning_rate": 4.701897090961527e-06,
      "loss": 0.3406043767929077,
      "memory(GiB)": 72.72,
      "step": 29110,
      "token_acc": 0.8424657534246576,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.715698162484843,
      "grad_norm": 3.492551565170288,
      "learning_rate": 4.700357554018648e-06,
      "loss": 0.3487069129943848,
      "memory(GiB)": 72.72,
      "step": 29115,
      "token_acc": 0.6470588235294118,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7161645368902154,
      "grad_norm": 4.044403076171875,
      "learning_rate": 4.6988180455858266e-06,
      "loss": 0.33869662284851076,
      "memory(GiB)": 72.72,
      "step": 29120,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.716630911295588,
      "grad_norm": 3.453092336654663,
      "learning_rate": 4.697278565809539e-06,
      "loss": 0.323382306098938,
      "memory(GiB)": 72.72,
      "step": 29125,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.7170972857009605,
      "grad_norm": 3.6236090660095215,
      "learning_rate": 4.695739114836264e-06,
      "loss": 0.34448301792144775,
      "memory(GiB)": 72.72,
      "step": 29130,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7175636601063333,
      "grad_norm": 3.28104567527771,
      "learning_rate": 4.694199692812474e-06,
      "loss": 0.30989220142364504,
      "memory(GiB)": 72.72,
      "step": 29135,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.718030034511706,
      "grad_norm": 7.892760276794434,
      "learning_rate": 4.6926602998846404e-06,
      "loss": 0.3741705894470215,
      "memory(GiB)": 72.72,
      "step": 29140,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.718496408917079,
      "grad_norm": 10.044968605041504,
      "learning_rate": 4.691120936199234e-06,
      "loss": 0.3557471036911011,
      "memory(GiB)": 72.72,
      "step": 29145,
      "token_acc": 0.7397260273972602,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7189627833224512,
      "grad_norm": 3.808692693710327,
      "learning_rate": 4.689581601902718e-06,
      "loss": 0.35544576644897463,
      "memory(GiB)": 72.72,
      "step": 29150,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.719429157727824,
      "grad_norm": 5.541080951690674,
      "learning_rate": 4.688042297141557e-06,
      "loss": 0.3753048419952393,
      "memory(GiB)": 72.72,
      "step": 29155,
      "token_acc": 0.5802469135802469,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.7198955321331963,
      "grad_norm": 2.67055606842041,
      "learning_rate": 4.686503022062212e-06,
      "loss": 0.36613667011260986,
      "memory(GiB)": 72.72,
      "step": 29160,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.720361906538569,
      "grad_norm": 3.7471914291381836,
      "learning_rate": 4.684963776811137e-06,
      "loss": 0.31130080223083495,
      "memory(GiB)": 72.72,
      "step": 29165,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.720828280943942,
      "grad_norm": 3.2151951789855957,
      "learning_rate": 4.683424561534788e-06,
      "loss": 0.3924545764923096,
      "memory(GiB)": 72.72,
      "step": 29170,
      "token_acc": 0.5340909090909091,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.7212946553493147,
      "grad_norm": 2.5059094429016113,
      "learning_rate": 4.681885376379616e-06,
      "loss": 0.31764533519744875,
      "memory(GiB)": 72.72,
      "step": 29175,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.721761029754687,
      "grad_norm": 3.3889622688293457,
      "learning_rate": 4.680346221492072e-06,
      "loss": 0.36380579471588137,
      "memory(GiB)": 72.72,
      "step": 29180,
      "token_acc": 0.6304347826086957,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.72222740416006,
      "grad_norm": 3.1600725650787354,
      "learning_rate": 4.6788070970186e-06,
      "loss": 0.3419231176376343,
      "memory(GiB)": 72.72,
      "step": 29185,
      "token_acc": 0.9404761904761905,
      "train_speed(iter/s)": 0.251275
    },
    {
      "epoch": 2.722693778565432,
      "grad_norm": 3.134354829788208,
      "learning_rate": 4.677268003105643e-06,
      "loss": 0.3281933069229126,
      "memory(GiB)": 72.72,
      "step": 29190,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.251275
    },
    {
      "epoch": 2.723160152970805,
      "grad_norm": 4.344760894775391,
      "learning_rate": 4.675728939899641e-06,
      "loss": 0.37488768100738523,
      "memory(GiB)": 72.72,
      "step": 29195,
      "token_acc": 0.36538461538461536,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.7236265273761777,
      "grad_norm": 4.755670070648193,
      "learning_rate": 4.674189907547032e-06,
      "loss": 0.3501661062240601,
      "memory(GiB)": 72.72,
      "step": 29200,
      "token_acc": 0.66,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.7240929017815505,
      "grad_norm": 4.08837890625,
      "learning_rate": 4.672650906194248e-06,
      "loss": 0.37186007499694823,
      "memory(GiB)": 72.72,
      "step": 29205,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.724559276186923,
      "grad_norm": 7.74488639831543,
      "learning_rate": 4.671111935987724e-06,
      "loss": 0.36010046005249025,
      "memory(GiB)": 72.72,
      "step": 29210,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.7250256505922956,
      "grad_norm": 3.238621234893799,
      "learning_rate": 4.669572997073885e-06,
      "loss": 0.33920626640319823,
      "memory(GiB)": 72.72,
      "step": 29215,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.725492024997668,
      "grad_norm": 3.0188488960266113,
      "learning_rate": 4.668034089599158e-06,
      "loss": 0.360429573059082,
      "memory(GiB)": 72.72,
      "step": 29220,
      "train_speed(iter/s)": 0.251277
    },
    {
      "epoch": 2.7259583994030407,
      "grad_norm": 3.2706539630889893,
      "learning_rate": 4.666495213709965e-06,
      "loss": 0.33482286930084226,
      "memory(GiB)": 72.72,
      "step": 29225,
      "token_acc": 0.9137931034482759,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.7264247738084135,
      "grad_norm": 5.710205554962158,
      "learning_rate": 4.6649563695527235e-06,
      "loss": 0.3338714838027954,
      "memory(GiB)": 72.72,
      "step": 29230,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.726891148213786,
      "grad_norm": 4.556074619293213,
      "learning_rate": 4.6634175572738535e-06,
      "loss": 0.35119707584381105,
      "memory(GiB)": 72.72,
      "step": 29235,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.7273575226191586,
      "grad_norm": 2.8733930587768555,
      "learning_rate": 4.661878777019764e-06,
      "loss": 0.30516371726989744,
      "memory(GiB)": 72.72,
      "step": 29240,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.7278238970245314,
      "grad_norm": 2.9807305335998535,
      "learning_rate": 4.660340028936868e-06,
      "loss": 0.3545464038848877,
      "memory(GiB)": 72.72,
      "step": 29245,
      "token_acc": 0.753968253968254,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.7282902714299038,
      "grad_norm": 3.4636213779449463,
      "learning_rate": 4.658801313171572e-06,
      "loss": 0.34216511249542236,
      "memory(GiB)": 72.72,
      "step": 29250,
      "token_acc": 0.5671641791044776,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.7287566458352766,
      "grad_norm": 2.9962360858917236,
      "learning_rate": 4.657262629870279e-06,
      "loss": 0.3252077341079712,
      "memory(GiB)": 72.72,
      "step": 29255,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.7292230202406493,
      "grad_norm": 3.5601370334625244,
      "learning_rate": 4.655723979179394e-06,
      "loss": 0.3273270845413208,
      "memory(GiB)": 72.72,
      "step": 29260,
      "token_acc": 0.5462962962962963,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.7296893946460217,
      "grad_norm": 4.0708513259887695,
      "learning_rate": 4.65418536124531e-06,
      "loss": 0.3685157299041748,
      "memory(GiB)": 72.72,
      "step": 29265,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.7301557690513945,
      "grad_norm": 5.54696798324585,
      "learning_rate": 4.6526467762144226e-06,
      "loss": 0.3571657657623291,
      "memory(GiB)": 72.72,
      "step": 29270,
      "token_acc": 0.5471698113207547,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.7306221434567672,
      "grad_norm": 4.226940155029297,
      "learning_rate": 4.651108224233123e-06,
      "loss": 0.3775164127349854,
      "memory(GiB)": 72.72,
      "step": 29275,
      "token_acc": 0.6379310344827587,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.7310885178621396,
      "grad_norm": 6.508967399597168,
      "learning_rate": 4.649569705447804e-06,
      "loss": 0.3570970058441162,
      "memory(GiB)": 72.72,
      "step": 29280,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.7315548922675124,
      "grad_norm": 15.776912689208984,
      "learning_rate": 4.648031220004848e-06,
      "loss": 0.3598606109619141,
      "memory(GiB)": 72.72,
      "step": 29285,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.732021266672885,
      "grad_norm": 3.0396673679351807,
      "learning_rate": 4.646492768050637e-06,
      "loss": 0.32522532939910886,
      "memory(GiB)": 72.72,
      "step": 29290,
      "token_acc": 0.7551020408163265,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.7324876410782575,
      "grad_norm": 5.353367328643799,
      "learning_rate": 4.644954349731549e-06,
      "loss": 0.3671770811080933,
      "memory(GiB)": 72.72,
      "step": 29295,
      "token_acc": 0.5531914893617021,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.7329540154836303,
      "grad_norm": 3.182569742202759,
      "learning_rate": 4.643415965193962e-06,
      "loss": 0.35660979747772215,
      "memory(GiB)": 72.72,
      "step": 29300,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.733420389889003,
      "grad_norm": 3.981597423553467,
      "learning_rate": 4.641877614584246e-06,
      "loss": 0.3530445098876953,
      "memory(GiB)": 72.72,
      "step": 29305,
      "token_acc": 0.9782608695652174,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.7338867642943754,
      "grad_norm": 3.182286262512207,
      "learning_rate": 4.640339298048772e-06,
      "loss": 0.3263838768005371,
      "memory(GiB)": 72.72,
      "step": 29310,
      "token_acc": 0.6888888888888889,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.734353138699748,
      "grad_norm": 3.520001173019409,
      "learning_rate": 4.638801015733906e-06,
      "loss": 0.32489447593688964,
      "memory(GiB)": 72.72,
      "step": 29315,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.734819513105121,
      "grad_norm": 3.2749218940734863,
      "learning_rate": 4.637262767786011e-06,
      "loss": 0.3610720634460449,
      "memory(GiB)": 72.72,
      "step": 29320,
      "token_acc": 0.5897435897435898,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.7352858875104933,
      "grad_norm": 3.151320219039917,
      "learning_rate": 4.635724554351446e-06,
      "loss": 0.37781822681427,
      "memory(GiB)": 72.72,
      "step": 29325,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.735752261915866,
      "grad_norm": 2.744133472442627,
      "learning_rate": 4.634186375576568e-06,
      "loss": 0.3485221862792969,
      "memory(GiB)": 72.72,
      "step": 29330,
      "token_acc": 0.95,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.736218636321239,
      "grad_norm": 6.236948490142822,
      "learning_rate": 4.6326482316077305e-06,
      "loss": 0.34477009773254397,
      "memory(GiB)": 72.72,
      "step": 29335,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.736685010726611,
      "grad_norm": 6.715700626373291,
      "learning_rate": 4.631110122591281e-06,
      "loss": 0.3096773624420166,
      "memory(GiB)": 72.72,
      "step": 29340,
      "token_acc": 0.9705882352941176,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.737151385131984,
      "grad_norm": 6.057927131652832,
      "learning_rate": 4.629572048673564e-06,
      "loss": 0.31601686477661134,
      "memory(GiB)": 72.72,
      "step": 29345,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7376177595373568,
      "grad_norm": 3.1850225925445557,
      "learning_rate": 4.628034010000928e-06,
      "loss": 0.34567861557006835,
      "memory(GiB)": 72.72,
      "step": 29350,
      "token_acc": 0.7687861271676301,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.738084133942729,
      "grad_norm": 4.437905788421631,
      "learning_rate": 4.626496006719712e-06,
      "loss": 0.3473789691925049,
      "memory(GiB)": 72.72,
      "step": 29355,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.738550508348102,
      "grad_norm": 2.9891793727874756,
      "learning_rate": 4.624958038976248e-06,
      "loss": 0.3337120056152344,
      "memory(GiB)": 72.72,
      "step": 29360,
      "token_acc": 0.6041666666666666,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.739016882753474,
      "grad_norm": 4.874638557434082,
      "learning_rate": 4.623420106916872e-06,
      "loss": 0.3203634023666382,
      "memory(GiB)": 72.72,
      "step": 29365,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.739483257158847,
      "grad_norm": 2.5462563037872314,
      "learning_rate": 4.621882210687912e-06,
      "loss": 0.3026399850845337,
      "memory(GiB)": 72.72,
      "step": 29370,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.73994963156422,
      "grad_norm": 2.3283770084381104,
      "learning_rate": 4.620344350435695e-06,
      "loss": 0.3086703777313232,
      "memory(GiB)": 72.72,
      "step": 29375,
      "token_acc": 0.7647058823529411,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.7404160059695926,
      "grad_norm": 4.135768413543701,
      "learning_rate": 4.618806526306544e-06,
      "loss": 0.3206944942474365,
      "memory(GiB)": 72.72,
      "step": 29380,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.740882380374965,
      "grad_norm": 3.9820759296417236,
      "learning_rate": 4.617268738446777e-06,
      "loss": 0.3645485401153564,
      "memory(GiB)": 72.72,
      "step": 29385,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.7413487547803377,
      "grad_norm": 3.1326122283935547,
      "learning_rate": 4.615730987002712e-06,
      "loss": 0.3664992809295654,
      "memory(GiB)": 72.72,
      "step": 29390,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.74181512918571,
      "grad_norm": 7.334765911102295,
      "learning_rate": 4.614193272120659e-06,
      "loss": 0.3693019151687622,
      "memory(GiB)": 72.72,
      "step": 29395,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.742281503591083,
      "grad_norm": 3.5870189666748047,
      "learning_rate": 4.612655593946928e-06,
      "loss": 0.3919793128967285,
      "memory(GiB)": 72.72,
      "step": 29400,
      "token_acc": 0.45901639344262296,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.7427478779964556,
      "grad_norm": 3.351912498474121,
      "learning_rate": 4.611117952627823e-06,
      "loss": 0.3521714687347412,
      "memory(GiB)": 72.72,
      "step": 29405,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.7432142524018284,
      "grad_norm": 3.4015307426452637,
      "learning_rate": 4.609580348309647e-06,
      "loss": 0.36837377548217776,
      "memory(GiB)": 72.72,
      "step": 29410,
      "token_acc": 0.6162790697674418,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 2.7436806268072007,
      "grad_norm": 3.3791658878326416,
      "learning_rate": 4.608042781138698e-06,
      "loss": 0.37093515396118165,
      "memory(GiB)": 72.72,
      "step": 29415,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.7441470012125735,
      "grad_norm": 5.855319976806641,
      "learning_rate": 4.606505251261271e-06,
      "loss": 0.34795207977294923,
      "memory(GiB)": 72.72,
      "step": 29420,
      "token_acc": 0.44642857142857145,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.744613375617946,
      "grad_norm": 3.8892428874969482,
      "learning_rate": 4.604967758823658e-06,
      "loss": 0.34100754261016847,
      "memory(GiB)": 72.72,
      "step": 29425,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.7450797500233186,
      "grad_norm": 2.6593241691589355,
      "learning_rate": 4.603430303972146e-06,
      "loss": 0.3474619388580322,
      "memory(GiB)": 72.72,
      "step": 29430,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.7455461244286914,
      "grad_norm": 3.2932963371276855,
      "learning_rate": 4.601892886853019e-06,
      "loss": 0.43316082954406737,
      "memory(GiB)": 72.72,
      "step": 29435,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.746012498834064,
      "grad_norm": 3.77006459236145,
      "learning_rate": 4.600355507612557e-06,
      "loss": 0.3260969161987305,
      "memory(GiB)": 72.72,
      "step": 29440,
      "token_acc": 0.5666666666666667,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.7464788732394365,
      "grad_norm": 3.2966439723968506,
      "learning_rate": 4.598818166397035e-06,
      "loss": 0.35790185928344725,
      "memory(GiB)": 72.72,
      "step": 29445,
      "token_acc": 0.5670103092783505,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.7469452476448093,
      "grad_norm": 2.1610515117645264,
      "learning_rate": 4.5972808633527305e-06,
      "loss": 0.3408764600753784,
      "memory(GiB)": 72.72,
      "step": 29450,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.7474116220501816,
      "grad_norm": 5.985296249389648,
      "learning_rate": 4.595743598625912e-06,
      "loss": 0.3556774616241455,
      "memory(GiB)": 72.72,
      "step": 29455,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.7478779964555544,
      "grad_norm": 6.152430057525635,
      "learning_rate": 4.594206372362845e-06,
      "loss": 0.32389540672302247,
      "memory(GiB)": 72.72,
      "step": 29460,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.748344370860927,
      "grad_norm": 4.593680381774902,
      "learning_rate": 4.59266918470979e-06,
      "loss": 0.35997323989868163,
      "memory(GiB)": 72.72,
      "step": 29465,
      "token_acc": 0.5614035087719298,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.7488107452663,
      "grad_norm": 2.788717031478882,
      "learning_rate": 4.591132035813009e-06,
      "loss": 0.3420044183731079,
      "memory(GiB)": 72.72,
      "step": 29470,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.7492771196716723,
      "grad_norm": 5.4919633865356445,
      "learning_rate": 4.589594925818754e-06,
      "loss": 0.30872857570648193,
      "memory(GiB)": 72.72,
      "step": 29475,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.749743494077045,
      "grad_norm": 3.1028337478637695,
      "learning_rate": 4.5880578548732765e-06,
      "loss": 0.3790256500244141,
      "memory(GiB)": 72.72,
      "step": 29480,
      "token_acc": 0.5348837209302325,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 2.7502098684824174,
      "grad_norm": 2.6190037727355957,
      "learning_rate": 4.5865208231228264e-06,
      "loss": 0.3591240167617798,
      "memory(GiB)": 72.72,
      "step": 29485,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.7506762428877902,
      "grad_norm": 2.7016351222991943,
      "learning_rate": 4.584983830713647e-06,
      "loss": 0.32917964458465576,
      "memory(GiB)": 72.72,
      "step": 29490,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.751142617293163,
      "grad_norm": 5.868658542633057,
      "learning_rate": 4.583446877791976e-06,
      "loss": 0.3671501874923706,
      "memory(GiB)": 72.72,
      "step": 29495,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.751608991698536,
      "grad_norm": 14.379119873046875,
      "learning_rate": 4.581909964504053e-06,
      "loss": 0.3194985866546631,
      "memory(GiB)": 72.72,
      "step": 29500,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.752075366103908,
      "grad_norm": 2.7437233924865723,
      "learning_rate": 4.580373090996107e-06,
      "loss": 0.32458064556121824,
      "memory(GiB)": 72.72,
      "step": 29505,
      "token_acc": 0.828125,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.752541740509281,
      "grad_norm": 3.0201776027679443,
      "learning_rate": 4.578836257414369e-06,
      "loss": 0.33960766792297364,
      "memory(GiB)": 72.72,
      "step": 29510,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.7530081149146532,
      "grad_norm": 2.3279600143432617,
      "learning_rate": 4.577299463905065e-06,
      "loss": 0.3281234264373779,
      "memory(GiB)": 72.72,
      "step": 29515,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.753474489320026,
      "grad_norm": 3.1136765480041504,
      "learning_rate": 4.575762710614414e-06,
      "loss": 0.32639641761779786,
      "memory(GiB)": 72.72,
      "step": 29520,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.753940863725399,
      "grad_norm": 3.613116979598999,
      "learning_rate": 4.574225997688635e-06,
      "loss": 0.3798628330230713,
      "memory(GiB)": 72.72,
      "step": 29525,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.7544072381307716,
      "grad_norm": 3.091078996658325,
      "learning_rate": 4.57268932527394e-06,
      "loss": 0.35160796642303466,
      "memory(GiB)": 72.72,
      "step": 29530,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.754873612536144,
      "grad_norm": 2.8242902755737305,
      "learning_rate": 4.571152693516541e-06,
      "loss": 0.34978246688842773,
      "memory(GiB)": 72.72,
      "step": 29535,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.7553399869415167,
      "grad_norm": 2.858549118041992,
      "learning_rate": 4.56961610256264e-06,
      "loss": 0.32607054710388184,
      "memory(GiB)": 72.72,
      "step": 29540,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 2.755806361346889,
      "grad_norm": 2.8493101596832275,
      "learning_rate": 4.56807955255844e-06,
      "loss": 0.30965752601623536,
      "memory(GiB)": 72.72,
      "step": 29545,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.756272735752262,
      "grad_norm": 5.429373264312744,
      "learning_rate": 4.566543043650142e-06,
      "loss": 0.3290865421295166,
      "memory(GiB)": 72.72,
      "step": 29550,
      "token_acc": 0.6825396825396826,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 2.7567391101576346,
      "grad_norm": 3.4903817176818848,
      "learning_rate": 4.565006575983938e-06,
      "loss": 0.32174997329711913,
      "memory(GiB)": 72.72,
      "step": 29555,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.7572054845630074,
      "grad_norm": 3.0402839183807373,
      "learning_rate": 4.5634701497060185e-06,
      "loss": 0.34091792106628416,
      "memory(GiB)": 72.72,
      "step": 29560,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.7576718589683797,
      "grad_norm": 2.950026750564575,
      "learning_rate": 4.5619337649625695e-06,
      "loss": 0.3341084003448486,
      "memory(GiB)": 72.72,
      "step": 29565,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 2.7581382333737525,
      "grad_norm": 4.2501749992370605,
      "learning_rate": 4.560397421899773e-06,
      "loss": 0.34087333679199217,
      "memory(GiB)": 72.72,
      "step": 29570,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.758604607779125,
      "grad_norm": 4.1414384841918945,
      "learning_rate": 4.558861120663807e-06,
      "loss": 0.34132232666015627,
      "memory(GiB)": 72.72,
      "step": 29575,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.7590709821844976,
      "grad_norm": 4.761911392211914,
      "learning_rate": 4.5573248614008455e-06,
      "loss": 0.3396818399429321,
      "memory(GiB)": 72.72,
      "step": 29580,
      "token_acc": 0.4909090909090909,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 2.7595373565898704,
      "grad_norm": 2.96647047996521,
      "learning_rate": 4.555788644257061e-06,
      "loss": 0.3816758394241333,
      "memory(GiB)": 72.72,
      "step": 29585,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 2.760003730995243,
      "grad_norm": 2.881603956222534,
      "learning_rate": 4.554252469378619e-06,
      "loss": 0.3361975908279419,
      "memory(GiB)": 72.72,
      "step": 29590,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 2.7604701054006155,
      "grad_norm": 2.417325019836426,
      "learning_rate": 4.5527163369116815e-06,
      "loss": 0.370539116859436,
      "memory(GiB)": 72.72,
      "step": 29595,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 2.7609364798059883,
      "grad_norm": 2.57930326461792,
      "learning_rate": 4.551180247002406e-06,
      "loss": 0.3474907398223877,
      "memory(GiB)": 72.72,
      "step": 29600,
      "token_acc": 0.46938775510204084,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.7614028542113607,
      "grad_norm": 3.240403652191162,
      "learning_rate": 4.549644199796947e-06,
      "loss": 0.33641159534454346,
      "memory(GiB)": 72.72,
      "step": 29605,
      "token_acc": 0.550561797752809,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 2.7618692286167335,
      "grad_norm": 8.903401374816895,
      "learning_rate": 4.5481081954414565e-06,
      "loss": 0.34016473293304444,
      "memory(GiB)": 72.72,
      "step": 29610,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 2.7623356030221062,
      "grad_norm": 2.8537862300872803,
      "learning_rate": 4.546572234082076e-06,
      "loss": 0.35599403381347655,
      "memory(GiB)": 72.72,
      "step": 29615,
      "token_acc": 0.9296875,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 2.762801977427479,
      "grad_norm": 3.964235782623291,
      "learning_rate": 4.545036315864953e-06,
      "loss": 0.3292029857635498,
      "memory(GiB)": 72.72,
      "step": 29620,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 2.7632683518328514,
      "grad_norm": 3.7032344341278076,
      "learning_rate": 4.543500440936223e-06,
      "loss": 0.3331413745880127,
      "memory(GiB)": 72.72,
      "step": 29625,
      "token_acc": 0.9534883720930233,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.763734726238224,
      "grad_norm": 3.600903034210205,
      "learning_rate": 4.5419646094420205e-06,
      "loss": 0.3671398639678955,
      "memory(GiB)": 72.72,
      "step": 29630,
      "token_acc": 0.5846153846153846,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.7642011006435965,
      "grad_norm": 2.8492043018341064,
      "learning_rate": 4.540428821528474e-06,
      "loss": 0.3409783124923706,
      "memory(GiB)": 72.72,
      "step": 29635,
      "token_acc": 0.945054945054945,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.7646674750489693,
      "grad_norm": 5.2909746170043945,
      "learning_rate": 4.538893077341708e-06,
      "loss": 0.3311504364013672,
      "memory(GiB)": 72.72,
      "step": 29640,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.765133849454342,
      "grad_norm": 4.863702774047852,
      "learning_rate": 4.537357377027847e-06,
      "loss": 0.33526628017425536,
      "memory(GiB)": 72.72,
      "step": 29645,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 2.765600223859715,
      "grad_norm": 3.1180508136749268,
      "learning_rate": 4.5358217207330035e-06,
      "loss": 0.3742880344390869,
      "memory(GiB)": 72.72,
      "step": 29650,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 2.766066598265087,
      "grad_norm": 3.4380462169647217,
      "learning_rate": 4.534286108603296e-06,
      "loss": 0.34451847076416015,
      "memory(GiB)": 72.72,
      "step": 29655,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 2.76653297267046,
      "grad_norm": 4.400702953338623,
      "learning_rate": 4.532750540784829e-06,
      "loss": 0.3393531084060669,
      "memory(GiB)": 72.72,
      "step": 29660,
      "train_speed(iter/s)": 0.251292
    },
    {
      "epoch": 2.7669993470758323,
      "grad_norm": 2.392226219177246,
      "learning_rate": 4.53121501742371e-06,
      "loss": 0.33291051387786863,
      "memory(GiB)": 72.72,
      "step": 29665,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 2.767465721481205,
      "grad_norm": 2.621347188949585,
      "learning_rate": 4.529679538666037e-06,
      "loss": 0.341571569442749,
      "memory(GiB)": 72.72,
      "step": 29670,
      "token_acc": 0.9176470588235294,
      "train_speed(iter/s)": 0.25129
    },
    {
      "epoch": 2.767932095886578,
      "grad_norm": 3.1451103687286377,
      "learning_rate": 4.528144104657908e-06,
      "loss": 0.31832826137542725,
      "memory(GiB)": 72.72,
      "step": 29675,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 2.7683984702919506,
      "grad_norm": 3.6594531536102295,
      "learning_rate": 4.5266087155454125e-06,
      "loss": 0.3686579704284668,
      "memory(GiB)": 72.72,
      "step": 29680,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 2.768864844697323,
      "grad_norm": 2.798029661178589,
      "learning_rate": 4.52507337147464e-06,
      "loss": 0.31166715621948243,
      "memory(GiB)": 72.72,
      "step": 29685,
      "token_acc": 0.8916666666666667,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 2.7693312191026958,
      "grad_norm": 5.627218246459961,
      "learning_rate": 4.523538072591674e-06,
      "loss": 0.3344397068023682,
      "memory(GiB)": 72.72,
      "step": 29690,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 2.769797593508068,
      "grad_norm": 4.04295539855957,
      "learning_rate": 4.522002819042592e-06,
      "loss": 0.3736129283905029,
      "memory(GiB)": 72.72,
      "step": 29695,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 2.770263967913441,
      "grad_norm": 3.360755443572998,
      "learning_rate": 4.520467610973469e-06,
      "loss": 0.3314135789871216,
      "memory(GiB)": 72.72,
      "step": 29700,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.7707303423188137,
      "grad_norm": 2.9606881141662598,
      "learning_rate": 4.518932448530376e-06,
      "loss": 0.34102463722229004,
      "memory(GiB)": 72.72,
      "step": 29705,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.7711967167241864,
      "grad_norm": 3.126168727874756,
      "learning_rate": 4.517397331859379e-06,
      "loss": 0.37726693153381347,
      "memory(GiB)": 72.72,
      "step": 29710,
      "token_acc": 0.9418604651162791,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 2.7716630911295588,
      "grad_norm": 5.384421348571777,
      "learning_rate": 4.515862261106537e-06,
      "loss": 0.33635878562927246,
      "memory(GiB)": 72.72,
      "step": 29715,
      "token_acc": 0.963302752293578,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 2.7721294655349316,
      "grad_norm": 2.4473941326141357,
      "learning_rate": 4.514327236417911e-06,
      "loss": 0.3141166687011719,
      "memory(GiB)": 72.72,
      "step": 29720,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 2.772595839940304,
      "grad_norm": 2.615963935852051,
      "learning_rate": 4.512792257939552e-06,
      "loss": 0.31658895015716554,
      "memory(GiB)": 72.72,
      "step": 29725,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.7730622143456767,
      "grad_norm": 3.05517315864563,
      "learning_rate": 4.51125732581751e-06,
      "loss": 0.3616952419281006,
      "memory(GiB)": 72.72,
      "step": 29730,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 2.7735285887510495,
      "grad_norm": 3.0143308639526367,
      "learning_rate": 4.509722440197827e-06,
      "loss": 0.3219513654708862,
      "memory(GiB)": 72.72,
      "step": 29735,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.7739949631564222,
      "grad_norm": 3.570056915283203,
      "learning_rate": 4.508187601226544e-06,
      "loss": 0.3624671697616577,
      "memory(GiB)": 72.72,
      "step": 29740,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.7744613375617946,
      "grad_norm": 2.6110105514526367,
      "learning_rate": 4.506652809049694e-06,
      "loss": 0.3476531982421875,
      "memory(GiB)": 72.72,
      "step": 29745,
      "token_acc": 0.40350877192982454,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 2.7749277119671674,
      "grad_norm": 3.0936107635498047,
      "learning_rate": 4.50511806381331e-06,
      "loss": 0.338334321975708,
      "memory(GiB)": 72.72,
      "step": 29750,
      "token_acc": 0.546875,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 2.7753940863725397,
      "grad_norm": 3.9203977584838867,
      "learning_rate": 4.503583365663418e-06,
      "loss": 0.314439582824707,
      "memory(GiB)": 72.72,
      "step": 29755,
      "token_acc": 0.6422018348623854,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 2.7758604607779125,
      "grad_norm": 4.821112155914307,
      "learning_rate": 4.50204871474604e-06,
      "loss": 0.3364179849624634,
      "memory(GiB)": 72.72,
      "step": 29760,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.7763268351832853,
      "grad_norm": 3.060577630996704,
      "learning_rate": 4.500514111207193e-06,
      "loss": 0.3762716770172119,
      "memory(GiB)": 72.72,
      "step": 29765,
      "token_acc": 0.7909090909090909,
      "train_speed(iter/s)": 0.251297
    },
    {
      "epoch": 2.776793209588658,
      "grad_norm": 5.801173686981201,
      "learning_rate": 4.49897955519289e-06,
      "loss": 0.3474642276763916,
      "memory(GiB)": 72.72,
      "step": 29770,
      "token_acc": 0.5526315789473685,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.7772595839940304,
      "grad_norm": 3.3738372325897217,
      "learning_rate": 4.4974450468491375e-06,
      "loss": 0.3259760618209839,
      "memory(GiB)": 72.72,
      "step": 29775,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.777725958399403,
      "grad_norm": 3.667879343032837,
      "learning_rate": 4.495910586321941e-06,
      "loss": 0.3612722873687744,
      "memory(GiB)": 72.72,
      "step": 29780,
      "token_acc": 0.49206349206349204,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.7781923328047755,
      "grad_norm": 3.4705710411071777,
      "learning_rate": 4.494376173757299e-06,
      "loss": 0.34863312244415284,
      "memory(GiB)": 72.72,
      "step": 29785,
      "token_acc": 0.7872340425531915,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 2.7786587072101483,
      "grad_norm": 2.7600576877593994,
      "learning_rate": 4.4928418093012065e-06,
      "loss": 0.3157228708267212,
      "memory(GiB)": 72.72,
      "step": 29790,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 2.779125081615521,
      "grad_norm": 3.066131830215454,
      "learning_rate": 4.491307493099654e-06,
      "loss": 0.3391707897186279,
      "memory(GiB)": 72.72,
      "step": 29795,
      "token_acc": 0.9489795918367347,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.7795914560208934,
      "grad_norm": 2.5807201862335205,
      "learning_rate": 4.489773225298626e-06,
      "loss": 0.3150300979614258,
      "memory(GiB)": 72.72,
      "step": 29800,
      "train_speed(iter/s)": 0.251292
    },
    {
      "epoch": 2.780057830426266,
      "grad_norm": 3.4924817085266113,
      "learning_rate": 4.488239006044105e-06,
      "loss": 0.3018326282501221,
      "memory(GiB)": 72.72,
      "step": 29805,
      "token_acc": 0.5409836065573771,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.780524204831639,
      "grad_norm": 3.164536714553833,
      "learning_rate": 4.486704835482066e-06,
      "loss": 0.39064507484436034,
      "memory(GiB)": 72.72,
      "step": 29810,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.7809905792370113,
      "grad_norm": 2.801541328430176,
      "learning_rate": 4.485170713758478e-06,
      "loss": 0.3504354476928711,
      "memory(GiB)": 72.72,
      "step": 29815,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.781456953642384,
      "grad_norm": 2.884779930114746,
      "learning_rate": 4.483636641019312e-06,
      "loss": 0.321863055229187,
      "memory(GiB)": 72.72,
      "step": 29820,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.781923328047757,
      "grad_norm": 3.410107135772705,
      "learning_rate": 4.48210261741053e-06,
      "loss": 0.3477048873901367,
      "memory(GiB)": 72.72,
      "step": 29825,
      "train_speed(iter/s)": 0.251298
    },
    {
      "epoch": 2.782389702453129,
      "grad_norm": 3.193293571472168,
      "learning_rate": 4.4805686430780894e-06,
      "loss": 0.3131662130355835,
      "memory(GiB)": 72.72,
      "step": 29830,
      "token_acc": 0.6865671641791045,
      "train_speed(iter/s)": 0.251298
    },
    {
      "epoch": 2.782856076858502,
      "grad_norm": 3.424651622772217,
      "learning_rate": 4.479034718167941e-06,
      "loss": 0.3467120170593262,
      "memory(GiB)": 72.72,
      "step": 29835,
      "train_speed(iter/s)": 0.251301
    },
    {
      "epoch": 2.783322451263875,
      "grad_norm": 3.241198778152466,
      "learning_rate": 4.477500842826034e-06,
      "loss": 0.35875911712646485,
      "memory(GiB)": 72.72,
      "step": 29840,
      "train_speed(iter/s)": 0.251299
    },
    {
      "epoch": 2.783788825669247,
      "grad_norm": 5.326316833496094,
      "learning_rate": 4.4759670171983125e-06,
      "loss": 0.3511155605316162,
      "memory(GiB)": 72.72,
      "step": 29845,
      "train_speed(iter/s)": 0.2513
    },
    {
      "epoch": 2.78425520007462,
      "grad_norm": 3.918050527572632,
      "learning_rate": 4.474433241430714e-06,
      "loss": 0.3121626377105713,
      "memory(GiB)": 72.72,
      "step": 29850,
      "token_acc": 0.6037735849056604,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.7847215744799927,
      "grad_norm": 4.670284271240234,
      "learning_rate": 4.472899515669174e-06,
      "loss": 0.3711463451385498,
      "memory(GiB)": 72.72,
      "step": 29855,
      "token_acc": 0.9583333333333334,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 2.785187948885365,
      "grad_norm": 8.601302146911621,
      "learning_rate": 4.4713658400596225e-06,
      "loss": 0.33215644359588625,
      "memory(GiB)": 72.72,
      "step": 29860,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.785654323290738,
      "grad_norm": 2.8684310913085938,
      "learning_rate": 4.469832214747982e-06,
      "loss": 0.3311776876449585,
      "memory(GiB)": 72.72,
      "step": 29865,
      "token_acc": 0.546875,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.7861206976961106,
      "grad_norm": 3.6856799125671387,
      "learning_rate": 4.468298639880172e-06,
      "loss": 0.3328678607940674,
      "memory(GiB)": 72.72,
      "step": 29870,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.786587072101483,
      "grad_norm": 4.19542121887207,
      "learning_rate": 4.46676511560211e-06,
      "loss": 0.3165607929229736,
      "memory(GiB)": 72.72,
      "step": 29875,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.7870534465068557,
      "grad_norm": 3.4577064514160156,
      "learning_rate": 4.465231642059705e-06,
      "loss": 0.3311444282531738,
      "memory(GiB)": 72.72,
      "step": 29880,
      "token_acc": 0.6842105263157895,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.7875198209122285,
      "grad_norm": 5.33153772354126,
      "learning_rate": 4.463698219398859e-06,
      "loss": 0.3363812923431396,
      "memory(GiB)": 72.72,
      "step": 29885,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.787986195317601,
      "grad_norm": 5.604944705963135,
      "learning_rate": 4.4621648477654775e-06,
      "loss": 0.38241560459136964,
      "memory(GiB)": 72.72,
      "step": 29890,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.7884525697229736,
      "grad_norm": 3.2621140480041504,
      "learning_rate": 4.460631527305454e-06,
      "loss": 0.3181817054748535,
      "memory(GiB)": 72.72,
      "step": 29895,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.7889189441283464,
      "grad_norm": 3.1082265377044678,
      "learning_rate": 4.459098258164679e-06,
      "loss": 0.3264976978302002,
      "memory(GiB)": 72.72,
      "step": 29900,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.7893853185337187,
      "grad_norm": 4.049045562744141,
      "learning_rate": 4.457565040489039e-06,
      "loss": 0.37009172439575194,
      "memory(GiB)": 72.72,
      "step": 29905,
      "token_acc": 0.9259259259259259,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.7898516929390915,
      "grad_norm": 2.5950002670288086,
      "learning_rate": 4.456031874424414e-06,
      "loss": 0.3004432201385498,
      "memory(GiB)": 72.72,
      "step": 29910,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.7903180673444643,
      "grad_norm": 5.130122661590576,
      "learning_rate": 4.45449876011668e-06,
      "loss": 0.3723666429519653,
      "memory(GiB)": 72.72,
      "step": 29915,
      "token_acc": 0.5223880597014925,
      "train_speed(iter/s)": 0.251312
    },
    {
      "epoch": 2.7907844417498366,
      "grad_norm": 5.698938369750977,
      "learning_rate": 4.452965697711707e-06,
      "loss": 0.3614237308502197,
      "memory(GiB)": 72.72,
      "step": 29920,
      "token_acc": 0.3939393939393939,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 2.7912508161552094,
      "grad_norm": 9.162657737731934,
      "learning_rate": 4.451432687355365e-06,
      "loss": 0.36069583892822266,
      "memory(GiB)": 72.72,
      "step": 29925,
      "token_acc": 0.54,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 2.7917171905605818,
      "grad_norm": 4.244142532348633,
      "learning_rate": 4.449899729193512e-06,
      "loss": 0.36324596405029297,
      "memory(GiB)": 72.72,
      "step": 29930,
      "token_acc": 0.6538461538461539,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 2.7921835649659545,
      "grad_norm": 2.8020238876342773,
      "learning_rate": 4.448366823372006e-06,
      "loss": 0.32698514461517336,
      "memory(GiB)": 72.72,
      "step": 29935,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.7926499393713273,
      "grad_norm": 4.455963134765625,
      "learning_rate": 4.446833970036696e-06,
      "loss": 0.3653381824493408,
      "memory(GiB)": 72.72,
      "step": 29940,
      "token_acc": 0.578125,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 2.7931163137767,
      "grad_norm": 2.551861047744751,
      "learning_rate": 4.44530116933343e-06,
      "loss": 0.32400825023651125,
      "memory(GiB)": 72.72,
      "step": 29945,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.7935826881820724,
      "grad_norm": 12.20887279510498,
      "learning_rate": 4.44376842140805e-06,
      "loss": 0.32786951065063474,
      "memory(GiB)": 72.72,
      "step": 29950,
      "token_acc": 0.5342465753424658,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.7940490625874452,
      "grad_norm": 3.8194518089294434,
      "learning_rate": 4.442235726406389e-06,
      "loss": 0.3271945953369141,
      "memory(GiB)": 72.72,
      "step": 29955,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.7945154369928176,
      "grad_norm": 3.158844470977783,
      "learning_rate": 4.440703084474282e-06,
      "loss": 0.3316559076309204,
      "memory(GiB)": 72.72,
      "step": 29960,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 2.7949818113981904,
      "grad_norm": 6.589810371398926,
      "learning_rate": 4.439170495757554e-06,
      "loss": 0.35335826873779297,
      "memory(GiB)": 72.72,
      "step": 29965,
      "token_acc": 0.696969696969697,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 2.795448185803563,
      "grad_norm": 5.292924404144287,
      "learning_rate": 4.437637960402025e-06,
      "loss": 0.37572977542877195,
      "memory(GiB)": 72.72,
      "step": 29970,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 2.795914560208936,
      "grad_norm": 4.9932050704956055,
      "learning_rate": 4.436105478553512e-06,
      "loss": 0.38457684516906737,
      "memory(GiB)": 72.72,
      "step": 29975,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 2.7963809346143083,
      "grad_norm": 3.3907086849212646,
      "learning_rate": 4.434573050357826e-06,
      "loss": 0.33431105613708495,
      "memory(GiB)": 72.72,
      "step": 29980,
      "train_speed(iter/s)": 0.2513
    },
    {
      "epoch": 2.796847309019681,
      "grad_norm": 3.1952741146087646,
      "learning_rate": 4.43304067596077e-06,
      "loss": 0.3507744312286377,
      "memory(GiB)": 72.72,
      "step": 29985,
      "token_acc": 0.9473684210526315,
      "train_speed(iter/s)": 0.251297
    },
    {
      "epoch": 2.7973136834250534,
      "grad_norm": 3.979081630706787,
      "learning_rate": 4.431508355508149e-06,
      "loss": 0.3583082914352417,
      "memory(GiB)": 72.72,
      "step": 29990,
      "train_speed(iter/s)": 0.251297
    },
    {
      "epoch": 2.797780057830426,
      "grad_norm": 2.904405355453491,
      "learning_rate": 4.4299760891457565e-06,
      "loss": 0.351669979095459,
      "memory(GiB)": 72.72,
      "step": 29995,
      "token_acc": 0.9791666666666666,
      "train_speed(iter/s)": 0.251297
    },
    {
      "epoch": 2.798246432235799,
      "grad_norm": 4.6378068923950195,
      "learning_rate": 4.428443877019383e-06,
      "loss": 0.3622945785522461,
      "memory(GiB)": 72.72,
      "step": 30000,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.7987128066411717,
      "grad_norm": 2.523963451385498,
      "learning_rate": 4.426911719274815e-06,
      "loss": 0.3478217840194702,
      "memory(GiB)": 72.72,
      "step": 30005,
      "train_speed(iter/s)": 0.251241
    },
    {
      "epoch": 2.799179181046544,
      "grad_norm": 3.5597856044769287,
      "learning_rate": 4.425379616057831e-06,
      "loss": 0.365450382232666,
      "memory(GiB)": 72.72,
      "step": 30010,
      "train_speed(iter/s)": 0.251242
    },
    {
      "epoch": 2.799645555451917,
      "grad_norm": 4.1194353103637695,
      "learning_rate": 4.423847567514206e-06,
      "loss": 0.3343313694000244,
      "memory(GiB)": 72.72,
      "step": 30015,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251241
    },
    {
      "epoch": 2.800111929857289,
      "grad_norm": 5.533106803894043,
      "learning_rate": 4.422315573789708e-06,
      "loss": 0.3609808921813965,
      "memory(GiB)": 72.72,
      "step": 30020,
      "train_speed(iter/s)": 0.251242
    },
    {
      "epoch": 2.800578304262662,
      "grad_norm": 3.4138238430023193,
      "learning_rate": 4.420783635030107e-06,
      "loss": 0.33128430843353274,
      "memory(GiB)": 72.72,
      "step": 30025,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.251241
    },
    {
      "epoch": 2.8010446786680347,
      "grad_norm": 3.1699657440185547,
      "learning_rate": 4.419251751381157e-06,
      "loss": 0.3307753801345825,
      "memory(GiB)": 72.72,
      "step": 30030,
      "train_speed(iter/s)": 0.251243
    },
    {
      "epoch": 2.8015110530734075,
      "grad_norm": 3.1292684078216553,
      "learning_rate": 4.417719922988614e-06,
      "loss": 0.3078925609588623,
      "memory(GiB)": 72.72,
      "step": 30035,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251243
    },
    {
      "epoch": 2.80197742747878,
      "grad_norm": 8.768431663513184,
      "learning_rate": 4.416188149998227e-06,
      "loss": 0.3268491268157959,
      "memory(GiB)": 72.72,
      "step": 30040,
      "train_speed(iter/s)": 0.251243
    },
    {
      "epoch": 2.8024438018841527,
      "grad_norm": 7.3527069091796875,
      "learning_rate": 4.414656432555739e-06,
      "loss": 0.34029221534729004,
      "memory(GiB)": 72.72,
      "step": 30045,
      "token_acc": 0.4918032786885246,
      "train_speed(iter/s)": 0.251242
    },
    {
      "epoch": 2.802910176289525,
      "grad_norm": 3.5981249809265137,
      "learning_rate": 4.413124770806888e-06,
      "loss": 0.3444253921508789,
      "memory(GiB)": 72.72,
      "step": 30050,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251241
    },
    {
      "epoch": 2.8033765506948978,
      "grad_norm": 3.164999008178711,
      "learning_rate": 4.4115931648974064e-06,
      "loss": 0.32743148803710936,
      "memory(GiB)": 72.72,
      "step": 30055,
      "train_speed(iter/s)": 0.251238
    },
    {
      "epoch": 2.8038429251002706,
      "grad_norm": 3.493053436279297,
      "learning_rate": 4.410061614973023e-06,
      "loss": 0.3414417266845703,
      "memory(GiB)": 72.72,
      "step": 30060,
      "token_acc": 0.9487179487179487,
      "train_speed(iter/s)": 0.251239
    },
    {
      "epoch": 2.8043092995056433,
      "grad_norm": 4.16787576675415,
      "learning_rate": 4.40853012117946e-06,
      "loss": 0.30177114009857176,
      "memory(GiB)": 72.72,
      "step": 30065,
      "train_speed(iter/s)": 0.251241
    },
    {
      "epoch": 2.8047756739110157,
      "grad_norm": 7.68420934677124,
      "learning_rate": 4.406998683662434e-06,
      "loss": 0.3215494155883789,
      "memory(GiB)": 72.72,
      "step": 30070,
      "token_acc": 0.589041095890411,
      "train_speed(iter/s)": 0.251241
    },
    {
      "epoch": 2.8052420483163885,
      "grad_norm": 4.62028694152832,
      "learning_rate": 4.405467302567657e-06,
      "loss": 0.33072638511657715,
      "memory(GiB)": 72.72,
      "step": 30075,
      "token_acc": 0.6484375,
      "train_speed(iter/s)": 0.251242
    },
    {
      "epoch": 2.805708422721761,
      "grad_norm": 2.2865493297576904,
      "learning_rate": 4.403935978040835e-06,
      "loss": 0.3089121341705322,
      "memory(GiB)": 72.72,
      "step": 30080,
      "token_acc": 0.9044117647058824,
      "train_speed(iter/s)": 0.251246
    },
    {
      "epoch": 2.8061747971271336,
      "grad_norm": 3.125556707382202,
      "learning_rate": 4.402404710227667e-06,
      "loss": 0.36048312187194825,
      "memory(GiB)": 72.72,
      "step": 30085,
      "token_acc": 0.5609756097560976,
      "train_speed(iter/s)": 0.251246
    },
    {
      "epoch": 2.8066411715325064,
      "grad_norm": 2.5997281074523926,
      "learning_rate": 4.400873499273848e-06,
      "loss": 0.3300523042678833,
      "memory(GiB)": 72.72,
      "step": 30090,
      "token_acc": 0.978021978021978,
      "train_speed(iter/s)": 0.251246
    },
    {
      "epoch": 2.807107545937879,
      "grad_norm": 3.0853092670440674,
      "learning_rate": 4.399342345325072e-06,
      "loss": 0.37031898498535154,
      "memory(GiB)": 72.72,
      "step": 30095,
      "train_speed(iter/s)": 0.251246
    },
    {
      "epoch": 2.8075739203432515,
      "grad_norm": 2.7379937171936035,
      "learning_rate": 4.397811248527022e-06,
      "loss": 0.3395893096923828,
      "memory(GiB)": 72.72,
      "step": 30100,
      "train_speed(iter/s)": 0.251247
    },
    {
      "epoch": 2.8080402947486243,
      "grad_norm": 5.198075294494629,
      "learning_rate": 4.396280209025377e-06,
      "loss": 0.35945920944213866,
      "memory(GiB)": 72.72,
      "step": 30105,
      "token_acc": 0.8098159509202454,
      "train_speed(iter/s)": 0.251245
    },
    {
      "epoch": 2.8085066691539966,
      "grad_norm": 3.4437191486358643,
      "learning_rate": 4.39474922696581e-06,
      "loss": 0.3217050075531006,
      "memory(GiB)": 72.72,
      "step": 30110,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.251246
    },
    {
      "epoch": 2.8089730435593694,
      "grad_norm": 3.353606700897217,
      "learning_rate": 4.393218302493989e-06,
      "loss": 0.31623790264129636,
      "memory(GiB)": 72.72,
      "step": 30115,
      "train_speed(iter/s)": 0.251247
    },
    {
      "epoch": 2.809439417964742,
      "grad_norm": 5.2623443603515625,
      "learning_rate": 4.391687435755578e-06,
      "loss": 0.3508429050445557,
      "memory(GiB)": 72.72,
      "step": 30120,
      "token_acc": 0.9320388349514563,
      "train_speed(iter/s)": 0.251247
    },
    {
      "epoch": 2.809905792370115,
      "grad_norm": 3.0591094493865967,
      "learning_rate": 4.390156626896231e-06,
      "loss": 0.2884621858596802,
      "memory(GiB)": 72.72,
      "step": 30125,
      "train_speed(iter/s)": 0.251248
    },
    {
      "epoch": 2.8103721667754873,
      "grad_norm": 3.5268380641937256,
      "learning_rate": 4.388625876061605e-06,
      "loss": 0.3423832178115845,
      "memory(GiB)": 72.72,
      "step": 30130,
      "train_speed(iter/s)": 0.25125
    },
    {
      "epoch": 2.81083854118086,
      "grad_norm": 4.85538387298584,
      "learning_rate": 4.387095183397342e-06,
      "loss": 0.3572711944580078,
      "memory(GiB)": 72.72,
      "step": 30135,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.251249
    },
    {
      "epoch": 2.8113049155862324,
      "grad_norm": 5.860750675201416,
      "learning_rate": 4.385564549049086e-06,
      "loss": 0.327860426902771,
      "memory(GiB)": 72.72,
      "step": 30140,
      "token_acc": 0.5901639344262295,
      "train_speed(iter/s)": 0.251252
    },
    {
      "epoch": 2.811771289991605,
      "grad_norm": 6.133838653564453,
      "learning_rate": 4.384033973162469e-06,
      "loss": 0.3383347988128662,
      "memory(GiB)": 72.72,
      "step": 30145,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251247
    },
    {
      "epoch": 2.812237664396978,
      "grad_norm": 5.157276630401611,
      "learning_rate": 4.382503455883122e-06,
      "loss": 0.34920854568481446,
      "memory(GiB)": 72.72,
      "step": 30150,
      "train_speed(iter/s)": 0.251244
    },
    {
      "epoch": 2.8127040388023508,
      "grad_norm": 4.334444046020508,
      "learning_rate": 4.380972997356668e-06,
      "loss": 0.3109539747238159,
      "memory(GiB)": 72.72,
      "step": 30155,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.251245
    },
    {
      "epoch": 2.813170413207723,
      "grad_norm": 4.056576251983643,
      "learning_rate": 4.379442597728727e-06,
      "loss": 0.31850008964538573,
      "memory(GiB)": 72.72,
      "step": 30160,
      "token_acc": 0.6078431372549019,
      "train_speed(iter/s)": 0.251248
    },
    {
      "epoch": 2.813636787613096,
      "grad_norm": 2.8994851112365723,
      "learning_rate": 4.377912257144912e-06,
      "loss": 0.3152834415435791,
      "memory(GiB)": 72.72,
      "step": 30165,
      "train_speed(iter/s)": 0.251248
    },
    {
      "epoch": 2.814103162018468,
      "grad_norm": 3.9954335689544678,
      "learning_rate": 4.376381975750829e-06,
      "loss": 0.3102604389190674,
      "memory(GiB)": 72.72,
      "step": 30170,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251246
    },
    {
      "epoch": 2.814569536423841,
      "grad_norm": 4.641663074493408,
      "learning_rate": 4.37485175369208e-06,
      "loss": 0.3305908203125,
      "memory(GiB)": 72.72,
      "step": 30175,
      "train_speed(iter/s)": 0.251248
    },
    {
      "epoch": 2.815035910829214,
      "grad_norm": 3.752310037612915,
      "learning_rate": 4.3733215911142616e-06,
      "loss": 0.3418872833251953,
      "memory(GiB)": 72.72,
      "step": 30180,
      "train_speed(iter/s)": 0.25125
    },
    {
      "epoch": 2.8155022852345866,
      "grad_norm": 5.346503734588623,
      "learning_rate": 4.371791488162962e-06,
      "loss": 0.35717525482177737,
      "memory(GiB)": 72.72,
      "step": 30185,
      "token_acc": 0.7291666666666666,
      "train_speed(iter/s)": 0.251251
    },
    {
      "epoch": 2.815968659639959,
      "grad_norm": 3.1247899532318115,
      "learning_rate": 4.370261444983766e-06,
      "loss": 0.2931671142578125,
      "memory(GiB)": 72.72,
      "step": 30190,
      "token_acc": 0.9634146341463414,
      "train_speed(iter/s)": 0.251248
    },
    {
      "epoch": 2.8164350340453317,
      "grad_norm": 7.311905860900879,
      "learning_rate": 4.368731461722255e-06,
      "loss": 0.3712503910064697,
      "memory(GiB)": 72.72,
      "step": 30195,
      "train_speed(iter/s)": 0.25125
    },
    {
      "epoch": 2.816901408450704,
      "grad_norm": 4.101523399353027,
      "learning_rate": 4.367201538524002e-06,
      "loss": 0.33069729804992676,
      "memory(GiB)": 72.72,
      "step": 30200,
      "token_acc": 0.5853658536585366,
      "train_speed(iter/s)": 0.251249
    },
    {
      "epoch": 2.817367782856077,
      "grad_norm": 3.6526246070861816,
      "learning_rate": 4.365671675534572e-06,
      "loss": 0.3249695062637329,
      "memory(GiB)": 72.72,
      "step": 30205,
      "token_acc": 0.9292929292929293,
      "train_speed(iter/s)": 0.25125
    },
    {
      "epoch": 2.8178341572614496,
      "grad_norm": 4.077662467956543,
      "learning_rate": 4.3641418728995275e-06,
      "loss": 0.342680025100708,
      "memory(GiB)": 72.72,
      "step": 30210,
      "token_acc": 0.574468085106383,
      "train_speed(iter/s)": 0.251252
    },
    {
      "epoch": 2.8183005316668224,
      "grad_norm": 3.221026659011841,
      "learning_rate": 4.362612130764425e-06,
      "loss": 0.39003887176513674,
      "memory(GiB)": 72.72,
      "step": 30215,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.8187669060721947,
      "grad_norm": 3.1239333152770996,
      "learning_rate": 4.361082449274815e-06,
      "loss": 0.3450387239456177,
      "memory(GiB)": 72.72,
      "step": 30220,
      "token_acc": 0.5688073394495413,
      "train_speed(iter/s)": 0.251255
    },
    {
      "epoch": 2.8192332804775675,
      "grad_norm": 2.3432250022888184,
      "learning_rate": 4.359552828576241e-06,
      "loss": 0.341593074798584,
      "memory(GiB)": 72.72,
      "step": 30225,
      "train_speed(iter/s)": 0.251257
    },
    {
      "epoch": 2.81969965488294,
      "grad_norm": 4.039447784423828,
      "learning_rate": 4.358023268814244e-06,
      "loss": 0.32846789360046386,
      "memory(GiB)": 72.72,
      "step": 30230,
      "token_acc": 0.8954248366013072,
      "train_speed(iter/s)": 0.251255
    },
    {
      "epoch": 2.8201660292883126,
      "grad_norm": 3.5718495845794678,
      "learning_rate": 4.3564937701343544e-06,
      "loss": 0.3420440673828125,
      "memory(GiB)": 72.72,
      "step": 30235,
      "train_speed(iter/s)": 0.251257
    },
    {
      "epoch": 2.8206324036936854,
      "grad_norm": 2.6062960624694824,
      "learning_rate": 4.3549643326821e-06,
      "loss": 0.32619104385375974,
      "memory(GiB)": 72.72,
      "step": 30240,
      "train_speed(iter/s)": 0.251254
    },
    {
      "epoch": 2.821098778099058,
      "grad_norm": 3.427271842956543,
      "learning_rate": 4.3534349566030035e-06,
      "loss": 0.3288844108581543,
      "memory(GiB)": 72.72,
      "step": 30245,
      "train_speed(iter/s)": 0.251256
    },
    {
      "epoch": 2.8215651525044305,
      "grad_norm": 19.433210372924805,
      "learning_rate": 4.3519056420425775e-06,
      "loss": 0.3426951885223389,
      "memory(GiB)": 72.72,
      "step": 30250,
      "token_acc": 0.6262626262626263,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.8220315269098033,
      "grad_norm": 3.342677116394043,
      "learning_rate": 4.350376389146334e-06,
      "loss": 0.3598784446716309,
      "memory(GiB)": 72.72,
      "step": 30255,
      "train_speed(iter/s)": 0.251257
    },
    {
      "epoch": 2.8224979013151756,
      "grad_norm": 4.236703872680664,
      "learning_rate": 4.348847198059774e-06,
      "loss": 0.3944192886352539,
      "memory(GiB)": 72.72,
      "step": 30260,
      "token_acc": 0.584070796460177,
      "train_speed(iter/s)": 0.251257
    },
    {
      "epoch": 2.8229642757205484,
      "grad_norm": 5.08522891998291,
      "learning_rate": 4.3473180689284e-06,
      "loss": 0.3180811405181885,
      "memory(GiB)": 72.72,
      "step": 30265,
      "token_acc": 0.5737704918032787,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.823430650125921,
      "grad_norm": 4.24645471572876,
      "learning_rate": 4.3457890018977e-06,
      "loss": 0.3407755374908447,
      "memory(GiB)": 72.72,
      "step": 30270,
      "train_speed(iter/s)": 0.251259
    },
    {
      "epoch": 2.823897024531294,
      "grad_norm": 2.6823947429656982,
      "learning_rate": 4.344259997113161e-06,
      "loss": 0.30163211822509767,
      "memory(GiB)": 72.72,
      "step": 30275,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 2.8243633989366663,
      "grad_norm": 3.74783992767334,
      "learning_rate": 4.3427310547202644e-06,
      "loss": 0.3330689430236816,
      "memory(GiB)": 72.72,
      "step": 30280,
      "token_acc": 0.48717948717948717,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 2.824829773342039,
      "grad_norm": 5.111357688903809,
      "learning_rate": 4.341202174864482e-06,
      "loss": 0.3518876791000366,
      "memory(GiB)": 72.72,
      "step": 30285,
      "token_acc": 0.463768115942029,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.8252961477474114,
      "grad_norm": 2.706054449081421,
      "learning_rate": 4.339673357691281e-06,
      "loss": 0.33154830932617185,
      "memory(GiB)": 72.72,
      "step": 30290,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 2.8257625221527842,
      "grad_norm": 2.7186691761016846,
      "learning_rate": 4.338144603346129e-06,
      "loss": 0.351702356338501,
      "memory(GiB)": 72.72,
      "step": 30295,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 2.826228896558157,
      "grad_norm": 1.9051076173782349,
      "learning_rate": 4.336615911974479e-06,
      "loss": 0.31545698642730713,
      "memory(GiB)": 72.72,
      "step": 30300,
      "token_acc": 0.9252336448598131,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 2.82669527096353,
      "grad_norm": 3.3622565269470215,
      "learning_rate": 4.3350872837217804e-06,
      "loss": 0.322017502784729,
      "memory(GiB)": 72.72,
      "step": 30305,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.827161645368902,
      "grad_norm": 3.030102252960205,
      "learning_rate": 4.3335587187334796e-06,
      "loss": 0.3565147876739502,
      "memory(GiB)": 72.72,
      "step": 30310,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.827628019774275,
      "grad_norm": 2.7611589431762695,
      "learning_rate": 4.332030217155012e-06,
      "loss": 0.32796449661254884,
      "memory(GiB)": 72.72,
      "step": 30315,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.8280943941796473,
      "grad_norm": 3.6679928302764893,
      "learning_rate": 4.330501779131813e-06,
      "loss": 0.3669325351715088,
      "memory(GiB)": 72.72,
      "step": 30320,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.82856076858502,
      "grad_norm": 3.556615114212036,
      "learning_rate": 4.3289734048093045e-06,
      "loss": 0.35225539207458495,
      "memory(GiB)": 72.72,
      "step": 30325,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.829027142990393,
      "grad_norm": 3.6680662631988525,
      "learning_rate": 4.327445094332912e-06,
      "loss": 0.33641276359558103,
      "memory(GiB)": 72.72,
      "step": 30330,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 2.829493517395765,
      "grad_norm": 4.622939109802246,
      "learning_rate": 4.325916847848046e-06,
      "loss": 0.3575983762741089,
      "memory(GiB)": 72.72,
      "step": 30335,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 2.829959891801138,
      "grad_norm": 3.319155693054199,
      "learning_rate": 4.324388665500116e-06,
      "loss": 0.34043810367584226,
      "memory(GiB)": 72.72,
      "step": 30340,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 2.8304262662065107,
      "grad_norm": 3.501088857650757,
      "learning_rate": 4.322860547434523e-06,
      "loss": 0.365716814994812,
      "memory(GiB)": 72.72,
      "step": 30345,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.830892640611883,
      "grad_norm": 22.548147201538086,
      "learning_rate": 4.321332493796663e-06,
      "loss": 0.31453595161437986,
      "memory(GiB)": 72.72,
      "step": 30350,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.831359015017256,
      "grad_norm": 4.789967060089111,
      "learning_rate": 4.319804504731926e-06,
      "loss": 0.3490936756134033,
      "memory(GiB)": 72.72,
      "step": 30355,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 2.8318253894226286,
      "grad_norm": 2.6462597846984863,
      "learning_rate": 4.318276580385692e-06,
      "loss": 0.3371721744537354,
      "memory(GiB)": 72.72,
      "step": 30360,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.832291763828001,
      "grad_norm": 3.3008811473846436,
      "learning_rate": 4.316748720903344e-06,
      "loss": 0.3630023956298828,
      "memory(GiB)": 72.72,
      "step": 30365,
      "token_acc": 0.4264705882352941,
      "train_speed(iter/s)": 0.251277
    },
    {
      "epoch": 2.8327581382333737,
      "grad_norm": 2.2092156410217285,
      "learning_rate": 4.31522092643025e-06,
      "loss": 0.3314821720123291,
      "memory(GiB)": 72.72,
      "step": 30370,
      "token_acc": 0.7525252525252525,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 2.8332245126387465,
      "grad_norm": 4.678107261657715,
      "learning_rate": 4.313693197111776e-06,
      "loss": 0.31249403953552246,
      "memory(GiB)": 72.72,
      "step": 30375,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.833690887044119,
      "grad_norm": 10.753366470336914,
      "learning_rate": 4.31216553309328e-06,
      "loss": 0.313505220413208,
      "memory(GiB)": 72.72,
      "step": 30380,
      "train_speed(iter/s)": 0.251275
    },
    {
      "epoch": 2.8341572614494916,
      "grad_norm": 3.7640044689178467,
      "learning_rate": 4.310637934520114e-06,
      "loss": 0.3501989126205444,
      "memory(GiB)": 72.72,
      "step": 30385,
      "train_speed(iter/s)": 0.251275
    },
    {
      "epoch": 2.8346236358548644,
      "grad_norm": 5.185790061950684,
      "learning_rate": 4.309110401537625e-06,
      "loss": 0.32923173904418945,
      "memory(GiB)": 72.72,
      "step": 30390,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 2.8350900102602368,
      "grad_norm": 3.1796388626098633,
      "learning_rate": 4.307582934291151e-06,
      "loss": 0.3515974521636963,
      "memory(GiB)": 72.72,
      "step": 30395,
      "token_acc": 0.8125,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 2.8355563846656096,
      "grad_norm": 3.492271661758423,
      "learning_rate": 4.306055532926031e-06,
      "loss": 0.3826423645019531,
      "memory(GiB)": 72.72,
      "step": 30400,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 2.8360227590709823,
      "grad_norm": 4.58734655380249,
      "learning_rate": 4.304528197587587e-06,
      "loss": 0.3133018970489502,
      "memory(GiB)": 72.72,
      "step": 30405,
      "token_acc": 0.9885057471264368,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 2.8364891334763547,
      "grad_norm": 3.142625570297241,
      "learning_rate": 4.303000928421144e-06,
      "loss": 0.3444777011871338,
      "memory(GiB)": 72.72,
      "step": 30410,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 2.8369555078817275,
      "grad_norm": 8.488986015319824,
      "learning_rate": 4.3014737255720154e-06,
      "loss": 0.3442254066467285,
      "memory(GiB)": 72.72,
      "step": 30415,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 2.8374218822871002,
      "grad_norm": 3.266643524169922,
      "learning_rate": 4.299946589185509e-06,
      "loss": 0.3808842897415161,
      "memory(GiB)": 72.72,
      "step": 30420,
      "token_acc": 0.8282208588957055,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 2.8378882566924726,
      "grad_norm": 3.8489439487457275,
      "learning_rate": 4.298419519406929e-06,
      "loss": 0.3682387113571167,
      "memory(GiB)": 72.72,
      "step": 30425,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 2.8383546310978454,
      "grad_norm": 3.5652425289154053,
      "learning_rate": 4.296892516381569e-06,
      "loss": 0.3480983734130859,
      "memory(GiB)": 72.72,
      "step": 30430,
      "token_acc": 0.6296296296296297,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 2.838821005503218,
      "grad_norm": 2.4997267723083496,
      "learning_rate": 4.295365580254721e-06,
      "loss": 0.3248124599456787,
      "memory(GiB)": 72.72,
      "step": 30435,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 2.8392873799085905,
      "grad_norm": 2.4038515090942383,
      "learning_rate": 4.293838711171667e-06,
      "loss": 0.34012951850891116,
      "memory(GiB)": 72.72,
      "step": 30440,
      "token_acc": 0.6938775510204082,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 2.8397537543139633,
      "grad_norm": 2.634650230407715,
      "learning_rate": 4.292311909277686e-06,
      "loss": 0.3326472520828247,
      "memory(GiB)": 72.72,
      "step": 30445,
      "token_acc": 0.9263157894736842,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 2.840220128719336,
      "grad_norm": 2.420344114303589,
      "learning_rate": 4.290785174718045e-06,
      "loss": 0.3427713632583618,
      "memory(GiB)": 72.72,
      "step": 30450,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 2.8406865031247084,
      "grad_norm": 6.035646438598633,
      "learning_rate": 4.289258507638011e-06,
      "loss": 0.325182843208313,
      "memory(GiB)": 72.72,
      "step": 30455,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 2.841152877530081,
      "grad_norm": 3.77290415763855,
      "learning_rate": 4.287731908182839e-06,
      "loss": 0.32398509979248047,
      "memory(GiB)": 72.72,
      "step": 30460,
      "token_acc": 0.8783783783783784,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 2.8416192519354535,
      "grad_norm": 7.545928955078125,
      "learning_rate": 4.2862053764977815e-06,
      "loss": 0.33886051177978516,
      "memory(GiB)": 72.72,
      "step": 30465,
      "token_acc": 0.8037974683544303,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 2.8420856263408263,
      "grad_norm": 3.42733097076416,
      "learning_rate": 4.2846789127280845e-06,
      "loss": 0.34001452922821046,
      "memory(GiB)": 72.72,
      "step": 30470,
      "token_acc": 0.9316239316239316,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 2.842552000746199,
      "grad_norm": 4.0710649490356445,
      "learning_rate": 4.283152517018987e-06,
      "loss": 0.35219826698303225,
      "memory(GiB)": 72.72,
      "step": 30475,
      "token_acc": 0.6116504854368932,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.843018375151572,
      "grad_norm": 4.143843173980713,
      "learning_rate": 4.2816261895157175e-06,
      "loss": 0.33972463607788084,
      "memory(GiB)": 72.72,
      "step": 30480,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.843484749556944,
      "grad_norm": 4.516367435455322,
      "learning_rate": 4.280099930363504e-06,
      "loss": 0.3407094478607178,
      "memory(GiB)": 72.72,
      "step": 30485,
      "token_acc": 0.6326530612244898,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 2.843951123962317,
      "grad_norm": 14.053317070007324,
      "learning_rate": 4.278573739707564e-06,
      "loss": 0.38234858512878417,
      "memory(GiB)": 72.72,
      "step": 30490,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.8444174983676893,
      "grad_norm": 5.656529903411865,
      "learning_rate": 4.277047617693108e-06,
      "loss": 0.3314424991607666,
      "memory(GiB)": 72.72,
      "step": 30495,
      "token_acc": 0.7307692307692307,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.844883872773062,
      "grad_norm": 6.350353240966797,
      "learning_rate": 4.275521564465346e-06,
      "loss": 0.3472407341003418,
      "memory(GiB)": 72.72,
      "step": 30500,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.845350247178435,
      "grad_norm": 4.027939319610596,
      "learning_rate": 4.273995580169476e-06,
      "loss": 0.3511399030685425,
      "memory(GiB)": 72.72,
      "step": 30505,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 2.8458166215838077,
      "grad_norm": 2.831587314605713,
      "learning_rate": 4.272469664950689e-06,
      "loss": 0.32137470245361327,
      "memory(GiB)": 72.72,
      "step": 30510,
      "token_acc": 0.48,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.84628299598918,
      "grad_norm": 3.7956860065460205,
      "learning_rate": 4.270943818954172e-06,
      "loss": 0.33652267456054685,
      "memory(GiB)": 72.72,
      "step": 30515,
      "token_acc": 0.5306122448979592,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 2.846749370394553,
      "grad_norm": 2.580381155014038,
      "learning_rate": 4.269418042325105e-06,
      "loss": 0.35132875442504885,
      "memory(GiB)": 72.72,
      "step": 30520,
      "token_acc": 0.543859649122807,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 2.847215744799925,
      "grad_norm": 3.2064008712768555,
      "learning_rate": 4.267892335208661e-06,
      "loss": 0.3836060047149658,
      "memory(GiB)": 72.72,
      "step": 30525,
      "token_acc": 0.6956521739130435,
      "train_speed(iter/s)": 0.25129
    },
    {
      "epoch": 2.847682119205298,
      "grad_norm": 12.478206634521484,
      "learning_rate": 4.2663666977500055e-06,
      "loss": 0.34135448932647705,
      "memory(GiB)": 72.72,
      "step": 30530,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 2.8481484936106707,
      "grad_norm": 3.7291629314422607,
      "learning_rate": 4.264841130094299e-06,
      "loss": 0.34536123275756836,
      "memory(GiB)": 72.72,
      "step": 30535,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.8486148680160435,
      "grad_norm": 5.612085342407227,
      "learning_rate": 4.2633156323866945e-06,
      "loss": 0.3437335968017578,
      "memory(GiB)": 72.72,
      "step": 30540,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.849081242421416,
      "grad_norm": 3.2217724323272705,
      "learning_rate": 4.261790204772337e-06,
      "loss": 0.3355985164642334,
      "memory(GiB)": 72.72,
      "step": 30545,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.8495476168267886,
      "grad_norm": 5.818726062774658,
      "learning_rate": 4.26026484739637e-06,
      "loss": 0.3410283088684082,
      "memory(GiB)": 72.72,
      "step": 30550,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.850013991232161,
      "grad_norm": 5.3497796058654785,
      "learning_rate": 4.258739560403923e-06,
      "loss": 0.35429160594940184,
      "memory(GiB)": 72.72,
      "step": 30555,
      "token_acc": 0.7777777777777778,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.8504803656375337,
      "grad_norm": 3.3000903129577637,
      "learning_rate": 4.257214343940122e-06,
      "loss": 0.3303215980529785,
      "memory(GiB)": 72.72,
      "step": 30560,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 2.8509467400429065,
      "grad_norm": 2.748206615447998,
      "learning_rate": 4.255689198150087e-06,
      "loss": 0.35036425590515136,
      "memory(GiB)": 72.72,
      "step": 30565,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.8514131144482793,
      "grad_norm": 3.7872700691223145,
      "learning_rate": 4.2541641231789334e-06,
      "loss": 0.3193584680557251,
      "memory(GiB)": 72.72,
      "step": 30570,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.8518794888536516,
      "grad_norm": 2.9048733711242676,
      "learning_rate": 4.252639119171767e-06,
      "loss": 0.3759875774383545,
      "memory(GiB)": 72.72,
      "step": 30575,
      "train_speed(iter/s)": 0.251299
    },
    {
      "epoch": 2.8523458632590244,
      "grad_norm": 3.78741717338562,
      "learning_rate": 4.251114186273685e-06,
      "loss": 0.30937354564666747,
      "memory(GiB)": 72.72,
      "step": 30580,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.8528122376643967,
      "grad_norm": 4.233058929443359,
      "learning_rate": 4.2495893246297815e-06,
      "loss": 0.3149528980255127,
      "memory(GiB)": 72.72,
      "step": 30585,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.8532786120697695,
      "grad_norm": 3.283640146255493,
      "learning_rate": 4.248064534385142e-06,
      "loss": 0.3693362236022949,
      "memory(GiB)": 72.72,
      "step": 30590,
      "token_acc": 0.6086956521739131,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 2.8537449864751423,
      "grad_norm": 3.981727123260498,
      "learning_rate": 4.246539815684844e-06,
      "loss": 0.35409107208251955,
      "memory(GiB)": 72.72,
      "step": 30595,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 2.854211360880515,
      "grad_norm": 2.6732475757598877,
      "learning_rate": 4.245015168673963e-06,
      "loss": 0.31593947410583495,
      "memory(GiB)": 72.72,
      "step": 30600,
      "token_acc": 0.6619718309859155,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.8546777352858874,
      "grad_norm": 2.622987985610962,
      "learning_rate": 4.2434905934975634e-06,
      "loss": 0.30660300254821776,
      "memory(GiB)": 72.72,
      "step": 30605,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 2.85514410969126,
      "grad_norm": 3.2745654582977295,
      "learning_rate": 4.2419660903007024e-06,
      "loss": 0.33823509216308595,
      "memory(GiB)": 72.72,
      "step": 30610,
      "train_speed(iter/s)": 0.251297
    },
    {
      "epoch": 2.8556104840966325,
      "grad_norm": 2.743288278579712,
      "learning_rate": 4.2404416592284335e-06,
      "loss": 0.3835474967956543,
      "memory(GiB)": 72.72,
      "step": 30615,
      "train_speed(iter/s)": 0.251298
    },
    {
      "epoch": 2.8560768585020053,
      "grad_norm": 3.1405396461486816,
      "learning_rate": 4.238917300425801e-06,
      "loss": 0.3405085802078247,
      "memory(GiB)": 72.72,
      "step": 30620,
      "train_speed(iter/s)": 0.251301
    },
    {
      "epoch": 2.856543232907378,
      "grad_norm": 4.595828056335449,
      "learning_rate": 4.237393014037842e-06,
      "loss": 0.3175063133239746,
      "memory(GiB)": 72.72,
      "step": 30625,
      "token_acc": 0.9572649572649573,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 2.857009607312751,
      "grad_norm": 3.4174304008483887,
      "learning_rate": 4.235868800209587e-06,
      "loss": 0.3205989599227905,
      "memory(GiB)": 72.72,
      "step": 30630,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 2.8574759817181232,
      "grad_norm": 14.38265323638916,
      "learning_rate": 4.234344659086063e-06,
      "loss": 0.3441036224365234,
      "memory(GiB)": 72.72,
      "step": 30635,
      "token_acc": 0.44642857142857145,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 2.857942356123496,
      "grad_norm": 4.563422679901123,
      "learning_rate": 4.2328205908122875e-06,
      "loss": 0.3573976755142212,
      "memory(GiB)": 72.72,
      "step": 30640,
      "token_acc": 0.6233766233766234,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.8584087305288683,
      "grad_norm": 3.831824779510498,
      "learning_rate": 4.231296595533268e-06,
      "loss": 0.32470548152923584,
      "memory(GiB)": 72.72,
      "step": 30645,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 2.858875104934241,
      "grad_norm": 2.856562376022339,
      "learning_rate": 4.22977267339401e-06,
      "loss": 0.34316246509552,
      "memory(GiB)": 72.72,
      "step": 30650,
      "token_acc": 0.7866666666666666,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 2.859341479339614,
      "grad_norm": 3.6227200031280518,
      "learning_rate": 4.2282488245395105e-06,
      "loss": 0.36654999256134035,
      "memory(GiB)": 72.72,
      "step": 30655,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 2.8598078537449867,
      "grad_norm": 3.055536985397339,
      "learning_rate": 4.226725049114756e-06,
      "loss": 0.32962894439697266,
      "memory(GiB)": 72.72,
      "step": 30660,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 2.860274228150359,
      "grad_norm": 3.137019157409668,
      "learning_rate": 4.22520134726473e-06,
      "loss": 0.3467054605484009,
      "memory(GiB)": 72.72,
      "step": 30665,
      "train_speed(iter/s)": 0.25132
    },
    {
      "epoch": 2.860740602555732,
      "grad_norm": 3.7268450260162354,
      "learning_rate": 4.223677719134411e-06,
      "loss": 0.3255991220474243,
      "memory(GiB)": 72.72,
      "step": 30670,
      "train_speed(iter/s)": 0.25132
    },
    {
      "epoch": 2.861206976961104,
      "grad_norm": 3.1800918579101562,
      "learning_rate": 4.2221541648687654e-06,
      "loss": 0.33069162368774413,
      "memory(GiB)": 72.72,
      "step": 30675,
      "train_speed(iter/s)": 0.251321
    },
    {
      "epoch": 2.861673351366477,
      "grad_norm": 5.325164794921875,
      "learning_rate": 4.2206306846127544e-06,
      "loss": 0.3611420154571533,
      "memory(GiB)": 72.72,
      "step": 30680,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 2.8621397257718497,
      "grad_norm": 3.025430679321289,
      "learning_rate": 4.219107278511333e-06,
      "loss": 0.35997576713562013,
      "memory(GiB)": 72.72,
      "step": 30685,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 2.8626061001772225,
      "grad_norm": 3.4105279445648193,
      "learning_rate": 4.217583946709448e-06,
      "loss": 0.34062533378601073,
      "memory(GiB)": 72.72,
      "step": 30690,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 2.863072474582595,
      "grad_norm": 2.786896228790283,
      "learning_rate": 4.216060689352041e-06,
      "loss": 0.31851966381073,
      "memory(GiB)": 72.72,
      "step": 30695,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 2.8635388489879676,
      "grad_norm": 2.389619827270508,
      "learning_rate": 4.214537506584042e-06,
      "loss": 0.328851580619812,
      "memory(GiB)": 72.72,
      "step": 30700,
      "token_acc": 0.5689655172413793,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 2.86400522339334,
      "grad_norm": 3.4941704273223877,
      "learning_rate": 4.213014398550382e-06,
      "loss": 0.31205790042877196,
      "memory(GiB)": 72.72,
      "step": 30705,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 2.8644715977987127,
      "grad_norm": 4.832429885864258,
      "learning_rate": 4.211491365395977e-06,
      "loss": 0.3686148881912231,
      "memory(GiB)": 72.72,
      "step": 30710,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 2.8649379722040855,
      "grad_norm": 2.907616376876831,
      "learning_rate": 4.20996840726574e-06,
      "loss": 0.30209836959838865,
      "memory(GiB)": 72.72,
      "step": 30715,
      "token_acc": 0.6727272727272727,
      "train_speed(iter/s)": 0.251332
    },
    {
      "epoch": 2.8654043466094583,
      "grad_norm": 5.0132060050964355,
      "learning_rate": 4.208445524304575e-06,
      "loss": 0.37116475105285646,
      "memory(GiB)": 72.72,
      "step": 30720,
      "token_acc": 0.7611940298507462,
      "train_speed(iter/s)": 0.251331
    },
    {
      "epoch": 2.8658707210148306,
      "grad_norm": 2.9386138916015625,
      "learning_rate": 4.20692271665738e-06,
      "loss": 0.287088680267334,
      "memory(GiB)": 72.72,
      "step": 30725,
      "train_speed(iter/s)": 0.251332
    },
    {
      "epoch": 2.8663370954202034,
      "grad_norm": 3.633090019226074,
      "learning_rate": 4.205399984469046e-06,
      "loss": 0.34770357608795166,
      "memory(GiB)": 72.72,
      "step": 30730,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.8668034698255758,
      "grad_norm": 6.508918285369873,
      "learning_rate": 4.2038773278844524e-06,
      "loss": 0.3464647769927979,
      "memory(GiB)": 72.72,
      "step": 30735,
      "token_acc": 0.5972222222222222,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 2.8672698442309486,
      "grad_norm": 3.0142955780029297,
      "learning_rate": 4.202354747048481e-06,
      "loss": 0.33466854095458987,
      "memory(GiB)": 72.72,
      "step": 30740,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 2.8677362186363213,
      "grad_norm": 1.9307504892349243,
      "learning_rate": 4.200832242105998e-06,
      "loss": 0.3697678089141846,
      "memory(GiB)": 72.72,
      "step": 30745,
      "token_acc": 0.7785234899328859,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 2.868202593041694,
      "grad_norm": 3.459617853164673,
      "learning_rate": 4.199309813201867e-06,
      "loss": 0.3493955612182617,
      "memory(GiB)": 72.72,
      "step": 30750,
      "train_speed(iter/s)": 0.251336
    },
    {
      "epoch": 2.8686689674470665,
      "grad_norm": 3.1534478664398193,
      "learning_rate": 4.197787460480939e-06,
      "loss": 0.34203214645385743,
      "memory(GiB)": 72.72,
      "step": 30755,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.251338
    },
    {
      "epoch": 2.8691353418524392,
      "grad_norm": 2.820608615875244,
      "learning_rate": 4.196265184088063e-06,
      "loss": 0.37032437324523926,
      "memory(GiB)": 72.72,
      "step": 30760,
      "train_speed(iter/s)": 0.251336
    },
    {
      "epoch": 2.8696017162578116,
      "grad_norm": 2.6122047901153564,
      "learning_rate": 4.194742984168077e-06,
      "loss": 0.29273500442504885,
      "memory(GiB)": 72.72,
      "step": 30765,
      "token_acc": 0.9659090909090909,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.8700680906631844,
      "grad_norm": 3.043544054031372,
      "learning_rate": 4.193220860865817e-06,
      "loss": 0.3212575912475586,
      "memory(GiB)": 72.72,
      "step": 30770,
      "train_speed(iter/s)": 0.251332
    },
    {
      "epoch": 2.870534465068557,
      "grad_norm": 3.1755025386810303,
      "learning_rate": 4.191698814326108e-06,
      "loss": 0.34384660720825194,
      "memory(GiB)": 72.72,
      "step": 30775,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 2.87100083947393,
      "grad_norm": 2.8705809116363525,
      "learning_rate": 4.190176844693765e-06,
      "loss": 0.35879154205322267,
      "memory(GiB)": 72.72,
      "step": 30780,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 2.8714672138793023,
      "grad_norm": 5.344146251678467,
      "learning_rate": 4.188654952113602e-06,
      "loss": 0.33624083995819093,
      "memory(GiB)": 72.72,
      "step": 30785,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.871933588284675,
      "grad_norm": 13.630156517028809,
      "learning_rate": 4.187133136730419e-06,
      "loss": 0.33547229766845704,
      "memory(GiB)": 72.72,
      "step": 30790,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 2.8723999626900474,
      "grad_norm": 3.3138208389282227,
      "learning_rate": 4.185611398689016e-06,
      "loss": 0.35007171630859374,
      "memory(GiB)": 72.72,
      "step": 30795,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.87286633709542,
      "grad_norm": 2.385441303253174,
      "learning_rate": 4.184089738134177e-06,
      "loss": 0.3292075157165527,
      "memory(GiB)": 72.72,
      "step": 30800,
      "train_speed(iter/s)": 0.251331
    },
    {
      "epoch": 2.873332711500793,
      "grad_norm": 2.844397783279419,
      "learning_rate": 4.182568155210688e-06,
      "loss": 0.34242897033691405,
      "memory(GiB)": 72.72,
      "step": 30805,
      "token_acc": 0.9565217391304348,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.8737990859061657,
      "grad_norm": 4.050858974456787,
      "learning_rate": 4.181046650063321e-06,
      "loss": 0.3513331890106201,
      "memory(GiB)": 72.72,
      "step": 30810,
      "train_speed(iter/s)": 0.251337
    },
    {
      "epoch": 2.874265460311538,
      "grad_norm": 5.147119045257568,
      "learning_rate": 4.179525222836841e-06,
      "loss": 0.3276527404785156,
      "memory(GiB)": 72.72,
      "step": 30815,
      "token_acc": 0.7777777777777778,
      "train_speed(iter/s)": 0.251335
    },
    {
      "epoch": 2.874731834716911,
      "grad_norm": 4.0757341384887695,
      "learning_rate": 4.17800387367601e-06,
      "loss": 0.3516291856765747,
      "memory(GiB)": 72.72,
      "step": 30820,
      "token_acc": 0.5157894736842106,
      "train_speed(iter/s)": 0.251338
    },
    {
      "epoch": 2.875198209122283,
      "grad_norm": 3.470755100250244,
      "learning_rate": 4.176482602725578e-06,
      "loss": 0.3481533288955688,
      "memory(GiB)": 72.72,
      "step": 30825,
      "token_acc": 0.6206896551724138,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 2.875664583527656,
      "grad_norm": 3.1145005226135254,
      "learning_rate": 4.17496141013029e-06,
      "loss": 0.35878286361694334,
      "memory(GiB)": 72.72,
      "step": 30830,
      "token_acc": 0.8,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 2.8761309579330288,
      "grad_norm": 3.5776660442352295,
      "learning_rate": 4.1734402960348785e-06,
      "loss": 0.3254669189453125,
      "memory(GiB)": 72.72,
      "step": 30835,
      "token_acc": 0.676923076923077,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 2.8765973323384015,
      "grad_norm": 5.532484531402588,
      "learning_rate": 4.17191926058408e-06,
      "loss": 0.3565086841583252,
      "memory(GiB)": 72.72,
      "step": 30840,
      "train_speed(iter/s)": 0.251341
    },
    {
      "epoch": 2.877063706743774,
      "grad_norm": 3.4265291690826416,
      "learning_rate": 4.170398303922612e-06,
      "loss": 0.30067930221557615,
      "memory(GiB)": 72.72,
      "step": 30845,
      "token_acc": 0.6323529411764706,
      "train_speed(iter/s)": 0.251338
    },
    {
      "epoch": 2.8775300811491467,
      "grad_norm": 2.8699045181274414,
      "learning_rate": 4.168877426195191e-06,
      "loss": 0.32763209342956545,
      "memory(GiB)": 72.72,
      "step": 30850,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 2.877996455554519,
      "grad_norm": 3.6562817096710205,
      "learning_rate": 4.167356627546521e-06,
      "loss": 0.3478665351867676,
      "memory(GiB)": 72.72,
      "step": 30855,
      "token_acc": 0.7058823529411765,
      "train_speed(iter/s)": 0.251337
    },
    {
      "epoch": 2.8784628299598918,
      "grad_norm": 4.333998680114746,
      "learning_rate": 4.165835908121304e-06,
      "loss": 0.32768056392669676,
      "memory(GiB)": 72.72,
      "step": 30860,
      "train_speed(iter/s)": 0.251338
    },
    {
      "epoch": 2.8789292043652646,
      "grad_norm": 5.249650478363037,
      "learning_rate": 4.16431526806423e-06,
      "loss": 0.35207223892211914,
      "memory(GiB)": 72.72,
      "step": 30865,
      "train_speed(iter/s)": 0.251337
    },
    {
      "epoch": 2.8793955787706373,
      "grad_norm": 2.9974770545959473,
      "learning_rate": 4.162794707519982e-06,
      "loss": 0.3423463344573975,
      "memory(GiB)": 72.72,
      "step": 30870,
      "train_speed(iter/s)": 0.251338
    },
    {
      "epoch": 2.8798619531760097,
      "grad_norm": 3.979602813720703,
      "learning_rate": 4.161274226633242e-06,
      "loss": 0.3250056266784668,
      "memory(GiB)": 72.72,
      "step": 30875,
      "token_acc": 0.47368421052631576,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 2.8803283275813825,
      "grad_norm": 4.075338840484619,
      "learning_rate": 4.159753825548673e-06,
      "loss": 0.3531042575836182,
      "memory(GiB)": 72.72,
      "step": 30880,
      "token_acc": 0.6744186046511628,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 2.880794701986755,
      "grad_norm": 4.355917930603027,
      "learning_rate": 4.15823350441094e-06,
      "loss": 0.34064857959747313,
      "memory(GiB)": 72.72,
      "step": 30885,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 2.8812610763921276,
      "grad_norm": 3.086944818496704,
      "learning_rate": 4.156713263364696e-06,
      "loss": 0.32955188751220704,
      "memory(GiB)": 72.72,
      "step": 30890,
      "train_speed(iter/s)": 0.25134
    },
    {
      "epoch": 2.8817274507975004,
      "grad_norm": 4.7493181228637695,
      "learning_rate": 4.155193102554587e-06,
      "loss": 0.2844785451889038,
      "memory(GiB)": 72.72,
      "step": 30895,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 2.8821938252028727,
      "grad_norm": 2.8364577293395996,
      "learning_rate": 4.153673022125252e-06,
      "loss": 0.33354954719543456,
      "memory(GiB)": 72.72,
      "step": 30900,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 2.8826601996082455,
      "grad_norm": 2.7569522857666016,
      "learning_rate": 4.152153022221321e-06,
      "loss": 0.3219768047332764,
      "memory(GiB)": 72.72,
      "step": 30905,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 2.8831265740136183,
      "grad_norm": 3.0061957836151123,
      "learning_rate": 4.150633102987418e-06,
      "loss": 0.35203943252563474,
      "memory(GiB)": 72.72,
      "step": 30910,
      "token_acc": 0.7696969696969697,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 2.8835929484189906,
      "grad_norm": 3.006525993347168,
      "learning_rate": 4.14911326456816e-06,
      "loss": 0.3419419050216675,
      "memory(GiB)": 72.72,
      "step": 30915,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 2.8840593228243634,
      "grad_norm": 5.299825191497803,
      "learning_rate": 4.147593507108153e-06,
      "loss": 0.3400630235671997,
      "memory(GiB)": 72.72,
      "step": 30920,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 2.884525697229736,
      "grad_norm": 13.231324195861816,
      "learning_rate": 4.1460738307519985e-06,
      "loss": 0.3540734529495239,
      "memory(GiB)": 72.72,
      "step": 30925,
      "token_acc": 0.5125,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 2.8849920716351085,
      "grad_norm": 2.584887981414795,
      "learning_rate": 4.144554235644288e-06,
      "loss": 0.3421370029449463,
      "memory(GiB)": 72.72,
      "step": 30930,
      "token_acc": 0.96,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.8854584460404813,
      "grad_norm": 3.39151668548584,
      "learning_rate": 4.143034721929605e-06,
      "loss": 0.3589600086212158,
      "memory(GiB)": 72.72,
      "step": 30935,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 2.885924820445854,
      "grad_norm": 2.542048454284668,
      "learning_rate": 4.14151528975253e-06,
      "loss": 0.3178516387939453,
      "memory(GiB)": 72.72,
      "step": 30940,
      "token_acc": 0.5849056603773585,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 2.8863911948512264,
      "grad_norm": 2.178359270095825,
      "learning_rate": 4.139995939257631e-06,
      "loss": 0.3255162715911865,
      "memory(GiB)": 72.72,
      "step": 30945,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 2.886857569256599,
      "grad_norm": 2.0693812370300293,
      "learning_rate": 4.138476670589469e-06,
      "loss": 0.324905252456665,
      "memory(GiB)": 72.72,
      "step": 30950,
      "token_acc": 0.5161290322580645,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 2.887323943661972,
      "grad_norm": 2.4819719791412354,
      "learning_rate": 4.136957483892598e-06,
      "loss": 0.33238327503204346,
      "memory(GiB)": 72.72,
      "step": 30955,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.8877903180673443,
      "grad_norm": 4.430922031402588,
      "learning_rate": 4.135438379311562e-06,
      "loss": 0.33684067726135253,
      "memory(GiB)": 72.72,
      "step": 30960,
      "token_acc": 0.6764705882352942,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.888256692472717,
      "grad_norm": 2.897779941558838,
      "learning_rate": 4.133919356990902e-06,
      "loss": 0.3252614259719849,
      "memory(GiB)": 72.72,
      "step": 30965,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.88872306687809,
      "grad_norm": 3.7130892276763916,
      "learning_rate": 4.132400417075147e-06,
      "loss": 0.35717291831970216,
      "memory(GiB)": 72.72,
      "step": 30970,
      "token_acc": 0.6341463414634146,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 2.8891894412834622,
      "grad_norm": 3.7887673377990723,
      "learning_rate": 4.1308815597088194e-06,
      "loss": 0.33970255851745607,
      "memory(GiB)": 72.72,
      "step": 30975,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.889655815688835,
      "grad_norm": 7.821885585784912,
      "learning_rate": 4.129362785036434e-06,
      "loss": 0.35702598094940186,
      "memory(GiB)": 72.72,
      "step": 30980,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.890122190094208,
      "grad_norm": 4.583281993865967,
      "learning_rate": 4.127844093202498e-06,
      "loss": 0.3370589971542358,
      "memory(GiB)": 72.72,
      "step": 30985,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.89058856449958,
      "grad_norm": 2.938847541809082,
      "learning_rate": 4.12632548435151e-06,
      "loss": 0.37334365844726564,
      "memory(GiB)": 72.72,
      "step": 30990,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.891054938904953,
      "grad_norm": 3.746500253677368,
      "learning_rate": 4.1248069586279605e-06,
      "loss": 0.3402383804321289,
      "memory(GiB)": 72.72,
      "step": 30995,
      "token_acc": 0.6938775510204082,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 2.8915213133103257,
      "grad_norm": 3.4810538291931152,
      "learning_rate": 4.123288516176332e-06,
      "loss": 0.3457975387573242,
      "memory(GiB)": 72.72,
      "step": 31000,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.891987687715698,
      "grad_norm": 7.918254852294922,
      "learning_rate": 4.121770157141101e-06,
      "loss": 0.330091667175293,
      "memory(GiB)": 72.72,
      "step": 31005,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 2.892454062121071,
      "grad_norm": 2.834739923477173,
      "learning_rate": 4.120251881666734e-06,
      "loss": 0.33195807933807375,
      "memory(GiB)": 72.72,
      "step": 31010,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 2.8929204365264436,
      "grad_norm": 3.403606653213501,
      "learning_rate": 4.11873368989769e-06,
      "loss": 0.3202119112014771,
      "memory(GiB)": 72.72,
      "step": 31015,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 2.893386810931816,
      "grad_norm": 3.213080644607544,
      "learning_rate": 4.117215581978421e-06,
      "loss": 0.33479526042938235,
      "memory(GiB)": 72.72,
      "step": 31020,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 2.8938531853371887,
      "grad_norm": 2.179025411605835,
      "learning_rate": 4.115697558053372e-06,
      "loss": 0.35019550323486326,
      "memory(GiB)": 72.72,
      "step": 31025,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 2.894319559742561,
      "grad_norm": 5.433759689331055,
      "learning_rate": 4.114179618266974e-06,
      "loss": 0.37001571655273435,
      "memory(GiB)": 72.72,
      "step": 31030,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 2.894785934147934,
      "grad_norm": 3.3414549827575684,
      "learning_rate": 4.1126617627636566e-06,
      "loss": 0.35096240043640137,
      "memory(GiB)": 72.72,
      "step": 31035,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 2.8952523085533066,
      "grad_norm": 3.2553131580352783,
      "learning_rate": 4.111143991687837e-06,
      "loss": 0.34120566844940187,
      "memory(GiB)": 72.72,
      "step": 31040,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 2.8957186829586794,
      "grad_norm": 3.3164007663726807,
      "learning_rate": 4.109626305183931e-06,
      "loss": 0.3282632350921631,
      "memory(GiB)": 72.72,
      "step": 31045,
      "train_speed(iter/s)": 0.251338
    },
    {
      "epoch": 2.8961850573640517,
      "grad_norm": 4.073392391204834,
      "learning_rate": 4.108108703396338e-06,
      "loss": 0.34166955947875977,
      "memory(GiB)": 72.72,
      "step": 31050,
      "token_acc": 0.6458333333333334,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 2.8966514317694245,
      "grad_norm": 5.440288543701172,
      "learning_rate": 4.106591186469456e-06,
      "loss": 0.36042749881744385,
      "memory(GiB)": 72.72,
      "step": 31055,
      "token_acc": 0.7298578199052133,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 2.897117806174797,
      "grad_norm": 2.818441390991211,
      "learning_rate": 4.10507375454767e-06,
      "loss": 0.31780009269714354,
      "memory(GiB)": 72.72,
      "step": 31060,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 2.8975841805801696,
      "grad_norm": 2.879702091217041,
      "learning_rate": 4.103556407775358e-06,
      "loss": 0.3771359920501709,
      "memory(GiB)": 72.72,
      "step": 31065,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 2.8980505549855424,
      "grad_norm": 3.1634459495544434,
      "learning_rate": 4.102039146296892e-06,
      "loss": 0.33347468376159667,
      "memory(GiB)": 72.72,
      "step": 31070,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 2.898516929390915,
      "grad_norm": 3.7133524417877197,
      "learning_rate": 4.1005219702566356e-06,
      "loss": 0.32093794345855714,
      "memory(GiB)": 72.72,
      "step": 31075,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 2.8989833037962875,
      "grad_norm": 2.6565468311309814,
      "learning_rate": 4.099004879798943e-06,
      "loss": 0.31531429290771484,
      "memory(GiB)": 72.72,
      "step": 31080,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 2.8994496782016603,
      "grad_norm": 4.446159839630127,
      "learning_rate": 4.097487875068161e-06,
      "loss": 0.33634066581726074,
      "memory(GiB)": 72.72,
      "step": 31085,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 2.8999160526070327,
      "grad_norm": 2.5852129459381104,
      "learning_rate": 4.095970956208627e-06,
      "loss": 0.3317551612854004,
      "memory(GiB)": 72.72,
      "step": 31090,
      "token_acc": 0.6829268292682927,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 2.9003824270124055,
      "grad_norm": 2.825770616531372,
      "learning_rate": 4.0944541233646715e-06,
      "loss": 0.31788589954376223,
      "memory(GiB)": 72.72,
      "step": 31095,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 2.9008488014177782,
      "grad_norm": 5.097562313079834,
      "learning_rate": 4.092937376680617e-06,
      "loss": 0.36031599044799806,
      "memory(GiB)": 72.72,
      "step": 31100,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 2.901315175823151,
      "grad_norm": 4.418497562408447,
      "learning_rate": 4.091420716300776e-06,
      "loss": 0.35679068565368655,
      "memory(GiB)": 72.72,
      "step": 31105,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 2.9017815502285234,
      "grad_norm": 2.6861934661865234,
      "learning_rate": 4.089904142369455e-06,
      "loss": 0.32123403549194335,
      "memory(GiB)": 72.72,
      "step": 31110,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 2.902247924633896,
      "grad_norm": 3.7521345615386963,
      "learning_rate": 4.088387655030952e-06,
      "loss": 0.30272464752197265,
      "memory(GiB)": 72.72,
      "step": 31115,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 2.9027142990392685,
      "grad_norm": 9.983558654785156,
      "learning_rate": 4.086871254429555e-06,
      "loss": 0.351125431060791,
      "memory(GiB)": 72.72,
      "step": 31120,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 2.9031806734446413,
      "grad_norm": 4.4721574783325195,
      "learning_rate": 4.085354940709546e-06,
      "loss": 0.3566657543182373,
      "memory(GiB)": 72.72,
      "step": 31125,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 2.903647047850014,
      "grad_norm": 2.544929265975952,
      "learning_rate": 4.083838714015196e-06,
      "loss": 0.3273369789123535,
      "memory(GiB)": 72.72,
      "step": 31130,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 2.904113422255387,
      "grad_norm": 3.2055184841156006,
      "learning_rate": 4.08232257449077e-06,
      "loss": 0.3305467128753662,
      "memory(GiB)": 72.72,
      "step": 31135,
      "token_acc": 0.7733333333333333,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 2.904579796660759,
      "grad_norm": 4.556095600128174,
      "learning_rate": 4.080806522280523e-06,
      "loss": 0.33973782062530516,
      "memory(GiB)": 72.72,
      "step": 31140,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 2.905046171066132,
      "grad_norm": 2.28912091255188,
      "learning_rate": 4.079290557528706e-06,
      "loss": 0.3255443572998047,
      "memory(GiB)": 72.72,
      "step": 31145,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 2.9055125454715043,
      "grad_norm": 3.018714427947998,
      "learning_rate": 4.077774680379554e-06,
      "loss": 0.3365973472595215,
      "memory(GiB)": 72.72,
      "step": 31150,
      "token_acc": 0.8412698412698413,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 2.905978919876877,
      "grad_norm": 2.768188714981079,
      "learning_rate": 4.0762588909773015e-06,
      "loss": 0.33164842128753663,
      "memory(GiB)": 72.72,
      "step": 31155,
      "token_acc": 0.5526315789473685,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 2.90644529428225,
      "grad_norm": 2.8347647190093994,
      "learning_rate": 4.07474318946617e-06,
      "loss": 0.31780614852905276,
      "memory(GiB)": 72.72,
      "step": 31160,
      "token_acc": 0.9529411764705882,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 2.9069116686876226,
      "grad_norm": 3.2822699546813965,
      "learning_rate": 4.073227575990373e-06,
      "loss": 0.3502481698989868,
      "memory(GiB)": 72.72,
      "step": 31165,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 2.907378043092995,
      "grad_norm": 17.366247177124023,
      "learning_rate": 4.071712050694117e-06,
      "loss": 0.38190417289733886,
      "memory(GiB)": 72.72,
      "step": 31170,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 2.9078444174983678,
      "grad_norm": 4.195674896240234,
      "learning_rate": 4.070196613721599e-06,
      "loss": 0.3414579391479492,
      "memory(GiB)": 72.72,
      "step": 31175,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.90831079190374,
      "grad_norm": 7.458273887634277,
      "learning_rate": 4.0686812652170105e-06,
      "loss": 0.3517699956893921,
      "memory(GiB)": 72.72,
      "step": 31180,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 2.908777166309113,
      "grad_norm": 4.4940505027771,
      "learning_rate": 4.06716600532453e-06,
      "loss": 0.32908406257629397,
      "memory(GiB)": 72.72,
      "step": 31185,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 2.9092435407144857,
      "grad_norm": 5.062862396240234,
      "learning_rate": 4.06565083418833e-06,
      "loss": 0.33006939888000486,
      "memory(GiB)": 72.72,
      "step": 31190,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 2.9097099151198584,
      "grad_norm": 3.6559243202209473,
      "learning_rate": 4.064135751952576e-06,
      "loss": 0.31478147506713866,
      "memory(GiB)": 72.72,
      "step": 31195,
      "token_acc": 0.7777777777777778,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 2.9101762895252308,
      "grad_norm": 3.258939504623413,
      "learning_rate": 4.062620758761422e-06,
      "loss": 0.35686383247375486,
      "memory(GiB)": 72.72,
      "step": 31200,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 2.9106426639306036,
      "grad_norm": 2.9260191917419434,
      "learning_rate": 4.0611058547590154e-06,
      "loss": 0.35910377502441404,
      "memory(GiB)": 72.72,
      "step": 31205,
      "token_acc": 0.49056603773584906,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 2.911109038335976,
      "grad_norm": 2.594672679901123,
      "learning_rate": 4.059591040089491e-06,
      "loss": 0.30503015518188475,
      "memory(GiB)": 72.72,
      "step": 31210,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.9115754127413487,
      "grad_norm": 3.788734197616577,
      "learning_rate": 4.058076314896985e-06,
      "loss": 0.3358497619628906,
      "memory(GiB)": 72.72,
      "step": 31215,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.9120417871467215,
      "grad_norm": 2.570361375808716,
      "learning_rate": 4.056561679325615e-06,
      "loss": 0.32021474838256836,
      "memory(GiB)": 72.72,
      "step": 31220,
      "token_acc": 0.8347107438016529,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.9125081615520942,
      "grad_norm": 3.3817007541656494,
      "learning_rate": 4.055047133519497e-06,
      "loss": 0.401473331451416,
      "memory(GiB)": 72.72,
      "step": 31225,
      "token_acc": 0.968421052631579,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 2.9129745359574666,
      "grad_norm": 5.258251190185547,
      "learning_rate": 4.053532677622733e-06,
      "loss": 0.3375916242599487,
      "memory(GiB)": 72.72,
      "step": 31230,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 2.9134409103628394,
      "grad_norm": 3.616968870162964,
      "learning_rate": 4.052018311779417e-06,
      "loss": 0.38422508239746095,
      "memory(GiB)": 72.72,
      "step": 31235,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 2.9139072847682117,
      "grad_norm": 2.686783790588379,
      "learning_rate": 4.0505040361336375e-06,
      "loss": 0.33704557418823244,
      "memory(GiB)": 72.72,
      "step": 31240,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 2.9143736591735845,
      "grad_norm": 5.097743034362793,
      "learning_rate": 4.048989850829476e-06,
      "loss": 0.3136005878448486,
      "memory(GiB)": 72.72,
      "step": 31245,
      "token_acc": 0.5824175824175825,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 2.9148400335789573,
      "grad_norm": 2.837498188018799,
      "learning_rate": 4.047475756011001e-06,
      "loss": 0.28190436363220217,
      "memory(GiB)": 72.72,
      "step": 31250,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 2.91530640798433,
      "grad_norm": 4.036959171295166,
      "learning_rate": 4.045961751822273e-06,
      "loss": 0.34918813705444335,
      "memory(GiB)": 72.72,
      "step": 31255,
      "token_acc": 0.5918367346938775,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 2.9157727823897024,
      "grad_norm": 6.20485782623291,
      "learning_rate": 4.044447838407345e-06,
      "loss": 0.33925719261169435,
      "memory(GiB)": 72.72,
      "step": 31260,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 2.916239156795075,
      "grad_norm": 3.7540857791900635,
      "learning_rate": 4.0429340159102615e-06,
      "loss": 0.35436253547668456,
      "memory(GiB)": 72.72,
      "step": 31265,
      "token_acc": 0.5223880597014925,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 2.9167055312004475,
      "grad_norm": 2.1847996711730957,
      "learning_rate": 4.041420284475059e-06,
      "loss": 0.31689703464508057,
      "memory(GiB)": 72.72,
      "step": 31270,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 2.9171719056058203,
      "grad_norm": 60.32661819458008,
      "learning_rate": 4.039906644245761e-06,
      "loss": 0.308486008644104,
      "memory(GiB)": 72.72,
      "step": 31275,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 2.917638280011193,
      "grad_norm": 2.82241153717041,
      "learning_rate": 4.038393095366389e-06,
      "loss": 0.3274137735366821,
      "memory(GiB)": 72.72,
      "step": 31280,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 2.918104654416566,
      "grad_norm": 4.943103313446045,
      "learning_rate": 4.036879637980953e-06,
      "loss": 0.37169589996337893,
      "memory(GiB)": 72.72,
      "step": 31285,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 2.918571028821938,
      "grad_norm": 17.872852325439453,
      "learning_rate": 4.035366272233452e-06,
      "loss": 0.3433692455291748,
      "memory(GiB)": 72.72,
      "step": 31290,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 2.919037403227311,
      "grad_norm": 3.4988884925842285,
      "learning_rate": 4.033852998267878e-06,
      "loss": 0.3069987058639526,
      "memory(GiB)": 72.72,
      "step": 31295,
      "token_acc": 0.7719298245614035,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 2.9195037776326833,
      "grad_norm": 6.594586372375488,
      "learning_rate": 4.032339816228217e-06,
      "loss": 0.3200898885726929,
      "memory(GiB)": 72.72,
      "step": 31300,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 2.919970152038056,
      "grad_norm": 2.9811863899230957,
      "learning_rate": 4.03082672625844e-06,
      "loss": 0.3192404270172119,
      "memory(GiB)": 72.72,
      "step": 31305,
      "token_acc": 0.5844155844155844,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 2.920436526443429,
      "grad_norm": 3.3741166591644287,
      "learning_rate": 4.029313728502512e-06,
      "loss": 0.3274660587310791,
      "memory(GiB)": 72.72,
      "step": 31310,
      "token_acc": 0.6885245901639344,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 2.9209029008488017,
      "grad_norm": 7.953892707824707,
      "learning_rate": 4.027800823104395e-06,
      "loss": 0.29073324203491213,
      "memory(GiB)": 72.72,
      "step": 31315,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 2.921369275254174,
      "grad_norm": 4.074690818786621,
      "learning_rate": 4.026288010208036e-06,
      "loss": 0.32884836196899414,
      "memory(GiB)": 72.72,
      "step": 31320,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 2.921835649659547,
      "grad_norm": 2.256009340286255,
      "learning_rate": 4.024775289957371e-06,
      "loss": 0.3235619068145752,
      "memory(GiB)": 72.72,
      "step": 31325,
      "token_acc": 0.9711538461538461,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 2.922302024064919,
      "grad_norm": 2.7012627124786377,
      "learning_rate": 4.023262662496334e-06,
      "loss": 0.3438995122909546,
      "memory(GiB)": 72.72,
      "step": 31330,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.922768398470292,
      "grad_norm": 2.5293796062469482,
      "learning_rate": 4.021750127968845e-06,
      "loss": 0.31862404346466067,
      "memory(GiB)": 72.72,
      "step": 31335,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 2.9232347728756647,
      "grad_norm": 2.365525722503662,
      "learning_rate": 4.0202376865188185e-06,
      "loss": 0.308049750328064,
      "memory(GiB)": 72.72,
      "step": 31340,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.9237011472810375,
      "grad_norm": 4.51251220703125,
      "learning_rate": 4.018725338290157e-06,
      "loss": 0.3231525897979736,
      "memory(GiB)": 72.72,
      "step": 31345,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.92416752168641,
      "grad_norm": 3.0536935329437256,
      "learning_rate": 4.017213083426757e-06,
      "loss": 0.396496844291687,
      "memory(GiB)": 72.72,
      "step": 31350,
      "token_acc": 0.3875,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 2.9246338960917826,
      "grad_norm": 2.0861809253692627,
      "learning_rate": 4.0157009220725044e-06,
      "loss": 0.36271376609802247,
      "memory(GiB)": 72.72,
      "step": 31355,
      "token_acc": 0.912621359223301,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 2.925100270497155,
      "grad_norm": 2.497490882873535,
      "learning_rate": 4.0141888543712775e-06,
      "loss": 0.3125671625137329,
      "memory(GiB)": 72.72,
      "step": 31360,
      "token_acc": 0.7560975609756098,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 2.9255666449025277,
      "grad_norm": 5.792389392852783,
      "learning_rate": 4.012676880466944e-06,
      "loss": 0.33158349990844727,
      "memory(GiB)": 72.72,
      "step": 31365,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 2.9260330193079005,
      "grad_norm": 3.0656418800354004,
      "learning_rate": 4.0111650005033645e-06,
      "loss": 0.35113770961761476,
      "memory(GiB)": 72.72,
      "step": 31370,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 2.9264993937132733,
      "grad_norm": 3.4331917762756348,
      "learning_rate": 4.009653214624387e-06,
      "loss": 0.3520139932632446,
      "memory(GiB)": 72.72,
      "step": 31375,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 2.9269657681186456,
      "grad_norm": 2.740339994430542,
      "learning_rate": 4.008141522973856e-06,
      "loss": 0.32052552700042725,
      "memory(GiB)": 72.72,
      "step": 31380,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 2.9274321425240184,
      "grad_norm": 2.412341833114624,
      "learning_rate": 4.0066299256956046e-06,
      "loss": 0.33155598640441897,
      "memory(GiB)": 72.72,
      "step": 31385,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 2.9278985169293907,
      "grad_norm": 2.7802467346191406,
      "learning_rate": 4.005118422933455e-06,
      "loss": 0.3695988655090332,
      "memory(GiB)": 72.72,
      "step": 31390,
      "token_acc": 0.5641025641025641,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 2.9283648913347635,
      "grad_norm": 4.133937358856201,
      "learning_rate": 4.003607014831223e-06,
      "loss": 0.33114898204803467,
      "memory(GiB)": 72.72,
      "step": 31395,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 2.9288312657401363,
      "grad_norm": 2.996379852294922,
      "learning_rate": 4.002095701532716e-06,
      "loss": 0.3459354877471924,
      "memory(GiB)": 72.72,
      "step": 31400,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 2.929297640145509,
      "grad_norm": 2.861860990524292,
      "learning_rate": 4.000584483181726e-06,
      "loss": 0.33142881393432616,
      "memory(GiB)": 72.72,
      "step": 31405,
      "token_acc": 0.6166666666666667,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 2.9297640145508814,
      "grad_norm": 2.8716461658477783,
      "learning_rate": 3.999073359922042e-06,
      "loss": 0.3148851156234741,
      "memory(GiB)": 72.72,
      "step": 31410,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 2.930230388956254,
      "grad_norm": 3.996413230895996,
      "learning_rate": 3.997562331897447e-06,
      "loss": 0.3642261505126953,
      "memory(GiB)": 72.72,
      "step": 31415,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 2.9306967633616265,
      "grad_norm": 2.8133280277252197,
      "learning_rate": 3.9960513992517095e-06,
      "loss": 0.3032261371612549,
      "memory(GiB)": 72.72,
      "step": 31420,
      "token_acc": 0.6904761904761905,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 2.9311631377669993,
      "grad_norm": 3.1312313079833984,
      "learning_rate": 3.994540562128587e-06,
      "loss": 0.31706976890563965,
      "memory(GiB)": 72.72,
      "step": 31425,
      "token_acc": 0.49122807017543857,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.931629512172372,
      "grad_norm": 3.458364725112915,
      "learning_rate": 3.9930298206718325e-06,
      "loss": 0.3498422145843506,
      "memory(GiB)": 72.72,
      "step": 31430,
      "token_acc": 0.6590909090909091,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 2.9320958865777444,
      "grad_norm": 3.480895519256592,
      "learning_rate": 3.991519175025189e-06,
      "loss": 0.37976832389831544,
      "memory(GiB)": 72.72,
      "step": 31435,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.9325622609831172,
      "grad_norm": 4.226852893829346,
      "learning_rate": 3.990008625332389e-06,
      "loss": 0.3608358860015869,
      "memory(GiB)": 72.72,
      "step": 31440,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.93302863538849,
      "grad_norm": 2.405607223510742,
      "learning_rate": 3.988498171737155e-06,
      "loss": 0.3163748264312744,
      "memory(GiB)": 72.72,
      "step": 31445,
      "token_acc": 0.6595744680851063,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.9334950097938624,
      "grad_norm": 3.4250447750091553,
      "learning_rate": 3.986987814383206e-06,
      "loss": 0.3589467525482178,
      "memory(GiB)": 72.72,
      "step": 31450,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 2.933961384199235,
      "grad_norm": 4.245239734649658,
      "learning_rate": 3.985477553414246e-06,
      "loss": 0.32114343643188475,
      "memory(GiB)": 72.72,
      "step": 31455,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 2.934427758604608,
      "grad_norm": 4.142428874969482,
      "learning_rate": 3.983967388973971e-06,
      "loss": 0.355575704574585,
      "memory(GiB)": 72.72,
      "step": 31460,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.9348941330099803,
      "grad_norm": 2.6882011890411377,
      "learning_rate": 3.982457321206069e-06,
      "loss": 0.37031352519989014,
      "memory(GiB)": 72.72,
      "step": 31465,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.935360507415353,
      "grad_norm": 4.32130241394043,
      "learning_rate": 3.980947350254219e-06,
      "loss": 0.36597278118133547,
      "memory(GiB)": 72.72,
      "step": 31470,
      "token_acc": 0.8974358974358975,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 2.935826881820726,
      "grad_norm": 3.3942275047302246,
      "learning_rate": 3.979437476262089e-06,
      "loss": 0.31419954299926756,
      "memory(GiB)": 72.72,
      "step": 31475,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 2.936293256226098,
      "grad_norm": 2.9787979125976562,
      "learning_rate": 3.977927699373338e-06,
      "loss": 0.3278780460357666,
      "memory(GiB)": 72.72,
      "step": 31480,
      "token_acc": 0.9320388349514563,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.936759630631471,
      "grad_norm": 2.829967498779297,
      "learning_rate": 3.976418019731618e-06,
      "loss": 0.3253138303756714,
      "memory(GiB)": 72.72,
      "step": 31485,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.9372260050368437,
      "grad_norm": 3.16267991065979,
      "learning_rate": 3.974908437480571e-06,
      "loss": 0.33595364093780516,
      "memory(GiB)": 72.72,
      "step": 31490,
      "token_acc": 0.9101123595505618,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.937692379442216,
      "grad_norm": 3.8279411792755127,
      "learning_rate": 3.9733989527638284e-06,
      "loss": 0.347829008102417,
      "memory(GiB)": 72.72,
      "step": 31495,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.938158753847589,
      "grad_norm": 2.6023201942443848,
      "learning_rate": 3.971889565725013e-06,
      "loss": 0.3411861896514893,
      "memory(GiB)": 72.72,
      "step": 31500,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.9386251282529616,
      "grad_norm": 4.382022857666016,
      "learning_rate": 3.970380276507739e-06,
      "loss": 0.3096144676208496,
      "memory(GiB)": 72.72,
      "step": 31505,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.939091502658334,
      "grad_norm": 6.004645824432373,
      "learning_rate": 3.9688710852556086e-06,
      "loss": 0.34774887561798096,
      "memory(GiB)": 72.72,
      "step": 31510,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 2.9395578770637067,
      "grad_norm": 3.2151482105255127,
      "learning_rate": 3.967361992112216e-06,
      "loss": 0.33052592277526854,
      "memory(GiB)": 72.72,
      "step": 31515,
      "token_acc": 0.6617647058823529,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 2.9400242514690795,
      "grad_norm": 2.6375255584716797,
      "learning_rate": 3.965852997221153e-06,
      "loss": 0.3428798198699951,
      "memory(GiB)": 72.72,
      "step": 31520,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.940490625874452,
      "grad_norm": 3.3048758506774902,
      "learning_rate": 3.964344100725988e-06,
      "loss": 0.3379974365234375,
      "memory(GiB)": 72.72,
      "step": 31525,
      "token_acc": 0.9479166666666666,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.9409570002798247,
      "grad_norm": 3.5712640285491943,
      "learning_rate": 3.962835302770293e-06,
      "loss": 0.32069361209869385,
      "memory(GiB)": 72.72,
      "step": 31530,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.9414233746851974,
      "grad_norm": 3.0497193336486816,
      "learning_rate": 3.961326603497625e-06,
      "loss": 0.35655148029327394,
      "memory(GiB)": 72.72,
      "step": 31535,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 2.9418897490905698,
      "grad_norm": 2.503272294998169,
      "learning_rate": 3.959818003051529e-06,
      "loss": 0.3191677093505859,
      "memory(GiB)": 72.72,
      "step": 31540,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 2.9423561234959426,
      "grad_norm": 3.98856782913208,
      "learning_rate": 3.958309501575546e-06,
      "loss": 0.3107825756072998,
      "memory(GiB)": 72.72,
      "step": 31545,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.9428224979013153,
      "grad_norm": 2.977153778076172,
      "learning_rate": 3.956801099213205e-06,
      "loss": 0.36891794204711914,
      "memory(GiB)": 72.72,
      "step": 31550,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 2.9432888723066877,
      "grad_norm": 2.9511680603027344,
      "learning_rate": 3.955292796108026e-06,
      "loss": 0.3130764961242676,
      "memory(GiB)": 72.72,
      "step": 31555,
      "token_acc": 0.7647058823529411,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.9437552467120605,
      "grad_norm": 4.26140022277832,
      "learning_rate": 3.95378459240352e-06,
      "loss": 0.3424380779266357,
      "memory(GiB)": 72.72,
      "step": 31560,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.9442216211174332,
      "grad_norm": 5.162339687347412,
      "learning_rate": 3.952276488243185e-06,
      "loss": 0.36320319175720217,
      "memory(GiB)": 72.72,
      "step": 31565,
      "token_acc": 0.5154639175257731,
      "train_speed(iter/s)": 0.251374
    },
    {
      "epoch": 2.9446879955228056,
      "grad_norm": 4.622471809387207,
      "learning_rate": 3.950768483770517e-06,
      "loss": 0.32058522701263426,
      "memory(GiB)": 72.72,
      "step": 31570,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.9451543699281784,
      "grad_norm": 2.855931043624878,
      "learning_rate": 3.949260579128995e-06,
      "loss": 0.3349325656890869,
      "memory(GiB)": 72.72,
      "step": 31575,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.945620744333551,
      "grad_norm": 2.9965474605560303,
      "learning_rate": 3.94775277446209e-06,
      "loss": 0.33295626640319825,
      "memory(GiB)": 72.72,
      "step": 31580,
      "token_acc": 0.5517241379310345,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.9460871187389235,
      "grad_norm": 3.1749143600463867,
      "learning_rate": 3.946245069913268e-06,
      "loss": 0.34939327239990237,
      "memory(GiB)": 72.72,
      "step": 31585,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.9465534931442963,
      "grad_norm": 3.744387626647949,
      "learning_rate": 3.9447374656259814e-06,
      "loss": 0.3319652318954468,
      "memory(GiB)": 72.72,
      "step": 31590,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 2.9470198675496686,
      "grad_norm": 3.1461355686187744,
      "learning_rate": 3.943229961743677e-06,
      "loss": 0.29644203186035156,
      "memory(GiB)": 72.72,
      "step": 31595,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 2.9474862419550414,
      "grad_norm": 4.089597225189209,
      "learning_rate": 3.941722558409783e-06,
      "loss": 0.3527109622955322,
      "memory(GiB)": 72.72,
      "step": 31600,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 2.947952616360414,
      "grad_norm": 3.4422974586486816,
      "learning_rate": 3.940215255767729e-06,
      "loss": 0.3256378650665283,
      "memory(GiB)": 72.72,
      "step": 31605,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 2.948418990765787,
      "grad_norm": 2.9345781803131104,
      "learning_rate": 3.938708053960927e-06,
      "loss": 0.31709942817687986,
      "memory(GiB)": 72.72,
      "step": 31610,
      "token_acc": 0.9647058823529412,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 2.9488853651711593,
      "grad_norm": 3.2687976360321045,
      "learning_rate": 3.937200953132785e-06,
      "loss": 0.3384109973907471,
      "memory(GiB)": 72.72,
      "step": 31615,
      "token_acc": 0.5855855855855856,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 2.949351739576532,
      "grad_norm": 2.656599283218384,
      "learning_rate": 3.935693953426698e-06,
      "loss": 0.3236408233642578,
      "memory(GiB)": 72.72,
      "step": 31620,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 2.9498181139819044,
      "grad_norm": 2.9571690559387207,
      "learning_rate": 3.934187054986053e-06,
      "loss": 0.3287788152694702,
      "memory(GiB)": 72.72,
      "step": 31625,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 2.950284488387277,
      "grad_norm": 2.1981985569000244,
      "learning_rate": 3.932680257954227e-06,
      "loss": 0.28502845764160156,
      "memory(GiB)": 72.72,
      "step": 31630,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 2.95075086279265,
      "grad_norm": 2.7631657123565674,
      "learning_rate": 3.931173562474586e-06,
      "loss": 0.3144699573516846,
      "memory(GiB)": 72.72,
      "step": 31635,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 2.9512172371980228,
      "grad_norm": 3.267792224884033,
      "learning_rate": 3.929666968690488e-06,
      "loss": 0.30873129367828367,
      "memory(GiB)": 72.72,
      "step": 31640,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 2.951683611603395,
      "grad_norm": 3.9690306186676025,
      "learning_rate": 3.928160476745281e-06,
      "loss": 0.3475175857543945,
      "memory(GiB)": 72.72,
      "step": 31645,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 2.952149986008768,
      "grad_norm": 7.940308570861816,
      "learning_rate": 3.926654086782301e-06,
      "loss": 0.32067275047302246,
      "memory(GiB)": 72.72,
      "step": 31650,
      "token_acc": 0.5964912280701754,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.95261636041414,
      "grad_norm": 3.860496759414673,
      "learning_rate": 3.92514779894488e-06,
      "loss": 0.33272218704223633,
      "memory(GiB)": 72.72,
      "step": 31655,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.953082734819513,
      "grad_norm": 3.7290828227996826,
      "learning_rate": 3.923641613376334e-06,
      "loss": 0.3426779508590698,
      "memory(GiB)": 72.72,
      "step": 31660,
      "token_acc": 0.6491228070175439,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.953549109224886,
      "grad_norm": 3.459491729736328,
      "learning_rate": 3.922135530219973e-06,
      "loss": 0.31413774490356444,
      "memory(GiB)": 72.72,
      "step": 31665,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.9540154836302586,
      "grad_norm": 2.3119232654571533,
      "learning_rate": 3.920629549619096e-06,
      "loss": 0.3379185199737549,
      "memory(GiB)": 72.72,
      "step": 31670,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 2.954481858035631,
      "grad_norm": 4.228691101074219,
      "learning_rate": 3.919123671716993e-06,
      "loss": 0.32446587085723877,
      "memory(GiB)": 72.72,
      "step": 31675,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 2.9549482324410037,
      "grad_norm": 3.1098344326019287,
      "learning_rate": 3.917617896656942e-06,
      "loss": 0.3718599319458008,
      "memory(GiB)": 72.72,
      "step": 31680,
      "token_acc": 0.525974025974026,
      "train_speed(iter/s)": 0.251392
    },
    {
      "epoch": 2.955414606846376,
      "grad_norm": 2.4931836128234863,
      "learning_rate": 3.916112224582212e-06,
      "loss": 0.3450628757476807,
      "memory(GiB)": 72.72,
      "step": 31685,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 2.955880981251749,
      "grad_norm": 3.444430112838745,
      "learning_rate": 3.9146066556360665e-06,
      "loss": 0.34990749359130857,
      "memory(GiB)": 72.72,
      "step": 31690,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.9563473556571216,
      "grad_norm": 3.100929021835327,
      "learning_rate": 3.913101189961756e-06,
      "loss": 0.3212253570556641,
      "memory(GiB)": 72.72,
      "step": 31695,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 2.9568137300624944,
      "grad_norm": 2.46744441986084,
      "learning_rate": 3.911595827702517e-06,
      "loss": 0.29619855880737306,
      "memory(GiB)": 72.72,
      "step": 31700,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.9572801044678667,
      "grad_norm": 2.6367125511169434,
      "learning_rate": 3.910090569001582e-06,
      "loss": 0.3417510032653809,
      "memory(GiB)": 72.72,
      "step": 31705,
      "token_acc": 0.96875,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.9577464788732395,
      "grad_norm": 2.4791488647460938,
      "learning_rate": 3.908585414002173e-06,
      "loss": 0.3100300312042236,
      "memory(GiB)": 72.72,
      "step": 31710,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.958212853278612,
      "grad_norm": 2.9420583248138428,
      "learning_rate": 3.907080362847497e-06,
      "loss": 0.3412060499191284,
      "memory(GiB)": 72.72,
      "step": 31715,
      "token_acc": 0.5581395348837209,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.9586792276839846,
      "grad_norm": 3.808389902114868,
      "learning_rate": 3.90557541568076e-06,
      "loss": 0.38022613525390625,
      "memory(GiB)": 72.72,
      "step": 31720,
      "token_acc": 0.6351351351351351,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.9591456020893574,
      "grad_norm": 4.411902904510498,
      "learning_rate": 3.90407057264515e-06,
      "loss": 0.36164679527282717,
      "memory(GiB)": 72.72,
      "step": 31725,
      "token_acc": 0.5526315789473685,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.95961197649473,
      "grad_norm": 3.2465426921844482,
      "learning_rate": 3.902565833883849e-06,
      "loss": 0.3545775175094604,
      "memory(GiB)": 72.72,
      "step": 31730,
      "token_acc": 0.47115384615384615,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.9600783509001025,
      "grad_norm": 2.863842725753784,
      "learning_rate": 3.901061199540029e-06,
      "loss": 0.3423454284667969,
      "memory(GiB)": 72.72,
      "step": 31735,
      "token_acc": 0.5230769230769231,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.9605447253054753,
      "grad_norm": 4.919966220855713,
      "learning_rate": 3.8995566697568495e-06,
      "loss": 0.3430027961730957,
      "memory(GiB)": 72.72,
      "step": 31740,
      "token_acc": 0.6122448979591837,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.9610110997108476,
      "grad_norm": 2.481656312942505,
      "learning_rate": 3.898052244677463e-06,
      "loss": 0.31162114143371583,
      "memory(GiB)": 72.72,
      "step": 31745,
      "token_acc": 0.9278350515463918,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 2.9614774741162204,
      "grad_norm": 11.719120979309082,
      "learning_rate": 3.89654792444501e-06,
      "loss": 0.34666383266448975,
      "memory(GiB)": 72.72,
      "step": 31750,
      "token_acc": 0.8592592592592593,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.961943848521593,
      "grad_norm": 2.7453060150146484,
      "learning_rate": 3.895043709202624e-06,
      "loss": 0.323047399520874,
      "memory(GiB)": 72.72,
      "step": 31755,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.962410222926966,
      "grad_norm": 6.064733505249023,
      "learning_rate": 3.893539599093425e-06,
      "loss": 0.306593132019043,
      "memory(GiB)": 72.72,
      "step": 31760,
      "token_acc": 0.5684210526315789,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.9628765973323383,
      "grad_norm": 3.7473697662353516,
      "learning_rate": 3.892035594260524e-06,
      "loss": 0.3178199529647827,
      "memory(GiB)": 72.72,
      "step": 31765,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.963342971737711,
      "grad_norm": 3.3312954902648926,
      "learning_rate": 3.890531694847023e-06,
      "loss": 0.35072021484375,
      "memory(GiB)": 72.72,
      "step": 31770,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.9638093461430834,
      "grad_norm": 4.371648788452148,
      "learning_rate": 3.889027900996015e-06,
      "loss": 0.3067343235015869,
      "memory(GiB)": 72.72,
      "step": 31775,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.9642757205484562,
      "grad_norm": 4.616514682769775,
      "learning_rate": 3.887524212850579e-06,
      "loss": 0.34152171611785886,
      "memory(GiB)": 72.72,
      "step": 31780,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.964742094953829,
      "grad_norm": 4.653252124786377,
      "learning_rate": 3.886020630553785e-06,
      "loss": 0.35553574562072754,
      "memory(GiB)": 72.72,
      "step": 31785,
      "token_acc": 0.5869565217391305,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.965208469359202,
      "grad_norm": 3.9091134071350098,
      "learning_rate": 3.884517154248698e-06,
      "loss": 0.3545250415802002,
      "memory(GiB)": 72.72,
      "step": 31790,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.965674843764574,
      "grad_norm": 3.3478784561157227,
      "learning_rate": 3.883013784078369e-06,
      "loss": 0.32803595066070557,
      "memory(GiB)": 72.72,
      "step": 31795,
      "token_acc": 0.9787234042553191,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 2.966141218169947,
      "grad_norm": 2.4788827896118164,
      "learning_rate": 3.881510520185836e-06,
      "loss": 0.306165885925293,
      "memory(GiB)": 72.72,
      "step": 31800,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 2.9666075925753193,
      "grad_norm": 2.937373399734497,
      "learning_rate": 3.880007362714131e-06,
      "loss": 0.3183660745620728,
      "memory(GiB)": 72.72,
      "step": 31805,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 2.967073966980692,
      "grad_norm": 3.675715208053589,
      "learning_rate": 3.878504311806276e-06,
      "loss": 0.3380859851837158,
      "memory(GiB)": 72.72,
      "step": 31810,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 2.967540341386065,
      "grad_norm": 5.0379486083984375,
      "learning_rate": 3.87700136760528e-06,
      "loss": 0.3452235221862793,
      "memory(GiB)": 72.72,
      "step": 31815,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 2.9680067157914376,
      "grad_norm": 2.833792209625244,
      "learning_rate": 3.8754985302541446e-06,
      "loss": 0.32663166522979736,
      "memory(GiB)": 72.72,
      "step": 31820,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.96847309019681,
      "grad_norm": 3.5272910594940186,
      "learning_rate": 3.8739957998958595e-06,
      "loss": 0.32102384567260744,
      "memory(GiB)": 72.72,
      "step": 31825,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 2.9689394646021827,
      "grad_norm": 3.139274835586548,
      "learning_rate": 3.872493176673406e-06,
      "loss": 0.3272511959075928,
      "memory(GiB)": 72.72,
      "step": 31830,
      "token_acc": 0.9595959595959596,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.969405839007555,
      "grad_norm": 3.681507110595703,
      "learning_rate": 3.870990660729754e-06,
      "loss": 0.3522507190704346,
      "memory(GiB)": 72.72,
      "step": 31835,
      "token_acc": 0.9891304347826086,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 2.969872213412928,
      "grad_norm": 2.839052200317383,
      "learning_rate": 3.869488252207863e-06,
      "loss": 0.32747468948364256,
      "memory(GiB)": 72.72,
      "step": 31840,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 2.9703385878183006,
      "grad_norm": 2.9179019927978516,
      "learning_rate": 3.867985951250681e-06,
      "loss": 0.34691171646118163,
      "memory(GiB)": 72.72,
      "step": 31845,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 2.9708049622236734,
      "grad_norm": 17.413053512573242,
      "learning_rate": 3.866483758001147e-06,
      "loss": 0.3581278324127197,
      "memory(GiB)": 72.72,
      "step": 31850,
      "token_acc": 0.9871794871794872,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 2.9712713366290457,
      "grad_norm": 2.409593105316162,
      "learning_rate": 3.864981672602193e-06,
      "loss": 0.3227465391159058,
      "memory(GiB)": 72.72,
      "step": 31855,
      "token_acc": 0.5138888888888888,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 2.9717377110344185,
      "grad_norm": 3.5208349227905273,
      "learning_rate": 3.863479695196737e-06,
      "loss": 0.3561598777770996,
      "memory(GiB)": 72.72,
      "step": 31860,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 2.972204085439791,
      "grad_norm": 3.619751214981079,
      "learning_rate": 3.8619778259276865e-06,
      "loss": 0.3500474691390991,
      "memory(GiB)": 72.72,
      "step": 31865,
      "token_acc": 0.9888888888888889,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 2.9726704598451636,
      "grad_norm": 3.8668694496154785,
      "learning_rate": 3.860476064937942e-06,
      "loss": 0.3229588270187378,
      "memory(GiB)": 72.72,
      "step": 31870,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 2.9731368342505364,
      "grad_norm": 2.8153798580169678,
      "learning_rate": 3.858974412370387e-06,
      "loss": 0.32028894424438475,
      "memory(GiB)": 72.72,
      "step": 31875,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 2.973603208655909,
      "grad_norm": 2.470268726348877,
      "learning_rate": 3.857472868367902e-06,
      "loss": 0.3189410209655762,
      "memory(GiB)": 72.72,
      "step": 31880,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 2.9740695830612816,
      "grad_norm": 8.796065330505371,
      "learning_rate": 3.855971433073352e-06,
      "loss": 0.36646475791931155,
      "memory(GiB)": 72.72,
      "step": 31885,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.9745359574666543,
      "grad_norm": 11.127100944519043,
      "learning_rate": 3.8544701066295995e-06,
      "loss": 0.32312440872192383,
      "memory(GiB)": 72.72,
      "step": 31890,
      "token_acc": 0.5111111111111111,
      "train_speed(iter/s)": 0.251374
    },
    {
      "epoch": 2.9750023318720267,
      "grad_norm": 2.6997804641723633,
      "learning_rate": 3.852968889179486e-06,
      "loss": 0.328973126411438,
      "memory(GiB)": 72.72,
      "step": 31895,
      "token_acc": 0.5121951219512195,
      "train_speed(iter/s)": 0.251374
    },
    {
      "epoch": 2.9754687062773995,
      "grad_norm": 2.8406600952148438,
      "learning_rate": 3.851467780865849e-06,
      "loss": 0.35963010787963867,
      "memory(GiB)": 72.72,
      "step": 31900,
      "token_acc": 0.5425531914893617,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 2.9759350806827722,
      "grad_norm": 2.7336835861206055,
      "learning_rate": 3.8499667818315145e-06,
      "loss": 0.3463606834411621,
      "memory(GiB)": 72.72,
      "step": 31905,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 2.976401455088145,
      "grad_norm": 2.9298064708709717,
      "learning_rate": 3.8484658922192985e-06,
      "loss": 0.31893062591552734,
      "memory(GiB)": 72.72,
      "step": 31910,
      "train_speed(iter/s)": 0.251377
    },
    {
      "epoch": 2.9768678294935174,
      "grad_norm": 3.312246561050415,
      "learning_rate": 3.8469651121720055e-06,
      "loss": 0.3369471073150635,
      "memory(GiB)": 72.72,
      "step": 31915,
      "token_acc": 0.6846846846846847,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 2.97733420389889,
      "grad_norm": 3.4542646408081055,
      "learning_rate": 3.845464441832428e-06,
      "loss": 0.317122220993042,
      "memory(GiB)": 72.72,
      "step": 31920,
      "token_acc": 0.9662921348314607,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 2.9778005783042625,
      "grad_norm": 3.0436646938323975,
      "learning_rate": 3.843963881343355e-06,
      "loss": 0.33640992641448975,
      "memory(GiB)": 72.72,
      "step": 31925,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.251377
    },
    {
      "epoch": 2.9782669527096353,
      "grad_norm": 2.8948159217834473,
      "learning_rate": 3.842463430847555e-06,
      "loss": 0.3260641098022461,
      "memory(GiB)": 72.72,
      "step": 31930,
      "token_acc": 0.9897959183673469,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.978733327115008,
      "grad_norm": 2.255035400390625,
      "learning_rate": 3.840963090487795e-06,
      "loss": 0.34656691551208496,
      "memory(GiB)": 72.72,
      "step": 31935,
      "train_speed(iter/s)": 0.251377
    },
    {
      "epoch": 2.979199701520381,
      "grad_norm": 8.416120529174805,
      "learning_rate": 3.839462860406827e-06,
      "loss": 0.3578911304473877,
      "memory(GiB)": 72.72,
      "step": 31940,
      "train_speed(iter/s)": 0.251374
    },
    {
      "epoch": 2.979666075925753,
      "grad_norm": 4.855620384216309,
      "learning_rate": 3.8379627407473925e-06,
      "loss": 0.3361765623092651,
      "memory(GiB)": 72.72,
      "step": 31945,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.980132450331126,
      "grad_norm": 3.258413553237915,
      "learning_rate": 3.836462731652224e-06,
      "loss": 0.331727409362793,
      "memory(GiB)": 72.72,
      "step": 31950,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.9805988247364983,
      "grad_norm": 2.4801957607269287,
      "learning_rate": 3.8349628332640395e-06,
      "loss": 0.3188997507095337,
      "memory(GiB)": 72.72,
      "step": 31955,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.981065199141871,
      "grad_norm": 4.496558666229248,
      "learning_rate": 3.833463045725554e-06,
      "loss": 0.3492161273956299,
      "memory(GiB)": 72.72,
      "step": 31960,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 2.981531573547244,
      "grad_norm": 3.4022626876831055,
      "learning_rate": 3.831963369179466e-06,
      "loss": 0.3237758159637451,
      "memory(GiB)": 72.72,
      "step": 31965,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 2.9819979479526166,
      "grad_norm": 3.4327521324157715,
      "learning_rate": 3.830463803768467e-06,
      "loss": 0.34961686134338377,
      "memory(GiB)": 72.72,
      "step": 31970,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 2.982464322357989,
      "grad_norm": 1.9848620891571045,
      "learning_rate": 3.828964349635233e-06,
      "loss": 0.3170583724975586,
      "memory(GiB)": 72.72,
      "step": 31975,
      "token_acc": 0.6728395061728395,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 2.9829306967633618,
      "grad_norm": 3.044017791748047,
      "learning_rate": 3.827465006922434e-06,
      "loss": 0.32249960899353025,
      "memory(GiB)": 72.72,
      "step": 31980,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 2.983397071168734,
      "grad_norm": 5.183862686157227,
      "learning_rate": 3.8259657757727265e-06,
      "loss": 0.32470202445983887,
      "memory(GiB)": 72.72,
      "step": 31985,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.983863445574107,
      "grad_norm": 3.050663709640503,
      "learning_rate": 3.824466656328758e-06,
      "loss": 0.3438847780227661,
      "memory(GiB)": 72.72,
      "step": 31990,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.9843298199794797,
      "grad_norm": 3.089188575744629,
      "learning_rate": 3.822967648733167e-06,
      "loss": 0.3568993806838989,
      "memory(GiB)": 72.72,
      "step": 31995,
      "token_acc": 0.5227272727272727,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 2.984796194384852,
      "grad_norm": 3.114751100540161,
      "learning_rate": 3.821468753128578e-06,
      "loss": 0.3232101917266846,
      "memory(GiB)": 72.72,
      "step": 32000,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 2.985262568790225,
      "grad_norm": 3.61019229888916,
      "learning_rate": 3.819969969657607e-06,
      "loss": 0.3190751552581787,
      "memory(GiB)": 72.72,
      "step": 32005,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 2.9857289431955976,
      "grad_norm": 4.148343086242676,
      "learning_rate": 3.818471298462858e-06,
      "loss": 0.3148950099945068,
      "memory(GiB)": 72.72,
      "step": 32010,
      "token_acc": 0.5819672131147541,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 2.98619531760097,
      "grad_norm": 3.37760329246521,
      "learning_rate": 3.816972739686926e-06,
      "loss": 0.3414731740951538,
      "memory(GiB)": 72.72,
      "step": 32015,
      "token_acc": 0.9464285714285714,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.9866616920063427,
      "grad_norm": 3.317004919052124,
      "learning_rate": 3.815474293472392e-06,
      "loss": 0.3285244941711426,
      "memory(GiB)": 72.72,
      "step": 32020,
      "train_speed(iter/s)": 0.251332
    },
    {
      "epoch": 2.9871280664117155,
      "grad_norm": 5.615225315093994,
      "learning_rate": 3.8139759599618296e-06,
      "loss": 0.3239760398864746,
      "memory(GiB)": 72.72,
      "step": 32025,
      "train_speed(iter/s)": 0.251331
    },
    {
      "epoch": 2.987594440817088,
      "grad_norm": 2.836846113204956,
      "learning_rate": 3.8124777392978026e-06,
      "loss": 0.3294987201690674,
      "memory(GiB)": 72.72,
      "step": 32030,
      "token_acc": 0.5777777777777777,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 2.9880608152224606,
      "grad_norm": 4.952104091644287,
      "learning_rate": 3.8109796316228597e-06,
      "loss": 0.32582571506500246,
      "memory(GiB)": 72.72,
      "step": 32035,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 2.9885271896278334,
      "grad_norm": 2.949291706085205,
      "learning_rate": 3.8094816370795422e-06,
      "loss": 0.3259266376495361,
      "memory(GiB)": 72.72,
      "step": 32040,
      "token_acc": 0.5337423312883436,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 2.9889935640332057,
      "grad_norm": 2.46755313873291,
      "learning_rate": 3.8079837558103796e-06,
      "loss": 0.33775739669799804,
      "memory(GiB)": 72.72,
      "step": 32045,
      "train_speed(iter/s)": 0.251331
    },
    {
      "epoch": 2.9894599384385785,
      "grad_norm": 2.6055538654327393,
      "learning_rate": 3.8064859879578913e-06,
      "loss": 0.30617566108703614,
      "memory(GiB)": 72.72,
      "step": 32050,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 2.9899263128439513,
      "grad_norm": 3.405259132385254,
      "learning_rate": 3.8049883336645815e-06,
      "loss": 0.33949759006500246,
      "memory(GiB)": 72.72,
      "step": 32055,
      "token_acc": 0.5616438356164384,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 2.9903926872493236,
      "grad_norm": 2.629877805709839,
      "learning_rate": 3.8034907930729525e-06,
      "loss": 0.3262279987335205,
      "memory(GiB)": 72.72,
      "step": 32060,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 2.9908590616546964,
      "grad_norm": 3.1557321548461914,
      "learning_rate": 3.8019933663254886e-06,
      "loss": 0.3709654569625854,
      "memory(GiB)": 72.72,
      "step": 32065,
      "token_acc": 0.6557377049180327,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.991325436060069,
      "grad_norm": 3.325894355773926,
      "learning_rate": 3.8004960535646667e-06,
      "loss": 0.33837032318115234,
      "memory(GiB)": 72.72,
      "step": 32070,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251335
    },
    {
      "epoch": 2.9917918104654415,
      "grad_norm": 2.8752193450927734,
      "learning_rate": 3.7989988549329486e-06,
      "loss": 0.363776421546936,
      "memory(GiB)": 72.72,
      "step": 32075,
      "token_acc": 0.5441176470588235,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.9922581848708143,
      "grad_norm": 2.7114994525909424,
      "learning_rate": 3.7975017705727903e-06,
      "loss": 0.3311032772064209,
      "memory(GiB)": 72.72,
      "step": 32080,
      "train_speed(iter/s)": 0.251335
    },
    {
      "epoch": 2.992724559276187,
      "grad_norm": 3.9124534130096436,
      "learning_rate": 3.7960048006266335e-06,
      "loss": 0.3333998680114746,
      "memory(GiB)": 72.72,
      "step": 32085,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.251335
    },
    {
      "epoch": 2.9931909336815594,
      "grad_norm": 8.493816375732422,
      "learning_rate": 3.7945079452369098e-06,
      "loss": 0.3484625339508057,
      "memory(GiB)": 72.72,
      "step": 32090,
      "token_acc": 0.781021897810219,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.993657308086932,
      "grad_norm": 2.8866679668426514,
      "learning_rate": 3.793011204546043e-06,
      "loss": 0.3225250244140625,
      "memory(GiB)": 72.72,
      "step": 32095,
      "token_acc": 0.7368421052631579,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.994123682492305,
      "grad_norm": 3.1440067291259766,
      "learning_rate": 3.791514578696442e-06,
      "loss": 0.3433522701263428,
      "memory(GiB)": 72.72,
      "step": 32100,
      "token_acc": 0.8977272727272727,
      "train_speed(iter/s)": 0.251331
    },
    {
      "epoch": 2.9945900568976773,
      "grad_norm": 3.6615631580352783,
      "learning_rate": 3.7900180678305054e-06,
      "loss": 0.30801239013671877,
      "memory(GiB)": 72.72,
      "step": 32105,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.99505643130305,
      "grad_norm": 2.6889281272888184,
      "learning_rate": 3.7885216720906224e-06,
      "loss": 0.3533834934234619,
      "memory(GiB)": 72.72,
      "step": 32110,
      "token_acc": 0.5740740740740741,
      "train_speed(iter/s)": 0.251335
    },
    {
      "epoch": 2.995522805708423,
      "grad_norm": 3.1411375999450684,
      "learning_rate": 3.7870253916191707e-06,
      "loss": 0.3153520107269287,
      "memory(GiB)": 72.72,
      "step": 32115,
      "token_acc": 0.9411764705882353,
      "train_speed(iter/s)": 0.251335
    },
    {
      "epoch": 2.9959891801137952,
      "grad_norm": 2.905381679534912,
      "learning_rate": 3.7855292265585157e-06,
      "loss": 0.3582566738128662,
      "memory(GiB)": 72.72,
      "step": 32120,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 2.996455554519168,
      "grad_norm": 4.881103992462158,
      "learning_rate": 3.784033177051013e-06,
      "loss": 0.33324522972106935,
      "memory(GiB)": 72.72,
      "step": 32125,
      "token_acc": 0.5641025641025641,
      "train_speed(iter/s)": 0.251335
    },
    {
      "epoch": 2.9969219289245403,
      "grad_norm": 3.2887203693389893,
      "learning_rate": 3.7825372432390084e-06,
      "loss": 0.3102367401123047,
      "memory(GiB)": 72.72,
      "step": 32130,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 2.997388303329913,
      "grad_norm": 3.1790931224823,
      "learning_rate": 3.7810414252648347e-06,
      "loss": 0.33910748958587644,
      "memory(GiB)": 72.72,
      "step": 32135,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 2.997854677735286,
      "grad_norm": 5.041963577270508,
      "learning_rate": 3.7795457232708146e-06,
      "loss": 0.3186501979827881,
      "memory(GiB)": 72.72,
      "step": 32140,
      "token_acc": 0.62,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.9983210521406587,
      "grad_norm": 3.207791328430176,
      "learning_rate": 3.7780501373992597e-06,
      "loss": 0.3830712080001831,
      "memory(GiB)": 72.72,
      "step": 32145,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.998787426546031,
      "grad_norm": 3.0065698623657227,
      "learning_rate": 3.776554667792469e-06,
      "loss": 0.33478355407714844,
      "memory(GiB)": 72.72,
      "step": 32150,
      "token_acc": 0.7692307692307693,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.999253800951404,
      "grad_norm": 3.318634033203125,
      "learning_rate": 3.7750593145927313e-06,
      "loss": 0.32494754791259767,
      "memory(GiB)": 72.72,
      "step": 32155,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 2.999720175356776,
      "grad_norm": 7.584212303161621,
      "learning_rate": 3.7735640779423277e-06,
      "loss": 0.321671462059021,
      "memory(GiB)": 72.72,
      "step": 32160,
      "train_speed(iter/s)": 0.251331
    },
    {
      "epoch": 3.000186549762149,
      "grad_norm": 4.216742515563965,
      "learning_rate": 3.7720689579835253e-06,
      "loss": 0.339231014251709,
      "memory(GiB)": 72.72,
      "step": 32165,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0006529241675217,
      "grad_norm": 2.783902406692505,
      "learning_rate": 3.7705739548585773e-06,
      "loss": 0.30219392776489257,
      "memory(GiB)": 72.72,
      "step": 32170,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0011192985728945,
      "grad_norm": 3.5666821002960205,
      "learning_rate": 3.7690790687097305e-06,
      "loss": 0.3366828918457031,
      "memory(GiB)": 72.72,
      "step": 32175,
      "token_acc": 0.9680851063829787,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.001585672978267,
      "grad_norm": 3.1528356075286865,
      "learning_rate": 3.7675842996792184e-06,
      "loss": 0.338180685043335,
      "memory(GiB)": 72.72,
      "step": 32180,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.0020520473836396,
      "grad_norm": 2.6055469512939453,
      "learning_rate": 3.7660896479092633e-06,
      "loss": 0.3567253351211548,
      "memory(GiB)": 72.72,
      "step": 32185,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0025184217890124,
      "grad_norm": 2.620364189147949,
      "learning_rate": 3.764595113542077e-06,
      "loss": 0.32459654808044436,
      "memory(GiB)": 72.72,
      "step": 32190,
      "token_acc": 0.9642857142857143,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0029847961943847,
      "grad_norm": 3.1625266075134277,
      "learning_rate": 3.76310069671986e-06,
      "loss": 0.3288259744644165,
      "memory(GiB)": 72.72,
      "step": 32195,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0034511705997575,
      "grad_norm": 3.466252326965332,
      "learning_rate": 3.7616063975848012e-06,
      "loss": 0.30595054626464846,
      "memory(GiB)": 72.72,
      "step": 32200,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0039175450051303,
      "grad_norm": 2.4244511127471924,
      "learning_rate": 3.760112216279079e-06,
      "loss": 0.32738566398620605,
      "memory(GiB)": 72.72,
      "step": 32205,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0043839194105026,
      "grad_norm": 3.0847699642181396,
      "learning_rate": 3.7586181529448603e-06,
      "loss": 0.39018702507019043,
      "memory(GiB)": 72.72,
      "step": 32210,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0048502938158754,
      "grad_norm": 3.1878998279571533,
      "learning_rate": 3.7571242077243e-06,
      "loss": 0.3760584831237793,
      "memory(GiB)": 72.72,
      "step": 32215,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.005316668221248,
      "grad_norm": 4.754876613616943,
      "learning_rate": 3.755630380759542e-06,
      "loss": 0.3318494319915771,
      "memory(GiB)": 72.72,
      "step": 32220,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0057830426266205,
      "grad_norm": 4.044337272644043,
      "learning_rate": 3.7541366721927193e-06,
      "loss": 0.3159532070159912,
      "memory(GiB)": 72.72,
      "step": 32225,
      "token_acc": 0.6428571428571429,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0062494170319933,
      "grad_norm": 3.1578993797302246,
      "learning_rate": 3.752643082165955e-06,
      "loss": 0.3648902416229248,
      "memory(GiB)": 72.72,
      "step": 32230,
      "token_acc": 0.6037735849056604,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.006715791437366,
      "grad_norm": 4.078555583953857,
      "learning_rate": 3.751149610821359e-06,
      "loss": 0.31707167625427246,
      "memory(GiB)": 72.72,
      "step": 32235,
      "token_acc": 0.8921568627450981,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0071821658427385,
      "grad_norm": 4.9044508934021,
      "learning_rate": 3.7496562583010302e-06,
      "loss": 0.3237947940826416,
      "memory(GiB)": 72.72,
      "step": 32240,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0076485402481112,
      "grad_norm": 3.123624801635742,
      "learning_rate": 3.748163024747058e-06,
      "loss": 0.33715124130249025,
      "memory(GiB)": 72.72,
      "step": 32245,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.008114914653484,
      "grad_norm": 2.3525593280792236,
      "learning_rate": 3.746669910301517e-06,
      "loss": 0.3271175384521484,
      "memory(GiB)": 72.72,
      "step": 32250,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0085812890588564,
      "grad_norm": 3.761204481124878,
      "learning_rate": 3.745176915106472e-06,
      "loss": 0.310754132270813,
      "memory(GiB)": 72.72,
      "step": 32255,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.009047663464229,
      "grad_norm": 2.237096071243286,
      "learning_rate": 3.7436840393039765e-06,
      "loss": 0.3538216114044189,
      "memory(GiB)": 72.72,
      "step": 32260,
      "token_acc": 0.7066666666666667,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.009514037869602,
      "grad_norm": 3.1526811122894287,
      "learning_rate": 3.7421912830360774e-06,
      "loss": 0.3253300189971924,
      "memory(GiB)": 72.72,
      "step": 32265,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.0099804122749743,
      "grad_norm": 3.6975274085998535,
      "learning_rate": 3.7406986464448024e-06,
      "loss": 0.3924661159515381,
      "memory(GiB)": 72.72,
      "step": 32270,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.010446786680347,
      "grad_norm": 3.3507821559906006,
      "learning_rate": 3.7392061296721717e-06,
      "loss": 0.31816864013671875,
      "memory(GiB)": 72.72,
      "step": 32275,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.01091316108572,
      "grad_norm": 2.903656482696533,
      "learning_rate": 3.737713732860193e-06,
      "loss": 0.35000009536743165,
      "memory(GiB)": 72.72,
      "step": 32280,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.011379535491092,
      "grad_norm": 3.9609336853027344,
      "learning_rate": 3.736221456150865e-06,
      "loss": 0.325118350982666,
      "memory(GiB)": 72.72,
      "step": 32285,
      "token_acc": 0.69,
      "train_speed(iter/s)": 0.251277
    },
    {
      "epoch": 3.011845909896465,
      "grad_norm": 2.5663740634918213,
      "learning_rate": 3.7347292996861717e-06,
      "loss": 0.3241751670837402,
      "memory(GiB)": 72.72,
      "step": 32290,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.0123122843018377,
      "grad_norm": 2.468498945236206,
      "learning_rate": 3.7332372636080865e-06,
      "loss": 0.3476731300354004,
      "memory(GiB)": 72.72,
      "step": 32295,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.01277865870721,
      "grad_norm": 3.095789670944214,
      "learning_rate": 3.7317453480585752e-06,
      "loss": 0.3500226020812988,
      "memory(GiB)": 72.72,
      "step": 32300,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 3.013245033112583,
      "grad_norm": 3.010651111602783,
      "learning_rate": 3.7302535531795863e-06,
      "loss": 0.3509341239929199,
      "memory(GiB)": 72.72,
      "step": 32305,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.0137114075179556,
      "grad_norm": 2.6324548721313477,
      "learning_rate": 3.7287618791130608e-06,
      "loss": 0.30236315727233887,
      "memory(GiB)": 72.72,
      "step": 32310,
      "train_speed(iter/s)": 0.251275
    },
    {
      "epoch": 3.014177781923328,
      "grad_norm": 2.4145498275756836,
      "learning_rate": 3.727270326000926e-06,
      "loss": 0.3353855133056641,
      "memory(GiB)": 72.72,
      "step": 32315,
      "token_acc": 0.5925925925925926,
      "train_speed(iter/s)": 0.251275
    },
    {
      "epoch": 3.0146441563287008,
      "grad_norm": 2.0669329166412354,
      "learning_rate": 3.7257788939850993e-06,
      "loss": 0.3653325796127319,
      "memory(GiB)": 72.72,
      "step": 32320,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.251277
    },
    {
      "epoch": 3.0151105307340735,
      "grad_norm": 2.4135801792144775,
      "learning_rate": 3.7242875832074837e-06,
      "loss": 0.34240171909332273,
      "memory(GiB)": 72.72,
      "step": 32325,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.015576905139446,
      "grad_norm": 2.9376440048217773,
      "learning_rate": 3.7227963938099766e-06,
      "loss": 0.29717326164245605,
      "memory(GiB)": 72.72,
      "step": 32330,
      "token_acc": 0.6161616161616161,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.0160432795448187,
      "grad_norm": 4.131939888000488,
      "learning_rate": 3.7213053259344578e-06,
      "loss": 0.3274662017822266,
      "memory(GiB)": 72.72,
      "step": 32335,
      "token_acc": 0.979381443298969,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.016509653950191,
      "grad_norm": 2.269916534423828,
      "learning_rate": 3.7198143797227975e-06,
      "loss": 0.29351582527160647,
      "memory(GiB)": 72.72,
      "step": 32340,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0169760283555638,
      "grad_norm": 6.43037223815918,
      "learning_rate": 3.7183235553168573e-06,
      "loss": 0.32503414154052734,
      "memory(GiB)": 72.72,
      "step": 32345,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0174424027609366,
      "grad_norm": 2.468513011932373,
      "learning_rate": 3.716832852858481e-06,
      "loss": 0.3105828046798706,
      "memory(GiB)": 72.72,
      "step": 32350,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.017908777166309,
      "grad_norm": 3.0826094150543213,
      "learning_rate": 3.7153422724895057e-06,
      "loss": 0.3317363977432251,
      "memory(GiB)": 72.72,
      "step": 32355,
      "token_acc": 0.7,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0183751515716817,
      "grad_norm": 3.69069242477417,
      "learning_rate": 3.7138518143517533e-06,
      "loss": 0.32628979682922366,
      "memory(GiB)": 72.72,
      "step": 32360,
      "token_acc": 0.7058823529411765,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0188415259770545,
      "grad_norm": 3.338198184967041,
      "learning_rate": 3.7123614785870426e-06,
      "loss": 0.3233158111572266,
      "memory(GiB)": 72.72,
      "step": 32365,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 3.019307900382427,
      "grad_norm": 4.648365020751953,
      "learning_rate": 3.7108712653371693e-06,
      "loss": 0.34422550201416013,
      "memory(GiB)": 72.72,
      "step": 32370,
      "token_acc": 0.5465116279069767,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 3.0197742747877996,
      "grad_norm": 4.326530456542969,
      "learning_rate": 3.7093811747439233e-06,
      "loss": 0.37922916412353513,
      "memory(GiB)": 72.72,
      "step": 32375,
      "token_acc": 0.5967741935483871,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0202406491931724,
      "grad_norm": 2.7215874195098877,
      "learning_rate": 3.7078912069490837e-06,
      "loss": 0.3265805721282959,
      "memory(GiB)": 72.72,
      "step": 32380,
      "token_acc": 0.6444444444444445,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0207070235985447,
      "grad_norm": 3.6806681156158447,
      "learning_rate": 3.7064013620944144e-06,
      "loss": 0.34662346839904784,
      "memory(GiB)": 72.72,
      "step": 32385,
      "token_acc": 0.8299319727891157,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.0211733980039175,
      "grad_norm": 4.609863758087158,
      "learning_rate": 3.704911640321671e-06,
      "loss": 0.4242240428924561,
      "memory(GiB)": 72.72,
      "step": 32390,
      "token_acc": 0.9555555555555556,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 3.0216397724092903,
      "grad_norm": 2.866401195526123,
      "learning_rate": 3.703422041772594e-06,
      "loss": 0.3106837749481201,
      "memory(GiB)": 72.72,
      "step": 32395,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0221061468146626,
      "grad_norm": 3.5405678749084473,
      "learning_rate": 3.7019325665889164e-06,
      "loss": 0.35121803283691405,
      "memory(GiB)": 72.72,
      "step": 32400,
      "token_acc": 0.9595959595959596,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0225725212200354,
      "grad_norm": 4.786701679229736,
      "learning_rate": 3.700443214912357e-06,
      "loss": 0.317557168006897,
      "memory(GiB)": 72.72,
      "step": 32405,
      "token_acc": 0.5740740740740741,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.023038895625408,
      "grad_norm": 2.96197247505188,
      "learning_rate": 3.6989539868846215e-06,
      "loss": 0.3439840793609619,
      "memory(GiB)": 72.72,
      "step": 32410,
      "token_acc": 0.7674418604651163,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 3.0235052700307805,
      "grad_norm": 5.325984477996826,
      "learning_rate": 3.697464882647407e-06,
      "loss": 0.33959484100341797,
      "memory(GiB)": 72.72,
      "step": 32415,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 3.0239716444361533,
      "grad_norm": 3.3452064990997314,
      "learning_rate": 3.695975902342397e-06,
      "loss": 0.3389130592346191,
      "memory(GiB)": 72.72,
      "step": 32420,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 3.024438018841526,
      "grad_norm": 2.8312478065490723,
      "learning_rate": 3.6944870461112613e-06,
      "loss": 0.3171771764755249,
      "memory(GiB)": 72.72,
      "step": 32425,
      "token_acc": 0.8297872340425532,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 3.0249043932468984,
      "grad_norm": 2.956465721130371,
      "learning_rate": 3.6929983140956597e-06,
      "loss": 0.3134528636932373,
      "memory(GiB)": 72.72,
      "step": 32430,
      "token_acc": 0.9514563106796117,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 3.025370767652271,
      "grad_norm": 6.524583339691162,
      "learning_rate": 3.6915097064372448e-06,
      "loss": 0.34523234367370603,
      "memory(GiB)": 72.72,
      "step": 32435,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 3.025837142057644,
      "grad_norm": 2.975770950317383,
      "learning_rate": 3.6900212232776513e-06,
      "loss": 0.3675750970840454,
      "memory(GiB)": 72.72,
      "step": 32440,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 3.0263035164630163,
      "grad_norm": 2.307990789413452,
      "learning_rate": 3.688532864758501e-06,
      "loss": 0.33533082008361814,
      "memory(GiB)": 72.72,
      "step": 32445,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 3.026769890868389,
      "grad_norm": 3.145627021789551,
      "learning_rate": 3.687044631021409e-06,
      "loss": 0.31618309020996094,
      "memory(GiB)": 72.72,
      "step": 32450,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 3.027236265273762,
      "grad_norm": 3.1326675415039062,
      "learning_rate": 3.6855565222079758e-06,
      "loss": 0.3321697235107422,
      "memory(GiB)": 72.72,
      "step": 32455,
      "token_acc": 0.961038961038961,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 3.0277026396791342,
      "grad_norm": 3.809551954269409,
      "learning_rate": 3.6840685384597907e-06,
      "loss": 0.3328577995300293,
      "memory(GiB)": 72.72,
      "step": 32460,
      "token_acc": 0.94,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 3.028169014084507,
      "grad_norm": 2.5141549110412598,
      "learning_rate": 3.682580679918428e-06,
      "loss": 0.3047868490219116,
      "memory(GiB)": 72.72,
      "step": 32465,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 3.02863538848988,
      "grad_norm": 3.0347847938537598,
      "learning_rate": 3.6810929467254573e-06,
      "loss": 0.3453512668609619,
      "memory(GiB)": 72.72,
      "step": 32470,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 3.029101762895252,
      "grad_norm": 2.983079195022583,
      "learning_rate": 3.6796053390224297e-06,
      "loss": 0.35869812965393066,
      "memory(GiB)": 72.72,
      "step": 32475,
      "token_acc": 0.4339622641509434,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 3.029568137300625,
      "grad_norm": 2.709212064743042,
      "learning_rate": 3.6781178569508868e-06,
      "loss": 0.3574804782867432,
      "memory(GiB)": 72.72,
      "step": 32480,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 3.0300345117059977,
      "grad_norm": 3.297116994857788,
      "learning_rate": 3.6766305006523574e-06,
      "loss": 0.33552463054656984,
      "memory(GiB)": 72.72,
      "step": 32485,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.25129
    },
    {
      "epoch": 3.03050088611137,
      "grad_norm": 2.8773608207702637,
      "learning_rate": 3.675143270268359e-06,
      "loss": 0.30313544273376464,
      "memory(GiB)": 72.72,
      "step": 32490,
      "train_speed(iter/s)": 0.251289
    },
    {
      "epoch": 3.030967260516743,
      "grad_norm": 3.855313301086426,
      "learning_rate": 3.6736561659403957e-06,
      "loss": 0.3376472949981689,
      "memory(GiB)": 72.72,
      "step": 32495,
      "token_acc": 0.6352941176470588,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 3.0314336349221156,
      "grad_norm": 3.0610430240631104,
      "learning_rate": 3.672169187809963e-06,
      "loss": 0.34419076442718505,
      "memory(GiB)": 72.72,
      "step": 32500,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 3.031900009327488,
      "grad_norm": 3.9737439155578613,
      "learning_rate": 3.670682336018543e-06,
      "loss": 0.37900433540344236,
      "memory(GiB)": 72.72,
      "step": 32505,
      "token_acc": 0.9529411764705882,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 3.0323663837328607,
      "grad_norm": 2.6703317165374756,
      "learning_rate": 3.6691956107076028e-06,
      "loss": 0.3365190029144287,
      "memory(GiB)": 72.72,
      "step": 32510,
      "token_acc": 0.9502262443438914,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 3.0328327581382335,
      "grad_norm": 20.02463150024414,
      "learning_rate": 3.6677090120186006e-06,
      "loss": 0.3563453197479248,
      "memory(GiB)": 72.72,
      "step": 32515,
      "train_speed(iter/s)": 0.251287
    },
    {
      "epoch": 3.033299132543606,
      "grad_norm": 2.9268648624420166,
      "learning_rate": 3.666222540092983e-06,
      "loss": 0.35135593414306643,
      "memory(GiB)": 72.72,
      "step": 32520,
      "token_acc": 0.5432098765432098,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 3.0337655069489786,
      "grad_norm": 2.8341894149780273,
      "learning_rate": 3.6647361950721803e-06,
      "loss": 0.34585962295532224,
      "memory(GiB)": 72.72,
      "step": 32525,
      "token_acc": 0.539568345323741,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 3.0342318813543514,
      "grad_norm": 3.699091672897339,
      "learning_rate": 3.6632499770976136e-06,
      "loss": 0.3344215154647827,
      "memory(GiB)": 72.72,
      "step": 32530,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0346982557597237,
      "grad_norm": 6.351810455322266,
      "learning_rate": 3.661763886310696e-06,
      "loss": 0.339421820640564,
      "memory(GiB)": 72.72,
      "step": 32535,
      "token_acc": 0.9719626168224299,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0351646301650965,
      "grad_norm": 3.7358005046844482,
      "learning_rate": 3.6602779228528225e-06,
      "loss": 0.3415710687637329,
      "memory(GiB)": 72.72,
      "step": 32540,
      "token_acc": 0.6086956521739131,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0356310045704693,
      "grad_norm": 2.7260539531707764,
      "learning_rate": 3.658792086865377e-06,
      "loss": 0.3264223575592041,
      "memory(GiB)": 72.72,
      "step": 32545,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0360973789758416,
      "grad_norm": 3.911248207092285,
      "learning_rate": 3.657306378489732e-06,
      "loss": 0.3222798824310303,
      "memory(GiB)": 72.72,
      "step": 32550,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0365637533812144,
      "grad_norm": 6.044089317321777,
      "learning_rate": 3.65582079786725e-06,
      "loss": 0.3328840255737305,
      "memory(GiB)": 72.72,
      "step": 32555,
      "token_acc": 0.5076923076923077,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.037030127786587,
      "grad_norm": 2.7167444229125977,
      "learning_rate": 3.6543353451392773e-06,
      "loss": 0.29499590396881104,
      "memory(GiB)": 72.72,
      "step": 32560,
      "token_acc": 0.6792452830188679,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 3.0374965021919595,
      "grad_norm": 4.343734264373779,
      "learning_rate": 3.65285002044715e-06,
      "loss": 0.33605711460113524,
      "memory(GiB)": 72.72,
      "step": 32565,
      "token_acc": 0.6111111111111112,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0379628765973323,
      "grad_norm": 2.7721939086914062,
      "learning_rate": 3.6513648239321948e-06,
      "loss": 0.3520035743713379,
      "memory(GiB)": 72.72,
      "step": 32570,
      "token_acc": 0.5175438596491229,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 3.038429251002705,
      "grad_norm": 2.9538357257843018,
      "learning_rate": 3.6498797557357217e-06,
      "loss": 0.30709898471832275,
      "memory(GiB)": 72.72,
      "step": 32575,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0388956254080774,
      "grad_norm": 3.7557809352874756,
      "learning_rate": 3.6483948159990313e-06,
      "loss": 0.3261021375656128,
      "memory(GiB)": 72.72,
      "step": 32580,
      "token_acc": 0.6164383561643836,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0393619998134502,
      "grad_norm": 2.638000965118408,
      "learning_rate": 3.64691000486341e-06,
      "loss": 0.3041813373565674,
      "memory(GiB)": 72.72,
      "step": 32585,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.039828374218823,
      "grad_norm": 2.7345688343048096,
      "learning_rate": 3.645425322470133e-06,
      "loss": 0.3410618782043457,
      "memory(GiB)": 72.72,
      "step": 32590,
      "token_acc": 0.7692307692307693,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0402947486241954,
      "grad_norm": 2.303175926208496,
      "learning_rate": 3.6439407689604655e-06,
      "loss": 0.31079792976379395,
      "memory(GiB)": 72.72,
      "step": 32595,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.040761123029568,
      "grad_norm": 2.8747479915618896,
      "learning_rate": 3.642456344475652e-06,
      "loss": 0.3823465585708618,
      "memory(GiB)": 72.72,
      "step": 32600,
      "token_acc": 0.5591397849462365,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.041227497434941,
      "grad_norm": 3.3566694259643555,
      "learning_rate": 3.6409720491569388e-06,
      "loss": 0.3518707275390625,
      "memory(GiB)": 72.72,
      "step": 32605,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0416938718403133,
      "grad_norm": 2.8748576641082764,
      "learning_rate": 3.639487883145548e-06,
      "loss": 0.3209190845489502,
      "memory(GiB)": 72.72,
      "step": 32610,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.042160246245686,
      "grad_norm": 3.550978422164917,
      "learning_rate": 3.6380038465826938e-06,
      "loss": 0.3772379636764526,
      "memory(GiB)": 72.72,
      "step": 32615,
      "token_acc": 0.4,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.042626620651059,
      "grad_norm": 4.204009532928467,
      "learning_rate": 3.63651993960958e-06,
      "loss": 0.3626511573791504,
      "memory(GiB)": 72.72,
      "step": 32620,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.043092995056431,
      "grad_norm": 6.319128036499023,
      "learning_rate": 3.6350361623673912e-06,
      "loss": 0.3574859619140625,
      "memory(GiB)": 72.72,
      "step": 32625,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.043559369461804,
      "grad_norm": 4.7837324142456055,
      "learning_rate": 3.6335525149973048e-06,
      "loss": 0.3235358715057373,
      "memory(GiB)": 72.72,
      "step": 32630,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0440257438671767,
      "grad_norm": 4.763494968414307,
      "learning_rate": 3.63206899764049e-06,
      "loss": 0.3049919605255127,
      "memory(GiB)": 72.72,
      "step": 32635,
      "token_acc": 0.5964912280701754,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.044492118272549,
      "grad_norm": 2.4717016220092773,
      "learning_rate": 3.6305856104380966e-06,
      "loss": 0.3211127758026123,
      "memory(GiB)": 72.72,
      "step": 32640,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.044958492677922,
      "grad_norm": 3.727613687515259,
      "learning_rate": 3.6291023535312625e-06,
      "loss": 0.29703145027160643,
      "memory(GiB)": 72.72,
      "step": 32645,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0454248670832946,
      "grad_norm": 3.131272077560425,
      "learning_rate": 3.6276192270611166e-06,
      "loss": 0.33868224620819093,
      "memory(GiB)": 72.72,
      "step": 32650,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.045891241488667,
      "grad_norm": 2.922276735305786,
      "learning_rate": 3.626136231168773e-06,
      "loss": 0.3268782615661621,
      "memory(GiB)": 72.72,
      "step": 32655,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0463576158940397,
      "grad_norm": 2.3728606700897217,
      "learning_rate": 3.624653365995335e-06,
      "loss": 0.34906678199768065,
      "memory(GiB)": 72.72,
      "step": 32660,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0468239902994125,
      "grad_norm": 3.363534927368164,
      "learning_rate": 3.6231706316818926e-06,
      "loss": 0.31647188663482667,
      "memory(GiB)": 72.72,
      "step": 32665,
      "token_acc": 0.639344262295082,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.047290364704785,
      "grad_norm": 3.5154383182525635,
      "learning_rate": 3.6216880283695225e-06,
      "loss": 0.34914841651916506,
      "memory(GiB)": 72.72,
      "step": 32670,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0477567391101577,
      "grad_norm": 4.182484149932861,
      "learning_rate": 3.620205556199291e-06,
      "loss": 0.3244499683380127,
      "memory(GiB)": 72.72,
      "step": 32675,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0482231135155304,
      "grad_norm": 3.1491591930389404,
      "learning_rate": 3.618723215312251e-06,
      "loss": 0.31025042533874514,
      "memory(GiB)": 72.72,
      "step": 32680,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0486894879209028,
      "grad_norm": 2.9833102226257324,
      "learning_rate": 3.6172410058494413e-06,
      "loss": 0.36695284843444825,
      "memory(GiB)": 72.72,
      "step": 32685,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.0491558623262756,
      "grad_norm": 3.1854634284973145,
      "learning_rate": 3.61575892795189e-06,
      "loss": 0.3505393505096436,
      "memory(GiB)": 72.72,
      "step": 32690,
      "token_acc": 0.9294117647058824,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0496222367316483,
      "grad_norm": 4.925894737243652,
      "learning_rate": 3.6142769817606137e-06,
      "loss": 0.29882063865661623,
      "memory(GiB)": 72.72,
      "step": 32695,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0500886111370207,
      "grad_norm": 3.0774898529052734,
      "learning_rate": 3.6127951674166105e-06,
      "loss": 0.34717416763305664,
      "memory(GiB)": 72.72,
      "step": 32700,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.0505549855423935,
      "grad_norm": 3.5182926654815674,
      "learning_rate": 3.611313485060877e-06,
      "loss": 0.3025516986846924,
      "memory(GiB)": 72.72,
      "step": 32705,
      "token_acc": 0.46551724137931033,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 3.0510213599477662,
      "grad_norm": 2.7765049934387207,
      "learning_rate": 3.6098319348343856e-06,
      "loss": 0.33467464447021483,
      "memory(GiB)": 72.72,
      "step": 32710,
      "token_acc": 0.7,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0514877343531386,
      "grad_norm": 3.612182140350342,
      "learning_rate": 3.608350516878105e-06,
      "loss": 0.2671018600463867,
      "memory(GiB)": 72.72,
      "step": 32715,
      "token_acc": 0.5675675675675675,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0519541087585114,
      "grad_norm": 3.8425464630126953,
      "learning_rate": 3.6068692313329843e-06,
      "loss": 0.3181323528289795,
      "memory(GiB)": 72.72,
      "step": 32720,
      "token_acc": 0.9560439560439561,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.052420483163884,
      "grad_norm": 2.789547920227051,
      "learning_rate": 3.605388078339965e-06,
      "loss": 0.336654806137085,
      "memory(GiB)": 72.72,
      "step": 32725,
      "train_speed(iter/s)": 0.251282
    },
    {
      "epoch": 3.0528868575692565,
      "grad_norm": 2.4889490604400635,
      "learning_rate": 3.603907058039974e-06,
      "loss": 0.319444465637207,
      "memory(GiB)": 72.72,
      "step": 32730,
      "token_acc": 0.7368421052631579,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0533532319746293,
      "grad_norm": 2.880384922027588,
      "learning_rate": 3.602426170573924e-06,
      "loss": 0.2985290765762329,
      "memory(GiB)": 72.72,
      "step": 32735,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.053819606380002,
      "grad_norm": 3.837446451187134,
      "learning_rate": 3.60094541608272e-06,
      "loss": 0.34219956398010254,
      "memory(GiB)": 72.72,
      "step": 32740,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0542859807853744,
      "grad_norm": 16.042903900146484,
      "learning_rate": 3.5994647947072496e-06,
      "loss": 0.34330058097839355,
      "memory(GiB)": 72.72,
      "step": 32745,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.054752355190747,
      "grad_norm": 3.3263769149780273,
      "learning_rate": 3.5979843065883895e-06,
      "loss": 0.3376907825469971,
      "memory(GiB)": 72.72,
      "step": 32750,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.05521872959612,
      "grad_norm": 4.090000629425049,
      "learning_rate": 3.596503951867004e-06,
      "loss": 0.31115448474884033,
      "memory(GiB)": 72.72,
      "step": 32755,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.0556851040014923,
      "grad_norm": 5.725106239318848,
      "learning_rate": 3.595023730683943e-06,
      "loss": 0.35350611209869387,
      "memory(GiB)": 72.72,
      "step": 32760,
      "token_acc": 0.6111111111111112,
      "train_speed(iter/s)": 0.251285
    },
    {
      "epoch": 3.056151478406865,
      "grad_norm": 4.795398712158203,
      "learning_rate": 3.593543643180047e-06,
      "loss": 0.3517275810241699,
      "memory(GiB)": 72.72,
      "step": 32765,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 3.056617852812238,
      "grad_norm": 4.347026824951172,
      "learning_rate": 3.592063689496139e-06,
      "loss": 0.36952598094940187,
      "memory(GiB)": 72.72,
      "step": 32770,
      "token_acc": 0.7870967741935484,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.05708422721761,
      "grad_norm": 4.4944682121276855,
      "learning_rate": 3.5905838697730343e-06,
      "loss": 0.3238107204437256,
      "memory(GiB)": 72.72,
      "step": 32775,
      "token_acc": 0.71875,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 3.057550601622983,
      "grad_norm": 3.050973415374756,
      "learning_rate": 3.5891041841515338e-06,
      "loss": 0.3263104915618896,
      "memory(GiB)": 72.72,
      "step": 32780,
      "token_acc": 0.5151515151515151,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.0580169760283558,
      "grad_norm": 2.941387891769409,
      "learning_rate": 3.587624632772423e-06,
      "loss": 0.30872511863708496,
      "memory(GiB)": 72.72,
      "step": 32785,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.058483350433728,
      "grad_norm": 2.9433741569519043,
      "learning_rate": 3.5861452157764777e-06,
      "loss": 0.32222418785095214,
      "memory(GiB)": 72.72,
      "step": 32790,
      "token_acc": 0.5757575757575758,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.058949724839101,
      "grad_norm": 4.370972633361816,
      "learning_rate": 3.5846659333044602e-06,
      "loss": 0.32915725708007815,
      "memory(GiB)": 72.72,
      "step": 32795,
      "token_acc": 0.941747572815534,
      "train_speed(iter/s)": 0.251277
    },
    {
      "epoch": 3.0594160992444737,
      "grad_norm": 5.6957550048828125,
      "learning_rate": 3.5831867854971165e-06,
      "loss": 0.322307825088501,
      "memory(GiB)": 72.72,
      "step": 32800,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.059882473649846,
      "grad_norm": 3.834730386734009,
      "learning_rate": 3.5817077724951875e-06,
      "loss": 0.3191394805908203,
      "memory(GiB)": 72.72,
      "step": 32805,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.060348848055219,
      "grad_norm": 3.7224464416503906,
      "learning_rate": 3.580228894439395e-06,
      "loss": 0.3091276168823242,
      "memory(GiB)": 72.72,
      "step": 32810,
      "train_speed(iter/s)": 0.25128
    },
    {
      "epoch": 3.0608152224605916,
      "grad_norm": 3.2213990688323975,
      "learning_rate": 3.5787501514704498e-06,
      "loss": 0.33946425914764405,
      "memory(GiB)": 72.72,
      "step": 32815,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.061281596865964,
      "grad_norm": 3.634855031967163,
      "learning_rate": 3.577271543729049e-06,
      "loss": 0.3458235740661621,
      "memory(GiB)": 72.72,
      "step": 32820,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.0617479712713367,
      "grad_norm": 3.254549026489258,
      "learning_rate": 3.5757930713558776e-06,
      "loss": 0.3553614139556885,
      "memory(GiB)": 72.72,
      "step": 32825,
      "train_speed(iter/s)": 0.251277
    },
    {
      "epoch": 3.0622143456767095,
      "grad_norm": 3.2182157039642334,
      "learning_rate": 3.5743147344916083e-06,
      "loss": 0.3283729553222656,
      "memory(GiB)": 72.72,
      "step": 32830,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251274
    },
    {
      "epoch": 3.062680720082082,
      "grad_norm": 3.3613197803497314,
      "learning_rate": 3.5728365332768986e-06,
      "loss": 0.32931792736053467,
      "memory(GiB)": 72.72,
      "step": 32835,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 3.0631470944874546,
      "grad_norm": 3.390320062637329,
      "learning_rate": 3.571358467852398e-06,
      "loss": 0.29500317573547363,
      "memory(GiB)": 72.72,
      "step": 32840,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.0636134688928274,
      "grad_norm": 2.2789039611816406,
      "learning_rate": 3.5698805383587386e-06,
      "loss": 0.34458396434783933,
      "memory(GiB)": 72.72,
      "step": 32845,
      "token_acc": 0.6530612244897959,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.0640798432981997,
      "grad_norm": 4.41903829574585,
      "learning_rate": 3.5684027449365396e-06,
      "loss": 0.34172759056091306,
      "memory(GiB)": 72.72,
      "step": 32850,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.0645462177035725,
      "grad_norm": 3.26800274848938,
      "learning_rate": 3.5669250877264093e-06,
      "loss": 0.3322092056274414,
      "memory(GiB)": 72.72,
      "step": 32855,
      "token_acc": 0.3709677419354839,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 3.0650125921089453,
      "grad_norm": 3.0605578422546387,
      "learning_rate": 3.5654475668689425e-06,
      "loss": 0.3266613960266113,
      "memory(GiB)": 72.72,
      "step": 32860,
      "token_acc": 0.8552631578947368,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 3.0654789665143176,
      "grad_norm": 3.171142101287842,
      "learning_rate": 3.56397018250472e-06,
      "loss": 0.30455403327941893,
      "memory(GiB)": 72.72,
      "step": 32865,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.0659453409196904,
      "grad_norm": 4.533766269683838,
      "learning_rate": 3.56249293477431e-06,
      "loss": 0.31381831169128416,
      "memory(GiB)": 72.72,
      "step": 32870,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.0664117153250627,
      "grad_norm": 4.191669464111328,
      "learning_rate": 3.56101582381827e-06,
      "loss": 0.3892120122909546,
      "memory(GiB)": 72.72,
      "step": 32875,
      "token_acc": 0.9469026548672567,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.0668780897304355,
      "grad_norm": 3.0473685264587402,
      "learning_rate": 3.559538849777141e-06,
      "loss": 0.34359843730926515,
      "memory(GiB)": 72.72,
      "step": 32880,
      "token_acc": 0.7238493723849372,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0673444641358083,
      "grad_norm": 2.458101749420166,
      "learning_rate": 3.5580620127914537e-06,
      "loss": 0.3203227758407593,
      "memory(GiB)": 72.72,
      "step": 32885,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.067810838541181,
      "grad_norm": 2.685495376586914,
      "learning_rate": 3.5565853130017237e-06,
      "loss": 0.3066277265548706,
      "memory(GiB)": 72.72,
      "step": 32890,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 3.0682772129465534,
      "grad_norm": 2.649966239929199,
      "learning_rate": 3.555108750548456e-06,
      "loss": 0.3415855407714844,
      "memory(GiB)": 72.72,
      "step": 32895,
      "token_acc": 0.5405405405405406,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.068743587351926,
      "grad_norm": 5.766554355621338,
      "learning_rate": 3.5536323255721377e-06,
      "loss": 0.30907564163208007,
      "memory(GiB)": 72.72,
      "step": 32900,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.0692099617572985,
      "grad_norm": 7.145787715911865,
      "learning_rate": 3.5521560382132465e-06,
      "loss": 0.36133522987365724,
      "memory(GiB)": 72.72,
      "step": 32905,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.0696763361626713,
      "grad_norm": 3.1295106410980225,
      "learning_rate": 3.5506798886122494e-06,
      "loss": 0.34901130199432373,
      "memory(GiB)": 72.72,
      "step": 32910,
      "token_acc": 0.4957983193277311,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.070142710568044,
      "grad_norm": 2.591984987258911,
      "learning_rate": 3.549203876909598e-06,
      "loss": 0.29410810470581056,
      "memory(GiB)": 72.72,
      "step": 32915,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.0706090849734164,
      "grad_norm": 2.6550540924072266,
      "learning_rate": 3.547728003245727e-06,
      "loss": 0.2938926935195923,
      "memory(GiB)": 72.72,
      "step": 32920,
      "token_acc": 0.6511627906976745,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 3.0710754593787892,
      "grad_norm": 3.441972494125366,
      "learning_rate": 3.5462522677610633e-06,
      "loss": 0.3122608184814453,
      "memory(GiB)": 72.72,
      "step": 32925,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.071541833784162,
      "grad_norm": 3.1080315113067627,
      "learning_rate": 3.5447766705960175e-06,
      "loss": 0.32471089363098143,
      "memory(GiB)": 72.72,
      "step": 32930,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 3.0720082081895344,
      "grad_norm": 5.158551216125488,
      "learning_rate": 3.543301211890987e-06,
      "loss": 0.3967172861099243,
      "memory(GiB)": 72.72,
      "step": 32935,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 3.072474582594907,
      "grad_norm": 5.190551280975342,
      "learning_rate": 3.5418258917863605e-06,
      "loss": 0.28645930290222166,
      "memory(GiB)": 72.72,
      "step": 32940,
      "token_acc": 0.9903846153846154,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 3.07294095700028,
      "grad_norm": 2.6888036727905273,
      "learning_rate": 3.5403507104225082e-06,
      "loss": 0.3152503967285156,
      "memory(GiB)": 72.72,
      "step": 32945,
      "token_acc": 0.6228070175438597,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 3.0734073314056523,
      "grad_norm": 3.22052001953125,
      "learning_rate": 3.5388756679397895e-06,
      "loss": 0.3470630168914795,
      "memory(GiB)": 72.72,
      "step": 32950,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 3.073873705811025,
      "grad_norm": 7.4106550216674805,
      "learning_rate": 3.537400764478549e-06,
      "loss": 0.2914785146713257,
      "memory(GiB)": 72.72,
      "step": 32955,
      "token_acc": 0.6956521739130435,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.074340080216398,
      "grad_norm": 2.679623603820801,
      "learning_rate": 3.5359260001791205e-06,
      "loss": 0.3220694065093994,
      "memory(GiB)": 72.72,
      "step": 32960,
      "token_acc": 0.9603960396039604,
      "train_speed(iter/s)": 0.25127
    },
    {
      "epoch": 3.07480645462177,
      "grad_norm": 6.713120937347412,
      "learning_rate": 3.5344513751818234e-06,
      "loss": 0.3543060779571533,
      "memory(GiB)": 72.72,
      "step": 32965,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.075272829027143,
      "grad_norm": 3.582014560699463,
      "learning_rate": 3.532976889626962e-06,
      "loss": 0.295942497253418,
      "memory(GiB)": 72.72,
      "step": 32970,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.0757392034325157,
      "grad_norm": 2.4494190216064453,
      "learning_rate": 3.531502543654831e-06,
      "loss": 0.31172444820404055,
      "memory(GiB)": 72.72,
      "step": 32975,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.076205577837888,
      "grad_norm": 2.869147300720215,
      "learning_rate": 3.53002833740571e-06,
      "loss": 0.3342566967010498,
      "memory(GiB)": 72.72,
      "step": 32980,
      "token_acc": 0.5154639175257731,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.076671952243261,
      "grad_norm": 4.1314826011657715,
      "learning_rate": 3.5285542710198627e-06,
      "loss": 0.35551764965057375,
      "memory(GiB)": 72.72,
      "step": 32985,
      "token_acc": 0.56,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.0771383266486336,
      "grad_norm": 4.642542362213135,
      "learning_rate": 3.5270803446375455e-06,
      "loss": 0.35344843864440917,
      "memory(GiB)": 72.72,
      "step": 32990,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.077604701054006,
      "grad_norm": 3.073267936706543,
      "learning_rate": 3.5256065583989958e-06,
      "loss": 0.3412453651428223,
      "memory(GiB)": 72.72,
      "step": 32995,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.0780710754593787,
      "grad_norm": 2.596614360809326,
      "learning_rate": 3.524132912444439e-06,
      "loss": 0.3374551057815552,
      "memory(GiB)": 72.72,
      "step": 33000,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.0785374498647515,
      "grad_norm": 2.957209348678589,
      "learning_rate": 3.5226594069140876e-06,
      "loss": 0.3489564895629883,
      "memory(GiB)": 72.72,
      "step": 33005,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.079003824270124,
      "grad_norm": 2.697108030319214,
      "learning_rate": 3.5211860419481457e-06,
      "loss": 0.3556253671646118,
      "memory(GiB)": 72.72,
      "step": 33010,
      "token_acc": 0.979381443298969,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0794701986754967,
      "grad_norm": 2.6225459575653076,
      "learning_rate": 3.5197128176867944e-06,
      "loss": 0.31000618934631347,
      "memory(GiB)": 72.72,
      "step": 33015,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.0799365730808694,
      "grad_norm": 2.679731845855713,
      "learning_rate": 3.5182397342702094e-06,
      "loss": 0.3395741701126099,
      "memory(GiB)": 72.72,
      "step": 33020,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.0804029474862418,
      "grad_norm": 3.005154609680176,
      "learning_rate": 3.5167667918385485e-06,
      "loss": 0.37050886154174806,
      "memory(GiB)": 72.72,
      "step": 33025,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.0808693218916146,
      "grad_norm": 2.72847056388855,
      "learning_rate": 3.5152939905319583e-06,
      "loss": 0.30819828510284425,
      "memory(GiB)": 72.72,
      "step": 33030,
      "train_speed(iter/s)": 0.251269
    },
    {
      "epoch": 3.0813356962969873,
      "grad_norm": 3.8544769287109375,
      "learning_rate": 3.513821330490571e-06,
      "loss": 0.32248940467834475,
      "memory(GiB)": 72.72,
      "step": 33035,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0818020707023597,
      "grad_norm": 2.5540056228637695,
      "learning_rate": 3.512348811854505e-06,
      "loss": 0.3370509624481201,
      "memory(GiB)": 72.72,
      "step": 33040,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 3.0822684451077325,
      "grad_norm": 6.688327789306641,
      "learning_rate": 3.510876434763868e-06,
      "loss": 0.32002360820770265,
      "memory(GiB)": 72.72,
      "step": 33045,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.0827348195131052,
      "grad_norm": 2.639467239379883,
      "learning_rate": 3.50940419935875e-06,
      "loss": 0.34034817218780516,
      "memory(GiB)": 72.72,
      "step": 33050,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 3.0832011939184776,
      "grad_norm": 2.23047137260437,
      "learning_rate": 3.5079321057792316e-06,
      "loss": 0.31811506748199464,
      "memory(GiB)": 72.72,
      "step": 33055,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 3.0836675683238504,
      "grad_norm": 3.107728958129883,
      "learning_rate": 3.5064601541653763e-06,
      "loss": 0.3031050682067871,
      "memory(GiB)": 72.72,
      "step": 33060,
      "token_acc": 0.5111111111111111,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 3.084133942729223,
      "grad_norm": 4.207560062408447,
      "learning_rate": 3.5049883446572365e-06,
      "loss": 0.34375662803649903,
      "memory(GiB)": 72.72,
      "step": 33065,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 3.0846003171345955,
      "grad_norm": 2.9287021160125732,
      "learning_rate": 3.5035166773948514e-06,
      "loss": 0.3450178623199463,
      "memory(GiB)": 72.72,
      "step": 33070,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 3.0850666915399683,
      "grad_norm": 2.628164291381836,
      "learning_rate": 3.502045152518241e-06,
      "loss": 0.33594837188720705,
      "memory(GiB)": 72.72,
      "step": 33075,
      "token_acc": 0.5538461538461539,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 3.085533065945341,
      "grad_norm": 2.779679775238037,
      "learning_rate": 3.5005737701674215e-06,
      "loss": 0.3442704439163208,
      "memory(GiB)": 72.72,
      "step": 33080,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 3.0859994403507134,
      "grad_norm": 2.4935522079467773,
      "learning_rate": 3.4991025304823897e-06,
      "loss": 0.2987708806991577,
      "memory(GiB)": 72.72,
      "step": 33085,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.086465814756086,
      "grad_norm": 2.8946075439453125,
      "learning_rate": 3.4976314336031287e-06,
      "loss": 0.31672868728637693,
      "memory(GiB)": 72.72,
      "step": 33090,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 3.086932189161459,
      "grad_norm": 3.1483426094055176,
      "learning_rate": 3.496160479669608e-06,
      "loss": 0.2911652088165283,
      "memory(GiB)": 72.72,
      "step": 33095,
      "train_speed(iter/s)": 0.251263
    },
    {
      "epoch": 3.0873985635668313,
      "grad_norm": 3.4473719596862793,
      "learning_rate": 3.4946896688217846e-06,
      "loss": 0.36303575038909913,
      "memory(GiB)": 72.72,
      "step": 33100,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 3.087864937972204,
      "grad_norm": 6.38154411315918,
      "learning_rate": 3.4932190011996004e-06,
      "loss": 0.35822105407714844,
      "memory(GiB)": 72.72,
      "step": 33105,
      "train_speed(iter/s)": 0.251264
    },
    {
      "epoch": 3.088331312377577,
      "grad_norm": 3.2184746265411377,
      "learning_rate": 3.4917484769429887e-06,
      "loss": 0.33029732704162595,
      "memory(GiB)": 72.72,
      "step": 33110,
      "token_acc": 0.5689655172413793,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 3.088797686782949,
      "grad_norm": 3.220623254776001,
      "learning_rate": 3.490278096191863e-06,
      "loss": 0.32167088985443115,
      "memory(GiB)": 72.72,
      "step": 33115,
      "train_speed(iter/s)": 0.251261
    },
    {
      "epoch": 3.089264061188322,
      "grad_norm": 3.0447394847869873,
      "learning_rate": 3.4888078590861252e-06,
      "loss": 0.37297136783599855,
      "memory(GiB)": 72.72,
      "step": 33120,
      "train_speed(iter/s)": 0.25126
    },
    {
      "epoch": 3.0897304355936948,
      "grad_norm": 5.562445163726807,
      "learning_rate": 3.487337765765665e-06,
      "loss": 0.31369647979736326,
      "memory(GiB)": 72.72,
      "step": 33125,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.251262
    },
    {
      "epoch": 3.090196809999067,
      "grad_norm": 2.89457106590271,
      "learning_rate": 3.485867816370355e-06,
      "loss": 0.3337759494781494,
      "memory(GiB)": 72.72,
      "step": 33130,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.09066318440444,
      "grad_norm": 2.668816566467285,
      "learning_rate": 3.4843980110400593e-06,
      "loss": 0.3235382318496704,
      "memory(GiB)": 72.72,
      "step": 33135,
      "token_acc": 0.9772727272727273,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.0911295588098127,
      "grad_norm": 3.617786169052124,
      "learning_rate": 3.4829283499146227e-06,
      "loss": 0.3301896572113037,
      "memory(GiB)": 72.72,
      "step": 33140,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 3.091595933215185,
      "grad_norm": 3.3666129112243652,
      "learning_rate": 3.4814588331338804e-06,
      "loss": 0.3534515619277954,
      "memory(GiB)": 72.72,
      "step": 33145,
      "train_speed(iter/s)": 0.251265
    },
    {
      "epoch": 3.092062307620558,
      "grad_norm": 4.647992134094238,
      "learning_rate": 3.479989460837653e-06,
      "loss": 0.30329031944274903,
      "memory(GiB)": 72.72,
      "step": 33150,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0925286820259306,
      "grad_norm": 3.026456594467163,
      "learning_rate": 3.478520233165745e-06,
      "loss": 0.36284732818603516,
      "memory(GiB)": 72.72,
      "step": 33155,
      "train_speed(iter/s)": 0.251267
    },
    {
      "epoch": 3.092995056431303,
      "grad_norm": 2.999199867248535,
      "learning_rate": 3.4770511502579505e-06,
      "loss": 0.28029232025146483,
      "memory(GiB)": 72.72,
      "step": 33160,
      "token_acc": 0.5189873417721519,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0934614308366757,
      "grad_norm": 3.0236055850982666,
      "learning_rate": 3.4755822122540473e-06,
      "loss": 0.3334489345550537,
      "memory(GiB)": 72.72,
      "step": 33165,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0939278052420485,
      "grad_norm": 3.6915812492370605,
      "learning_rate": 3.474113419293802e-06,
      "loss": 0.31934170722961425,
      "memory(GiB)": 72.72,
      "step": 33170,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.094394179647421,
      "grad_norm": 2.860358715057373,
      "learning_rate": 3.47264477151696e-06,
      "loss": 0.34679226875305175,
      "memory(GiB)": 72.72,
      "step": 33175,
      "train_speed(iter/s)": 0.251266
    },
    {
      "epoch": 3.0948605540527936,
      "grad_norm": 5.500516414642334,
      "learning_rate": 3.4711762690632663e-06,
      "loss": 0.35005836486816405,
      "memory(GiB)": 72.72,
      "step": 33180,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0953269284581664,
      "grad_norm": 2.405320405960083,
      "learning_rate": 3.46970791207244e-06,
      "loss": 0.33528196811676025,
      "memory(GiB)": 72.72,
      "step": 33185,
      "token_acc": 0.7073170731707317,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0957933028635387,
      "grad_norm": 3.5726490020751953,
      "learning_rate": 3.4682397006841927e-06,
      "loss": 0.33978288173675536,
      "memory(GiB)": 72.72,
      "step": 33190,
      "token_acc": 0.7333333333333333,
      "train_speed(iter/s)": 0.251268
    },
    {
      "epoch": 3.0962596772689115,
      "grad_norm": 2.379682779312134,
      "learning_rate": 3.4667716350382187e-06,
      "loss": 0.31171526908874514,
      "memory(GiB)": 72.72,
      "step": 33195,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.251271
    },
    {
      "epoch": 3.0967260516742843,
      "grad_norm": 2.487907648086548,
      "learning_rate": 3.4653037152742004e-06,
      "loss": 0.306077766418457,
      "memory(GiB)": 72.72,
      "step": 33200,
      "token_acc": 0.5535714285714286,
      "train_speed(iter/s)": 0.251272
    },
    {
      "epoch": 3.0971924260796566,
      "grad_norm": 2.8335604667663574,
      "learning_rate": 3.463835941531806e-06,
      "loss": 0.34636778831481935,
      "memory(GiB)": 72.72,
      "step": 33205,
      "token_acc": 0.6532258064516129,
      "train_speed(iter/s)": 0.251273
    },
    {
      "epoch": 3.0976588004850294,
      "grad_norm": 5.2349653244018555,
      "learning_rate": 3.462368313950687e-06,
      "loss": 0.32558956146240237,
      "memory(GiB)": 72.72,
      "step": 33210,
      "token_acc": 0.6486486486486487,
      "train_speed(iter/s)": 0.251276
    },
    {
      "epoch": 3.098125174890402,
      "grad_norm": 2.6828839778900146,
      "learning_rate": 3.4609008326704887e-06,
      "loss": 0.3324517965316772,
      "memory(GiB)": 72.72,
      "step": 33215,
      "token_acc": 0.967032967032967,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.0985915492957745,
      "grad_norm": 2.3597042560577393,
      "learning_rate": 3.459433497830834e-06,
      "loss": 0.3118535041809082,
      "memory(GiB)": 72.72,
      "step": 33220,
      "train_speed(iter/s)": 0.251278
    },
    {
      "epoch": 3.0990579237011473,
      "grad_norm": 2.2687904834747314,
      "learning_rate": 3.4579663095713367e-06,
      "loss": 0.3124366521835327,
      "memory(GiB)": 72.72,
      "step": 33225,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.09952429810652,
      "grad_norm": 3.1844162940979004,
      "learning_rate": 3.4564992680315945e-06,
      "loss": 0.3598538875579834,
      "memory(GiB)": 72.72,
      "step": 33230,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.0999906725118924,
      "grad_norm": 2.3541126251220703,
      "learning_rate": 3.455032373351192e-06,
      "loss": 0.3824302673339844,
      "memory(GiB)": 72.72,
      "step": 33235,
      "token_acc": 0.65,
      "train_speed(iter/s)": 0.251279
    },
    {
      "epoch": 3.100457046917265,
      "grad_norm": 2.9554970264434814,
      "learning_rate": 3.4535656256697e-06,
      "loss": 0.3437807559967041,
      "memory(GiB)": 72.72,
      "step": 33240,
      "token_acc": 0.6176470588235294,
      "train_speed(iter/s)": 0.251283
    },
    {
      "epoch": 3.100923421322638,
      "grad_norm": 3.7165133953094482,
      "learning_rate": 3.4520990251266735e-06,
      "loss": 0.2877859115600586,
      "memory(GiB)": 72.72,
      "step": 33245,
      "token_acc": 0.9139784946236559,
      "train_speed(iter/s)": 0.251281
    },
    {
      "epoch": 3.1013897957280103,
      "grad_norm": 2.9700868129730225,
      "learning_rate": 3.4506325718616575e-06,
      "loss": 0.33951425552368164,
      "memory(GiB)": 72.72,
      "step": 33250,
      "token_acc": 0.46296296296296297,
      "train_speed(iter/s)": 0.251284
    },
    {
      "epoch": 3.101856170133383,
      "grad_norm": 3.136280059814453,
      "learning_rate": 3.449166266014179e-06,
      "loss": 0.28706018924713134,
      "memory(GiB)": 72.72,
      "step": 33255,
      "train_speed(iter/s)": 0.251286
    },
    {
      "epoch": 3.102322544538756,
      "grad_norm": 2.822252035140991,
      "learning_rate": 3.4477001077237538e-06,
      "loss": 0.31376550197601316,
      "memory(GiB)": 72.72,
      "step": 33260,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 3.1027889189441282,
      "grad_norm": 2.695685863494873,
      "learning_rate": 3.446234097129881e-06,
      "loss": 0.2935680866241455,
      "memory(GiB)": 72.72,
      "step": 33265,
      "token_acc": 0.5869565217391305,
      "train_speed(iter/s)": 0.251288
    },
    {
      "epoch": 3.103255293349501,
      "grad_norm": 3.2980129718780518,
      "learning_rate": 3.444768234372048e-06,
      "loss": 0.2887326717376709,
      "memory(GiB)": 72.72,
      "step": 33270,
      "token_acc": 0.7228915662650602,
      "train_speed(iter/s)": 0.251291
    },
    {
      "epoch": 3.103721667754874,
      "grad_norm": 3.3701813220977783,
      "learning_rate": 3.443302519589723e-06,
      "loss": 0.34716751575469973,
      "memory(GiB)": 72.72,
      "step": 33275,
      "train_speed(iter/s)": 0.25129
    },
    {
      "epoch": 3.104188042160246,
      "grad_norm": 3.038569450378418,
      "learning_rate": 3.4418369529223706e-06,
      "loss": 0.36943318843841555,
      "memory(GiB)": 72.72,
      "step": 33280,
      "token_acc": 0.6293103448275862,
      "train_speed(iter/s)": 0.251292
    },
    {
      "epoch": 3.104654416565619,
      "grad_norm": 3.2113161087036133,
      "learning_rate": 3.4403715345094323e-06,
      "loss": 0.35257534980773925,
      "memory(GiB)": 72.72,
      "step": 33285,
      "token_acc": 0.6744186046511628,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 3.1051207909709917,
      "grad_norm": 31.532020568847656,
      "learning_rate": 3.438906264490338e-06,
      "loss": 0.29874815940856936,
      "memory(GiB)": 72.72,
      "step": 33290,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 3.105587165376364,
      "grad_norm": 3.0525002479553223,
      "learning_rate": 3.437441143004503e-06,
      "loss": 0.32896597385406495,
      "memory(GiB)": 72.72,
      "step": 33295,
      "token_acc": 0.5267857142857143,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 3.106053539781737,
      "grad_norm": 3.2397828102111816,
      "learning_rate": 3.43597617019133e-06,
      "loss": 0.3255216121673584,
      "memory(GiB)": 72.72,
      "step": 33300,
      "train_speed(iter/s)": 0.251296
    },
    {
      "epoch": 3.1065199141871096,
      "grad_norm": 3.3160970211029053,
      "learning_rate": 3.4345113461902057e-06,
      "loss": 0.3460372447967529,
      "memory(GiB)": 72.72,
      "step": 33305,
      "token_acc": 0.9191919191919192,
      "train_speed(iter/s)": 0.2513
    },
    {
      "epoch": 3.106986288592482,
      "grad_norm": 3.1586430072784424,
      "learning_rate": 3.433046671140503e-06,
      "loss": 0.32280797958374025,
      "memory(GiB)": 72.72,
      "step": 33310,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 3.1074526629978547,
      "grad_norm": 2.5531342029571533,
      "learning_rate": 3.4315821451815846e-06,
      "loss": 0.3413196802139282,
      "memory(GiB)": 72.72,
      "step": 33315,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 3.1079190374032275,
      "grad_norm": 3.4039907455444336,
      "learning_rate": 3.430117768452792e-06,
      "loss": 0.3685730457305908,
      "memory(GiB)": 72.72,
      "step": 33320,
      "train_speed(iter/s)": 0.2513
    },
    {
      "epoch": 3.1083854118086,
      "grad_norm": 3.7118208408355713,
      "learning_rate": 3.4286535410934585e-06,
      "loss": 0.33905835151672364,
      "memory(GiB)": 72.72,
      "step": 33325,
      "train_speed(iter/s)": 0.251302
    },
    {
      "epoch": 3.1088517862139726,
      "grad_norm": 2.9460201263427734,
      "learning_rate": 3.4271894632429e-06,
      "loss": 0.33849472999572755,
      "memory(GiB)": 72.72,
      "step": 33330,
      "token_acc": 0.43103448275862066,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 3.1093181606193454,
      "grad_norm": 3.228560447692871,
      "learning_rate": 3.4257255350404184e-06,
      "loss": 0.3136024475097656,
      "memory(GiB)": 72.72,
      "step": 33335,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 3.1097845350247177,
      "grad_norm": 2.3402976989746094,
      "learning_rate": 3.424261756625303e-06,
      "loss": 0.3139225482940674,
      "memory(GiB)": 72.72,
      "step": 33340,
      "token_acc": 0.967391304347826,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 3.1102509094300905,
      "grad_norm": 3.3906912803649902,
      "learning_rate": 3.422798128136826e-06,
      "loss": 0.34435667991638186,
      "memory(GiB)": 72.72,
      "step": 33345,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 3.1107172838354633,
      "grad_norm": 2.8949215412139893,
      "learning_rate": 3.4213346497142495e-06,
      "loss": 0.3500227928161621,
      "memory(GiB)": 72.72,
      "step": 33350,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 3.1111836582408356,
      "grad_norm": 3.325212001800537,
      "learning_rate": 3.4198713214968176e-06,
      "loss": 0.3345836877822876,
      "memory(GiB)": 72.72,
      "step": 33355,
      "token_acc": 0.65,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 3.1116500326462084,
      "grad_norm": 6.665272235870361,
      "learning_rate": 3.418408143623762e-06,
      "loss": 0.36173985004425047,
      "memory(GiB)": 72.72,
      "step": 33360,
      "token_acc": 0.37142857142857144,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 3.112116407051581,
      "grad_norm": 2.198660135269165,
      "learning_rate": 3.4169451162343004e-06,
      "loss": 0.2959830522537231,
      "memory(GiB)": 72.72,
      "step": 33365,
      "token_acc": 0.5370370370370371,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 3.1125827814569536,
      "grad_norm": 2.710394859313965,
      "learning_rate": 3.4154822394676336e-06,
      "loss": 0.3330526351928711,
      "memory(GiB)": 72.72,
      "step": 33370,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 3.1130491558623263,
      "grad_norm": 3.5337977409362793,
      "learning_rate": 3.4140195134629495e-06,
      "loss": 0.3254769563674927,
      "memory(GiB)": 72.72,
      "step": 33375,
      "token_acc": 0.9863013698630136,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 3.113515530267699,
      "grad_norm": 4.565842628479004,
      "learning_rate": 3.4125569383594215e-06,
      "loss": 0.3608997821807861,
      "memory(GiB)": 72.72,
      "step": 33380,
      "token_acc": 0.8157894736842105,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 3.1139819046730715,
      "grad_norm": 4.576898097991943,
      "learning_rate": 3.411094514296214e-06,
      "loss": 0.32163162231445314,
      "memory(GiB)": 72.72,
      "step": 33385,
      "token_acc": 0.9487179487179487,
      "train_speed(iter/s)": 0.251309
    },
    {
      "epoch": 3.1144482790784442,
      "grad_norm": 2.592313528060913,
      "learning_rate": 3.4096322414124672e-06,
      "loss": 0.30675997734069826,
      "memory(GiB)": 72.72,
      "step": 33390,
      "token_acc": 0.4264705882352941,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 3.114914653483817,
      "grad_norm": 9.991928100585938,
      "learning_rate": 3.4081701198473133e-06,
      "loss": 0.3079050540924072,
      "memory(GiB)": 72.72,
      "step": 33395,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 3.1153810278891894,
      "grad_norm": 3.3227455615997314,
      "learning_rate": 3.406708149739869e-06,
      "loss": 0.3460158109664917,
      "memory(GiB)": 72.72,
      "step": 33400,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 3.115847402294562,
      "grad_norm": 3.018035411834717,
      "learning_rate": 3.405246331229236e-06,
      "loss": 0.3065779209136963,
      "memory(GiB)": 72.72,
      "step": 33405,
      "token_acc": 0.9560439560439561,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 3.1163137766999345,
      "grad_norm": 8.831391334533691,
      "learning_rate": 3.4037846644545003e-06,
      "loss": 0.3271541357040405,
      "memory(GiB)": 72.72,
      "step": 33410,
      "token_acc": 0.6578947368421053,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 3.1167801511053073,
      "grad_norm": 4.075070381164551,
      "learning_rate": 3.402323149554738e-06,
      "loss": 0.3524848222732544,
      "memory(GiB)": 72.72,
      "step": 33415,
      "token_acc": 0.9702970297029703,
      "train_speed(iter/s)": 0.251312
    },
    {
      "epoch": 3.11724652551068,
      "grad_norm": 2.764845371246338,
      "learning_rate": 3.4008617866690065e-06,
      "loss": 0.327576208114624,
      "memory(GiB)": 72.72,
      "step": 33420,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 3.117712899916053,
      "grad_norm": 6.069121837615967,
      "learning_rate": 3.3994005759363493e-06,
      "loss": 0.342344331741333,
      "memory(GiB)": 72.72,
      "step": 33425,
      "token_acc": 0.6078431372549019,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 3.118179274321425,
      "grad_norm": 3.468944549560547,
      "learning_rate": 3.397939517495797e-06,
      "loss": 0.32553682327270506,
      "memory(GiB)": 72.72,
      "step": 33430,
      "token_acc": 0.9354838709677419,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 3.118645648726798,
      "grad_norm": 3.223904609680176,
      "learning_rate": 3.3964786114863634e-06,
      "loss": 0.3544012546539307,
      "memory(GiB)": 72.72,
      "step": 33435,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 3.1191120231321703,
      "grad_norm": 2.538783311843872,
      "learning_rate": 3.3950178580470517e-06,
      "loss": 0.3042816400527954,
      "memory(GiB)": 72.72,
      "step": 33440,
      "train_speed(iter/s)": 0.251311
    },
    {
      "epoch": 3.119578397537543,
      "grad_norm": 2.4993345737457275,
      "learning_rate": 3.393557257316844e-06,
      "loss": 0.3472848892211914,
      "memory(GiB)": 72.72,
      "step": 33445,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 3.120044771942916,
      "grad_norm": 4.687510013580322,
      "learning_rate": 3.3920968094347162e-06,
      "loss": 0.31363601684570314,
      "memory(GiB)": 72.72,
      "step": 33450,
      "train_speed(iter/s)": 0.251315
    },
    {
      "epoch": 3.1205111463482886,
      "grad_norm": 2.886991500854492,
      "learning_rate": 3.390636514539624e-06,
      "loss": 0.29469799995422363,
      "memory(GiB)": 72.72,
      "step": 33455,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 3.120977520753661,
      "grad_norm": 3.1046669483184814,
      "learning_rate": 3.389176372770509e-06,
      "loss": 0.32540287971496584,
      "memory(GiB)": 72.72,
      "step": 33460,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 3.1214438951590338,
      "grad_norm": 3.2927346229553223,
      "learning_rate": 3.3877163842663007e-06,
      "loss": 0.34703075885772705,
      "memory(GiB)": 72.72,
      "step": 33465,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 3.121910269564406,
      "grad_norm": 2.924915313720703,
      "learning_rate": 3.3862565491659116e-06,
      "loss": 0.29103999137878417,
      "memory(GiB)": 72.72,
      "step": 33470,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 3.122376643969779,
      "grad_norm": 2.661079168319702,
      "learning_rate": 3.38479686760824e-06,
      "loss": 0.32625088691711424,
      "memory(GiB)": 72.72,
      "step": 33475,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 3.1228430183751517,
      "grad_norm": 2.56917142868042,
      "learning_rate": 3.383337339732169e-06,
      "loss": 0.30458407402038573,
      "memory(GiB)": 72.72,
      "step": 33480,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 3.123309392780524,
      "grad_norm": 2.846825122833252,
      "learning_rate": 3.381877965676573e-06,
      "loss": 0.31694397926330564,
      "memory(GiB)": 72.72,
      "step": 33485,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 3.123775767185897,
      "grad_norm": 2.8040053844451904,
      "learning_rate": 3.3804187455803023e-06,
      "loss": 0.3310660123825073,
      "memory(GiB)": 72.72,
      "step": 33490,
      "token_acc": 0.777027027027027,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 3.1242421415912696,
      "grad_norm": 2.2743356227874756,
      "learning_rate": 3.378959679582199e-06,
      "loss": 0.33884482383728026,
      "memory(GiB)": 72.72,
      "step": 33495,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 3.124708515996642,
      "grad_norm": 2.2403156757354736,
      "learning_rate": 3.377500767821088e-06,
      "loss": 0.3003579378128052,
      "memory(GiB)": 72.72,
      "step": 33500,
      "token_acc": 0.7377049180327869,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 3.1251748904020147,
      "grad_norm": 5.659960746765137,
      "learning_rate": 3.3760420104357816e-06,
      "loss": 0.33757283687591555,
      "memory(GiB)": 72.72,
      "step": 33505,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 3.1256412648073875,
      "grad_norm": 2.732595443725586,
      "learning_rate": 3.374583407565074e-06,
      "loss": 0.3272287845611572,
      "memory(GiB)": 72.72,
      "step": 33510,
      "train_speed(iter/s)": 0.251322
    },
    {
      "epoch": 3.12610763921276,
      "grad_norm": 2.5897903442382812,
      "learning_rate": 3.3731249593477476e-06,
      "loss": 0.28278183937072754,
      "memory(GiB)": 72.72,
      "step": 33515,
      "token_acc": 0.6226415094339622,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 3.1265740136181326,
      "grad_norm": 3.135335683822632,
      "learning_rate": 3.3716666659225704e-06,
      "loss": 0.30208210945129393,
      "memory(GiB)": 72.72,
      "step": 33520,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 3.1270403880235054,
      "grad_norm": 3.695871591567993,
      "learning_rate": 3.3702085274282946e-06,
      "loss": 0.3236954927444458,
      "memory(GiB)": 72.72,
      "step": 33525,
      "token_acc": 0.6026490066225165,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 3.1275067624288777,
      "grad_norm": 3.2336983680725098,
      "learning_rate": 3.3687505440036562e-06,
      "loss": 0.3484815120697021,
      "memory(GiB)": 72.72,
      "step": 33530,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 3.1279731368342505,
      "grad_norm": 5.555639266967773,
      "learning_rate": 3.367292715787378e-06,
      "loss": 0.3169675350189209,
      "memory(GiB)": 72.72,
      "step": 33535,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.1284395112396233,
      "grad_norm": 2.4708852767944336,
      "learning_rate": 3.3658350429181696e-06,
      "loss": 0.307891845703125,
      "memory(GiB)": 72.72,
      "step": 33540,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 3.1289058856449956,
      "grad_norm": 3.1258487701416016,
      "learning_rate": 3.364377525534721e-06,
      "loss": 0.3082260608673096,
      "memory(GiB)": 72.72,
      "step": 33545,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 3.1293722600503684,
      "grad_norm": 2.7401838302612305,
      "learning_rate": 3.3629201637757107e-06,
      "loss": 0.3206444025039673,
      "memory(GiB)": 72.72,
      "step": 33550,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 3.129838634455741,
      "grad_norm": 6.1771440505981445,
      "learning_rate": 3.361462957779806e-06,
      "loss": 0.3209783315658569,
      "memory(GiB)": 72.72,
      "step": 33555,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 3.1303050088611135,
      "grad_norm": 2.6286816596984863,
      "learning_rate": 3.360005907685654e-06,
      "loss": 0.34163780212402345,
      "memory(GiB)": 72.72,
      "step": 33560,
      "token_acc": 0.49056603773584906,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 3.1307713832664863,
      "grad_norm": 3.270702600479126,
      "learning_rate": 3.3585490136318865e-06,
      "loss": 0.3083000659942627,
      "memory(GiB)": 72.72,
      "step": 33565,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.131237757671859,
      "grad_norm": 2.4527955055236816,
      "learning_rate": 3.357092275757124e-06,
      "loss": 0.29131741523742677,
      "memory(GiB)": 72.72,
      "step": 33570,
      "token_acc": 0.9388888888888889,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 3.1317041320772314,
      "grad_norm": 3.019474983215332,
      "learning_rate": 3.3556356941999703e-06,
      "loss": 0.2898153305053711,
      "memory(GiB)": 72.72,
      "step": 33575,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 3.132170506482604,
      "grad_norm": 3.573117256164551,
      "learning_rate": 3.3541792690990127e-06,
      "loss": 0.32686400413513184,
      "memory(GiB)": 72.72,
      "step": 33580,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 3.132636880887977,
      "grad_norm": 5.566190242767334,
      "learning_rate": 3.35272300059283e-06,
      "loss": 0.30334224700927737,
      "memory(GiB)": 72.72,
      "step": 33585,
      "token_acc": 0.65,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.1331032552933493,
      "grad_norm": 3.162832498550415,
      "learning_rate": 3.3512668888199797e-06,
      "loss": 0.3631554841995239,
      "memory(GiB)": 72.72,
      "step": 33590,
      "token_acc": 0.6326530612244898,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.133569629698722,
      "grad_norm": 2.7324602603912354,
      "learning_rate": 3.3498109339190043e-06,
      "loss": 0.2884137392044067,
      "memory(GiB)": 72.72,
      "step": 33595,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.134036004104095,
      "grad_norm": 3.866544485092163,
      "learning_rate": 3.348355136028436e-06,
      "loss": 0.31305317878723143,
      "memory(GiB)": 72.72,
      "step": 33600,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 3.1345023785094672,
      "grad_norm": 4.3585920333862305,
      "learning_rate": 3.3468994952867885e-06,
      "loss": 0.3235782146453857,
      "memory(GiB)": 72.72,
      "step": 33605,
      "token_acc": 0.37037037037037035,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 3.13496875291484,
      "grad_norm": 3.466472625732422,
      "learning_rate": 3.3454440118325604e-06,
      "loss": 0.38106646537780764,
      "memory(GiB)": 72.72,
      "step": 33610,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 3.135435127320213,
      "grad_norm": 3.3792574405670166,
      "learning_rate": 3.3439886858042375e-06,
      "loss": 0.30129027366638184,
      "memory(GiB)": 72.72,
      "step": 33615,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 3.135901501725585,
      "grad_norm": 3.176316499710083,
      "learning_rate": 3.3425335173402905e-06,
      "loss": 0.3346655607223511,
      "memory(GiB)": 72.72,
      "step": 33620,
      "train_speed(iter/s)": 0.251323
    },
    {
      "epoch": 3.136367876130958,
      "grad_norm": 2.358264446258545,
      "learning_rate": 3.3410785065791734e-06,
      "loss": 0.3531782627105713,
      "memory(GiB)": 72.72,
      "step": 33625,
      "token_acc": 0.8027210884353742,
      "train_speed(iter/s)": 0.251322
    },
    {
      "epoch": 3.1368342505363307,
      "grad_norm": 4.3685302734375,
      "learning_rate": 3.339623653659326e-06,
      "loss": 0.37884998321533203,
      "memory(GiB)": 72.72,
      "step": 33630,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 3.137300624941703,
      "grad_norm": 2.2332115173339844,
      "learning_rate": 3.3381689587191737e-06,
      "loss": 0.28603472709655764,
      "memory(GiB)": 72.72,
      "step": 33635,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 3.137766999347076,
      "grad_norm": 3.137202501296997,
      "learning_rate": 3.3367144218971255e-06,
      "loss": 0.37378113269805907,
      "memory(GiB)": 72.72,
      "step": 33640,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 3.1382333737524486,
      "grad_norm": 2.329561471939087,
      "learning_rate": 3.3352600433315754e-06,
      "loss": 0.30146677494049073,
      "memory(GiB)": 72.72,
      "step": 33645,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 3.138699748157821,
      "grad_norm": 4.448842525482178,
      "learning_rate": 3.3338058231609018e-06,
      "loss": 0.34796340465545655,
      "memory(GiB)": 72.72,
      "step": 33650,
      "token_acc": 0.4726027397260274,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.1391661225631937,
      "grad_norm": 4.193842887878418,
      "learning_rate": 3.3323517615234734e-06,
      "loss": 0.31622092723846434,
      "memory(GiB)": 72.72,
      "step": 33655,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.1396324969685665,
      "grad_norm": 3.0092382431030273,
      "learning_rate": 3.330897858557639e-06,
      "loss": 0.34588122367858887,
      "memory(GiB)": 72.72,
      "step": 33660,
      "token_acc": 0.6538461538461539,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 3.140098871373939,
      "grad_norm": 2.7592227458953857,
      "learning_rate": 3.3294441144017303e-06,
      "loss": 0.3143459320068359,
      "memory(GiB)": 72.72,
      "step": 33665,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.1405652457793116,
      "grad_norm": 2.1449780464172363,
      "learning_rate": 3.327990529194067e-06,
      "loss": 0.3069467306137085,
      "memory(GiB)": 72.72,
      "step": 33670,
      "train_speed(iter/s)": 0.251328
    },
    {
      "epoch": 3.1410316201846844,
      "grad_norm": 2.1096389293670654,
      "learning_rate": 3.3265371030729552e-06,
      "loss": 0.3354637622833252,
      "memory(GiB)": 72.72,
      "step": 33675,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 3.1414979945900567,
      "grad_norm": 3.2716071605682373,
      "learning_rate": 3.3250838361766826e-06,
      "loss": 0.3474590539932251,
      "memory(GiB)": 72.72,
      "step": 33680,
      "token_acc": 0.9333333333333333,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 3.1419643689954295,
      "grad_norm": 2.2049670219421387,
      "learning_rate": 3.323630728643522e-06,
      "loss": 0.27625885009765627,
      "memory(GiB)": 72.72,
      "step": 33685,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 3.1424307434008023,
      "grad_norm": 4.276584625244141,
      "learning_rate": 3.322177780611735e-06,
      "loss": 0.3335293769836426,
      "memory(GiB)": 72.72,
      "step": 33690,
      "token_acc": 0.6724137931034483,
      "train_speed(iter/s)": 0.251333
    },
    {
      "epoch": 3.1428971178061746,
      "grad_norm": 2.940675735473633,
      "learning_rate": 3.3207249922195626e-06,
      "loss": 0.35880436897277834,
      "memory(GiB)": 72.72,
      "step": 33695,
      "token_acc": 0.47058823529411764,
      "train_speed(iter/s)": 0.251332
    },
    {
      "epoch": 3.1433634922115474,
      "grad_norm": 4.804147243499756,
      "learning_rate": 3.319272363605235e-06,
      "loss": 0.33326067924499514,
      "memory(GiB)": 72.72,
      "step": 33700,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 3.14382986661692,
      "grad_norm": 3.5691606998443604,
      "learning_rate": 3.317819894906964e-06,
      "loss": 0.3386292695999146,
      "memory(GiB)": 72.72,
      "step": 33705,
      "token_acc": 0.9565217391304348,
      "train_speed(iter/s)": 0.251336
    },
    {
      "epoch": 3.1442962410222925,
      "grad_norm": 2.7534449100494385,
      "learning_rate": 3.3163675862629475e-06,
      "loss": 0.3395552635192871,
      "memory(GiB)": 72.72,
      "step": 33710,
      "token_acc": 0.4318181818181818,
      "train_speed(iter/s)": 0.251337
    },
    {
      "epoch": 3.1447626154276653,
      "grad_norm": 3.261869430541992,
      "learning_rate": 3.314915437811368e-06,
      "loss": 0.32742435932159425,
      "memory(GiB)": 72.72,
      "step": 33715,
      "train_speed(iter/s)": 0.251337
    },
    {
      "epoch": 3.145228989833038,
      "grad_norm": 2.6628119945526123,
      "learning_rate": 3.3134634496903945e-06,
      "loss": 0.30232901573181153,
      "memory(GiB)": 72.72,
      "step": 33720,
      "token_acc": 0.9620253164556962,
      "train_speed(iter/s)": 0.25134
    },
    {
      "epoch": 3.1456953642384105,
      "grad_norm": 2.608112096786499,
      "learning_rate": 3.312011622038178e-06,
      "loss": 0.3387519359588623,
      "memory(GiB)": 72.72,
      "step": 33725,
      "train_speed(iter/s)": 0.25134
    },
    {
      "epoch": 3.1461617386437832,
      "grad_norm": 2.6508374214172363,
      "learning_rate": 3.310559954992856e-06,
      "loss": 0.3057298421859741,
      "memory(GiB)": 72.72,
      "step": 33730,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 3.146628113049156,
      "grad_norm": 2.5359723567962646,
      "learning_rate": 3.3091084486925498e-06,
      "loss": 0.2836991548538208,
      "memory(GiB)": 72.72,
      "step": 33735,
      "token_acc": 0.9753086419753086,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.1470944874545284,
      "grad_norm": 2.5372214317321777,
      "learning_rate": 3.3076571032753666e-06,
      "loss": 0.295514440536499,
      "memory(GiB)": 72.72,
      "step": 33740,
      "token_acc": 0.5775862068965517,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.147560861859901,
      "grad_norm": 5.196654796600342,
      "learning_rate": 3.306205918879396e-06,
      "loss": 0.31273303031921384,
      "memory(GiB)": 72.72,
      "step": 33745,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 3.148027236265274,
      "grad_norm": 2.152036190032959,
      "learning_rate": 3.304754895642712e-06,
      "loss": 0.31917943954467776,
      "memory(GiB)": 72.72,
      "step": 33750,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.1484936106706463,
      "grad_norm": 2.7885336875915527,
      "learning_rate": 3.3033040337033795e-06,
      "loss": 0.33089585304260255,
      "memory(GiB)": 72.72,
      "step": 33755,
      "token_acc": 0.7668711656441718,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.148959985076019,
      "grad_norm": 2.624354839324951,
      "learning_rate": 3.3018533331994425e-06,
      "loss": 0.3286156177520752,
      "memory(GiB)": 72.72,
      "step": 33760,
      "token_acc": 0.717948717948718,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.149426359481392,
      "grad_norm": 10.730880737304688,
      "learning_rate": 3.3004027942689287e-06,
      "loss": 0.30267407894134524,
      "memory(GiB)": 72.72,
      "step": 33765,
      "train_speed(iter/s)": 0.251341
    },
    {
      "epoch": 3.149892733886764,
      "grad_norm": 2.8244059085845947,
      "learning_rate": 3.2989524170498527e-06,
      "loss": 0.31865463256835935,
      "memory(GiB)": 72.72,
      "step": 33770,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.25134
    },
    {
      "epoch": 3.150359108292137,
      "grad_norm": 3.143880605697632,
      "learning_rate": 3.2975022016802145e-06,
      "loss": 0.3322165489196777,
      "memory(GiB)": 72.72,
      "step": 33775,
      "token_acc": 0.6949152542372882,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 3.1508254826975097,
      "grad_norm": 2.4518091678619385,
      "learning_rate": 3.296052148297997e-06,
      "loss": 0.2990291595458984,
      "memory(GiB)": 72.72,
      "step": 33780,
      "token_acc": 1.0,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 3.151291857102882,
      "grad_norm": 3.576085090637207,
      "learning_rate": 3.2946022570411673e-06,
      "loss": 0.3383692979812622,
      "memory(GiB)": 72.72,
      "step": 33785,
      "train_speed(iter/s)": 0.251341
    },
    {
      "epoch": 3.151758231508255,
      "grad_norm": 2.7424333095550537,
      "learning_rate": 3.2931525280476806e-06,
      "loss": 0.345882773399353,
      "memory(GiB)": 72.72,
      "step": 33790,
      "token_acc": 0.8529411764705882,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.1522246059136276,
      "grad_norm": 3.0938243865966797,
      "learning_rate": 3.2917029614554723e-06,
      "loss": 0.2998957633972168,
      "memory(GiB)": 72.72,
      "step": 33795,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 3.152690980319,
      "grad_norm": 3.0777134895324707,
      "learning_rate": 3.2902535574024652e-06,
      "loss": 0.2986886978149414,
      "memory(GiB)": 72.72,
      "step": 33800,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 3.1531573547243728,
      "grad_norm": 3.0876712799072266,
      "learning_rate": 3.288804316026565e-06,
      "loss": 0.3668696880340576,
      "memory(GiB)": 72.72,
      "step": 33805,
      "token_acc": 0.9634146341463414,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.1536237291297455,
      "grad_norm": 2.3680946826934814,
      "learning_rate": 3.2873552374656625e-06,
      "loss": 0.33728728294372556,
      "memory(GiB)": 72.72,
      "step": 33810,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.154090103535118,
      "grad_norm": 2.4951586723327637,
      "learning_rate": 3.2859063218576337e-06,
      "loss": 0.330767822265625,
      "memory(GiB)": 72.72,
      "step": 33815,
      "token_acc": 0.5675675675675675,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.1545564779404907,
      "grad_norm": 2.800410270690918,
      "learning_rate": 3.284457569340336e-06,
      "loss": 0.31154637336730956,
      "memory(GiB)": 72.72,
      "step": 33820,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.1550228523458634,
      "grad_norm": 3.994715929031372,
      "learning_rate": 3.283008980051617e-06,
      "loss": 0.30562710762023926,
      "memory(GiB)": 72.72,
      "step": 33825,
      "token_acc": 0.5581395348837209,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.1554892267512358,
      "grad_norm": 2.6116740703582764,
      "learning_rate": 3.2815605541293046e-06,
      "loss": 0.30757832527160645,
      "memory(GiB)": 72.72,
      "step": 33830,
      "token_acc": 0.9512195121951219,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.1559556011566086,
      "grad_norm": 2.4036202430725098,
      "learning_rate": 3.280112291711213e-06,
      "loss": 0.32756967544555665,
      "memory(GiB)": 72.72,
      "step": 33835,
      "token_acc": 0.4444444444444444,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.1564219755619813,
      "grad_norm": 2.786912679672241,
      "learning_rate": 3.2786641929351364e-06,
      "loss": 0.32867262363433836,
      "memory(GiB)": 72.72,
      "step": 33840,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.1568883499673537,
      "grad_norm": 3.5504794120788574,
      "learning_rate": 3.27721625793886e-06,
      "loss": 0.3347637176513672,
      "memory(GiB)": 72.72,
      "step": 33845,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.1573547243727265,
      "grad_norm": 3.3170995712280273,
      "learning_rate": 3.275768486860149e-06,
      "loss": 0.3216055393218994,
      "memory(GiB)": 72.72,
      "step": 33850,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.1578210987780992,
      "grad_norm": 2.308710813522339,
      "learning_rate": 3.274320879836753e-06,
      "loss": 0.29142050743103026,
      "memory(GiB)": 72.72,
      "step": 33855,
      "token_acc": 0.8551724137931035,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.1582874731834716,
      "grad_norm": 3.0306553840637207,
      "learning_rate": 3.272873437006413e-06,
      "loss": 0.3258852481842041,
      "memory(GiB)": 72.72,
      "step": 33860,
      "token_acc": 0.8961038961038961,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.1587538475888444,
      "grad_norm": 3.293286085128784,
      "learning_rate": 3.271426158506843e-06,
      "loss": 0.29820177555084226,
      "memory(GiB)": 72.72,
      "step": 33865,
      "token_acc": 0.6271186440677966,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.159220221994217,
      "grad_norm": 2.608125686645508,
      "learning_rate": 3.2699790444757494e-06,
      "loss": 0.332218074798584,
      "memory(GiB)": 72.72,
      "step": 33870,
      "token_acc": 0.967741935483871,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.1596865963995895,
      "grad_norm": 3.211721897125244,
      "learning_rate": 3.2685320950508205e-06,
      "loss": 0.3431734085083008,
      "memory(GiB)": 72.72,
      "step": 33875,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.1601529708049623,
      "grad_norm": 2.560662031173706,
      "learning_rate": 3.2670853103697285e-06,
      "loss": 0.3390872716903687,
      "memory(GiB)": 72.72,
      "step": 33880,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.160619345210335,
      "grad_norm": 2.4463841915130615,
      "learning_rate": 3.26563869057013e-06,
      "loss": 0.308437442779541,
      "memory(GiB)": 72.72,
      "step": 33885,
      "token_acc": 0.6833333333333333,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.1610857196157074,
      "grad_norm": 2.9403395652770996,
      "learning_rate": 3.2641922357896684e-06,
      "loss": 0.33723011016845705,
      "memory(GiB)": 72.72,
      "step": 33890,
      "token_acc": 0.5590062111801242,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.16155209402108,
      "grad_norm": 2.8778345584869385,
      "learning_rate": 3.2627459461659678e-06,
      "loss": 0.29372780323028563,
      "memory(GiB)": 72.72,
      "step": 33895,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.162018468426453,
      "grad_norm": 14.922086715698242,
      "learning_rate": 3.2612998218366387e-06,
      "loss": 0.3041975736618042,
      "memory(GiB)": 72.72,
      "step": 33900,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.1624848428318253,
      "grad_norm": 2.6062893867492676,
      "learning_rate": 3.2598538629392757e-06,
      "loss": 0.3279442310333252,
      "memory(GiB)": 72.72,
      "step": 33905,
      "token_acc": 0.7890625,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.162951217237198,
      "grad_norm": 2.965350866317749,
      "learning_rate": 3.2584080696114565e-06,
      "loss": 0.2752676486968994,
      "memory(GiB)": 72.72,
      "step": 33910,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.163417591642571,
      "grad_norm": 3.660090684890747,
      "learning_rate": 3.2569624419907464e-06,
      "loss": 0.34415378570556643,
      "memory(GiB)": 72.72,
      "step": 33915,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.163883966047943,
      "grad_norm": 3.093864917755127,
      "learning_rate": 3.255516980214686e-06,
      "loss": 0.3045064449310303,
      "memory(GiB)": 72.72,
      "step": 33920,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.164350340453316,
      "grad_norm": 2.70953106880188,
      "learning_rate": 3.254071684420814e-06,
      "loss": 0.3407618522644043,
      "memory(GiB)": 72.72,
      "step": 33925,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.1648167148586888,
      "grad_norm": 3.000654935836792,
      "learning_rate": 3.252626554746642e-06,
      "loss": 0.32935805320739747,
      "memory(GiB)": 72.72,
      "step": 33930,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.165283089264061,
      "grad_norm": 2.502486228942871,
      "learning_rate": 3.2511815913296717e-06,
      "loss": 0.3218050003051758,
      "memory(GiB)": 72.72,
      "step": 33935,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.165749463669434,
      "grad_norm": 2.302647113800049,
      "learning_rate": 3.2497367943073856e-06,
      "loss": 0.32438206672668457,
      "memory(GiB)": 72.72,
      "step": 33940,
      "token_acc": 0.5476190476190477,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.166215838074806,
      "grad_norm": 3.095036029815674,
      "learning_rate": 3.2482921638172504e-06,
      "loss": 0.31559998989105226,
      "memory(GiB)": 72.72,
      "step": 33945,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.166682212480179,
      "grad_norm": 2.2751307487487793,
      "learning_rate": 3.24684769999672e-06,
      "loss": 0.2995759010314941,
      "memory(GiB)": 72.72,
      "step": 33950,
      "token_acc": 0.6181818181818182,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.167148586885552,
      "grad_norm": 2.6228344440460205,
      "learning_rate": 3.2454034029832292e-06,
      "loss": 0.32817487716674804,
      "memory(GiB)": 72.72,
      "step": 33955,
      "token_acc": 0.6326530612244898,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.1676149612909246,
      "grad_norm": 2.1688315868377686,
      "learning_rate": 3.2439592729142e-06,
      "loss": 0.313568639755249,
      "memory(GiB)": 72.72,
      "step": 33960,
      "token_acc": 0.6956521739130435,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.168081335696297,
      "grad_norm": 2.40234112739563,
      "learning_rate": 3.2425153099270367e-06,
      "loss": 0.32426955699920657,
      "memory(GiB)": 72.72,
      "step": 33965,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.1685477101016697,
      "grad_norm": 2.31177020072937,
      "learning_rate": 3.2410715141591274e-06,
      "loss": 0.3142116546630859,
      "memory(GiB)": 72.72,
      "step": 33970,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.169014084507042,
      "grad_norm": 2.5745785236358643,
      "learning_rate": 3.239627885747846e-06,
      "loss": 0.3106525897979736,
      "memory(GiB)": 72.72,
      "step": 33975,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.169480458912415,
      "grad_norm": 3.166476249694824,
      "learning_rate": 3.238184424830547e-06,
      "loss": 0.30747461318969727,
      "memory(GiB)": 72.72,
      "step": 33980,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.1699468333177876,
      "grad_norm": 2.6083805561065674,
      "learning_rate": 3.236741131544574e-06,
      "loss": 0.32652237415313723,
      "memory(GiB)": 72.72,
      "step": 33985,
      "token_acc": 0.5076923076923077,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.1704132077231604,
      "grad_norm": 3.4543442726135254,
      "learning_rate": 3.235298006027248e-06,
      "loss": 0.3499922752380371,
      "memory(GiB)": 72.72,
      "step": 33990,
      "token_acc": 0.8380281690140845,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.1708795821285327,
      "grad_norm": 2.5410313606262207,
      "learning_rate": 3.2338550484158827e-06,
      "loss": 0.327868127822876,
      "memory(GiB)": 72.72,
      "step": 33995,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.1713459565339055,
      "grad_norm": 2.3831090927124023,
      "learning_rate": 3.232412258847768e-06,
      "loss": 0.32441732883453367,
      "memory(GiB)": 72.72,
      "step": 34000,
      "token_acc": 0.5245901639344263,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.171812330939278,
      "grad_norm": 2.159292697906494,
      "learning_rate": 3.230969637460182e-06,
      "loss": 0.3334081172943115,
      "memory(GiB)": 72.72,
      "step": 34005,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 3.1722787053446506,
      "grad_norm": 2.6913130283355713,
      "learning_rate": 3.2295271843903853e-06,
      "loss": 0.2993581295013428,
      "memory(GiB)": 72.72,
      "step": 34010,
      "token_acc": 0.84375,
      "train_speed(iter/s)": 0.251293
    },
    {
      "epoch": 3.1727450797500234,
      "grad_norm": 3.116602659225464,
      "learning_rate": 3.228084899775623e-06,
      "loss": 0.3216569900512695,
      "memory(GiB)": 72.72,
      "step": 34015,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.251292
    },
    {
      "epoch": 3.173211454155396,
      "grad_norm": 2.515545129776001,
      "learning_rate": 3.2266427837531246e-06,
      "loss": 0.3168473720550537,
      "memory(GiB)": 72.72,
      "step": 34020,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 3.1736778285607685,
      "grad_norm": 3.654388904571533,
      "learning_rate": 3.2252008364600995e-06,
      "loss": 0.3189223289489746,
      "memory(GiB)": 72.72,
      "step": 34025,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 3.1741442029661413,
      "grad_norm": 2.754587173461914,
      "learning_rate": 3.223759058033749e-06,
      "loss": 0.3325084924697876,
      "memory(GiB)": 72.72,
      "step": 34030,
      "token_acc": 0.7045454545454546,
      "train_speed(iter/s)": 0.251294
    },
    {
      "epoch": 3.1746105773715136,
      "grad_norm": 3.5466830730438232,
      "learning_rate": 3.222317448611254e-06,
      "loss": 0.30858798027038575,
      "memory(GiB)": 72.72,
      "step": 34035,
      "train_speed(iter/s)": 0.251295
    },
    {
      "epoch": 3.1750769517768864,
      "grad_norm": 4.112317085266113,
      "learning_rate": 3.2208760083297763e-06,
      "loss": 0.370554256439209,
      "memory(GiB)": 72.72,
      "step": 34040,
      "token_acc": 0.5260115606936416,
      "train_speed(iter/s)": 0.251298
    },
    {
      "epoch": 3.175543326182259,
      "grad_norm": 3.831484079360962,
      "learning_rate": 3.2194347373264657e-06,
      "loss": 0.3109919309616089,
      "memory(GiB)": 72.72,
      "step": 34045,
      "token_acc": 0.6190476190476191,
      "train_speed(iter/s)": 0.251298
    },
    {
      "epoch": 3.1760097005876315,
      "grad_norm": 2.015850305557251,
      "learning_rate": 3.2179936357384546e-06,
      "loss": 0.2952632188796997,
      "memory(GiB)": 72.72,
      "step": 34050,
      "token_acc": 0.6842105263157895,
      "train_speed(iter/s)": 0.251297
    },
    {
      "epoch": 3.1764760749930043,
      "grad_norm": 3.1709938049316406,
      "learning_rate": 3.216552703702858e-06,
      "loss": 0.3170111656188965,
      "memory(GiB)": 72.72,
      "step": 34055,
      "token_acc": 0.46,
      "train_speed(iter/s)": 0.251297
    },
    {
      "epoch": 3.176942449398377,
      "grad_norm": 1.920275330543518,
      "learning_rate": 3.2151119413567795e-06,
      "loss": 0.29953317642211913,
      "memory(GiB)": 72.72,
      "step": 34060,
      "token_acc": 0.6136363636363636,
      "train_speed(iter/s)": 0.251298
    },
    {
      "epoch": 3.1774088238037494,
      "grad_norm": 2.3685102462768555,
      "learning_rate": 3.2136713488373006e-06,
      "loss": 0.33255348205566404,
      "memory(GiB)": 72.72,
      "step": 34065,
      "token_acc": 0.4927536231884058,
      "train_speed(iter/s)": 0.251301
    },
    {
      "epoch": 3.1778751982091222,
      "grad_norm": 2.9815943241119385,
      "learning_rate": 3.2122309262814903e-06,
      "loss": 0.331707763671875,
      "memory(GiB)": 72.72,
      "step": 34070,
      "token_acc": 0.6842105263157895,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 3.178341572614495,
      "grad_norm": 2.4067368507385254,
      "learning_rate": 3.2107906738264e-06,
      "loss": 0.2800142288208008,
      "memory(GiB)": 72.72,
      "step": 34075,
      "train_speed(iter/s)": 0.251303
    },
    {
      "epoch": 3.1788079470198674,
      "grad_norm": 3.273526191711426,
      "learning_rate": 3.209350591609065e-06,
      "loss": 0.32405910491943357,
      "memory(GiB)": 72.72,
      "step": 34080,
      "train_speed(iter/s)": 0.251305
    },
    {
      "epoch": 3.17927432142524,
      "grad_norm": 3.359790563583374,
      "learning_rate": 3.207910679766505e-06,
      "loss": 0.3129130840301514,
      "memory(GiB)": 72.72,
      "step": 34085,
      "token_acc": 0.5660377358490566,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 3.179740695830613,
      "grad_norm": 2.839174270629883,
      "learning_rate": 3.206470938435723e-06,
      "loss": 0.3415702819824219,
      "memory(GiB)": 72.72,
      "step": 34090,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 3.1802070702359853,
      "grad_norm": 2.943058729171753,
      "learning_rate": 3.2050313677537058e-06,
      "loss": 0.335150146484375,
      "memory(GiB)": 72.72,
      "step": 34095,
      "token_acc": 0.7,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 3.180673444641358,
      "grad_norm": 2.5743818283081055,
      "learning_rate": 3.2035919678574255e-06,
      "loss": 0.28930490016937255,
      "memory(GiB)": 72.72,
      "step": 34100,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 3.181139819046731,
      "grad_norm": 2.5968403816223145,
      "learning_rate": 3.2021527388838347e-06,
      "loss": 0.33517041206359866,
      "memory(GiB)": 72.72,
      "step": 34105,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.251304
    },
    {
      "epoch": 3.181606193452103,
      "grad_norm": 2.970216751098633,
      "learning_rate": 3.2007136809698737e-06,
      "loss": 0.31914939880371096,
      "memory(GiB)": 72.72,
      "step": 34110,
      "train_speed(iter/s)": 0.251306
    },
    {
      "epoch": 3.182072567857476,
      "grad_norm": 3.332211494445801,
      "learning_rate": 3.1992747942524627e-06,
      "loss": 0.3335790395736694,
      "memory(GiB)": 72.72,
      "step": 34115,
      "train_speed(iter/s)": 0.251307
    },
    {
      "epoch": 3.1825389422628487,
      "grad_norm": 3.1075901985168457,
      "learning_rate": 3.197836078868507e-06,
      "loss": 0.332418417930603,
      "memory(GiB)": 72.72,
      "step": 34120,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.251308
    },
    {
      "epoch": 3.183005316668221,
      "grad_norm": 2.3949015140533447,
      "learning_rate": 3.1963975349548947e-06,
      "loss": 0.34113776683807373,
      "memory(GiB)": 72.72,
      "step": 34125,
      "token_acc": 0.5172413793103449,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 3.183471691073594,
      "grad_norm": 3.2804486751556396,
      "learning_rate": 3.194959162648504e-06,
      "loss": 0.3121653079986572,
      "memory(GiB)": 72.72,
      "step": 34130,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.25131
    },
    {
      "epoch": 3.1839380654789666,
      "grad_norm": 2.95292067527771,
      "learning_rate": 3.1935209620861873e-06,
      "loss": 0.296491003036499,
      "memory(GiB)": 72.72,
      "step": 34135,
      "token_acc": 0.8285714285714286,
      "train_speed(iter/s)": 0.251312
    },
    {
      "epoch": 3.184404439884339,
      "grad_norm": 2.977931499481201,
      "learning_rate": 3.1920829334047866e-06,
      "loss": 0.34628925323486326,
      "memory(GiB)": 72.72,
      "step": 34140,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 3.1848708142897117,
      "grad_norm": 2.6241345405578613,
      "learning_rate": 3.1906450767411246e-06,
      "loss": 0.3164797306060791,
      "memory(GiB)": 72.72,
      "step": 34145,
      "train_speed(iter/s)": 0.251313
    },
    {
      "epoch": 3.1853371886950845,
      "grad_norm": 3.3080241680145264,
      "learning_rate": 3.18920739223201e-06,
      "loss": 0.30596280097961426,
      "memory(GiB)": 72.72,
      "step": 34150,
      "train_speed(iter/s)": 0.251315
    },
    {
      "epoch": 3.185803563100457,
      "grad_norm": 3.0114388465881348,
      "learning_rate": 3.1877698800142338e-06,
      "loss": 0.3285072326660156,
      "memory(GiB)": 72.72,
      "step": 34155,
      "train_speed(iter/s)": 0.251314
    },
    {
      "epoch": 3.1862699375058297,
      "grad_norm": 4.193201065063477,
      "learning_rate": 3.1863325402245694e-06,
      "loss": 0.3177588701248169,
      "memory(GiB)": 72.72,
      "step": 34160,
      "token_acc": 0.43859649122807015,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 3.1867363119112024,
      "grad_norm": 2.879075765609741,
      "learning_rate": 3.1848953729997783e-06,
      "loss": 0.3021101713180542,
      "memory(GiB)": 72.72,
      "step": 34165,
      "token_acc": 0.62,
      "train_speed(iter/s)": 0.251319
    },
    {
      "epoch": 3.1872026863165748,
      "grad_norm": 5.506600379943848,
      "learning_rate": 3.1834583784766005e-06,
      "loss": 0.316504693031311,
      "memory(GiB)": 72.72,
      "step": 34170,
      "token_acc": 0.5128205128205128,
      "train_speed(iter/s)": 0.251317
    },
    {
      "epoch": 3.1876690607219476,
      "grad_norm": 4.139145851135254,
      "learning_rate": 3.1820215567917624e-06,
      "loss": 0.28663015365600586,
      "memory(GiB)": 72.72,
      "step": 34175,
      "token_acc": 0.6031746031746031,
      "train_speed(iter/s)": 0.251316
    },
    {
      "epoch": 3.1881354351273203,
      "grad_norm": 3.5240817070007324,
      "learning_rate": 3.1805849080819724e-06,
      "loss": 0.3076263427734375,
      "memory(GiB)": 72.72,
      "step": 34180,
      "token_acc": 0.5528455284552846,
      "train_speed(iter/s)": 0.25132
    },
    {
      "epoch": 3.1886018095326927,
      "grad_norm": 3.8395986557006836,
      "learning_rate": 3.179148432483924e-06,
      "loss": 0.33054921627044676,
      "memory(GiB)": 72.72,
      "step": 34185,
      "train_speed(iter/s)": 0.25132
    },
    {
      "epoch": 3.1890681839380655,
      "grad_norm": 2.2936723232269287,
      "learning_rate": 3.177712130134291e-06,
      "loss": 0.30841941833496095,
      "memory(GiB)": 72.72,
      "step": 34190,
      "train_speed(iter/s)": 0.251321
    },
    {
      "epoch": 3.1895345583434382,
      "grad_norm": 2.5027658939361572,
      "learning_rate": 3.176276001169737e-06,
      "loss": 0.32383503913879397,
      "memory(GiB)": 72.72,
      "step": 34195,
      "train_speed(iter/s)": 0.251322
    },
    {
      "epoch": 3.1900009327488106,
      "grad_norm": 2.4477601051330566,
      "learning_rate": 3.174840045726903e-06,
      "loss": 0.29574313163757326,
      "memory(GiB)": 72.72,
      "step": 34200,
      "token_acc": 0.5490196078431373,
      "train_speed(iter/s)": 0.251325
    },
    {
      "epoch": 3.1904673071541834,
      "grad_norm": 3.721134901046753,
      "learning_rate": 3.1734042639424164e-06,
      "loss": 0.2884246826171875,
      "memory(GiB)": 72.72,
      "step": 34205,
      "train_speed(iter/s)": 0.251324
    },
    {
      "epoch": 3.190933681559556,
      "grad_norm": 2.595231056213379,
      "learning_rate": 3.1719686559528873e-06,
      "loss": 0.33955271244049073,
      "memory(GiB)": 72.72,
      "step": 34210,
      "train_speed(iter/s)": 0.251323
    },
    {
      "epoch": 3.1914000559649285,
      "grad_norm": 3.101109027862549,
      "learning_rate": 3.170533221894909e-06,
      "loss": 0.3004890441894531,
      "memory(GiB)": 72.72,
      "step": 34215,
      "train_speed(iter/s)": 0.251326
    },
    {
      "epoch": 3.1918664303703013,
      "grad_norm": 3.183980941772461,
      "learning_rate": 3.169097961905059e-06,
      "loss": 0.3566277980804443,
      "memory(GiB)": 72.72,
      "step": 34220,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 3.192332804775674,
      "grad_norm": 4.488952159881592,
      "learning_rate": 3.1676628761198947e-06,
      "loss": 0.34882416725158694,
      "memory(GiB)": 72.72,
      "step": 34225,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 3.1927991791810464,
      "grad_norm": 3.0138370990753174,
      "learning_rate": 3.166227964675967e-06,
      "loss": 0.33629322052001953,
      "memory(GiB)": 72.72,
      "step": 34230,
      "token_acc": 0.8292682926829268,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 3.193265553586419,
      "grad_norm": 5.971398830413818,
      "learning_rate": 3.1647932277097982e-06,
      "loss": 0.3305121660232544,
      "memory(GiB)": 72.72,
      "step": 34235,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 3.193731927991792,
      "grad_norm": 3.3799045085906982,
      "learning_rate": 3.1633586653579e-06,
      "loss": 0.3164353847503662,
      "memory(GiB)": 72.72,
      "step": 34240,
      "train_speed(iter/s)": 0.251327
    },
    {
      "epoch": 3.1941983023971643,
      "grad_norm": 2.307451009750366,
      "learning_rate": 3.1619242777567672e-06,
      "loss": 0.3065379858016968,
      "memory(GiB)": 72.72,
      "step": 34245,
      "train_speed(iter/s)": 0.251329
    },
    {
      "epoch": 3.194664676802537,
      "grad_norm": 4.143810272216797,
      "learning_rate": 3.160490065042877e-06,
      "loss": 0.3531843662261963,
      "memory(GiB)": 72.72,
      "step": 34250,
      "token_acc": 0.5217391304347826,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 3.19513105120791,
      "grad_norm": 3.9614579677581787,
      "learning_rate": 3.1590560273526903e-06,
      "loss": 0.331573486328125,
      "memory(GiB)": 72.72,
      "step": 34255,
      "token_acc": 0.865546218487395,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 3.195597425613282,
      "grad_norm": 2.7926056385040283,
      "learning_rate": 3.1576221648226502e-06,
      "loss": 0.3999138832092285,
      "memory(GiB)": 72.72,
      "step": 34260,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 3.196063800018655,
      "grad_norm": 3.309157133102417,
      "learning_rate": 3.1561884775891864e-06,
      "loss": 0.3212193250656128,
      "memory(GiB)": 72.72,
      "step": 34265,
      "train_speed(iter/s)": 0.25133
    },
    {
      "epoch": 3.1965301744240278,
      "grad_norm": 3.9151947498321533,
      "learning_rate": 3.1547549657887095e-06,
      "loss": 0.32733993530273436,
      "memory(GiB)": 72.72,
      "step": 34270,
      "token_acc": 0.8108108108108109,
      "train_speed(iter/s)": 0.251332
    },
    {
      "epoch": 3.1969965488294,
      "grad_norm": 2.600576400756836,
      "learning_rate": 3.153321629557613e-06,
      "loss": 0.3020678997039795,
      "memory(GiB)": 72.72,
      "step": 34275,
      "train_speed(iter/s)": 0.251334
    },
    {
      "epoch": 3.197462923234773,
      "grad_norm": 2.3555145263671875,
      "learning_rate": 3.1518884690322748e-06,
      "loss": 0.3283276319503784,
      "memory(GiB)": 72.72,
      "step": 34280,
      "token_acc": 0.6346153846153846,
      "train_speed(iter/s)": 0.251337
    },
    {
      "epoch": 3.1979292976401457,
      "grad_norm": 2.987262010574341,
      "learning_rate": 3.1504554843490555e-06,
      "loss": 0.31689622402191164,
      "memory(GiB)": 72.72,
      "step": 34285,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 3.198395672045518,
      "grad_norm": 2.587494373321533,
      "learning_rate": 3.1490226756443e-06,
      "loss": 0.2939750671386719,
      "memory(GiB)": 72.72,
      "step": 34290,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.25134
    },
    {
      "epoch": 3.198862046450891,
      "grad_norm": 2.41448712348938,
      "learning_rate": 3.1475900430543314e-06,
      "loss": 0.30698654651641843,
      "memory(GiB)": 72.72,
      "step": 34295,
      "train_speed(iter/s)": 0.25134
    },
    {
      "epoch": 3.1993284208562636,
      "grad_norm": 3.043478488922119,
      "learning_rate": 3.146157586715466e-06,
      "loss": 0.3081194877624512,
      "memory(GiB)": 72.72,
      "step": 34300,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 3.199794795261636,
      "grad_norm": 3.8665435314178467,
      "learning_rate": 3.144725306763996e-06,
      "loss": 0.3028352975845337,
      "memory(GiB)": 72.72,
      "step": 34305,
      "train_speed(iter/s)": 0.25134
    },
    {
      "epoch": 3.2002611696670087,
      "grad_norm": 3.9786810874938965,
      "learning_rate": 3.143293203336198e-06,
      "loss": 0.33974499702453614,
      "memory(GiB)": 72.72,
      "step": 34310,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.2007275440723815,
      "grad_norm": 3.5341105461120605,
      "learning_rate": 3.141861276568331e-06,
      "loss": 0.33309664726257326,
      "memory(GiB)": 72.72,
      "step": 34315,
      "train_speed(iter/s)": 0.25134
    },
    {
      "epoch": 3.201193918477754,
      "grad_norm": 2.4807772636413574,
      "learning_rate": 3.14042952659664e-06,
      "loss": 0.3122848033905029,
      "memory(GiB)": 72.72,
      "step": 34320,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.2016602928831266,
      "grad_norm": 2.5027098655700684,
      "learning_rate": 3.1389979535573502e-06,
      "loss": 0.2838639259338379,
      "memory(GiB)": 72.72,
      "step": 34325,
      "token_acc": 0.9529411764705882,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.2021266672884994,
      "grad_norm": 2.7456321716308594,
      "learning_rate": 3.1375665575866715e-06,
      "loss": 0.33457436561584475,
      "memory(GiB)": 72.72,
      "step": 34330,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 3.2025930416938717,
      "grad_norm": 3.500716209411621,
      "learning_rate": 3.1361353388207982e-06,
      "loss": 0.34923250675201417,
      "memory(GiB)": 72.72,
      "step": 34335,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.2030594160992445,
      "grad_norm": 2.6302249431610107,
      "learning_rate": 3.1347042973959062e-06,
      "loss": 0.31129066944122313,
      "memory(GiB)": 72.72,
      "step": 34340,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 3.2035257905046173,
      "grad_norm": 2.438713312149048,
      "learning_rate": 3.133273433448154e-06,
      "loss": 0.29130289554595945,
      "memory(GiB)": 72.72,
      "step": 34345,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.2039921649099896,
      "grad_norm": 6.113885402679443,
      "learning_rate": 3.1318427471136837e-06,
      "loss": 0.350816011428833,
      "memory(GiB)": 72.72,
      "step": 34350,
      "token_acc": 0.54,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.2044585393153624,
      "grad_norm": 2.5050556659698486,
      "learning_rate": 3.1304122385286217e-06,
      "loss": 0.3257226705551147,
      "memory(GiB)": 72.72,
      "step": 34355,
      "token_acc": 0.64,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.204924913720735,
      "grad_norm": 2.4901998043060303,
      "learning_rate": 3.128981907829074e-06,
      "loss": 0.27481560707092284,
      "memory(GiB)": 72.72,
      "step": 34360,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.2053912881261075,
      "grad_norm": 3.1936569213867188,
      "learning_rate": 3.127551755151135e-06,
      "loss": 0.30721111297607423,
      "memory(GiB)": 72.72,
      "step": 34365,
      "token_acc": 0.7,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.2058576625314803,
      "grad_norm": 3.6752285957336426,
      "learning_rate": 3.1261217806308784e-06,
      "loss": 0.3104791879653931,
      "memory(GiB)": 72.72,
      "step": 34370,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.206324036936853,
      "grad_norm": 5.043188095092773,
      "learning_rate": 3.124691984404362e-06,
      "loss": 0.27648515701293946,
      "memory(GiB)": 72.72,
      "step": 34375,
      "token_acc": 0.6379310344827587,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.2067904113422254,
      "grad_norm": 2.6395649909973145,
      "learning_rate": 3.1232623666076266e-06,
      "loss": 0.3367793560028076,
      "memory(GiB)": 72.72,
      "step": 34380,
      "token_acc": 0.6136363636363636,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.207256785747598,
      "grad_norm": 2.5760436058044434,
      "learning_rate": 3.1218329273766955e-06,
      "loss": 0.3168388605117798,
      "memory(GiB)": 72.72,
      "step": 34385,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.207723160152971,
      "grad_norm": 2.8971047401428223,
      "learning_rate": 3.1204036668475757e-06,
      "loss": 0.2901782512664795,
      "memory(GiB)": 72.72,
      "step": 34390,
      "token_acc": 0.5423728813559322,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.2081895345583433,
      "grad_norm": 2.8327999114990234,
      "learning_rate": 3.1189745851562536e-06,
      "loss": 0.3439368486404419,
      "memory(GiB)": 72.72,
      "step": 34395,
      "token_acc": 0.7115384615384616,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.208655908963716,
      "grad_norm": 2.6343014240264893,
      "learning_rate": 3.1175456824387086e-06,
      "loss": 0.3132943630218506,
      "memory(GiB)": 72.72,
      "step": 34400,
      "token_acc": 0.5510204081632653,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.209122283369089,
      "grad_norm": 6.124999523162842,
      "learning_rate": 3.1161169588308927e-06,
      "loss": 0.2855708122253418,
      "memory(GiB)": 72.72,
      "step": 34405,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.2095886577744612,
      "grad_norm": 3.081566095352173,
      "learning_rate": 3.114688414468744e-06,
      "loss": 0.31859655380249025,
      "memory(GiB)": 72.72,
      "step": 34410,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.210055032179834,
      "grad_norm": 2.9537301063537598,
      "learning_rate": 3.113260049488185e-06,
      "loss": 0.30866477489471433,
      "memory(GiB)": 72.72,
      "step": 34415,
      "token_acc": 0.6170212765957447,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.210521406585207,
      "grad_norm": 2.7103357315063477,
      "learning_rate": 3.1118318640251196e-06,
      "loss": 0.3170865535736084,
      "memory(GiB)": 72.72,
      "step": 34420,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.210987780990579,
      "grad_norm": 2.1710190773010254,
      "learning_rate": 3.110403858215436e-06,
      "loss": 0.3274754524230957,
      "memory(GiB)": 72.72,
      "step": 34425,
      "token_acc": 0.7902097902097902,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.211454155395952,
      "grad_norm": 2.122361421585083,
      "learning_rate": 3.108976032195003e-06,
      "loss": 0.31231136322021485,
      "memory(GiB)": 72.72,
      "step": 34430,
      "token_acc": 0.7017543859649122,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.2119205298013247,
      "grad_norm": 3.2229573726654053,
      "learning_rate": 3.1075483860996757e-06,
      "loss": 0.31594114303588866,
      "memory(GiB)": 72.72,
      "step": 34435,
      "token_acc": 0.6274509803921569,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.212386904206697,
      "grad_norm": 2.9550318717956543,
      "learning_rate": 3.106120920065291e-06,
      "loss": 0.34155423641204835,
      "memory(GiB)": 72.72,
      "step": 34440,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.21285327861207,
      "grad_norm": 2.8640267848968506,
      "learning_rate": 3.1046936342276656e-06,
      "loss": 0.362526535987854,
      "memory(GiB)": 72.72,
      "step": 34445,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.2133196530174426,
      "grad_norm": 2.4640159606933594,
      "learning_rate": 3.1032665287226022e-06,
      "loss": 0.3251999616622925,
      "memory(GiB)": 72.72,
      "step": 34450,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.213786027422815,
      "grad_norm": 4.459619998931885,
      "learning_rate": 3.1018396036858856e-06,
      "loss": 0.2968922138214111,
      "memory(GiB)": 72.72,
      "step": 34455,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.2142524018281877,
      "grad_norm": 2.5011770725250244,
      "learning_rate": 3.1004128592532833e-06,
      "loss": 0.2666763782501221,
      "memory(GiB)": 72.72,
      "step": 34460,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.2147187762335605,
      "grad_norm": 3.3349506855010986,
      "learning_rate": 3.098986295560545e-06,
      "loss": 0.33544278144836426,
      "memory(GiB)": 72.72,
      "step": 34465,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.215185150638933,
      "grad_norm": 1.9892034530639648,
      "learning_rate": 3.0975599127434053e-06,
      "loss": 0.2916268348693848,
      "memory(GiB)": 72.72,
      "step": 34470,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.2156515250443056,
      "grad_norm": 3.233560562133789,
      "learning_rate": 3.096133710937579e-06,
      "loss": 0.313275146484375,
      "memory(GiB)": 72.72,
      "step": 34475,
      "token_acc": 0.7019230769230769,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.2161178994496784,
      "grad_norm": 4.155653476715088,
      "learning_rate": 3.0947076902787653e-06,
      "loss": 0.3357764005661011,
      "memory(GiB)": 72.72,
      "step": 34480,
      "token_acc": 0.41935483870967744,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.2165842738550507,
      "grad_norm": 2.6311142444610596,
      "learning_rate": 3.0932818509026463e-06,
      "loss": 0.31282799243927,
      "memory(GiB)": 72.72,
      "step": 34485,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.2170506482604235,
      "grad_norm": 3.034261465072632,
      "learning_rate": 3.0918561929448846e-06,
      "loss": 0.29126529693603515,
      "memory(GiB)": 72.72,
      "step": 34490,
      "token_acc": 0.5081967213114754,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.2175170226657963,
      "grad_norm": 2.8979170322418213,
      "learning_rate": 3.0904307165411263e-06,
      "loss": 0.29154081344604493,
      "memory(GiB)": 72.72,
      "step": 34495,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.2179833970711686,
      "grad_norm": 2.219655990600586,
      "learning_rate": 3.0890054218270036e-06,
      "loss": 0.32486417293548586,
      "memory(GiB)": 72.72,
      "step": 34500,
      "token_acc": 0.5511811023622047,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.2184497714765414,
      "grad_norm": 8.481192588806152,
      "learning_rate": 3.0875803089381305e-06,
      "loss": 0.282208514213562,
      "memory(GiB)": 72.72,
      "step": 34505,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.2189161458819138,
      "grad_norm": 2.6238198280334473,
      "learning_rate": 3.086155378010098e-06,
      "loss": 0.29442138671875,
      "memory(GiB)": 72.72,
      "step": 34510,
      "token_acc": 0.9545454545454546,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.2193825202872866,
      "grad_norm": 2.544782876968384,
      "learning_rate": 3.084730629178485e-06,
      "loss": 0.2906909942626953,
      "memory(GiB)": 72.72,
      "step": 34515,
      "token_acc": 0.5102040816326531,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.2198488946926593,
      "grad_norm": 2.114240884780884,
      "learning_rate": 3.0833060625788534e-06,
      "loss": 0.28958559036254883,
      "memory(GiB)": 72.72,
      "step": 34520,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.220315269098032,
      "grad_norm": 2.5292699337005615,
      "learning_rate": 3.0818816783467455e-06,
      "loss": 0.30612568855285643,
      "memory(GiB)": 72.72,
      "step": 34525,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.2207816435034045,
      "grad_norm": 6.721125602722168,
      "learning_rate": 3.0804574766176855e-06,
      "loss": 0.33369429111480714,
      "memory(GiB)": 72.72,
      "step": 34530,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.2212480179087772,
      "grad_norm": 4.723520755767822,
      "learning_rate": 3.079033457527184e-06,
      "loss": 0.3088786840438843,
      "memory(GiB)": 72.72,
      "step": 34535,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.2217143923141496,
      "grad_norm": 2.4661917686462402,
      "learning_rate": 3.0776096212107317e-06,
      "loss": 0.27104036808013915,
      "memory(GiB)": 72.72,
      "step": 34540,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.2221807667195224,
      "grad_norm": 2.648402214050293,
      "learning_rate": 3.076185967803802e-06,
      "loss": 0.32457895278930665,
      "memory(GiB)": 72.72,
      "step": 34545,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.222647141124895,
      "grad_norm": 2.3607704639434814,
      "learning_rate": 3.0747624974418505e-06,
      "loss": 0.3166120767593384,
      "memory(GiB)": 72.72,
      "step": 34550,
      "token_acc": 0.5474452554744526,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.223113515530268,
      "grad_norm": 3.2136244773864746,
      "learning_rate": 3.0733392102603165e-06,
      "loss": 0.3174456596374512,
      "memory(GiB)": 72.72,
      "step": 34555,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.2235798899356403,
      "grad_norm": 4.730525970458984,
      "learning_rate": 3.0719161063946224e-06,
      "loss": 0.32479066848754884,
      "memory(GiB)": 72.72,
      "step": 34560,
      "token_acc": 0.4888888888888889,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.224046264341013,
      "grad_norm": 3.4822559356689453,
      "learning_rate": 3.070493185980169e-06,
      "loss": 0.3264733552932739,
      "memory(GiB)": 72.72,
      "step": 34565,
      "token_acc": 0.9690721649484536,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.2245126387463854,
      "grad_norm": 2.4281771183013916,
      "learning_rate": 3.069070449152347e-06,
      "loss": 0.31560802459716797,
      "memory(GiB)": 72.72,
      "step": 34570,
      "token_acc": 0.7535211267605634,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.224979013151758,
      "grad_norm": 2.675804615020752,
      "learning_rate": 3.0676478960465226e-06,
      "loss": 0.3109283924102783,
      "memory(GiB)": 72.72,
      "step": 34575,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.225445387557131,
      "grad_norm": 2.23051118850708,
      "learning_rate": 3.066225526798048e-06,
      "loss": 0.30232017040252684,
      "memory(GiB)": 72.72,
      "step": 34580,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.2259117619625037,
      "grad_norm": 3.8010056018829346,
      "learning_rate": 3.0648033415422595e-06,
      "loss": 0.327632474899292,
      "memory(GiB)": 72.72,
      "step": 34585,
      "token_acc": 0.5263157894736842,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.226378136367876,
      "grad_norm": 2.23997163772583,
      "learning_rate": 3.0633813404144696e-06,
      "loss": 0.326098895072937,
      "memory(GiB)": 72.72,
      "step": 34590,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.226844510773249,
      "grad_norm": 6.243266582489014,
      "learning_rate": 3.06195952354998e-06,
      "loss": 0.3188797950744629,
      "memory(GiB)": 72.72,
      "step": 34595,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.227310885178621,
      "grad_norm": 2.7599034309387207,
      "learning_rate": 3.060537891084069e-06,
      "loss": 0.32488574981689455,
      "memory(GiB)": 72.72,
      "step": 34600,
      "token_acc": 0.9518072289156626,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.227777259583994,
      "grad_norm": 5.473355293273926,
      "learning_rate": 3.0591164431520053e-06,
      "loss": 0.3025667667388916,
      "memory(GiB)": 72.72,
      "step": 34605,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.2282436339893668,
      "grad_norm": 4.159244537353516,
      "learning_rate": 3.057695179889033e-06,
      "loss": 0.30625267028808595,
      "memory(GiB)": 72.72,
      "step": 34610,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.228710008394739,
      "grad_norm": 2.3759353160858154,
      "learning_rate": 3.0562741014303802e-06,
      "loss": 0.30279788970947263,
      "memory(GiB)": 72.72,
      "step": 34615,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.229176382800112,
      "grad_norm": 2.382093906402588,
      "learning_rate": 3.054853207911259e-06,
      "loss": 0.3057460069656372,
      "memory(GiB)": 72.72,
      "step": 34620,
      "token_acc": 0.6055045871559633,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.2296427572054847,
      "grad_norm": 2.6515207290649414,
      "learning_rate": 3.053432499466864e-06,
      "loss": 0.29993352890014646,
      "memory(GiB)": 72.72,
      "step": 34625,
      "token_acc": 0.7,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.230109131610857,
      "grad_norm": 2.5293848514556885,
      "learning_rate": 3.0520119762323687e-06,
      "loss": 0.32365310192108154,
      "memory(GiB)": 72.72,
      "step": 34630,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.23057550601623,
      "grad_norm": 6.859981060028076,
      "learning_rate": 3.0505916383429323e-06,
      "loss": 0.2948634624481201,
      "memory(GiB)": 72.72,
      "step": 34635,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.2310418804216026,
      "grad_norm": 4.909374237060547,
      "learning_rate": 3.0491714859336973e-06,
      "loss": 0.32789883613586424,
      "memory(GiB)": 72.72,
      "step": 34640,
      "token_acc": 0.43902439024390244,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.231508254826975,
      "grad_norm": 2.597797155380249,
      "learning_rate": 3.0477515191397866e-06,
      "loss": 0.3200213432312012,
      "memory(GiB)": 72.72,
      "step": 34645,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.2319746292323477,
      "grad_norm": 2.692294120788574,
      "learning_rate": 3.0463317380963035e-06,
      "loss": 0.2968148231506348,
      "memory(GiB)": 72.72,
      "step": 34650,
      "token_acc": 0.8392857142857143,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.2324410036377205,
      "grad_norm": 3.1292037963867188,
      "learning_rate": 3.0449121429383377e-06,
      "loss": 0.312698221206665,
      "memory(GiB)": 72.72,
      "step": 34655,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.232907378043093,
      "grad_norm": 2.439082384109497,
      "learning_rate": 3.0434927338009602e-06,
      "loss": 0.29094643592834474,
      "memory(GiB)": 72.72,
      "step": 34660,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.2333737524484656,
      "grad_norm": 3.466362714767456,
      "learning_rate": 3.042073510819218e-06,
      "loss": 0.30736074447631834,
      "memory(GiB)": 72.72,
      "step": 34665,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.2338401268538384,
      "grad_norm": 3.34243106842041,
      "learning_rate": 3.040654474128152e-06,
      "loss": 0.3531024694442749,
      "memory(GiB)": 72.72,
      "step": 34670,
      "token_acc": 0.9090909090909091,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.2343065012592107,
      "grad_norm": 2.756152868270874,
      "learning_rate": 3.039235623862777e-06,
      "loss": 0.31330318450927735,
      "memory(GiB)": 72.72,
      "step": 34675,
      "token_acc": 0.5348837209302325,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.2347728756645835,
      "grad_norm": 4.231122016906738,
      "learning_rate": 3.0378169601580933e-06,
      "loss": 0.3224313259124756,
      "memory(GiB)": 72.72,
      "step": 34680,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.2352392500699563,
      "grad_norm": 2.215754747390747,
      "learning_rate": 3.0363984831490794e-06,
      "loss": 0.2813666343688965,
      "memory(GiB)": 72.72,
      "step": 34685,
      "token_acc": 0.5196078431372549,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.2357056244753286,
      "grad_norm": 7.314222812652588,
      "learning_rate": 3.0349801929707013e-06,
      "loss": 0.2813788652420044,
      "memory(GiB)": 72.72,
      "step": 34690,
      "token_acc": 0.9090909090909091,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.2361719988807014,
      "grad_norm": 2.447444438934326,
      "learning_rate": 3.0335620897579044e-06,
      "loss": 0.2932483673095703,
      "memory(GiB)": 72.72,
      "step": 34695,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.236638373286074,
      "grad_norm": 3.8431010246276855,
      "learning_rate": 3.0321441736456155e-06,
      "loss": 0.31351280212402344,
      "memory(GiB)": 72.72,
      "step": 34700,
      "token_acc": 0.925,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.2371047476914465,
      "grad_norm": 5.691506862640381,
      "learning_rate": 3.0307264447687483e-06,
      "loss": 0.2983985662460327,
      "memory(GiB)": 72.72,
      "step": 34705,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.2375711220968193,
      "grad_norm": 2.899371862411499,
      "learning_rate": 3.029308903262193e-06,
      "loss": 0.3261419773101807,
      "memory(GiB)": 72.72,
      "step": 34710,
      "token_acc": 0.8486842105263158,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.238037496502192,
      "grad_norm": 3.423769950866699,
      "learning_rate": 3.027891549260825e-06,
      "loss": 0.32953453063964844,
      "memory(GiB)": 72.72,
      "step": 34715,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.2385038709075644,
      "grad_norm": 4.8519511222839355,
      "learning_rate": 3.0264743828995e-06,
      "loss": 0.2922390937805176,
      "memory(GiB)": 72.72,
      "step": 34720,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.238970245312937,
      "grad_norm": 3.1343448162078857,
      "learning_rate": 3.025057404313059e-06,
      "loss": 0.31365022659301756,
      "memory(GiB)": 72.72,
      "step": 34725,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.23943661971831,
      "grad_norm": 3.5506229400634766,
      "learning_rate": 3.0236406136363204e-06,
      "loss": 0.3004351854324341,
      "memory(GiB)": 72.72,
      "step": 34730,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251374
    },
    {
      "epoch": 3.2399029941236823,
      "grad_norm": 20.017772674560547,
      "learning_rate": 3.0222240110040895e-06,
      "loss": 0.30988781452178954,
      "memory(GiB)": 72.72,
      "step": 34735,
      "token_acc": 0.6435643564356436,
      "train_speed(iter/s)": 0.251374
    },
    {
      "epoch": 3.240369368529055,
      "grad_norm": 3.0137345790863037,
      "learning_rate": 3.020807596551152e-06,
      "loss": 0.29490070343017577,
      "memory(GiB)": 72.72,
      "step": 34740,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.240835742934428,
      "grad_norm": 2.7600302696228027,
      "learning_rate": 3.0193913704122747e-06,
      "loss": 0.3159597873687744,
      "memory(GiB)": 72.72,
      "step": 34745,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.2413021173398002,
      "grad_norm": 2.576646327972412,
      "learning_rate": 3.017975332722206e-06,
      "loss": 0.2631609678268433,
      "memory(GiB)": 72.72,
      "step": 34750,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.241768491745173,
      "grad_norm": 3.8791468143463135,
      "learning_rate": 3.0165594836156796e-06,
      "loss": 0.29901776313781736,
      "memory(GiB)": 72.72,
      "step": 34755,
      "token_acc": 0.8506493506493507,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.242234866150546,
      "grad_norm": 2.770042896270752,
      "learning_rate": 3.015143823227409e-06,
      "loss": 0.3233374834060669,
      "memory(GiB)": 72.72,
      "step": 34760,
      "token_acc": 0.55,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.242701240555918,
      "grad_norm": 7.872586250305176,
      "learning_rate": 3.0137283516920883e-06,
      "loss": 0.2894592761993408,
      "memory(GiB)": 72.72,
      "step": 34765,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.243167614961291,
      "grad_norm": 2.8220834732055664,
      "learning_rate": 3.0123130691443935e-06,
      "loss": 0.31574885845184325,
      "memory(GiB)": 72.72,
      "step": 34770,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.2436339893666637,
      "grad_norm": 2.818751335144043,
      "learning_rate": 3.0108979757189897e-06,
      "loss": 0.30853681564331054,
      "memory(GiB)": 72.72,
      "step": 34775,
      "token_acc": 0.48863636363636365,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.244100363772036,
      "grad_norm": 2.60599422454834,
      "learning_rate": 3.009483071550516e-06,
      "loss": 0.3426531791687012,
      "memory(GiB)": 72.72,
      "step": 34780,
      "token_acc": 0.6491228070175439,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.244566738177409,
      "grad_norm": 2.400214433670044,
      "learning_rate": 3.0080683567735965e-06,
      "loss": 0.30755295753479006,
      "memory(GiB)": 72.72,
      "step": 34785,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.2450331125827816,
      "grad_norm": 2.655487298965454,
      "learning_rate": 3.0066538315228356e-06,
      "loss": 0.3487239837646484,
      "memory(GiB)": 72.72,
      "step": 34790,
      "token_acc": 0.7096774193548387,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 3.245499486988154,
      "grad_norm": 4.7096052169799805,
      "learning_rate": 3.0052394959328224e-06,
      "loss": 0.3211310386657715,
      "memory(GiB)": 72.72,
      "step": 34795,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.2459658613935267,
      "grad_norm": 2.988858699798584,
      "learning_rate": 3.0038253501381254e-06,
      "loss": 0.3096458911895752,
      "memory(GiB)": 72.72,
      "step": 34800,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.2464322357988995,
      "grad_norm": 2.6096572875976562,
      "learning_rate": 3.0024113942732967e-06,
      "loss": 0.3244731664657593,
      "memory(GiB)": 72.72,
      "step": 34805,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.246898610204272,
      "grad_norm": 2.6856045722961426,
      "learning_rate": 3.000997628472871e-06,
      "loss": 0.30057785511016843,
      "memory(GiB)": 72.72,
      "step": 34810,
      "token_acc": 0.9342105263157895,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.2473649846096446,
      "grad_norm": 8.030051231384277,
      "learning_rate": 2.9995840528713625e-06,
      "loss": 0.3239713430404663,
      "memory(GiB)": 72.72,
      "step": 34815,
      "token_acc": 0.6447368421052632,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.2478313590150174,
      "grad_norm": 4.00731897354126,
      "learning_rate": 2.9981706676032695e-06,
      "loss": 0.3027978420257568,
      "memory(GiB)": 72.72,
      "step": 34820,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.2482977334203897,
      "grad_norm": 3.0882349014282227,
      "learning_rate": 2.99675747280307e-06,
      "loss": 0.32234702110290525,
      "memory(GiB)": 72.72,
      "step": 34825,
      "token_acc": 0.7947019867549668,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.2487641078257625,
      "grad_norm": 2.933515787124634,
      "learning_rate": 2.9953444686052265e-06,
      "loss": 0.3132122278213501,
      "memory(GiB)": 72.72,
      "step": 34830,
      "token_acc": 0.99,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.2492304822311353,
      "grad_norm": 2.1524713039398193,
      "learning_rate": 2.99393165514418e-06,
      "loss": 0.32421441078186036,
      "memory(GiB)": 72.72,
      "step": 34835,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.2496968566365076,
      "grad_norm": 2.531414747238159,
      "learning_rate": 2.9925190325543574e-06,
      "loss": 0.3082296371459961,
      "memory(GiB)": 72.72,
      "step": 34840,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.2501632310418804,
      "grad_norm": 2.8111093044281006,
      "learning_rate": 2.991106600970165e-06,
      "loss": 0.29044532775878906,
      "memory(GiB)": 72.72,
      "step": 34845,
      "token_acc": 0.4666666666666667,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.250629605447253,
      "grad_norm": 3.2444419860839844,
      "learning_rate": 2.9896943605259908e-06,
      "loss": 0.31481883525848386,
      "memory(GiB)": 72.72,
      "step": 34850,
      "token_acc": 0.43859649122807015,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.2510959798526256,
      "grad_norm": 2.0276548862457275,
      "learning_rate": 2.9882823113562055e-06,
      "loss": 0.2830773115158081,
      "memory(GiB)": 72.72,
      "step": 34855,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.2515623542579983,
      "grad_norm": 2.230593204498291,
      "learning_rate": 2.986870453595162e-06,
      "loss": 0.32044086456298826,
      "memory(GiB)": 72.72,
      "step": 34860,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.252028728663371,
      "grad_norm": 3.410151720046997,
      "learning_rate": 2.9854587873771924e-06,
      "loss": 0.31341328620910647,
      "memory(GiB)": 72.72,
      "step": 34865,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.2524951030687435,
      "grad_norm": 3.3043503761291504,
      "learning_rate": 2.984047312836611e-06,
      "loss": 0.34896273612976075,
      "memory(GiB)": 72.72,
      "step": 34870,
      "token_acc": 0.9385964912280702,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.2529614774741162,
      "grad_norm": 3.6953744888305664,
      "learning_rate": 2.982636030107719e-06,
      "loss": 0.30328404903411865,
      "memory(GiB)": 72.72,
      "step": 34875,
      "token_acc": 0.5660377358490566,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.253427851879489,
      "grad_norm": 3.9067623615264893,
      "learning_rate": 2.981224939324796e-06,
      "loss": 0.30049982070922854,
      "memory(GiB)": 72.72,
      "step": 34880,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.2538942262848614,
      "grad_norm": 2.9675893783569336,
      "learning_rate": 2.9798140406220995e-06,
      "loss": 0.29929118156433104,
      "memory(GiB)": 72.72,
      "step": 34885,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.254360600690234,
      "grad_norm": 3.2815768718719482,
      "learning_rate": 2.9784033341338737e-06,
      "loss": 0.3118333339691162,
      "memory(GiB)": 72.72,
      "step": 34890,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.254826975095607,
      "grad_norm": 3.924159049987793,
      "learning_rate": 2.9769928199943433e-06,
      "loss": 0.31951179504394533,
      "memory(GiB)": 72.72,
      "step": 34895,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.2552933495009793,
      "grad_norm": 2.6454524993896484,
      "learning_rate": 2.9755824983377135e-06,
      "loss": 0.31689815521240233,
      "memory(GiB)": 72.72,
      "step": 34900,
      "token_acc": 0.9775280898876404,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.255759723906352,
      "grad_norm": 2.684899091720581,
      "learning_rate": 2.9741723692981716e-06,
      "loss": 0.2792359352111816,
      "memory(GiB)": 72.72,
      "step": 34905,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.256226098311725,
      "grad_norm": 2.9389634132385254,
      "learning_rate": 2.9727624330098897e-06,
      "loss": 0.28712608814239504,
      "memory(GiB)": 72.72,
      "step": 34910,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.256692472717097,
      "grad_norm": 7.954738616943359,
      "learning_rate": 2.9713526896070167e-06,
      "loss": 0.32454006671905516,
      "memory(GiB)": 72.72,
      "step": 34915,
      "token_acc": 0.9572192513368984,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.25715884712247,
      "grad_norm": 2.841142177581787,
      "learning_rate": 2.9699431392236866e-06,
      "loss": 0.2706657648086548,
      "memory(GiB)": 72.72,
      "step": 34920,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.2576252215278427,
      "grad_norm": 3.9195456504821777,
      "learning_rate": 2.968533781994012e-06,
      "loss": 0.2859017372131348,
      "memory(GiB)": 72.72,
      "step": 34925,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.258091595933215,
      "grad_norm": 2.6498141288757324,
      "learning_rate": 2.967124618052091e-06,
      "loss": 0.30084640979766847,
      "memory(GiB)": 72.72,
      "step": 34930,
      "token_acc": 0.6831683168316832,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.258557970338588,
      "grad_norm": 4.693047046661377,
      "learning_rate": 2.965715647532e-06,
      "loss": 0.29715900421142577,
      "memory(GiB)": 72.72,
      "step": 34935,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.2590243447439606,
      "grad_norm": 3.3127663135528564,
      "learning_rate": 2.964306870567797e-06,
      "loss": 0.33499884605407715,
      "memory(GiB)": 72.72,
      "step": 34940,
      "token_acc": 0.5084745762711864,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.259490719149333,
      "grad_norm": 6.475975036621094,
      "learning_rate": 2.9628982872935247e-06,
      "loss": 0.28957219123840333,
      "memory(GiB)": 72.72,
      "step": 34945,
      "token_acc": 0.7291666666666666,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.2599570935547058,
      "grad_norm": 1.754380702972412,
      "learning_rate": 2.9614898978432057e-06,
      "loss": 0.2808283090591431,
      "memory(GiB)": 72.72,
      "step": 34950,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.2604234679600785,
      "grad_norm": 3.266751527786255,
      "learning_rate": 2.9600817023508433e-06,
      "loss": 0.3231369972229004,
      "memory(GiB)": 72.72,
      "step": 34955,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.260889842365451,
      "grad_norm": 2.474165916442871,
      "learning_rate": 2.958673700950423e-06,
      "loss": 0.2816030979156494,
      "memory(GiB)": 72.72,
      "step": 34960,
      "token_acc": 0.9711538461538461,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.2613562167708237,
      "grad_norm": 2.22707462310791,
      "learning_rate": 2.95726589377591e-06,
      "loss": 0.3390233516693115,
      "memory(GiB)": 72.72,
      "step": 34965,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.2618225911761964,
      "grad_norm": 2.903594970703125,
      "learning_rate": 2.955858280961254e-06,
      "loss": 0.3252603530883789,
      "memory(GiB)": 72.72,
      "step": 34970,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.262288965581569,
      "grad_norm": 4.7898268699646,
      "learning_rate": 2.9544508626403867e-06,
      "loss": 0.27308852672576905,
      "memory(GiB)": 72.72,
      "step": 34975,
      "token_acc": 0.627906976744186,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.2627553399869416,
      "grad_norm": 3.612936019897461,
      "learning_rate": 2.9530436389472196e-06,
      "loss": 0.36846165657043456,
      "memory(GiB)": 72.72,
      "step": 34980,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.2632217143923143,
      "grad_norm": 3.222398281097412,
      "learning_rate": 2.9516366100156437e-06,
      "loss": 0.34280507564544677,
      "memory(GiB)": 72.72,
      "step": 34985,
      "token_acc": 0.5357142857142857,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.2636880887976867,
      "grad_norm": 2.587067127227783,
      "learning_rate": 2.950229775979533e-06,
      "loss": 0.3093770980834961,
      "memory(GiB)": 72.72,
      "step": 34990,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.2641544632030595,
      "grad_norm": 2.44883131980896,
      "learning_rate": 2.948823136972746e-06,
      "loss": 0.29028661251068116,
      "memory(GiB)": 72.72,
      "step": 34995,
      "token_acc": 0.33962264150943394,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.2646208376084322,
      "grad_norm": 1.843849778175354,
      "learning_rate": 2.947416693129118e-06,
      "loss": 0.2829894065856934,
      "memory(GiB)": 72.72,
      "step": 35000,
      "token_acc": 0.9166666666666666,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.2650872120138046,
      "grad_norm": 3.411592483520508,
      "learning_rate": 2.9460104445824677e-06,
      "loss": 0.28873553276062014,
      "memory(GiB)": 72.72,
      "step": 35005,
      "token_acc": 0.7258064516129032,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.2655535864191774,
      "grad_norm": 3.355140447616577,
      "learning_rate": 2.9446043914665967e-06,
      "loss": 0.30479869842529295,
      "memory(GiB)": 72.72,
      "step": 35010,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.2660199608245497,
      "grad_norm": 9.692996978759766,
      "learning_rate": 2.943198533915287e-06,
      "loss": 0.3000894546508789,
      "memory(GiB)": 72.72,
      "step": 35015,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.2664863352299225,
      "grad_norm": 4.008552074432373,
      "learning_rate": 2.9417928720623e-06,
      "loss": 0.3127781867980957,
      "memory(GiB)": 72.72,
      "step": 35020,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.2669527096352953,
      "grad_norm": 2.2648041248321533,
      "learning_rate": 2.9403874060413806e-06,
      "loss": 0.31362993717193605,
      "memory(GiB)": 72.72,
      "step": 35025,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.267419084040668,
      "grad_norm": 3.1668145656585693,
      "learning_rate": 2.9389821359862545e-06,
      "loss": 0.29791946411132814,
      "memory(GiB)": 72.72,
      "step": 35030,
      "token_acc": 0.62,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.2678854584460404,
      "grad_norm": 2.802053451538086,
      "learning_rate": 2.937577062030631e-06,
      "loss": 0.3387721538543701,
      "memory(GiB)": 72.72,
      "step": 35035,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.268351832851413,
      "grad_norm": 9.731101036071777,
      "learning_rate": 2.9361721843081936e-06,
      "loss": 0.3072117805480957,
      "memory(GiB)": 72.72,
      "step": 35040,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.2688182072567855,
      "grad_norm": 3.156292200088501,
      "learning_rate": 2.9347675029526164e-06,
      "loss": 0.31306233406066897,
      "memory(GiB)": 72.72,
      "step": 35045,
      "token_acc": 0.7021276595744681,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.2692845816621583,
      "grad_norm": 3.7399544715881348,
      "learning_rate": 2.933363018097549e-06,
      "loss": 0.3401770830154419,
      "memory(GiB)": 72.72,
      "step": 35050,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.269750956067531,
      "grad_norm": 2.9717814922332764,
      "learning_rate": 2.9319587298766255e-06,
      "loss": 0.3032428026199341,
      "memory(GiB)": 72.72,
      "step": 35055,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.270217330472904,
      "grad_norm": 2.2553815841674805,
      "learning_rate": 2.9305546384234575e-06,
      "loss": 0.31554951667785647,
      "memory(GiB)": 72.72,
      "step": 35060,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.270683704878276,
      "grad_norm": 2.761770725250244,
      "learning_rate": 2.9291507438716392e-06,
      "loss": 0.3104926824569702,
      "memory(GiB)": 72.72,
      "step": 35065,
      "token_acc": 0.978494623655914,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.271150079283649,
      "grad_norm": 2.5265729427337646,
      "learning_rate": 2.92774704635475e-06,
      "loss": 0.2819380283355713,
      "memory(GiB)": 72.72,
      "step": 35070,
      "token_acc": 0.8106060606060606,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.2716164536890213,
      "grad_norm": 2.1984307765960693,
      "learning_rate": 2.9263435460063435e-06,
      "loss": 0.2736887216567993,
      "memory(GiB)": 72.72,
      "step": 35075,
      "token_acc": 0.8689655172413793,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.272082828094394,
      "grad_norm": 3.0989670753479004,
      "learning_rate": 2.9249402429599617e-06,
      "loss": 0.35413236618041993,
      "memory(GiB)": 72.72,
      "step": 35080,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.272549202499767,
      "grad_norm": 4.61672306060791,
      "learning_rate": 2.923537137349123e-06,
      "loss": 0.26497597694396974,
      "memory(GiB)": 72.72,
      "step": 35085,
      "token_acc": 0.6981132075471698,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.2730155769051397,
      "grad_norm": 3.8703911304473877,
      "learning_rate": 2.9221342293073297e-06,
      "loss": 0.33188748359680176,
      "memory(GiB)": 72.72,
      "step": 35090,
      "token_acc": 0.9873417721518988,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.273481951310512,
      "grad_norm": 3.3967690467834473,
      "learning_rate": 2.920731518968063e-06,
      "loss": 0.32857341766357423,
      "memory(GiB)": 72.72,
      "step": 35095,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.273948325715885,
      "grad_norm": 2.488438844680786,
      "learning_rate": 2.9193290064647874e-06,
      "loss": 0.27845492362976076,
      "memory(GiB)": 72.72,
      "step": 35100,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.274414700121257,
      "grad_norm": 2.8800272941589355,
      "learning_rate": 2.917926691930947e-06,
      "loss": 0.31983470916748047,
      "memory(GiB)": 72.72,
      "step": 35105,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.27488107452663,
      "grad_norm": 4.105981826782227,
      "learning_rate": 2.9165245754999657e-06,
      "loss": 0.29276347160339355,
      "memory(GiB)": 72.72,
      "step": 35110,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.2753474489320027,
      "grad_norm": 4.146810054779053,
      "learning_rate": 2.9151226573052565e-06,
      "loss": 0.29227547645568847,
      "memory(GiB)": 72.72,
      "step": 35115,
      "token_acc": 0.8125,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.2758138233373755,
      "grad_norm": 2.246713161468506,
      "learning_rate": 2.9137209374802022e-06,
      "loss": 0.3230725288391113,
      "memory(GiB)": 72.72,
      "step": 35120,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.276280197742748,
      "grad_norm": 3.4818897247314453,
      "learning_rate": 2.9123194161581734e-06,
      "loss": 0.30513241291046145,
      "memory(GiB)": 72.72,
      "step": 35125,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.2767465721481206,
      "grad_norm": 3.2548670768737793,
      "learning_rate": 2.9109180934725214e-06,
      "loss": 0.2923552989959717,
      "memory(GiB)": 72.72,
      "step": 35130,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.277212946553493,
      "grad_norm": 2.4939005374908447,
      "learning_rate": 2.909516969556577e-06,
      "loss": 0.32396206855773924,
      "memory(GiB)": 72.72,
      "step": 35135,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.2776793209588657,
      "grad_norm": 2.3650624752044678,
      "learning_rate": 2.9081160445436506e-06,
      "loss": 0.28160719871520995,
      "memory(GiB)": 72.72,
      "step": 35140,
      "token_acc": 0.4727272727272727,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.2781456953642385,
      "grad_norm": 9.634151458740234,
      "learning_rate": 2.906715318567041e-06,
      "loss": 0.30281331539154055,
      "memory(GiB)": 72.72,
      "step": 35145,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.2786120697696113,
      "grad_norm": 2.5909037590026855,
      "learning_rate": 2.90531479176002e-06,
      "loss": 0.3103806018829346,
      "memory(GiB)": 72.72,
      "step": 35150,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.2790784441749836,
      "grad_norm": 2.656795024871826,
      "learning_rate": 2.9039144642558436e-06,
      "loss": 0.27271246910095215,
      "memory(GiB)": 72.72,
      "step": 35155,
      "token_acc": 0.9022556390977443,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.2795448185803564,
      "grad_norm": 4.751548767089844,
      "learning_rate": 2.9025143361877496e-06,
      "loss": 0.31224451065063474,
      "memory(GiB)": 72.72,
      "step": 35160,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.2800111929857287,
      "grad_norm": 2.5787625312805176,
      "learning_rate": 2.901114407688954e-06,
      "loss": 0.3042553186416626,
      "memory(GiB)": 72.72,
      "step": 35165,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.2804775673911015,
      "grad_norm": 3.8344638347625732,
      "learning_rate": 2.8997146788926593e-06,
      "loss": 0.3519903659820557,
      "memory(GiB)": 72.72,
      "step": 35170,
      "token_acc": 0.9203539823008849,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.2809439417964743,
      "grad_norm": 2.298649311065674,
      "learning_rate": 2.8983151499320387e-06,
      "loss": 0.2952023983001709,
      "memory(GiB)": 72.72,
      "step": 35175,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.281410316201847,
      "grad_norm": 2.6241517066955566,
      "learning_rate": 2.896915820940259e-06,
      "loss": 0.26542067527770996,
      "memory(GiB)": 72.72,
      "step": 35180,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.2818766906072194,
      "grad_norm": 3.427607297897339,
      "learning_rate": 2.8955166920504608e-06,
      "loss": 0.27562265396118163,
      "memory(GiB)": 72.72,
      "step": 35185,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.282343065012592,
      "grad_norm": 6.957207202911377,
      "learning_rate": 2.894117763395766e-06,
      "loss": 0.3203751564025879,
      "memory(GiB)": 72.72,
      "step": 35190,
      "token_acc": 0.5084745762711864,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.2828094394179645,
      "grad_norm": 3.8337411880493164,
      "learning_rate": 2.8927190351092782e-06,
      "loss": 0.3125936985015869,
      "memory(GiB)": 72.72,
      "step": 35195,
      "token_acc": 0.9702970297029703,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.2832758138233373,
      "grad_norm": 3.0112195014953613,
      "learning_rate": 2.8913205073240834e-06,
      "loss": 0.29160561561584475,
      "memory(GiB)": 72.72,
      "step": 35200,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.28374218822871,
      "grad_norm": 5.9849653244018555,
      "learning_rate": 2.889922180173246e-06,
      "loss": 0.31165323257446287,
      "memory(GiB)": 72.72,
      "step": 35205,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.2842085626340825,
      "grad_norm": 2.432910680770874,
      "learning_rate": 2.8885240537898106e-06,
      "loss": 0.28878905773162844,
      "memory(GiB)": 72.72,
      "step": 35210,
      "token_acc": 0.6730769230769231,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.2846749370394552,
      "grad_norm": 2.7457709312438965,
      "learning_rate": 2.887126128306811e-06,
      "loss": 0.314545726776123,
      "memory(GiB)": 72.72,
      "step": 35215,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.285141311444828,
      "grad_norm": 8.281253814697266,
      "learning_rate": 2.88572840385725e-06,
      "loss": 0.29040074348449707,
      "memory(GiB)": 72.72,
      "step": 35220,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.2856076858502004,
      "grad_norm": 2.7556724548339844,
      "learning_rate": 2.8843308805741175e-06,
      "loss": 0.28743696212768555,
      "memory(GiB)": 72.72,
      "step": 35225,
      "token_acc": 0.9292929292929293,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.286074060255573,
      "grad_norm": 2.182941198348999,
      "learning_rate": 2.882933558590385e-06,
      "loss": 0.29822940826416017,
      "memory(GiB)": 72.72,
      "step": 35230,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.286540434660946,
      "grad_norm": 2.2917163372039795,
      "learning_rate": 2.881536438039002e-06,
      "loss": 0.29853990077972414,
      "memory(GiB)": 72.72,
      "step": 35235,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.2870068090663183,
      "grad_norm": 2.751885175704956,
      "learning_rate": 2.8801395190529015e-06,
      "loss": 0.288020658493042,
      "memory(GiB)": 72.72,
      "step": 35240,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.287473183471691,
      "grad_norm": 4.514509677886963,
      "learning_rate": 2.878742801764992e-06,
      "loss": 0.29391050338745117,
      "memory(GiB)": 72.72,
      "step": 35245,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.287939557877064,
      "grad_norm": 3.6649515628814697,
      "learning_rate": 2.8773462863081734e-06,
      "loss": 0.2675814628601074,
      "memory(GiB)": 72.72,
      "step": 35250,
      "token_acc": 0.7878787878787878,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.288405932282436,
      "grad_norm": 3.2917885780334473,
      "learning_rate": 2.875949972815316e-06,
      "loss": 0.27287628650665285,
      "memory(GiB)": 72.72,
      "step": 35255,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.288872306687809,
      "grad_norm": 2.4344985485076904,
      "learning_rate": 2.8745538614192764e-06,
      "loss": 0.2935617446899414,
      "memory(GiB)": 72.72,
      "step": 35260,
      "token_acc": 0.9680851063829787,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.2893386810931817,
      "grad_norm": 2.9786343574523926,
      "learning_rate": 2.8731579522528887e-06,
      "loss": 0.31655259132385255,
      "memory(GiB)": 72.72,
      "step": 35265,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.289805055498554,
      "grad_norm": 2.3767330646514893,
      "learning_rate": 2.8717622454489714e-06,
      "loss": 0.3077535152435303,
      "memory(GiB)": 72.72,
      "step": 35270,
      "token_acc": 0.6052631578947368,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.290271429903927,
      "grad_norm": 3.658742666244507,
      "learning_rate": 2.870366741140317e-06,
      "loss": 0.30153594017028806,
      "memory(GiB)": 72.72,
      "step": 35275,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.2907378043092996,
      "grad_norm": 2.754530429840088,
      "learning_rate": 2.8689714394597083e-06,
      "loss": 0.28849000930786134,
      "memory(GiB)": 72.72,
      "step": 35280,
      "token_acc": 0.7678571428571429,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.291204178714672,
      "grad_norm": 2.7503411769866943,
      "learning_rate": 2.8675763405399026e-06,
      "loss": 0.24747166633605958,
      "memory(GiB)": 72.72,
      "step": 35285,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.2916705531200448,
      "grad_norm": 3.181286334991455,
      "learning_rate": 2.866181444513639e-06,
      "loss": 0.3386102199554443,
      "memory(GiB)": 72.72,
      "step": 35290,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.2921369275254175,
      "grad_norm": 2.6915221214294434,
      "learning_rate": 2.8647867515136374e-06,
      "loss": 0.3096930027008057,
      "memory(GiB)": 72.72,
      "step": 35295,
      "token_acc": 0.9619047619047619,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.29260330193079,
      "grad_norm": 6.335335731506348,
      "learning_rate": 2.8633922616725985e-06,
      "loss": 0.29455697536468506,
      "memory(GiB)": 72.72,
      "step": 35300,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.2930696763361627,
      "grad_norm": 3.5486388206481934,
      "learning_rate": 2.861997975123204e-06,
      "loss": 0.31480166912078855,
      "memory(GiB)": 72.72,
      "step": 35305,
      "token_acc": 0.6612903225806451,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.2935360507415354,
      "grad_norm": 4.286692142486572,
      "learning_rate": 2.860603891998116e-06,
      "loss": 0.3106159925460815,
      "memory(GiB)": 72.72,
      "step": 35310,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.2940024251469078,
      "grad_norm": 2.566408634185791,
      "learning_rate": 2.859210012429977e-06,
      "loss": 0.33116874694824217,
      "memory(GiB)": 72.72,
      "step": 35315,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.2944687995522806,
      "grad_norm": 3.6353061199188232,
      "learning_rate": 2.857816336551411e-06,
      "loss": 0.3233911991119385,
      "memory(GiB)": 72.72,
      "step": 35320,
      "token_acc": 0.9879518072289156,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.2949351739576533,
      "grad_norm": 4.508106231689453,
      "learning_rate": 2.856422864495021e-06,
      "loss": 0.34426231384277345,
      "memory(GiB)": 72.72,
      "step": 35325,
      "token_acc": 0.5543478260869565,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.2954015483630257,
      "grad_norm": 3.6088337898254395,
      "learning_rate": 2.8550295963933917e-06,
      "loss": 0.2851172685623169,
      "memory(GiB)": 72.72,
      "step": 35330,
      "token_acc": 0.9555555555555556,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.2958679227683985,
      "grad_norm": 3.49849796295166,
      "learning_rate": 2.8536365323790892e-06,
      "loss": 0.30096960067749023,
      "memory(GiB)": 72.72,
      "step": 35335,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.2963342971737712,
      "grad_norm": 2.981663227081299,
      "learning_rate": 2.852243672584658e-06,
      "loss": 0.3116344213485718,
      "memory(GiB)": 72.72,
      "step": 35340,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.2968006715791436,
      "grad_norm": 3.2863149642944336,
      "learning_rate": 2.8508510171426236e-06,
      "loss": 0.27497618198394774,
      "memory(GiB)": 72.72,
      "step": 35345,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.2972670459845164,
      "grad_norm": 2.7206385135650635,
      "learning_rate": 2.849458566185496e-06,
      "loss": 0.3118371248245239,
      "memory(GiB)": 72.72,
      "step": 35350,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.297733420389889,
      "grad_norm": 5.246514797210693,
      "learning_rate": 2.848066319845761e-06,
      "loss": 0.3143853902816772,
      "memory(GiB)": 72.72,
      "step": 35355,
      "token_acc": 0.6078431372549019,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.2981997947952615,
      "grad_norm": 7.245546817779541,
      "learning_rate": 2.8466742782558864e-06,
      "loss": 0.3188468456268311,
      "memory(GiB)": 72.72,
      "step": 35360,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.2986661692006343,
      "grad_norm": 3.0137627124786377,
      "learning_rate": 2.8452824415483203e-06,
      "loss": 0.2960955142974854,
      "memory(GiB)": 72.72,
      "step": 35365,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.299132543606007,
      "grad_norm": 2.1214749813079834,
      "learning_rate": 2.8438908098554944e-06,
      "loss": 0.28278264999389646,
      "memory(GiB)": 72.72,
      "step": 35370,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.2995989180113794,
      "grad_norm": 2.396069049835205,
      "learning_rate": 2.842499383309815e-06,
      "loss": 0.3184009313583374,
      "memory(GiB)": 72.72,
      "step": 35375,
      "token_acc": 0.5961538461538461,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.300065292416752,
      "grad_norm": 3.4512393474578857,
      "learning_rate": 2.841108162043669e-06,
      "loss": 0.2909374713897705,
      "memory(GiB)": 72.72,
      "step": 35380,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.300531666822125,
      "grad_norm": 2.3634068965911865,
      "learning_rate": 2.839717146189434e-06,
      "loss": 0.29649529457092283,
      "memory(GiB)": 72.72,
      "step": 35385,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.3009980412274973,
      "grad_norm": 7.671761512756348,
      "learning_rate": 2.8383263358794573e-06,
      "loss": 0.2855804443359375,
      "memory(GiB)": 72.72,
      "step": 35390,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.30146441563287,
      "grad_norm": 3.122209072113037,
      "learning_rate": 2.8369357312460703e-06,
      "loss": 0.31412267684936523,
      "memory(GiB)": 72.72,
      "step": 35395,
      "token_acc": 0.7291666666666666,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.301930790038243,
      "grad_norm": 2.466456174850464,
      "learning_rate": 2.8355453324215856e-06,
      "loss": 0.27524447441101074,
      "memory(GiB)": 72.72,
      "step": 35400,
      "token_acc": 0.5247524752475248,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.302397164443615,
      "grad_norm": 3.3124797344207764,
      "learning_rate": 2.8341551395382944e-06,
      "loss": 0.3075653076171875,
      "memory(GiB)": 72.72,
      "step": 35405,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.302863538848988,
      "grad_norm": 3.998875856399536,
      "learning_rate": 2.8327651527284695e-06,
      "loss": 0.3076639652252197,
      "memory(GiB)": 72.72,
      "step": 35410,
      "token_acc": 0.8623188405797102,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.3033299132543608,
      "grad_norm": 3.3772733211517334,
      "learning_rate": 2.831375372124364e-06,
      "loss": 0.3197880744934082,
      "memory(GiB)": 72.72,
      "step": 35415,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.303796287659733,
      "grad_norm": 2.9453415870666504,
      "learning_rate": 2.8299857978582113e-06,
      "loss": 0.30837335586547854,
      "memory(GiB)": 72.72,
      "step": 35420,
      "token_acc": 0.6855345911949685,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.304262662065106,
      "grad_norm": 9.92003345489502,
      "learning_rate": 2.8285964300622255e-06,
      "loss": 0.3329492092132568,
      "memory(GiB)": 72.72,
      "step": 35425,
      "token_acc": 0.6153846153846154,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.3047290364704787,
      "grad_norm": 3.678593397140503,
      "learning_rate": 2.827207268868599e-06,
      "loss": 0.34419264793396,
      "memory(GiB)": 72.72,
      "step": 35430,
      "token_acc": 0.9464285714285714,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.305195410875851,
      "grad_norm": 18.259204864501953,
      "learning_rate": 2.8258183144095085e-06,
      "loss": 0.32456769943237307,
      "memory(GiB)": 72.72,
      "step": 35435,
      "token_acc": 0.9770114942528736,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.305661785281224,
      "grad_norm": 3.2322349548339844,
      "learning_rate": 2.824429566817107e-06,
      "loss": 0.30600240230560305,
      "memory(GiB)": 72.72,
      "step": 35440,
      "token_acc": 0.7555555555555555,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.3061281596865966,
      "grad_norm": 3.0566508769989014,
      "learning_rate": 2.8230410262235293e-06,
      "loss": 0.31923274993896483,
      "memory(GiB)": 72.72,
      "step": 35445,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.306594534091969,
      "grad_norm": 2.9184186458587646,
      "learning_rate": 2.821652692760893e-06,
      "loss": 0.30333456993103025,
      "memory(GiB)": 72.72,
      "step": 35450,
      "token_acc": 0.5964912280701754,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.3070609084973417,
      "grad_norm": 2.7483396530151367,
      "learning_rate": 2.8202645665612922e-06,
      "loss": 0.32988576889038085,
      "memory(GiB)": 72.72,
      "step": 35455,
      "token_acc": 0.44642857142857145,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3075272829027145,
      "grad_norm": 2.733548641204834,
      "learning_rate": 2.818876647756803e-06,
      "loss": 0.30220143795013427,
      "memory(GiB)": 72.72,
      "step": 35460,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.307993657308087,
      "grad_norm": 2.853616952896118,
      "learning_rate": 2.8174889364794823e-06,
      "loss": 0.276446533203125,
      "memory(GiB)": 72.72,
      "step": 35465,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.3084600317134596,
      "grad_norm": 2.6715731620788574,
      "learning_rate": 2.8161014328613674e-06,
      "loss": 0.3287330150604248,
      "memory(GiB)": 72.72,
      "step": 35470,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.3089264061188324,
      "grad_norm": 3.033203601837158,
      "learning_rate": 2.814714137034471e-06,
      "loss": 0.30916876792907716,
      "memory(GiB)": 72.72,
      "step": 35475,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.3093927805242047,
      "grad_norm": 2.737778425216675,
      "learning_rate": 2.8133270491307916e-06,
      "loss": 0.31559953689575193,
      "memory(GiB)": 72.72,
      "step": 35480,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3098591549295775,
      "grad_norm": 3.1559574604034424,
      "learning_rate": 2.811940169282309e-06,
      "loss": 0.24935054779052734,
      "memory(GiB)": 72.72,
      "step": 35485,
      "token_acc": 0.8823529411764706,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3103255293349503,
      "grad_norm": 3.590001106262207,
      "learning_rate": 2.810553497620978e-06,
      "loss": 0.3081228494644165,
      "memory(GiB)": 72.72,
      "step": 35490,
      "token_acc": 0.717391304347826,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3107919037403226,
      "grad_norm": 4.122803688049316,
      "learning_rate": 2.809167034278738e-06,
      "loss": 0.34815502166748047,
      "memory(GiB)": 72.72,
      "step": 35495,
      "token_acc": 0.5813953488372093,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.3112582781456954,
      "grad_norm": 3.9449541568756104,
      "learning_rate": 2.8077807793875043e-06,
      "loss": 0.3146015167236328,
      "memory(GiB)": 72.72,
      "step": 35500,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.311724652551068,
      "grad_norm": 3.1796905994415283,
      "learning_rate": 2.8063947330791775e-06,
      "loss": 0.3195647716522217,
      "memory(GiB)": 72.72,
      "step": 35505,
      "token_acc": 0.52,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.3121910269564405,
      "grad_norm": 2.983821392059326,
      "learning_rate": 2.8050088954856336e-06,
      "loss": 0.2684561491012573,
      "memory(GiB)": 72.72,
      "step": 35510,
      "token_acc": 0.5961538461538461,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3126574013618133,
      "grad_norm": 4.599888324737549,
      "learning_rate": 2.8036232667387318e-06,
      "loss": 0.29096646308898927,
      "memory(GiB)": 72.72,
      "step": 35515,
      "token_acc": 0.7866666666666666,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.313123775767186,
      "grad_norm": 3.346989393234253,
      "learning_rate": 2.80223784697031e-06,
      "loss": 0.3325916290283203,
      "memory(GiB)": 72.72,
      "step": 35520,
      "token_acc": 0.5614035087719298,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.3135901501725584,
      "grad_norm": 4.045320510864258,
      "learning_rate": 2.800852636312187e-06,
      "loss": 0.2666828155517578,
      "memory(GiB)": 72.72,
      "step": 35525,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.314056524577931,
      "grad_norm": 2.5989151000976562,
      "learning_rate": 2.79946763489616e-06,
      "loss": 0.3104372262954712,
      "memory(GiB)": 72.72,
      "step": 35530,
      "token_acc": 0.978494623655914,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.314522898983304,
      "grad_norm": 2.677088975906372,
      "learning_rate": 2.7980828428540097e-06,
      "loss": 0.3061369895935059,
      "memory(GiB)": 72.72,
      "step": 35535,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.3149892733886763,
      "grad_norm": 38.20674514770508,
      "learning_rate": 2.7966982603174932e-06,
      "loss": 0.29218530654907227,
      "memory(GiB)": 72.72,
      "step": 35540,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.315455647794049,
      "grad_norm": 3.3028059005737305,
      "learning_rate": 2.7953138874183494e-06,
      "loss": 0.2916088581085205,
      "memory(GiB)": 72.72,
      "step": 35545,
      "token_acc": 0.6904761904761905,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.3159220221994214,
      "grad_norm": 5.068718910217285,
      "learning_rate": 2.7939297242882956e-06,
      "loss": 0.34278695583343505,
      "memory(GiB)": 72.72,
      "step": 35550,
      "token_acc": 0.723404255319149,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.3163883966047942,
      "grad_norm": 2.778580904006958,
      "learning_rate": 2.7925457710590353e-06,
      "loss": 0.2814835548400879,
      "memory(GiB)": 72.72,
      "step": 35555,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.316854771010167,
      "grad_norm": 3.501081705093384,
      "learning_rate": 2.791162027862244e-06,
      "loss": 0.3059516906738281,
      "memory(GiB)": 72.72,
      "step": 35560,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.31732114541554,
      "grad_norm": 2.214106559753418,
      "learning_rate": 2.7897784948295837e-06,
      "loss": 0.3056429386138916,
      "memory(GiB)": 72.72,
      "step": 35565,
      "token_acc": 0.696969696969697,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.317787519820912,
      "grad_norm": 3.1262242794036865,
      "learning_rate": 2.788395172092689e-06,
      "loss": 0.287542724609375,
      "memory(GiB)": 72.72,
      "step": 35570,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.318253894226285,
      "grad_norm": 2.95639705657959,
      "learning_rate": 2.7870120597831806e-06,
      "loss": 0.2870390176773071,
      "memory(GiB)": 72.72,
      "step": 35575,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.3187202686316573,
      "grad_norm": 3.321178913116455,
      "learning_rate": 2.7856291580326567e-06,
      "loss": 0.31483612060546873,
      "memory(GiB)": 72.72,
      "step": 35580,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.31918664303703,
      "grad_norm": 3.6827282905578613,
      "learning_rate": 2.7842464669726955e-06,
      "loss": 0.29363102912902833,
      "memory(GiB)": 72.72,
      "step": 35585,
      "token_acc": 0.9318181818181818,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.319653017442403,
      "grad_norm": 3.0989043712615967,
      "learning_rate": 2.7828639867348596e-06,
      "loss": 0.28424906730651855,
      "memory(GiB)": 72.72,
      "step": 35590,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.3201193918477756,
      "grad_norm": 2.5561907291412354,
      "learning_rate": 2.7814817174506842e-06,
      "loss": 0.32129502296447754,
      "memory(GiB)": 72.72,
      "step": 35595,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.320585766253148,
      "grad_norm": 3.837995767593384,
      "learning_rate": 2.7800996592516895e-06,
      "loss": 0.336153507232666,
      "memory(GiB)": 72.72,
      "step": 35600,
      "token_acc": 0.4715447154471545,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.3210521406585207,
      "grad_norm": 2.4464845657348633,
      "learning_rate": 2.778717812269374e-06,
      "loss": 0.2811882972717285,
      "memory(GiB)": 72.72,
      "step": 35605,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.321518515063893,
      "grad_norm": 4.372698783874512,
      "learning_rate": 2.777336176635216e-06,
      "loss": 0.26998128890991213,
      "memory(GiB)": 72.72,
      "step": 35610,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.321984889469266,
      "grad_norm": 3.427659273147583,
      "learning_rate": 2.775954752480673e-06,
      "loss": 0.28206396102905273,
      "memory(GiB)": 72.72,
      "step": 35615,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3224512638746386,
      "grad_norm": 3.468945026397705,
      "learning_rate": 2.7745735399371843e-06,
      "loss": 0.3078402757644653,
      "memory(GiB)": 72.72,
      "step": 35620,
      "token_acc": 0.6140350877192983,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.3229176382800114,
      "grad_norm": 4.360503196716309,
      "learning_rate": 2.7731925391361674e-06,
      "loss": 0.3118860721588135,
      "memory(GiB)": 72.72,
      "step": 35625,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.3233840126853837,
      "grad_norm": 3.1950089931488037,
      "learning_rate": 2.771811750209021e-06,
      "loss": 0.28771138191223145,
      "memory(GiB)": 72.72,
      "step": 35630,
      "token_acc": 0.5666666666666667,
      "train_speed(iter/s)": 0.251367
    },
    {
      "epoch": 3.3238503870907565,
      "grad_norm": 2.378352642059326,
      "learning_rate": 2.770431173287122e-06,
      "loss": 0.313238525390625,
      "memory(GiB)": 72.72,
      "step": 35635,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.324316761496129,
      "grad_norm": 2.7573049068450928,
      "learning_rate": 2.7690508085018286e-06,
      "loss": 0.2993760347366333,
      "memory(GiB)": 72.72,
      "step": 35640,
      "token_acc": 0.5072463768115942,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3247831359015017,
      "grad_norm": 2.77392315864563,
      "learning_rate": 2.7676706559844786e-06,
      "loss": 0.29013357162475584,
      "memory(GiB)": 72.72,
      "step": 35645,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.3252495103068744,
      "grad_norm": 3.4457597732543945,
      "learning_rate": 2.7662907158663864e-06,
      "loss": 0.3183459758758545,
      "memory(GiB)": 72.72,
      "step": 35650,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.325715884712247,
      "grad_norm": 2.701988458633423,
      "learning_rate": 2.764910988278854e-06,
      "loss": 0.29265642166137695,
      "memory(GiB)": 72.72,
      "step": 35655,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.3261822591176196,
      "grad_norm": 3.1747560501098633,
      "learning_rate": 2.7635314733531547e-06,
      "loss": 0.29942736625671384,
      "memory(GiB)": 72.72,
      "step": 35660,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3266486335229923,
      "grad_norm": 4.061169147491455,
      "learning_rate": 2.762152171220549e-06,
      "loss": 0.32413372993469236,
      "memory(GiB)": 72.72,
      "step": 35665,
      "token_acc": 0.6476190476190476,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.3271150079283647,
      "grad_norm": 9.735116004943848,
      "learning_rate": 2.760773082012268e-06,
      "loss": 0.3315212965011597,
      "memory(GiB)": 72.72,
      "step": 35670,
      "token_acc": 0.945054945054945,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.3275813823337375,
      "grad_norm": 1.7709214687347412,
      "learning_rate": 2.7593942058595303e-06,
      "loss": 0.2942783355712891,
      "memory(GiB)": 72.72,
      "step": 35675,
      "token_acc": 0.5294117647058824,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.3280477567391102,
      "grad_norm": 5.414401054382324,
      "learning_rate": 2.7580155428935316e-06,
      "loss": 0.3129736423492432,
      "memory(GiB)": 72.72,
      "step": 35680,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.328514131144483,
      "grad_norm": 2.2804384231567383,
      "learning_rate": 2.756637093245445e-06,
      "loss": 0.27884578704833984,
      "memory(GiB)": 72.72,
      "step": 35685,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.3289805055498554,
      "grad_norm": 2.930022954940796,
      "learning_rate": 2.755258857046431e-06,
      "loss": 0.3553136348724365,
      "memory(GiB)": 72.72,
      "step": 35690,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.329446879955228,
      "grad_norm": 2.6515917778015137,
      "learning_rate": 2.75388083442762e-06,
      "loss": 0.2699882030487061,
      "memory(GiB)": 72.72,
      "step": 35695,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.3299132543606005,
      "grad_norm": 9.296019554138184,
      "learning_rate": 2.75250302552013e-06,
      "loss": 0.33617630004882815,
      "memory(GiB)": 72.72,
      "step": 35700,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.3303796287659733,
      "grad_norm": 2.6482012271881104,
      "learning_rate": 2.7511254304550527e-06,
      "loss": 0.2873628854751587,
      "memory(GiB)": 72.72,
      "step": 35705,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.330846003171346,
      "grad_norm": 3.477383852005005,
      "learning_rate": 2.7497480493634634e-06,
      "loss": 0.30335335731506347,
      "memory(GiB)": 72.72,
      "step": 35710,
      "token_acc": 0.9081632653061225,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.331312377576719,
      "grad_norm": 4.0380353927612305,
      "learning_rate": 2.7483708823764145e-06,
      "loss": 0.3174865484237671,
      "memory(GiB)": 72.72,
      "step": 35715,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.331778751982091,
      "grad_norm": 9.117661476135254,
      "learning_rate": 2.7469939296249397e-06,
      "loss": 0.31349592208862304,
      "memory(GiB)": 72.72,
      "step": 35720,
      "token_acc": 0.7254901960784313,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.332245126387464,
      "grad_norm": 3.7998085021972656,
      "learning_rate": 2.7456171912400528e-06,
      "loss": 0.2759865283966064,
      "memory(GiB)": 72.72,
      "step": 35725,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.3327115007928363,
      "grad_norm": 3.406202793121338,
      "learning_rate": 2.7442406673527445e-06,
      "loss": 0.30427045822143556,
      "memory(GiB)": 72.72,
      "step": 35730,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.333177875198209,
      "grad_norm": 2.939018964767456,
      "learning_rate": 2.7428643580939886e-06,
      "loss": 0.2862381458282471,
      "memory(GiB)": 72.72,
      "step": 35735,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.333644249603582,
      "grad_norm": 2.854285955429077,
      "learning_rate": 2.7414882635947347e-06,
      "loss": 0.28148179054260253,
      "memory(GiB)": 72.72,
      "step": 35740,
      "token_acc": 0.6724137931034483,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.3341106240089546,
      "grad_norm": 4.923396587371826,
      "learning_rate": 2.740112383985916e-06,
      "loss": 0.3061784267425537,
      "memory(GiB)": 72.72,
      "step": 35745,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.334576998414327,
      "grad_norm": 3.223052978515625,
      "learning_rate": 2.7387367193984393e-06,
      "loss": 0.3244930744171143,
      "memory(GiB)": 72.72,
      "step": 35750,
      "token_acc": 0.6326530612244898,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.3350433728196998,
      "grad_norm": 6.62038516998291,
      "learning_rate": 2.7373612699632004e-06,
      "loss": 0.3150409460067749,
      "memory(GiB)": 72.72,
      "step": 35755,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.335509747225072,
      "grad_norm": 3.4594955444335938,
      "learning_rate": 2.735986035811066e-06,
      "loss": 0.3037630319595337,
      "memory(GiB)": 72.72,
      "step": 35760,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.335976121630445,
      "grad_norm": 2.4179744720458984,
      "learning_rate": 2.7346110170728877e-06,
      "loss": 0.3136620044708252,
      "memory(GiB)": 72.72,
      "step": 35765,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.3364424960358177,
      "grad_norm": 3.0278265476226807,
      "learning_rate": 2.733236213879491e-06,
      "loss": 0.3409071445465088,
      "memory(GiB)": 72.72,
      "step": 35770,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.33690887044119,
      "grad_norm": 3.6021058559417725,
      "learning_rate": 2.7318616263616847e-06,
      "loss": 0.32079191207885743,
      "memory(GiB)": 72.72,
      "step": 35775,
      "token_acc": 0.9,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.337375244846563,
      "grad_norm": 3.812347650527954,
      "learning_rate": 2.730487254650258e-06,
      "loss": 0.3099242687225342,
      "memory(GiB)": 72.72,
      "step": 35780,
      "token_acc": 0.6836734693877551,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.3378416192519356,
      "grad_norm": 4.095867156982422,
      "learning_rate": 2.729113098875976e-06,
      "loss": 0.32137460708618165,
      "memory(GiB)": 72.72,
      "step": 35785,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.338307993657308,
      "grad_norm": 4.496189117431641,
      "learning_rate": 2.727739159169589e-06,
      "loss": 0.32695581912994387,
      "memory(GiB)": 72.72,
      "step": 35790,
      "token_acc": 0.5757575757575758,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.3387743680626807,
      "grad_norm": 2.2621281147003174,
      "learning_rate": 2.7263654356618207e-06,
      "loss": 0.3107325553894043,
      "memory(GiB)": 72.72,
      "step": 35795,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.3392407424680535,
      "grad_norm": 2.667356252670288,
      "learning_rate": 2.724991928483377e-06,
      "loss": 0.3359855890274048,
      "memory(GiB)": 72.72,
      "step": 35800,
      "token_acc": 0.45454545454545453,
      "train_speed(iter/s)": 0.251368
    },
    {
      "epoch": 3.339707116873426,
      "grad_norm": 2.4982850551605225,
      "learning_rate": 2.723618637764943e-06,
      "loss": 0.30735931396484373,
      "memory(GiB)": 72.72,
      "step": 35805,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.3401734912787986,
      "grad_norm": 3.1939847469329834,
      "learning_rate": 2.7222455636371837e-06,
      "loss": 0.2973355293273926,
      "memory(GiB)": 72.72,
      "step": 35810,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.3406398656841714,
      "grad_norm": 3.0198121070861816,
      "learning_rate": 2.7208727062307415e-06,
      "loss": 0.30017662048339844,
      "memory(GiB)": 72.72,
      "step": 35815,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.3411062400895437,
      "grad_norm": 4.293125152587891,
      "learning_rate": 2.719500065676241e-06,
      "loss": 0.2988304138183594,
      "memory(GiB)": 72.72,
      "step": 35820,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 3.3415726144949165,
      "grad_norm": 4.2621283531188965,
      "learning_rate": 2.7181276421042833e-06,
      "loss": 0.3359336853027344,
      "memory(GiB)": 72.72,
      "step": 35825,
      "token_acc": 0.9782608695652174,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 3.3420389889002893,
      "grad_norm": 2.8595457077026367,
      "learning_rate": 2.7167554356454516e-06,
      "loss": 0.3248962640762329,
      "memory(GiB)": 72.72,
      "step": 35830,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.3425053633056616,
      "grad_norm": 4.122780799865723,
      "learning_rate": 2.7153834464303056e-06,
      "loss": 0.29155840873718264,
      "memory(GiB)": 72.72,
      "step": 35835,
      "token_acc": 0.6909090909090909,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.3429717377110344,
      "grad_norm": 2.8022661209106445,
      "learning_rate": 2.7140116745893875e-06,
      "loss": 0.2758586645126343,
      "memory(GiB)": 72.72,
      "step": 35840,
      "token_acc": 0.6415094339622641,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.343438112116407,
      "grad_norm": 2.8204588890075684,
      "learning_rate": 2.712640120253216e-06,
      "loss": 0.322902250289917,
      "memory(GiB)": 72.72,
      "step": 35845,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.3439044865217795,
      "grad_norm": 15.134042739868164,
      "learning_rate": 2.711268783552291e-06,
      "loss": 0.27116737365722654,
      "memory(GiB)": 72.72,
      "step": 35850,
      "token_acc": 0.9724770642201835,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.3443708609271523,
      "grad_norm": 3.0874552726745605,
      "learning_rate": 2.709897664617088e-06,
      "loss": 0.2879956245422363,
      "memory(GiB)": 72.72,
      "step": 35855,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 3.344837235332525,
      "grad_norm": 3.139805316925049,
      "learning_rate": 2.7085267635780722e-06,
      "loss": 0.33548617362976074,
      "memory(GiB)": 72.72,
      "step": 35860,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 3.3453036097378974,
      "grad_norm": 3.3075714111328125,
      "learning_rate": 2.7071560805656736e-06,
      "loss": 0.28321874141693115,
      "memory(GiB)": 72.72,
      "step": 35865,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 3.34576998414327,
      "grad_norm": 2.455530881881714,
      "learning_rate": 2.70578561571031e-06,
      "loss": 0.29280853271484375,
      "memory(GiB)": 72.72,
      "step": 35870,
      "token_acc": 0.6067415730337079,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 3.346236358548643,
      "grad_norm": 3.0663063526153564,
      "learning_rate": 2.7044153691423787e-06,
      "loss": 0.32707078456878663,
      "memory(GiB)": 72.72,
      "step": 35875,
      "token_acc": 0.6190476190476191,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 3.3467027329540153,
      "grad_norm": 3.2841591835021973,
      "learning_rate": 2.7030453409922524e-06,
      "loss": 0.302688455581665,
      "memory(GiB)": 72.72,
      "step": 35880,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 3.347169107359388,
      "grad_norm": 2.8055105209350586,
      "learning_rate": 2.7016755313902863e-06,
      "loss": 0.29749245643615724,
      "memory(GiB)": 72.72,
      "step": 35885,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 3.347635481764761,
      "grad_norm": 3.612184762954712,
      "learning_rate": 2.7003059404668115e-06,
      "loss": 0.28476951122283933,
      "memory(GiB)": 72.72,
      "step": 35890,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.3481018561701332,
      "grad_norm": 3.815897226333618,
      "learning_rate": 2.6989365683521436e-06,
      "loss": 0.30554559230804446,
      "memory(GiB)": 72.72,
      "step": 35895,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 3.348568230575506,
      "grad_norm": 8.84707260131836,
      "learning_rate": 2.6975674151765728e-06,
      "loss": 0.2988322973251343,
      "memory(GiB)": 72.72,
      "step": 35900,
      "token_acc": 0.9479166666666666,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 3.349034604980879,
      "grad_norm": 2.5649256706237793,
      "learning_rate": 2.6961984810703694e-06,
      "loss": 0.3074824094772339,
      "memory(GiB)": 72.72,
      "step": 35905,
      "token_acc": 0.6181818181818182,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 3.349500979386251,
      "grad_norm": 4.053686618804932,
      "learning_rate": 2.6948297661637833e-06,
      "loss": 0.31739134788513185,
      "memory(GiB)": 72.72,
      "step": 35910,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 3.349967353791624,
      "grad_norm": 3.527358293533325,
      "learning_rate": 2.6934612705870443e-06,
      "loss": 0.3260634899139404,
      "memory(GiB)": 72.72,
      "step": 35915,
      "token_acc": 0.7010309278350515,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 3.3504337281969967,
      "grad_norm": 7.057307720184326,
      "learning_rate": 2.69209299447036e-06,
      "loss": 0.3017119407653809,
      "memory(GiB)": 72.72,
      "step": 35920,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 3.350900102602369,
      "grad_norm": 3.3724730014801025,
      "learning_rate": 2.690724937943917e-06,
      "loss": 0.30385942459106446,
      "memory(GiB)": 72.72,
      "step": 35925,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 3.351366477007742,
      "grad_norm": 4.58193826675415,
      "learning_rate": 2.6893571011378827e-06,
      "loss": 0.27458579540252687,
      "memory(GiB)": 72.72,
      "step": 35930,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 3.3518328514131146,
      "grad_norm": 3.6399009227752686,
      "learning_rate": 2.6879894841824017e-06,
      "loss": 0.2963383197784424,
      "memory(GiB)": 72.72,
      "step": 35935,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 3.352299225818487,
      "grad_norm": 3.0124425888061523,
      "learning_rate": 2.6866220872075993e-06,
      "loss": 0.32398285865783694,
      "memory(GiB)": 72.72,
      "step": 35940,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 3.3527656002238597,
      "grad_norm": 3.201483964920044,
      "learning_rate": 2.6852549103435786e-06,
      "loss": 0.3125463485717773,
      "memory(GiB)": 72.72,
      "step": 35945,
      "token_acc": 0.6836734693877551,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 3.3532319746292325,
      "grad_norm": 2.521815299987793,
      "learning_rate": 2.6838879537204228e-06,
      "loss": 0.2721235275268555,
      "memory(GiB)": 72.72,
      "step": 35950,
      "token_acc": 0.7349397590361446,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.353698349034605,
      "grad_norm": 3.5085363388061523,
      "learning_rate": 2.682521217468191e-06,
      "loss": 0.30250604152679444,
      "memory(GiB)": 72.72,
      "step": 35955,
      "token_acc": 0.5901639344262295,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.3541647234399776,
      "grad_norm": 3.4913763999938965,
      "learning_rate": 2.6811547017169305e-06,
      "loss": 0.3168672800064087,
      "memory(GiB)": 72.72,
      "step": 35960,
      "token_acc": 0.6486486486486487,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.3546310978453504,
      "grad_norm": 3.0668914318084717,
      "learning_rate": 2.679788406596654e-06,
      "loss": 0.28995909690856936,
      "memory(GiB)": 72.72,
      "step": 35965,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.3550974722507227,
      "grad_norm": 5.43698787689209,
      "learning_rate": 2.678422332237364e-06,
      "loss": 0.3117538928985596,
      "memory(GiB)": 72.72,
      "step": 35970,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.3555638466560955,
      "grad_norm": 9.347528457641602,
      "learning_rate": 2.6770564787690357e-06,
      "loss": 0.3068534374237061,
      "memory(GiB)": 72.72,
      "step": 35975,
      "token_acc": 0.6203703703703703,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.3560302210614683,
      "grad_norm": 10.612049102783203,
      "learning_rate": 2.675690846321629e-06,
      "loss": 0.31263322830200196,
      "memory(GiB)": 72.72,
      "step": 35980,
      "token_acc": 0.9494949494949495,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 3.3564965954668406,
      "grad_norm": 8.576358795166016,
      "learning_rate": 2.674325435025077e-06,
      "loss": 0.31525435447692873,
      "memory(GiB)": 72.72,
      "step": 35985,
      "token_acc": 0.782608695652174,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 3.3569629698722134,
      "grad_norm": 3.9797182083129883,
      "learning_rate": 2.672960245009294e-06,
      "loss": 0.329712963104248,
      "memory(GiB)": 72.72,
      "step": 35990,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 3.357429344277586,
      "grad_norm": 2.2348203659057617,
      "learning_rate": 2.6715952764041776e-06,
      "loss": 0.2726436614990234,
      "memory(GiB)": 72.72,
      "step": 35995,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 3.3578957186829586,
      "grad_norm": 2.649976968765259,
      "learning_rate": 2.670230529339597e-06,
      "loss": 0.2966854810714722,
      "memory(GiB)": 72.72,
      "step": 36000,
      "token_acc": 0.9675675675675676,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 3.3583620930883313,
      "grad_norm": 2.8210184574127197,
      "learning_rate": 2.6688660039454052e-06,
      "loss": 0.3118156909942627,
      "memory(GiB)": 72.72,
      "step": 36005,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.358828467493704,
      "grad_norm": 2.056748390197754,
      "learning_rate": 2.6675017003514307e-06,
      "loss": 0.2967780828475952,
      "memory(GiB)": 72.72,
      "step": 36010,
      "token_acc": 0.717391304347826,
      "train_speed(iter/s)": 0.251342
    },
    {
      "epoch": 3.3592948418990765,
      "grad_norm": 4.479328155517578,
      "learning_rate": 2.6661376186874867e-06,
      "loss": 0.2874001026153564,
      "memory(GiB)": 72.72,
      "step": 36015,
      "token_acc": 0.7953216374269005,
      "train_speed(iter/s)": 0.251341
    },
    {
      "epoch": 3.3597612163044492,
      "grad_norm": 2.881242275238037,
      "learning_rate": 2.6647737590833566e-06,
      "loss": 0.3138885498046875,
      "memory(GiB)": 72.72,
      "step": 36020,
      "token_acc": 0.825,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 3.360227590709822,
      "grad_norm": 2.137338399887085,
      "learning_rate": 2.663410121668808e-06,
      "loss": 0.29669549465179446,
      "memory(GiB)": 72.72,
      "step": 36025,
      "token_acc": 0.779874213836478,
      "train_speed(iter/s)": 0.251338
    },
    {
      "epoch": 3.3606939651151944,
      "grad_norm": 3.144624710083008,
      "learning_rate": 2.66204670657359e-06,
      "loss": 0.33871636390686033,
      "memory(GiB)": 72.72,
      "step": 36030,
      "token_acc": 0.6585365853658537,
      "train_speed(iter/s)": 0.251339
    },
    {
      "epoch": 3.361160339520567,
      "grad_norm": 2.7241837978363037,
      "learning_rate": 2.6606835139274253e-06,
      "loss": 0.2827184200286865,
      "memory(GiB)": 72.72,
      "step": 36035,
      "train_speed(iter/s)": 0.251341
    },
    {
      "epoch": 3.36162671392594,
      "grad_norm": 2.242631196975708,
      "learning_rate": 2.6593205438600177e-06,
      "loss": 0.2613210678100586,
      "memory(GiB)": 72.72,
      "step": 36040,
      "token_acc": 0.6698113207547169,
      "train_speed(iter/s)": 0.251343
    },
    {
      "epoch": 3.3620930883313123,
      "grad_norm": 2.4187660217285156,
      "learning_rate": 2.65795779650105e-06,
      "loss": 0.24844970703125,
      "memory(GiB)": 72.72,
      "step": 36045,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.362559462736685,
      "grad_norm": 3.607649564743042,
      "learning_rate": 2.656595271980183e-06,
      "loss": 0.2880412578582764,
      "memory(GiB)": 72.72,
      "step": 36050,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.363025837142058,
      "grad_norm": 2.3178815841674805,
      "learning_rate": 2.6552329704270553e-06,
      "loss": 0.3279112815856934,
      "memory(GiB)": 72.72,
      "step": 36055,
      "token_acc": 0.6222222222222222,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.36349221154743,
      "grad_norm": 2.913363456726074,
      "learning_rate": 2.6538708919712907e-06,
      "loss": 0.3116454124450684,
      "memory(GiB)": 72.72,
      "step": 36060,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.363958585952803,
      "grad_norm": 3.3186495304107666,
      "learning_rate": 2.652509036742481e-06,
      "loss": 0.34722561836242677,
      "memory(GiB)": 72.72,
      "step": 36065,
      "token_acc": 0.875,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3644249603581757,
      "grad_norm": 2.838578701019287,
      "learning_rate": 2.6511474048702056e-06,
      "loss": 0.2771038770675659,
      "memory(GiB)": 72.72,
      "step": 36070,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.364891334763548,
      "grad_norm": 3.250432014465332,
      "learning_rate": 2.6497859964840184e-06,
      "loss": 0.28394346237182616,
      "memory(GiB)": 72.72,
      "step": 36075,
      "token_acc": 0.8,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.365357709168921,
      "grad_norm": 3.8934683799743652,
      "learning_rate": 2.6484248117134536e-06,
      "loss": 0.2958993434906006,
      "memory(GiB)": 72.72,
      "step": 36080,
      "token_acc": 0.74,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.3658240835742936,
      "grad_norm": 3.2455832958221436,
      "learning_rate": 2.647063850688024e-06,
      "loss": 0.3069002628326416,
      "memory(GiB)": 72.72,
      "step": 36085,
      "token_acc": 0.8037974683544303,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.366290457979666,
      "grad_norm": 3.746877908706665,
      "learning_rate": 2.6457031135372185e-06,
      "loss": 0.2818333625793457,
      "memory(GiB)": 72.72,
      "step": 36090,
      "token_acc": 0.9206349206349206,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3667568323850388,
      "grad_norm": 3.0436153411865234,
      "learning_rate": 2.6443426003905108e-06,
      "loss": 0.284298300743103,
      "memory(GiB)": 72.72,
      "step": 36095,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.3672232067904115,
      "grad_norm": 2.5813324451446533,
      "learning_rate": 2.6429823113773483e-06,
      "loss": 0.3160225868225098,
      "memory(GiB)": 72.72,
      "step": 36100,
      "token_acc": 0.7727272727272727,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.367689581195784,
      "grad_norm": 2.5220553874969482,
      "learning_rate": 2.641622246627158e-06,
      "loss": 0.3338973045349121,
      "memory(GiB)": 72.72,
      "step": 36105,
      "token_acc": 0.6933333333333334,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.3681559556011567,
      "grad_norm": 2.7896013259887695,
      "learning_rate": 2.6402624062693456e-06,
      "loss": 0.32779674530029296,
      "memory(GiB)": 72.72,
      "step": 36110,
      "token_acc": 0.8666666666666667,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.368622330006529,
      "grad_norm": 4.508407115936279,
      "learning_rate": 2.6389027904332976e-06,
      "loss": 0.28360896110534667,
      "memory(GiB)": 72.72,
      "step": 36115,
      "token_acc": 0.5888888888888889,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.369088704411902,
      "grad_norm": 3.974485158920288,
      "learning_rate": 2.637543399248374e-06,
      "loss": 0.30052623748779295,
      "memory(GiB)": 72.72,
      "step": 36120,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.3695550788172746,
      "grad_norm": 2.5499024391174316,
      "learning_rate": 2.6361842328439157e-06,
      "loss": 0.3034416675567627,
      "memory(GiB)": 72.72,
      "step": 36125,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3700214532226473,
      "grad_norm": 3.1274406909942627,
      "learning_rate": 2.6348252913492487e-06,
      "loss": 0.2924958229064941,
      "memory(GiB)": 72.72,
      "step": 36130,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.3704878276280197,
      "grad_norm": 40.577003479003906,
      "learning_rate": 2.6334665748936684e-06,
      "loss": 0.30187292098999025,
      "memory(GiB)": 72.72,
      "step": 36135,
      "token_acc": 0.987012987012987,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.3709542020333925,
      "grad_norm": 4.469304084777832,
      "learning_rate": 2.632108083606453e-06,
      "loss": 0.29819293022155763,
      "memory(GiB)": 72.72,
      "step": 36140,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.371420576438765,
      "grad_norm": 3.2622475624084473,
      "learning_rate": 2.6307498176168596e-06,
      "loss": 0.27901930809020997,
      "memory(GiB)": 72.72,
      "step": 36145,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.3718869508441376,
      "grad_norm": 2.670806646347046,
      "learning_rate": 2.6293917770541223e-06,
      "loss": 0.290404224395752,
      "memory(GiB)": 72.72,
      "step": 36150,
      "token_acc": 0.6395348837209303,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.3723533252495104,
      "grad_norm": 2.6801164150238037,
      "learning_rate": 2.6280339620474536e-06,
      "loss": 0.2948322772979736,
      "memory(GiB)": 72.72,
      "step": 36155,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.372819699654883,
      "grad_norm": 4.318754196166992,
      "learning_rate": 2.626676372726048e-06,
      "loss": 0.30783882141113283,
      "memory(GiB)": 72.72,
      "step": 36160,
      "token_acc": 0.869281045751634,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3732860740602555,
      "grad_norm": 2.753028392791748,
      "learning_rate": 2.6253190092190735e-06,
      "loss": 0.31434264183044436,
      "memory(GiB)": 72.72,
      "step": 36165,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.3737524484656283,
      "grad_norm": 2.323139190673828,
      "learning_rate": 2.62396187165568e-06,
      "loss": 0.2818721294403076,
      "memory(GiB)": 72.72,
      "step": 36170,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.3742188228710006,
      "grad_norm": 3.5610036849975586,
      "learning_rate": 2.6226049601649943e-06,
      "loss": 0.2940648555755615,
      "memory(GiB)": 72.72,
      "step": 36175,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.3746851972763734,
      "grad_norm": 2.5899124145507812,
      "learning_rate": 2.621248274876124e-06,
      "loss": 0.3114147186279297,
      "memory(GiB)": 72.72,
      "step": 36180,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.375151571681746,
      "grad_norm": 3.0341074466705322,
      "learning_rate": 2.619891815918151e-06,
      "loss": 0.29440765380859374,
      "memory(GiB)": 72.72,
      "step": 36185,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.375617946087119,
      "grad_norm": 2.5726265907287598,
      "learning_rate": 2.6185355834201402e-06,
      "loss": 0.2987824440002441,
      "memory(GiB)": 72.72,
      "step": 36190,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3760843204924913,
      "grad_norm": 2.489598035812378,
      "learning_rate": 2.6171795775111306e-06,
      "loss": 0.27686586380004885,
      "memory(GiB)": 72.72,
      "step": 36195,
      "token_acc": 0.6122448979591837,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.376550694897864,
      "grad_norm": 4.9285759925842285,
      "learning_rate": 2.6158237983201464e-06,
      "loss": 0.3349581718444824,
      "memory(GiB)": 72.72,
      "step": 36200,
      "token_acc": 0.7647058823529411,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.3770170693032364,
      "grad_norm": 2.3066186904907227,
      "learning_rate": 2.6144682459761818e-06,
      "loss": 0.2960174083709717,
      "memory(GiB)": 72.72,
      "step": 36205,
      "token_acc": 0.711864406779661,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.377483443708609,
      "grad_norm": 2.994415760040283,
      "learning_rate": 2.6131129206082153e-06,
      "loss": 0.28000218868255616,
      "memory(GiB)": 72.72,
      "step": 36210,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.377949818113982,
      "grad_norm": 2.7414281368255615,
      "learning_rate": 2.6117578223452034e-06,
      "loss": 0.28070549964904784,
      "memory(GiB)": 72.72,
      "step": 36215,
      "token_acc": 0.6792452830188679,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3784161925193548,
      "grad_norm": 3.5583786964416504,
      "learning_rate": 2.6104029513160757e-06,
      "loss": 0.2861395597457886,
      "memory(GiB)": 72.72,
      "step": 36220,
      "token_acc": 0.3793103448275862,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.378882566924727,
      "grad_norm": 2.5437204837799072,
      "learning_rate": 2.609048307649744e-06,
      "loss": 0.28694682121276854,
      "memory(GiB)": 72.72,
      "step": 36225,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.3793489413301,
      "grad_norm": 2.74704647064209,
      "learning_rate": 2.607693891475102e-06,
      "loss": 0.30812768936157225,
      "memory(GiB)": 72.72,
      "step": 36230,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3798153157354722,
      "grad_norm": 3.3479528427124023,
      "learning_rate": 2.6063397029210168e-06,
      "loss": 0.2958528995513916,
      "memory(GiB)": 72.72,
      "step": 36235,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.380281690140845,
      "grad_norm": 2.690459728240967,
      "learning_rate": 2.604985742116335e-06,
      "loss": 0.31082472801208494,
      "memory(GiB)": 72.72,
      "step": 36240,
      "token_acc": 0.5483870967741935,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.380748064546218,
      "grad_norm": 3.651890754699707,
      "learning_rate": 2.6036320091898814e-06,
      "loss": 0.30055699348449705,
      "memory(GiB)": 72.72,
      "step": 36245,
      "token_acc": 0.7868852459016393,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3812144389515906,
      "grad_norm": 4.217136383056641,
      "learning_rate": 2.60227850427046e-06,
      "loss": 0.2904732465744019,
      "memory(GiB)": 72.72,
      "step": 36250,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.381680813356963,
      "grad_norm": 4.322535991668701,
      "learning_rate": 2.6009252274868534e-06,
      "loss": 0.32535572052001954,
      "memory(GiB)": 72.72,
      "step": 36255,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.3821471877623357,
      "grad_norm": 2.644007444381714,
      "learning_rate": 2.5995721789678196e-06,
      "loss": 0.34439303874969485,
      "memory(GiB)": 72.72,
      "step": 36260,
      "token_acc": 0.6808510638297872,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.382613562167708,
      "grad_norm": 3.628227472305298,
      "learning_rate": 2.598219358842099e-06,
      "loss": 0.3110802412033081,
      "memory(GiB)": 72.72,
      "step": 36265,
      "token_acc": 0.9893617021276596,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.383079936573081,
      "grad_norm": 2.418281078338623,
      "learning_rate": 2.5968667672384075e-06,
      "loss": 0.2706638813018799,
      "memory(GiB)": 72.72,
      "step": 36270,
      "token_acc": 0.6136363636363636,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.3835463109784536,
      "grad_norm": 2.5409584045410156,
      "learning_rate": 2.59551440428544e-06,
      "loss": 0.3112425088882446,
      "memory(GiB)": 72.72,
      "step": 36275,
      "token_acc": 0.4782608695652174,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.3840126853838264,
      "grad_norm": 3.445255994796753,
      "learning_rate": 2.59416227011187e-06,
      "loss": 0.2931098937988281,
      "memory(GiB)": 72.72,
      "step": 36280,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.3844790597891987,
      "grad_norm": 6.6238484382629395,
      "learning_rate": 2.592810364846349e-06,
      "loss": 0.3013350486755371,
      "memory(GiB)": 72.72,
      "step": 36285,
      "token_acc": 0.9534883720930233,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.3849454341945715,
      "grad_norm": 2.517333984375,
      "learning_rate": 2.5914586886175054e-06,
      "loss": 0.3117229461669922,
      "memory(GiB)": 72.72,
      "step": 36290,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.385411808599944,
      "grad_norm": 2.9591424465179443,
      "learning_rate": 2.590107241553946e-06,
      "loss": 0.3086503505706787,
      "memory(GiB)": 72.72,
      "step": 36295,
      "token_acc": 0.95,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.3858781830053166,
      "grad_norm": 2.3687541484832764,
      "learning_rate": 2.5887560237842605e-06,
      "loss": 0.2734653472900391,
      "memory(GiB)": 72.72,
      "step": 36300,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.3863445574106894,
      "grad_norm": 3.4235408306121826,
      "learning_rate": 2.5874050354370116e-06,
      "loss": 0.33488011360168457,
      "memory(GiB)": 72.72,
      "step": 36305,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.3868109318160617,
      "grad_norm": 2.7182488441467285,
      "learning_rate": 2.5860542766407413e-06,
      "loss": 0.3029660701751709,
      "memory(GiB)": 72.72,
      "step": 36310,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.3872773062214345,
      "grad_norm": 3.5847620964050293,
      "learning_rate": 2.5847037475239726e-06,
      "loss": 0.27227110862731935,
      "memory(GiB)": 72.72,
      "step": 36315,
      "token_acc": 0.6521739130434783,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.3877436806268073,
      "grad_norm": 3.422956705093384,
      "learning_rate": 2.5833534482152e-06,
      "loss": 0.2740634918212891,
      "memory(GiB)": 72.72,
      "step": 36320,
      "token_acc": 0.9739130434782609,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.3882100550321796,
      "grad_norm": 3.1152265071868896,
      "learning_rate": 2.582003378842901e-06,
      "loss": 0.2896623373031616,
      "memory(GiB)": 72.72,
      "step": 36325,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.3886764294375524,
      "grad_norm": 5.648288726806641,
      "learning_rate": 2.580653539535531e-06,
      "loss": 0.3117231369018555,
      "memory(GiB)": 72.72,
      "step": 36330,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.389142803842925,
      "grad_norm": 6.517984390258789,
      "learning_rate": 2.579303930421525e-06,
      "loss": 0.3035088539123535,
      "memory(GiB)": 72.72,
      "step": 36335,
      "token_acc": 0.6438356164383562,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.3896091782482975,
      "grad_norm": 3.013357400894165,
      "learning_rate": 2.577954551629293e-06,
      "loss": 0.2778473377227783,
      "memory(GiB)": 72.72,
      "step": 36340,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.3900755526536703,
      "grad_norm": 3.417891502380371,
      "learning_rate": 2.5766054032872245e-06,
      "loss": 0.32430880069732665,
      "memory(GiB)": 72.72,
      "step": 36345,
      "token_acc": 0.6288659793814433,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.390541927059043,
      "grad_norm": 3.9196391105651855,
      "learning_rate": 2.5752564855236863e-06,
      "loss": 0.31523706912994387,
      "memory(GiB)": 72.72,
      "step": 36350,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.3910083014644155,
      "grad_norm": 2.811718463897705,
      "learning_rate": 2.573907798467023e-06,
      "loss": 0.2970069646835327,
      "memory(GiB)": 72.72,
      "step": 36355,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.3914746758697882,
      "grad_norm": 2.912107467651367,
      "learning_rate": 2.5725593422455598e-06,
      "loss": 0.3240882635116577,
      "memory(GiB)": 72.72,
      "step": 36360,
      "token_acc": 0.8125,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.391941050275161,
      "grad_norm": 2.529865264892578,
      "learning_rate": 2.571211116987597e-06,
      "loss": 0.3091727256774902,
      "memory(GiB)": 72.72,
      "step": 36365,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.3924074246805334,
      "grad_norm": 3.6410443782806396,
      "learning_rate": 2.5698631228214144e-06,
      "loss": 0.30501422882080076,
      "memory(GiB)": 72.72,
      "step": 36370,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.392873799085906,
      "grad_norm": 2.835016965866089,
      "learning_rate": 2.568515359875269e-06,
      "loss": 0.299526572227478,
      "memory(GiB)": 72.72,
      "step": 36375,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.393340173491279,
      "grad_norm": 3.1491193771362305,
      "learning_rate": 2.5671678282773977e-06,
      "loss": 0.30255923271179197,
      "memory(GiB)": 72.72,
      "step": 36380,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.3938065478966513,
      "grad_norm": 2.5718541145324707,
      "learning_rate": 2.565820528156012e-06,
      "loss": 0.33337552547454835,
      "memory(GiB)": 72.72,
      "step": 36385,
      "token_acc": 0.5510204081632653,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.394272922302024,
      "grad_norm": 2.9947290420532227,
      "learning_rate": 2.564473459639305e-06,
      "loss": 0.3182066917419434,
      "memory(GiB)": 72.72,
      "step": 36390,
      "token_acc": 0.46511627906976744,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.394739296707397,
      "grad_norm": 2.4305734634399414,
      "learning_rate": 2.5631266228554434e-06,
      "loss": 0.2919013977050781,
      "memory(GiB)": 72.72,
      "step": 36395,
      "token_acc": 0.6065573770491803,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.395205671112769,
      "grad_norm": 9.95930004119873,
      "learning_rate": 2.561780017932579e-06,
      "loss": 0.2934441566467285,
      "memory(GiB)": 72.72,
      "step": 36400,
      "token_acc": 0.5645161290322581,
      "train_speed(iter/s)": 0.251349
    },
    {
      "epoch": 3.395672045518142,
      "grad_norm": 2.4800920486450195,
      "learning_rate": 2.560433644998834e-06,
      "loss": 0.2803357601165771,
      "memory(GiB)": 72.72,
      "step": 36405,
      "token_acc": 0.6842105263157895,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.3961384199235147,
      "grad_norm": 3.4122231006622314,
      "learning_rate": 2.5590875041823147e-06,
      "loss": 0.3001640796661377,
      "memory(GiB)": 72.72,
      "step": 36410,
      "token_acc": 0.49056603773584906,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.396604794328887,
      "grad_norm": 2.9903664588928223,
      "learning_rate": 2.5577415956110986e-06,
      "loss": 0.3495539665222168,
      "memory(GiB)": 72.72,
      "step": 36415,
      "token_acc": 0.8435374149659864,
      "train_speed(iter/s)": 0.251345
    },
    {
      "epoch": 3.39707116873426,
      "grad_norm": 3.71587872505188,
      "learning_rate": 2.5563959194132453e-06,
      "loss": 0.32565176486968994,
      "memory(GiB)": 72.72,
      "step": 36420,
      "train_speed(iter/s)": 0.251346
    },
    {
      "epoch": 3.3975375431396326,
      "grad_norm": 2.3076014518737793,
      "learning_rate": 2.5550504757167927e-06,
      "loss": 0.3213331699371338,
      "memory(GiB)": 72.72,
      "step": 36425,
      "token_acc": 0.5396825396825397,
      "train_speed(iter/s)": 0.251344
    },
    {
      "epoch": 3.398003917545005,
      "grad_norm": 3.0257842540740967,
      "learning_rate": 2.553705264649754e-06,
      "loss": 0.2936915397644043,
      "memory(GiB)": 72.72,
      "step": 36430,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.3984702919503778,
      "grad_norm": 12.255027770996094,
      "learning_rate": 2.552360286340125e-06,
      "loss": 0.2952871322631836,
      "memory(GiB)": 72.72,
      "step": 36435,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.3989366663557505,
      "grad_norm": 3.9843413829803467,
      "learning_rate": 2.551015540915874e-06,
      "loss": 0.29168655872344973,
      "memory(GiB)": 72.72,
      "step": 36440,
      "token_acc": 0.9382716049382716,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.399403040761123,
      "grad_norm": 2.4410555362701416,
      "learning_rate": 2.549671028504951e-06,
      "loss": 0.32310054302215574,
      "memory(GiB)": 72.72,
      "step": 36445,
      "token_acc": 0.54,
      "train_speed(iter/s)": 0.251347
    },
    {
      "epoch": 3.3998694151664957,
      "grad_norm": 2.8808844089508057,
      "learning_rate": 2.5483267492352805e-06,
      "loss": 0.29537162780761717,
      "memory(GiB)": 72.72,
      "step": 36450,
      "token_acc": 0.5707070707070707,
      "train_speed(iter/s)": 0.251348
    },
    {
      "epoch": 3.4003357895718684,
      "grad_norm": 2.769639253616333,
      "learning_rate": 2.546982703234768e-06,
      "loss": 0.3008249759674072,
      "memory(GiB)": 72.72,
      "step": 36455,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25135
    },
    {
      "epoch": 3.4008021639772408,
      "grad_norm": 2.967332363128662,
      "learning_rate": 2.545638890631294e-06,
      "loss": 0.29282498359680176,
      "memory(GiB)": 72.72,
      "step": 36460,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.4012685383826136,
      "grad_norm": 2.7072229385375977,
      "learning_rate": 2.544295311552719e-06,
      "loss": 0.28845150470733644,
      "memory(GiB)": 72.72,
      "step": 36465,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.4017349127879863,
      "grad_norm": 2.697946071624756,
      "learning_rate": 2.5429519661268797e-06,
      "loss": 0.28513565063476565,
      "memory(GiB)": 72.72,
      "step": 36470,
      "token_acc": 0.6129032258064516,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.4022012871933587,
      "grad_norm": 2.756265163421631,
      "learning_rate": 2.541608854481592e-06,
      "loss": 0.2833693265914917,
      "memory(GiB)": 72.72,
      "step": 36475,
      "token_acc": 0.6296296296296297,
      "train_speed(iter/s)": 0.251351
    },
    {
      "epoch": 3.4026676615987315,
      "grad_norm": 10.061395645141602,
      "learning_rate": 2.5402659767446486e-06,
      "loss": 0.280335521697998,
      "memory(GiB)": 72.72,
      "step": 36480,
      "token_acc": 0.6388888888888888,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.4031340360041042,
      "grad_norm": 2.8525829315185547,
      "learning_rate": 2.53892333304382e-06,
      "loss": 0.2760340690612793,
      "memory(GiB)": 72.72,
      "step": 36485,
      "token_acc": 0.6451612903225806,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.4036004104094766,
      "grad_norm": 2.762814521789551,
      "learning_rate": 2.5375809235068548e-06,
      "loss": 0.326000714302063,
      "memory(GiB)": 72.72,
      "step": 36490,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.4040667848148494,
      "grad_norm": 2.389075994491577,
      "learning_rate": 2.5362387482614794e-06,
      "loss": 0.2749794960021973,
      "memory(GiB)": 72.72,
      "step": 36495,
      "token_acc": 0.8571428571428571,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.404533159220222,
      "grad_norm": 3.370382070541382,
      "learning_rate": 2.534896807435394e-06,
      "loss": 0.32644755840301515,
      "memory(GiB)": 72.72,
      "step": 36500,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.4049995336255945,
      "grad_norm": 2.56209135055542,
      "learning_rate": 2.5335551011562863e-06,
      "loss": 0.2927284002304077,
      "memory(GiB)": 72.72,
      "step": 36505,
      "token_acc": 0.38596491228070173,
      "train_speed(iter/s)": 0.25136
    },
    {
      "epoch": 3.4054659080309673,
      "grad_norm": 4.62934684753418,
      "learning_rate": 2.532213629551815e-06,
      "loss": 0.31879453659057616,
      "memory(GiB)": 72.72,
      "step": 36510,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.40593228243634,
      "grad_norm": 4.128988742828369,
      "learning_rate": 2.5308723927496127e-06,
      "loss": 0.3169542789459229,
      "memory(GiB)": 72.72,
      "step": 36515,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.4063986568417124,
      "grad_norm": 5.300393581390381,
      "learning_rate": 2.5295313908772956e-06,
      "loss": 0.2615460157394409,
      "memory(GiB)": 72.72,
      "step": 36520,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.406865031247085,
      "grad_norm": 4.796998023986816,
      "learning_rate": 2.528190624062455e-06,
      "loss": 0.3082475423812866,
      "memory(GiB)": 72.72,
      "step": 36525,
      "token_acc": 0.5955056179775281,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.407331405652458,
      "grad_norm": 4.72307014465332,
      "learning_rate": 2.526850092432662e-06,
      "loss": 0.29526329040527344,
      "memory(GiB)": 72.72,
      "step": 36530,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.4077977800578303,
      "grad_norm": 2.5460588932037354,
      "learning_rate": 2.525509796115465e-06,
      "loss": 0.29825098514556886,
      "memory(GiB)": 72.72,
      "step": 36535,
      "train_speed(iter/s)": 0.251357
    },
    {
      "epoch": 3.408264154463203,
      "grad_norm": 2.882352352142334,
      "learning_rate": 2.5241697352383876e-06,
      "loss": 0.2822332143783569,
      "memory(GiB)": 72.72,
      "step": 36540,
      "token_acc": 0.5692307692307692,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.408730528868576,
      "grad_norm": 2.484551429748535,
      "learning_rate": 2.522829909928934e-06,
      "loss": 0.30087718963623045,
      "memory(GiB)": 72.72,
      "step": 36545,
      "token_acc": 0.6186440677966102,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.409196903273948,
      "grad_norm": 2.72186017036438,
      "learning_rate": 2.5214903203145825e-06,
      "loss": 0.2821675777435303,
      "memory(GiB)": 72.72,
      "step": 36550,
      "token_acc": 0.6285714285714286,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.409663277679321,
      "grad_norm": 2.495924949645996,
      "learning_rate": 2.520150966522792e-06,
      "loss": 0.2818115711212158,
      "memory(GiB)": 72.72,
      "step": 36555,
      "token_acc": 0.6444444444444445,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.4101296520846938,
      "grad_norm": 3.3597686290740967,
      "learning_rate": 2.5188118486809977e-06,
      "loss": 0.2993203639984131,
      "memory(GiB)": 72.72,
      "step": 36560,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.410596026490066,
      "grad_norm": 4.473572731018066,
      "learning_rate": 2.5174729669166125e-06,
      "loss": 0.3154796838760376,
      "memory(GiB)": 72.72,
      "step": 36565,
      "token_acc": 0.5978260869565217,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.411062400895439,
      "grad_norm": 3.5240461826324463,
      "learning_rate": 2.5161343213570267e-06,
      "loss": 0.28711614608764646,
      "memory(GiB)": 72.72,
      "step": 36570,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.4115287753008117,
      "grad_norm": 9.508349418640137,
      "learning_rate": 2.5147959121296084e-06,
      "loss": 0.292190408706665,
      "memory(GiB)": 72.72,
      "step": 36575,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.251356
    },
    {
      "epoch": 3.411995149706184,
      "grad_norm": 3.6897590160369873,
      "learning_rate": 2.5134577393617037e-06,
      "loss": 0.3166550874710083,
      "memory(GiB)": 72.72,
      "step": 36580,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.412461524111557,
      "grad_norm": 5.067033767700195,
      "learning_rate": 2.512119803180635e-06,
      "loss": 0.31665830612182616,
      "memory(GiB)": 72.72,
      "step": 36585,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.4129278985169296,
      "grad_norm": 2.5389795303344727,
      "learning_rate": 2.5107821037137025e-06,
      "loss": 0.27660226821899414,
      "memory(GiB)": 72.72,
      "step": 36590,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.413394272922302,
      "grad_norm": 2.115748882293701,
      "learning_rate": 2.5094446410881856e-06,
      "loss": 0.2851667881011963,
      "memory(GiB)": 72.72,
      "step": 36595,
      "train_speed(iter/s)": 0.251352
    },
    {
      "epoch": 3.4138606473276747,
      "grad_norm": 2.5828747749328613,
      "learning_rate": 2.5081074154313355e-06,
      "loss": 0.29188215732574463,
      "memory(GiB)": 72.72,
      "step": 36600,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.4143270217330475,
      "grad_norm": 2.365481376647949,
      "learning_rate": 2.506770426870391e-06,
      "loss": 0.29118914604187013,
      "memory(GiB)": 72.72,
      "step": 36605,
      "token_acc": 0.7428571428571429,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.41479339613842,
      "grad_norm": 2.8015944957733154,
      "learning_rate": 2.505433675532562e-06,
      "loss": 0.2828912973403931,
      "memory(GiB)": 72.72,
      "step": 36610,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.4152597705437926,
      "grad_norm": 2.9427788257598877,
      "learning_rate": 2.5040971615450315e-06,
      "loss": 0.30522899627685546,
      "memory(GiB)": 72.72,
      "step": 36615,
      "train_speed(iter/s)": 0.251354
    },
    {
      "epoch": 3.4157261449491654,
      "grad_norm": 2.1590843200683594,
      "learning_rate": 2.502760885034968e-06,
      "loss": 0.2774740934371948,
      "memory(GiB)": 72.72,
      "step": 36620,
      "token_acc": 0.967391304347826,
      "train_speed(iter/s)": 0.251353
    },
    {
      "epoch": 3.4161925193545377,
      "grad_norm": 3.0432255268096924,
      "learning_rate": 2.5014248461295126e-06,
      "loss": 0.27946603298187256,
      "memory(GiB)": 72.72,
      "step": 36625,
      "token_acc": 0.4626865671641791,
      "train_speed(iter/s)": 0.251355
    },
    {
      "epoch": 3.4166588937599105,
      "grad_norm": 3.085479259490967,
      "learning_rate": 2.500089044955786e-06,
      "loss": 0.3542016506195068,
      "memory(GiB)": 72.72,
      "step": 36630,
      "token_acc": 0.5694444444444444,
      "train_speed(iter/s)": 0.251358
    },
    {
      "epoch": 3.4171252681652833,
      "grad_norm": 3.5781302452087402,
      "learning_rate": 2.4987534816408844e-06,
      "loss": 0.34084358215332033,
      "memory(GiB)": 72.72,
      "step": 36635,
      "token_acc": 0.5645161290322581,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.4175916425706556,
      "grad_norm": 2.942736864089966,
      "learning_rate": 2.4974181563118854e-06,
      "loss": 0.29300565719604493,
      "memory(GiB)": 72.72,
      "step": 36640,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251359
    },
    {
      "epoch": 3.4180580169760284,
      "grad_norm": 2.8355727195739746,
      "learning_rate": 2.4960830690958392e-06,
      "loss": 0.2937087774276733,
      "memory(GiB)": 72.72,
      "step": 36645,
      "token_acc": 0.46153846153846156,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.4185243913814007,
      "grad_norm": 2.6867785453796387,
      "learning_rate": 2.494748220119776e-06,
      "loss": 0.2956933736801147,
      "memory(GiB)": 72.72,
      "step": 36650,
      "token_acc": 0.8618421052631579,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.4189907657867735,
      "grad_norm": 7.623778820037842,
      "learning_rate": 2.4934136095107014e-06,
      "loss": 0.2842928171157837,
      "memory(GiB)": 72.72,
      "step": 36655,
      "token_acc": 0.5901639344262295,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.4194571401921463,
      "grad_norm": 2.3754327297210693,
      "learning_rate": 2.4920792373956006e-06,
      "loss": 0.3018182754516602,
      "memory(GiB)": 72.72,
      "step": 36660,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.419923514597519,
      "grad_norm": 2.8124852180480957,
      "learning_rate": 2.4907451039014357e-06,
      "loss": 0.3040712594985962,
      "memory(GiB)": 72.72,
      "step": 36665,
      "token_acc": 0.9514563106796117,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.4203898890028914,
      "grad_norm": 3.8418614864349365,
      "learning_rate": 2.489411209155141e-06,
      "loss": 0.32616660594940183,
      "memory(GiB)": 72.72,
      "step": 36670,
      "token_acc": 0.5660377358490566,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.420856263408264,
      "grad_norm": 3.215578079223633,
      "learning_rate": 2.4880775532836376e-06,
      "loss": 0.2974138975143433,
      "memory(GiB)": 72.72,
      "step": 36675,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.4213226378136365,
      "grad_norm": 4.47528600692749,
      "learning_rate": 2.4867441364138165e-06,
      "loss": 0.3346812963485718,
      "memory(GiB)": 72.72,
      "step": 36680,
      "token_acc": 0.7941176470588235,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.4217890122190093,
      "grad_norm": 2.981315851211548,
      "learning_rate": 2.485410958672549e-06,
      "loss": 0.28310041427612304,
      "memory(GiB)": 72.72,
      "step": 36685,
      "token_acc": 0.576271186440678,
      "train_speed(iter/s)": 0.251361
    },
    {
      "epoch": 3.422255386624382,
      "grad_norm": 3.354210376739502,
      "learning_rate": 2.484078020186682e-06,
      "loss": 0.2899608135223389,
      "memory(GiB)": 72.72,
      "step": 36690,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.422721761029755,
      "grad_norm": 4.831528663635254,
      "learning_rate": 2.482745321083041e-06,
      "loss": 0.3004680395126343,
      "memory(GiB)": 72.72,
      "step": 36695,
      "token_acc": 0.6347826086956522,
      "train_speed(iter/s)": 0.251362
    },
    {
      "epoch": 3.4231881354351272,
      "grad_norm": 2.628038167953491,
      "learning_rate": 2.4814128614884263e-06,
      "loss": 0.32376530170440676,
      "memory(GiB)": 72.72,
      "step": 36700,
      "train_speed(iter/s)": 0.251363
    },
    {
      "epoch": 3.4236545098405,
      "grad_norm": 3.711916446685791,
      "learning_rate": 2.480080641529623e-06,
      "loss": 0.32695190906524657,
      "memory(GiB)": 72.72,
      "step": 36705,
      "token_acc": 0.6744186046511628,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.4241208842458724,
      "grad_norm": 2.5328152179718018,
      "learning_rate": 2.4787486613333815e-06,
      "loss": 0.3260359525680542,
      "memory(GiB)": 72.72,
      "step": 36710,
      "token_acc": 0.98989898989899,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.424587258651245,
      "grad_norm": 5.1466474533081055,
      "learning_rate": 2.4774169210264385e-06,
      "loss": 0.3258850574493408,
      "memory(GiB)": 72.72,
      "step": 36715,
      "train_speed(iter/s)": 0.251364
    },
    {
      "epoch": 3.425053633056618,
      "grad_norm": 2.465334892272949,
      "learning_rate": 2.4760854207355045e-06,
      "loss": 0.2912301540374756,
      "memory(GiB)": 72.72,
      "step": 36720,
      "token_acc": 0.7567567567567568,
      "train_speed(iter/s)": 0.251365
    },
    {
      "epoch": 3.4255200074619907,
      "grad_norm": 3.3528828620910645,
      "learning_rate": 2.474754160587267e-06,
      "loss": 0.3239119052886963,
      "memory(GiB)": 72.72,
      "step": 36725,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.425986381867363,
      "grad_norm": 5.227550506591797,
      "learning_rate": 2.4734231407083927e-06,
      "loss": 0.29073657989501955,
      "memory(GiB)": 72.72,
      "step": 36730,
      "token_acc": 0.6344086021505376,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.426452756272736,
      "grad_norm": 4.5896406173706055,
      "learning_rate": 2.472092361225521e-06,
      "loss": 0.30926194190979006,
      "memory(GiB)": 72.72,
      "step": 36735,
      "train_speed(iter/s)": 0.251366
    },
    {
      "epoch": 3.426919130678108,
      "grad_norm": 4.390281677246094,
      "learning_rate": 2.470761822265275e-06,
      "loss": 0.31183388233184817,
      "memory(GiB)": 72.72,
      "step": 36740,
      "token_acc": 0.4689655172413793,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.427385505083481,
      "grad_norm": 4.08270263671875,
      "learning_rate": 2.469431523954251e-06,
      "loss": 0.3282226324081421,
      "memory(GiB)": 72.72,
      "step": 36745,
      "train_speed(iter/s)": 0.251369
    },
    {
      "epoch": 3.4278518794888537,
      "grad_norm": 2.205824613571167,
      "learning_rate": 2.468101466419022e-06,
      "loss": 0.2756817817687988,
      "memory(GiB)": 72.72,
      "step": 36750,
      "token_acc": 0.7,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.4283182538942265,
      "grad_norm": 2.7476966381073,
      "learning_rate": 2.466771649786138e-06,
      "loss": 0.2919029712677002,
      "memory(GiB)": 72.72,
      "step": 36755,
      "token_acc": 0.6415094339622641,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.428784628299599,
      "grad_norm": 3.0698447227478027,
      "learning_rate": 2.465442074182128e-06,
      "loss": 0.28007686138153076,
      "memory(GiB)": 72.72,
      "step": 36760,
      "train_speed(iter/s)": 0.25137
    },
    {
      "epoch": 3.4292510027049716,
      "grad_norm": 2.7938640117645264,
      "learning_rate": 2.4641127397334983e-06,
      "loss": 0.3115828990936279,
      "memory(GiB)": 72.72,
      "step": 36765,
      "token_acc": 0.659217877094972,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.429717377110344,
      "grad_norm": 3.827174663543701,
      "learning_rate": 2.4627836465667266e-06,
      "loss": 0.2986768245697021,
      "memory(GiB)": 72.72,
      "step": 36770,
      "token_acc": 0.7659574468085106,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.4301837515157168,
      "grad_norm": 2.9570188522338867,
      "learning_rate": 2.4614547948082755e-06,
      "loss": 0.27971954345703126,
      "memory(GiB)": 72.72,
      "step": 36775,
      "train_speed(iter/s)": 0.251371
    },
    {
      "epoch": 3.4306501259210895,
      "grad_norm": 3.3160364627838135,
      "learning_rate": 2.4601261845845816e-06,
      "loss": 0.2950901985168457,
      "memory(GiB)": 72.72,
      "step": 36780,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.4311165003264623,
      "grad_norm": 3.818568468093872,
      "learning_rate": 2.4587978160220565e-06,
      "loss": 0.3063312292098999,
      "memory(GiB)": 72.72,
      "step": 36785,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 3.4315828747318347,
      "grad_norm": 3.256901741027832,
      "learning_rate": 2.4574696892470908e-06,
      "loss": 0.2674896240234375,
      "memory(GiB)": 72.72,
      "step": 36790,
      "train_speed(iter/s)": 0.251372
    },
    {
      "epoch": 3.4320492491372074,
      "grad_norm": 2.2573657035827637,
      "learning_rate": 2.4561418043860515e-06,
      "loss": 0.32315988540649415,
      "memory(GiB)": 72.72,
      "step": 36795,
      "train_speed(iter/s)": 0.251373
    },
    {
      "epoch": 3.4325156235425798,
      "grad_norm": 5.368202209472656,
      "learning_rate": 2.4548141615652833e-06,
      "loss": 0.2999390125274658,
      "memory(GiB)": 72.72,
      "step": 36800,
      "train_speed(iter/s)": 0.251374
    },
    {
      "epoch": 3.4329819979479526,
      "grad_norm": 2.4384548664093018,
      "learning_rate": 2.453486760911107e-06,
      "loss": 0.2580127716064453,
      "memory(GiB)": 72.72,
      "step": 36805,
      "train_speed(iter/s)": 0.251375
    },
    {
      "epoch": 3.4334483723533253,
      "grad_norm": 4.8048319816589355,
      "learning_rate": 2.4521596025498207e-06,
      "loss": 0.26073882579803465,
      "memory(GiB)": 72.72,
      "step": 36810,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 3.433914746758698,
      "grad_norm": 2.9669830799102783,
      "learning_rate": 2.4508326866076992e-06,
      "loss": 0.2825474262237549,
      "memory(GiB)": 72.72,
      "step": 36815,
      "token_acc": 0.5675675675675675,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 3.4343811211640705,
      "grad_norm": 2.779456615447998,
      "learning_rate": 2.4495060132109943e-06,
      "loss": 0.2792519569396973,
      "memory(GiB)": 72.72,
      "step": 36820,
      "token_acc": 0.8471337579617835,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 3.4348474955694432,
      "grad_norm": 4.153848648071289,
      "learning_rate": 2.448179582485936e-06,
      "loss": 0.2809438705444336,
      "memory(GiB)": 72.72,
      "step": 36825,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 3.4353138699748156,
      "grad_norm": 2.1433370113372803,
      "learning_rate": 2.446853394558729e-06,
      "loss": 0.31366894245147703,
      "memory(GiB)": 72.72,
      "step": 36830,
      "token_acc": 0.9523809523809523,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 3.4357802443801884,
      "grad_norm": 3.2809510231018066,
      "learning_rate": 2.445527449555554e-06,
      "loss": 0.3089029312133789,
      "memory(GiB)": 72.72,
      "step": 36835,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 3.436246618785561,
      "grad_norm": 3.8404462337493896,
      "learning_rate": 2.4442017476025758e-06,
      "loss": 0.34006557464599607,
      "memory(GiB)": 72.72,
      "step": 36840,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.436712993190934,
      "grad_norm": 4.352550983428955,
      "learning_rate": 2.4428762888259273e-06,
      "loss": 0.33744158744812014,
      "memory(GiB)": 72.72,
      "step": 36845,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 3.4371793675963063,
      "grad_norm": 2.8900411128997803,
      "learning_rate": 2.4415510733517227e-06,
      "loss": 0.2614351749420166,
      "memory(GiB)": 72.72,
      "step": 36850,
      "token_acc": 0.47692307692307695,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.437645742001679,
      "grad_norm": 3.780168294906616,
      "learning_rate": 2.4402261013060517e-06,
      "loss": 0.3312278509140015,
      "memory(GiB)": 72.72,
      "step": 36855,
      "token_acc": 0.6896551724137931,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 3.4381121164070514,
      "grad_norm": 5.318767070770264,
      "learning_rate": 2.4389013728149824e-06,
      "loss": 0.2981051206588745,
      "memory(GiB)": 72.72,
      "step": 36860,
      "token_acc": 0.5645161290322581,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.438578490812424,
      "grad_norm": 2.7735118865966797,
      "learning_rate": 2.4375768880045593e-06,
      "loss": 0.3175357341766357,
      "memory(GiB)": 72.72,
      "step": 36865,
      "token_acc": 0.7101449275362319,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.439044865217797,
      "grad_norm": 3.1343448162078857,
      "learning_rate": 2.4362526470007976e-06,
      "loss": 0.28517718315124513,
      "memory(GiB)": 72.72,
      "step": 36870,
      "token_acc": 0.9605263157894737,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.4395112396231693,
      "grad_norm": 2.2454428672790527,
      "learning_rate": 2.4349286499297002e-06,
      "loss": 0.2792325496673584,
      "memory(GiB)": 72.72,
      "step": 36875,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.439977614028542,
      "grad_norm": 6.135853290557861,
      "learning_rate": 2.4336048969172404e-06,
      "loss": 0.3108650207519531,
      "memory(GiB)": 72.72,
      "step": 36880,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 3.440443988433915,
      "grad_norm": 11.01447868347168,
      "learning_rate": 2.4322813880893686e-06,
      "loss": 0.25648138523101804,
      "memory(GiB)": 72.72,
      "step": 36885,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 3.440910362839287,
      "grad_norm": 2.896707534790039,
      "learning_rate": 2.4309581235720127e-06,
      "loss": 0.2821444034576416,
      "memory(GiB)": 72.72,
      "step": 36890,
      "token_acc": 0.8300653594771242,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 3.44137673724466,
      "grad_norm": 2.7049965858459473,
      "learning_rate": 2.429635103491077e-06,
      "loss": 0.30189995765686034,
      "memory(GiB)": 72.72,
      "step": 36895,
      "token_acc": 0.4489795918367347,
      "train_speed(iter/s)": 0.251379
    },
    {
      "epoch": 3.4418431116500328,
      "grad_norm": 3.0090315341949463,
      "learning_rate": 2.4283123279724434e-06,
      "loss": 0.28276352882385253,
      "memory(GiB)": 72.72,
      "step": 36900,
      "token_acc": 0.4772727272727273,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 3.442309486055405,
      "grad_norm": 9.323282241821289,
      "learning_rate": 2.4269897971419695e-06,
      "loss": 0.2772757291793823,
      "memory(GiB)": 72.72,
      "step": 36905,
      "token_acc": 0.7358490566037735,
      "train_speed(iter/s)": 0.251376
    },
    {
      "epoch": 3.442775860460778,
      "grad_norm": 4.349865913391113,
      "learning_rate": 2.4256675111254895e-06,
      "loss": 0.27741944789886475,
      "memory(GiB)": 72.72,
      "step": 36910,
      "train_speed(iter/s)": 0.251378
    },
    {
      "epoch": 3.4432422348661507,
      "grad_norm": 2.6904489994049072,
      "learning_rate": 2.4243454700488156e-06,
      "loss": 0.29649176597595217,
      "memory(GiB)": 72.72,
      "step": 36915,
      "token_acc": 0.7959183673469388,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 3.443708609271523,
      "grad_norm": 2.7114226818084717,
      "learning_rate": 2.423023674037736e-06,
      "loss": 0.30864098072052004,
      "memory(GiB)": 72.72,
      "step": 36920,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 3.444174983676896,
      "grad_norm": 4.026961803436279,
      "learning_rate": 2.421702123218015e-06,
      "loss": 0.30162074565887453,
      "memory(GiB)": 72.72,
      "step": 36925,
      "token_acc": 0.7291666666666666,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 3.4446413580822686,
      "grad_norm": 7.573127746582031,
      "learning_rate": 2.420380817715394e-06,
      "loss": 0.29951791763305663,
      "memory(GiB)": 72.72,
      "step": 36930,
      "token_acc": 0.6938775510204082,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 3.445107732487641,
      "grad_norm": 2.7572762966156006,
      "learning_rate": 2.4190597576555924e-06,
      "loss": 0.3150383949279785,
      "memory(GiB)": 72.72,
      "step": 36935,
      "token_acc": 0.7317073170731707,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.4455741068930137,
      "grad_norm": 2.549482583999634,
      "learning_rate": 2.4177389431643016e-06,
      "loss": 0.2759195327758789,
      "memory(GiB)": 72.72,
      "step": 36940,
      "token_acc": 0.9484536082474226,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.4460404812983865,
      "grad_norm": 3.0244343280792236,
      "learning_rate": 2.4164183743671975e-06,
      "loss": 0.2685678005218506,
      "memory(GiB)": 72.72,
      "step": 36945,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.446506855703759,
      "grad_norm": 3.1855785846710205,
      "learning_rate": 2.4150980513899263e-06,
      "loss": 0.30027594566345217,
      "memory(GiB)": 72.72,
      "step": 36950,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.4469732301091316,
      "grad_norm": 2.3341116905212402,
      "learning_rate": 2.4137779743581124e-06,
      "loss": 0.32827396392822267,
      "memory(GiB)": 72.72,
      "step": 36955,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.4474396045145044,
      "grad_norm": 2.6335182189941406,
      "learning_rate": 2.412458143397359e-06,
      "loss": 0.28705754280090334,
      "memory(GiB)": 72.72,
      "step": 36960,
      "token_acc": 0.6888888888888889,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 3.4479059789198767,
      "grad_norm": 3.070406198501587,
      "learning_rate": 2.41113855863324e-06,
      "loss": 0.2709565877914429,
      "memory(GiB)": 72.72,
      "step": 36965,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.4483723533252495,
      "grad_norm": 2.8511576652526855,
      "learning_rate": 2.409819220191312e-06,
      "loss": 0.2817580223083496,
      "memory(GiB)": 72.72,
      "step": 36970,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.4488387277306223,
      "grad_norm": 3.415945291519165,
      "learning_rate": 2.408500128197105e-06,
      "loss": 0.2650995016098022,
      "memory(GiB)": 72.72,
      "step": 36975,
      "token_acc": 0.6122448979591837,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.4493051021359946,
      "grad_norm": 2.8089492321014404,
      "learning_rate": 2.4071812827761288e-06,
      "loss": 0.2946295261383057,
      "memory(GiB)": 72.72,
      "step": 36980,
      "train_speed(iter/s)": 0.251383
    },
    {
      "epoch": 3.4497714765413674,
      "grad_norm": 4.399560928344727,
      "learning_rate": 2.4058626840538657e-06,
      "loss": 0.2755912780761719,
      "memory(GiB)": 72.72,
      "step": 36985,
      "token_acc": 0.5283018867924528,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 3.45023785094674,
      "grad_norm": 3.640117883682251,
      "learning_rate": 2.4045443321557773e-06,
      "loss": 0.2970774173736572,
      "memory(GiB)": 72.72,
      "step": 36990,
      "train_speed(iter/s)": 0.251381
    },
    {
      "epoch": 3.4507042253521125,
      "grad_norm": 4.091396331787109,
      "learning_rate": 2.4032262272073e-06,
      "loss": 0.2989753007888794,
      "memory(GiB)": 72.72,
      "step": 36995,
      "token_acc": 0.7291666666666666,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.4511705997574853,
      "grad_norm": 3.3875982761383057,
      "learning_rate": 2.4019083693338475e-06,
      "loss": 0.2835600137710571,
      "memory(GiB)": 72.72,
      "step": 37000,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.451636974162858,
      "grad_norm": 2.331141710281372,
      "learning_rate": 2.4005907586608103e-06,
      "loss": 0.2686600685119629,
      "memory(GiB)": 72.72,
      "step": 37005,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.4521033485682304,
      "grad_norm": 2.502382755279541,
      "learning_rate": 2.3992733953135544e-06,
      "loss": 0.3002598285675049,
      "memory(GiB)": 72.72,
      "step": 37010,
      "train_speed(iter/s)": 0.25138
    },
    {
      "epoch": 3.452569722973603,
      "grad_norm": 2.843526601791382,
      "learning_rate": 2.397956279417424e-06,
      "loss": 0.29673359394073484,
      "memory(GiB)": 72.72,
      "step": 37015,
      "train_speed(iter/s)": 0.251382
    },
    {
      "epoch": 3.453036097378976,
      "grad_norm": 2.921356201171875,
      "learning_rate": 2.396639411097737e-06,
      "loss": 0.32549903392791746,
      "memory(GiB)": 72.72,
      "step": 37020,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 3.4535024717843483,
      "grad_norm": 2.662477731704712,
      "learning_rate": 2.3953227904797904e-06,
      "loss": 0.2653821468353271,
      "memory(GiB)": 72.72,
      "step": 37025,
      "token_acc": 0.9514563106796117,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 3.453968846189721,
      "grad_norm": 2.651503324508667,
      "learning_rate": 2.394006417688856e-06,
      "loss": 0.2315066337585449,
      "memory(GiB)": 72.72,
      "step": 37030,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 3.454435220595094,
      "grad_norm": 2.73376202583313,
      "learning_rate": 2.392690292850184e-06,
      "loss": 0.26714634895324707,
      "memory(GiB)": 72.72,
      "step": 37035,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.4549015950004662,
      "grad_norm": 4.916263103485107,
      "learning_rate": 2.3913744160889957e-06,
      "loss": 0.28757944107055666,
      "memory(GiB)": 72.72,
      "step": 37040,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.455367969405839,
      "grad_norm": 2.923804521560669,
      "learning_rate": 2.3900587875304983e-06,
      "loss": 0.3020817041397095,
      "memory(GiB)": 72.72,
      "step": 37045,
      "token_acc": 0.7368421052631579,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.455834343811212,
      "grad_norm": 3.104942560195923,
      "learning_rate": 2.3887434072998667e-06,
      "loss": 0.2749921798706055,
      "memory(GiB)": 72.72,
      "step": 37050,
      "token_acc": 0.5950413223140496,
      "train_speed(iter/s)": 0.251391
    },
    {
      "epoch": 3.456300718216584,
      "grad_norm": 3.157839298248291,
      "learning_rate": 2.387428275522256e-06,
      "loss": 0.333221960067749,
      "memory(GiB)": 72.72,
      "step": 37055,
      "token_acc": 0.5806451612903226,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.456767092621957,
      "grad_norm": 2.586129903793335,
      "learning_rate": 2.386113392322798e-06,
      "loss": 0.25058856010437014,
      "memory(GiB)": 72.72,
      "step": 37060,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.4572334670273297,
      "grad_norm": 3.9118337631225586,
      "learning_rate": 2.3847987578265975e-06,
      "loss": 0.3132965087890625,
      "memory(GiB)": 72.72,
      "step": 37065,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.457699841432702,
      "grad_norm": 4.8300700187683105,
      "learning_rate": 2.383484372158738e-06,
      "loss": 0.30164179801940916,
      "memory(GiB)": 72.72,
      "step": 37070,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.458166215838075,
      "grad_norm": 3.941554307937622,
      "learning_rate": 2.3821702354442785e-06,
      "loss": 0.2837808609008789,
      "memory(GiB)": 72.72,
      "step": 37075,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.4586325902434476,
      "grad_norm": 3.312809944152832,
      "learning_rate": 2.3808563478082584e-06,
      "loss": 0.32196774482727053,
      "memory(GiB)": 72.72,
      "step": 37080,
      "train_speed(iter/s)": 0.251387
    },
    {
      "epoch": 3.45909896464882,
      "grad_norm": 2.649487018585205,
      "learning_rate": 2.3795427093756884e-06,
      "loss": 0.3247556447982788,
      "memory(GiB)": 72.72,
      "step": 37085,
      "token_acc": 0.42857142857142855,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 3.4595653390541927,
      "grad_norm": 7.404451847076416,
      "learning_rate": 2.3782293202715575e-06,
      "loss": 0.328622841835022,
      "memory(GiB)": 72.72,
      "step": 37090,
      "token_acc": 0.75,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 3.4600317134595655,
      "grad_norm": 3.353801727294922,
      "learning_rate": 2.37691618062083e-06,
      "loss": 0.3070209980010986,
      "memory(GiB)": 72.72,
      "step": 37095,
      "token_acc": 0.9626168224299065,
      "train_speed(iter/s)": 0.251384
    },
    {
      "epoch": 3.460498087864938,
      "grad_norm": 2.3331167697906494,
      "learning_rate": 2.375603290548447e-06,
      "loss": 0.2798757076263428,
      "memory(GiB)": 72.72,
      "step": 37100,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 3.4609644622703106,
      "grad_norm": 2.785353660583496,
      "learning_rate": 2.3742906501793267e-06,
      "loss": 0.27727887630462644,
      "memory(GiB)": 72.72,
      "step": 37105,
      "train_speed(iter/s)": 0.251385
    },
    {
      "epoch": 3.4614308366756834,
      "grad_norm": 2.9065287113189697,
      "learning_rate": 2.372978259638362e-06,
      "loss": 0.28446226119995116,
      "memory(GiB)": 72.72,
      "step": 37110,
      "train_speed(iter/s)": 0.251386
    },
    {
      "epoch": 3.4618972110810557,
      "grad_norm": 2.6939568519592285,
      "learning_rate": 2.371666119050423e-06,
      "loss": 0.31491928100585936,
      "memory(GiB)": 72.72,
      "step": 37115,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 3.4623635854864285,
      "grad_norm": 5.547158241271973,
      "learning_rate": 2.3703542285403564e-06,
      "loss": 0.3088357448577881,
      "memory(GiB)": 72.72,
      "step": 37120,
      "token_acc": 0.5333333333333333,
      "train_speed(iter/s)": 0.251388
    },
    {
      "epoch": 3.4628299598918013,
      "grad_norm": 3.0034940242767334,
      "learning_rate": 2.3690425882329845e-06,
      "loss": 0.29486923217773436,
      "memory(GiB)": 72.72,
      "step": 37125,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.4632963342971737,
      "grad_norm": 4.8751373291015625,
      "learning_rate": 2.367731198253105e-06,
      "loss": 0.28554592132568357,
      "memory(GiB)": 72.72,
      "step": 37130,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.4637627087025464,
      "grad_norm": 2.647228240966797,
      "learning_rate": 2.3664200587254926e-06,
      "loss": 0.2914433002471924,
      "memory(GiB)": 72.72,
      "step": 37135,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.464229083107919,
      "grad_norm": 4.7729010581970215,
      "learning_rate": 2.365109169774899e-06,
      "loss": 0.2552010536193848,
      "memory(GiB)": 72.72,
      "step": 37140,
      "token_acc": 0.7142857142857143,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.4646954575132916,
      "grad_norm": 5.0791096687316895,
      "learning_rate": 2.3637985315260494e-06,
      "loss": 0.3196743011474609,
      "memory(GiB)": 72.72,
      "step": 37145,
      "token_acc": 0.6578947368421053,
      "train_speed(iter/s)": 0.25139
    },
    {
      "epoch": 3.4651618319186643,
      "grad_norm": 16.4581356048584,
      "learning_rate": 2.36248814410365e-06,
      "loss": 0.2596837759017944,
      "memory(GiB)": 72.72,
      "step": 37150,
      "train_speed(iter/s)": 0.251389
    },
    {
      "epoch": 3.465628206324037,
      "grad_norm": 2.9919984340667725,
      "learning_rate": 2.3611780076323786e-06,
      "loss": 0.25376119613647463,
      "memory(GiB)": 72.72,
      "step": 37155,
      "train_speed(iter/s)": 0.251391
    },
    {
      "epoch": 3.4660945807294095,
      "grad_norm": 4.518098831176758,
      "learning_rate": 2.359868122236893e-06,
      "loss": 0.28373379707336427,
      "memory(GiB)": 72.72,
      "step": 37160,
      "train_speed(iter/s)": 0.251392
    },
    {
      "epoch": 3.4665609551347822,
      "grad_norm": 4.5324811935424805,
      "learning_rate": 2.35855848804182e-06,
      "loss": 0.29646055698394774,
      "memory(GiB)": 72.72,
      "step": 37165,
      "train_speed(iter/s)": 0.251394
    },
    {
      "epoch": 3.467027329540155,
      "grad_norm": 2.9725658893585205,
      "learning_rate": 2.35724910517177e-06,
      "loss": 0.2894197702407837,
      "memory(GiB)": 72.72,
      "step": 37170,
      "token_acc": 0.6111111111111112,
      "train_speed(iter/s)": 0.251394
    },
    {
      "epoch": 3.4674937039455274,
      "grad_norm": 3.1859259605407715,
      "learning_rate": 2.355939973751325e-06,
      "loss": 0.2994359493255615,
      "memory(GiB)": 72.72,
      "step": 37175,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.251398
    },
    {
      "epoch": 3.4679600783509,
      "grad_norm": 2.629284143447876,
      "learning_rate": 2.354631093905048e-06,
      "loss": 0.2956012487411499,
      "memory(GiB)": 72.72,
      "step": 37180,
      "train_speed(iter/s)": 0.251399
    },
    {
      "epoch": 3.468426452756273,
      "grad_norm": 3.367624044418335,
      "learning_rate": 2.353322465757472e-06,
      "loss": 0.307462215423584,
      "memory(GiB)": 72.72,
      "step": 37185,
      "train_speed(iter/s)": 0.251399
    },
    {
      "epoch": 3.4688928271616453,
      "grad_norm": 4.044819355010986,
      "learning_rate": 2.352014089433111e-06,
      "loss": 0.2799606084823608,
      "memory(GiB)": 72.72,
      "step": 37190,
      "token_acc": 0.6759259259259259,
      "train_speed(iter/s)": 0.2514
    },
    {
      "epoch": 3.469359201567018,
      "grad_norm": 2.953862428665161,
      "learning_rate": 2.3507059650564523e-06,
      "loss": 0.27589759826660154,
      "memory(GiB)": 72.72,
      "step": 37195,
      "train_speed(iter/s)": 0.251401
    },
    {
      "epoch": 3.469825575972391,
      "grad_norm": 3.45664381980896,
      "learning_rate": 2.3493980927519596e-06,
      "loss": 0.2900477647781372,
      "memory(GiB)": 72.72,
      "step": 37200,
      "train_speed(iter/s)": 0.251403
    },
    {
      "epoch": 3.470291950377763,
      "grad_norm": 3.4060728549957275,
      "learning_rate": 2.348090472644072e-06,
      "loss": 0.3096758365631104,
      "memory(GiB)": 72.72,
      "step": 37205,
      "token_acc": 0.7461928934010152,
      "train_speed(iter/s)": 0.251404
    },
    {
      "epoch": 3.470758324783136,
      "grad_norm": 2.7968945503234863,
      "learning_rate": 2.3467831048572078e-06,
      "loss": 0.2727238416671753,
      "memory(GiB)": 72.72,
      "step": 37210,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.4712246991885083,
      "grad_norm": 4.168956279754639,
      "learning_rate": 2.3454759895157574e-06,
      "loss": 0.2747488498687744,
      "memory(GiB)": 72.72,
      "step": 37215,
      "token_acc": 0.9625,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.471691073593881,
      "grad_norm": 4.867704391479492,
      "learning_rate": 2.3441691267440888e-06,
      "loss": 0.30908851623535155,
      "memory(GiB)": 72.72,
      "step": 37220,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.472157447999254,
      "grad_norm": 3.699575424194336,
      "learning_rate": 2.3428625166665463e-06,
      "loss": 0.3129204273223877,
      "memory(GiB)": 72.72,
      "step": 37225,
      "train_speed(iter/s)": 0.251404
    },
    {
      "epoch": 3.4726238224046266,
      "grad_norm": 3.3471007347106934,
      "learning_rate": 2.3415561594074504e-06,
      "loss": 0.3039269924163818,
      "memory(GiB)": 72.72,
      "step": 37230,
      "token_acc": 0.9090909090909091,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.473090196809999,
      "grad_norm": 2.816166877746582,
      "learning_rate": 2.3402500550910955e-06,
      "loss": 0.26488142013549804,
      "memory(GiB)": 72.72,
      "step": 37235,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.4735565712153718,
      "grad_norm": 2.243704319000244,
      "learning_rate": 2.338944203841755e-06,
      "loss": 0.27967631816864014,
      "memory(GiB)": 72.72,
      "step": 37240,
      "token_acc": 0.5319148936170213,
      "train_speed(iter/s)": 0.251404
    },
    {
      "epoch": 3.474022945620744,
      "grad_norm": 2.0712738037109375,
      "learning_rate": 2.337638605783674e-06,
      "loss": 0.27741713523864747,
      "memory(GiB)": 72.72,
      "step": 37245,
      "train_speed(iter/s)": 0.251403
    },
    {
      "epoch": 3.474489320026117,
      "grad_norm": 2.8723864555358887,
      "learning_rate": 2.33633326104108e-06,
      "loss": 0.26660590171813964,
      "memory(GiB)": 72.72,
      "step": 37250,
      "train_speed(iter/s)": 0.251403
    },
    {
      "epoch": 3.4749556944314897,
      "grad_norm": 2.221914291381836,
      "learning_rate": 2.335028169738172e-06,
      "loss": 0.27940709590911866,
      "memory(GiB)": 72.72,
      "step": 37255,
      "token_acc": 0.8368794326241135,
      "train_speed(iter/s)": 0.2514
    },
    {
      "epoch": 3.4754220688368624,
      "grad_norm": 4.15992546081543,
      "learning_rate": 2.333723331999122e-06,
      "loss": 0.28854823112487793,
      "memory(GiB)": 72.72,
      "step": 37260,
      "train_speed(iter/s)": 0.251399
    },
    {
      "epoch": 3.475888443242235,
      "grad_norm": 6.994790077209473,
      "learning_rate": 2.332418747948084e-06,
      "loss": 0.2671837329864502,
      "memory(GiB)": 72.72,
      "step": 37265,
      "train_speed(iter/s)": 0.2514
    },
    {
      "epoch": 3.4763548176476076,
      "grad_norm": 2.6753768920898438,
      "learning_rate": 2.331114417709184e-06,
      "loss": 0.29455482959747314,
      "memory(GiB)": 72.72,
      "step": 37270,
      "train_speed(iter/s)": 0.251398
    },
    {
      "epoch": 3.47682119205298,
      "grad_norm": 3.004889965057373,
      "learning_rate": 2.3298103414065253e-06,
      "loss": 0.2831376075744629,
      "memory(GiB)": 72.72,
      "step": 37275,
      "token_acc": 0.5945945945945946,
      "train_speed(iter/s)": 0.251399
    },
    {
      "epoch": 3.4772875664583527,
      "grad_norm": 4.074657440185547,
      "learning_rate": 2.3285065191641853e-06,
      "loss": 0.28434047698974607,
      "memory(GiB)": 72.72,
      "step": 37280,
      "train_speed(iter/s)": 0.251398
    },
    {
      "epoch": 3.4777539408637255,
      "grad_norm": 9.924580574035645,
      "learning_rate": 2.3272029511062223e-06,
      "loss": 0.2975014209747314,
      "memory(GiB)": 72.72,
      "step": 37285,
      "train_speed(iter/s)": 0.251398
    },
    {
      "epoch": 3.4782203152690983,
      "grad_norm": 2.8852756023406982,
      "learning_rate": 2.3258996373566643e-06,
      "loss": 0.30759191513061523,
      "memory(GiB)": 72.72,
      "step": 37290,
      "token_acc": 0.6555555555555556,
      "train_speed(iter/s)": 0.2514
    },
    {
      "epoch": 3.4786866896744706,
      "grad_norm": 5.045253276824951,
      "learning_rate": 2.3245965780395186e-06,
      "loss": 0.31822633743286133,
      "memory(GiB)": 72.72,
      "step": 37295,
      "train_speed(iter/s)": 0.251401
    },
    {
      "epoch": 3.4791530640798434,
      "grad_norm": 3.782268762588501,
      "learning_rate": 2.323293773278766e-06,
      "loss": 0.27330789566040037,
      "memory(GiB)": 72.72,
      "step": 37300,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 3.4796194384852157,
      "grad_norm": 2.7963223457336426,
      "learning_rate": 2.3219912231983654e-06,
      "loss": 0.2898083686828613,
      "memory(GiB)": 72.72,
      "step": 37305,
      "token_acc": 0.4222222222222222,
      "train_speed(iter/s)": 0.251401
    },
    {
      "epoch": 3.4800858128905885,
      "grad_norm": 2.9993691444396973,
      "learning_rate": 2.3206889279222506e-06,
      "loss": 0.26640441417694094,
      "memory(GiB)": 72.72,
      "step": 37310,
      "token_acc": 0.4528301886792453,
      "train_speed(iter/s)": 0.251403
    },
    {
      "epoch": 3.4805521872959613,
      "grad_norm": 2.2778282165527344,
      "learning_rate": 2.3193868875743296e-06,
      "loss": 0.2807039976119995,
      "memory(GiB)": 72.72,
      "step": 37315,
      "token_acc": 0.5849056603773585,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 3.481018561701334,
      "grad_norm": 2.1561696529388428,
      "learning_rate": 2.3180851022784894e-06,
      "loss": 0.29163963794708253,
      "memory(GiB)": 72.72,
      "step": 37320,
      "token_acc": 0.5789473684210527,
      "train_speed(iter/s)": 0.251403
    },
    {
      "epoch": 3.4814849361067064,
      "grad_norm": 2.980787992477417,
      "learning_rate": 2.3167835721585892e-06,
      "loss": 0.2758810520172119,
      "memory(GiB)": 72.72,
      "step": 37325,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.481951310512079,
      "grad_norm": 3.4918832778930664,
      "learning_rate": 2.3154822973384665e-06,
      "loss": 0.2872507095336914,
      "memory(GiB)": 72.72,
      "step": 37330,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.4824176849174515,
      "grad_norm": 3.560532331466675,
      "learning_rate": 2.314181277941933e-06,
      "loss": 0.31057090759277345,
      "memory(GiB)": 72.72,
      "step": 37335,
      "train_speed(iter/s)": 0.251404
    },
    {
      "epoch": 3.4828840593228243,
      "grad_norm": 3.5949788093566895,
      "learning_rate": 2.3128805140927774e-06,
      "loss": 0.3066983699798584,
      "memory(GiB)": 72.72,
      "step": 37340,
      "train_speed(iter/s)": 0.251403
    },
    {
      "epoch": 3.483350433728197,
      "grad_norm": 2.843508243560791,
      "learning_rate": 2.3115800059147607e-06,
      "loss": 0.2857794761657715,
      "memory(GiB)": 72.72,
      "step": 37345,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.48381680813357,
      "grad_norm": 3.055248260498047,
      "learning_rate": 2.310279753531627e-06,
      "loss": 0.26284863948822024,
      "memory(GiB)": 72.72,
      "step": 37350,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.484283182538942,
      "grad_norm": 2.4370200634002686,
      "learning_rate": 2.308979757067091e-06,
      "loss": 0.30241923332214354,
      "memory(GiB)": 72.72,
      "step": 37355,
      "token_acc": 0.5849056603773585,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.484749556944315,
      "grad_norm": 2.7238073348999023,
      "learning_rate": 2.307680016644838e-06,
      "loss": 0.2822865962982178,
      "memory(GiB)": 72.72,
      "step": 37360,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.4852159313496873,
      "grad_norm": 3.2880966663360596,
      "learning_rate": 2.3063805323885384e-06,
      "loss": 0.2691394567489624,
      "memory(GiB)": 72.72,
      "step": 37365,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 3.48568230575506,
      "grad_norm": 3.364412307739258,
      "learning_rate": 2.3050813044218335e-06,
      "loss": 0.27648043632507324,
      "memory(GiB)": 72.72,
      "step": 37370,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 3.486148680160433,
      "grad_norm": 2.6364071369171143,
      "learning_rate": 2.30378233286834e-06,
      "loss": 0.31319370269775393,
      "memory(GiB)": 72.72,
      "step": 37375,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251411
    },
    {
      "epoch": 3.4866150545658057,
      "grad_norm": 7.108603000640869,
      "learning_rate": 2.3024836178516503e-06,
      "loss": 0.2715289115905762,
      "memory(GiB)": 72.72,
      "step": 37380,
      "token_acc": 0.7714285714285715,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.487081428971178,
      "grad_norm": 3.072408676147461,
      "learning_rate": 2.301185159495336e-06,
      "loss": 0.2795713901519775,
      "memory(GiB)": 72.72,
      "step": 37385,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 3.487547803376551,
      "grad_norm": 3.204688549041748,
      "learning_rate": 2.29988695792294e-06,
      "loss": 0.2932273864746094,
      "memory(GiB)": 72.72,
      "step": 37390,
      "token_acc": 0.7213114754098361,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 3.488014177781923,
      "grad_norm": 2.615861177444458,
      "learning_rate": 2.298589013257982e-06,
      "loss": 0.2811079978942871,
      "memory(GiB)": 72.72,
      "step": 37395,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 3.488480552187296,
      "grad_norm": 2.5670456886291504,
      "learning_rate": 2.2972913256239577e-06,
      "loss": 0.2624587297439575,
      "memory(GiB)": 72.72,
      "step": 37400,
      "token_acc": 0.6333333333333333,
      "train_speed(iter/s)": 0.251411
    },
    {
      "epoch": 3.4889469265926687,
      "grad_norm": 2.378924608230591,
      "learning_rate": 2.295993895144337e-06,
      "loss": 0.27743680477142335,
      "memory(GiB)": 72.72,
      "step": 37405,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 3.489413300998041,
      "grad_norm": 2.594329595565796,
      "learning_rate": 2.2946967219425703e-06,
      "loss": 0.2759004831314087,
      "memory(GiB)": 72.72,
      "step": 37410,
      "token_acc": 0.7058823529411765,
      "train_speed(iter/s)": 0.251411
    },
    {
      "epoch": 3.489879675403414,
      "grad_norm": 3.044393539428711,
      "learning_rate": 2.293399806142072e-06,
      "loss": 0.30234379768371583,
      "memory(GiB)": 72.72,
      "step": 37415,
      "token_acc": 0.7021276595744681,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 3.4903460498087866,
      "grad_norm": 4.858560562133789,
      "learning_rate": 2.2921031478662463e-06,
      "loss": 0.27043981552124025,
      "memory(GiB)": 72.72,
      "step": 37420,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 3.490812424214159,
      "grad_norm": 10.607437133789062,
      "learning_rate": 2.290806747238465e-06,
      "loss": 0.26921634674072265,
      "memory(GiB)": 72.72,
      "step": 37425,
      "train_speed(iter/s)": 0.251413
    },
    {
      "epoch": 3.4912787986195317,
      "grad_norm": 2.2980282306671143,
      "learning_rate": 2.2895106043820747e-06,
      "loss": 0.2843782901763916,
      "memory(GiB)": 72.72,
      "step": 37430,
      "token_acc": 0.5538461538461539,
      "train_speed(iter/s)": 0.251413
    },
    {
      "epoch": 3.4917451730249045,
      "grad_norm": 2.594717264175415,
      "learning_rate": 2.288214719420401e-06,
      "loss": 0.2903322219848633,
      "memory(GiB)": 72.72,
      "step": 37435,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 3.492211547430277,
      "grad_norm": 2.2637569904327393,
      "learning_rate": 2.286919092476743e-06,
      "loss": 0.3137510299682617,
      "memory(GiB)": 72.72,
      "step": 37440,
      "token_acc": 0.6448598130841121,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 3.4926779218356496,
      "grad_norm": 2.632768392562866,
      "learning_rate": 2.2856237236743754e-06,
      "loss": 0.3162172794342041,
      "memory(GiB)": 72.72,
      "step": 37445,
      "token_acc": 0.5769230769230769,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 3.4931442962410224,
      "grad_norm": 4.45125150680542,
      "learning_rate": 2.284328613136547e-06,
      "loss": 0.3231798648834229,
      "memory(GiB)": 72.72,
      "step": 37450,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.4936106706463947,
      "grad_norm": 3.8676109313964844,
      "learning_rate": 2.283033760986489e-06,
      "loss": 0.3290873527526855,
      "memory(GiB)": 72.72,
      "step": 37455,
      "token_acc": 0.4594594594594595,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.4940770450517675,
      "grad_norm": 4.0185346603393555,
      "learning_rate": 2.2817391673473966e-06,
      "loss": 0.28286826610565186,
      "memory(GiB)": 72.72,
      "step": 37460,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.4945434194571403,
      "grad_norm": 2.6959218978881836,
      "learning_rate": 2.280444832342449e-06,
      "loss": 0.2764045238494873,
      "memory(GiB)": 72.72,
      "step": 37465,
      "token_acc": 0.7272727272727273,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.4950097938625126,
      "grad_norm": 3.0155463218688965,
      "learning_rate": 2.279150756094797e-06,
      "loss": 0.28998899459838867,
      "memory(GiB)": 72.72,
      "step": 37470,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.4954761682678854,
      "grad_norm": 2.5128164291381836,
      "learning_rate": 2.2778569387275696e-06,
      "loss": 0.3048957109451294,
      "memory(GiB)": 72.72,
      "step": 37475,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.495942542673258,
      "grad_norm": 5.114813804626465,
      "learning_rate": 2.2765633803638664e-06,
      "loss": 0.26990039348602296,
      "memory(GiB)": 72.72,
      "step": 37480,
      "token_acc": 0.9217391304347826,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.4964089170786306,
      "grad_norm": 2.300138235092163,
      "learning_rate": 2.2752700811267698e-06,
      "loss": 0.30671029090881347,
      "memory(GiB)": 72.72,
      "step": 37485,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.4968752914840033,
      "grad_norm": 2.0928890705108643,
      "learning_rate": 2.273977041139331e-06,
      "loss": 0.26793746948242186,
      "memory(GiB)": 72.72,
      "step": 37490,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.497341665889376,
      "grad_norm": 5.202055931091309,
      "learning_rate": 2.2726842605245797e-06,
      "loss": 0.2739282131195068,
      "memory(GiB)": 72.72,
      "step": 37495,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.4978080402947485,
      "grad_norm": 3.634350061416626,
      "learning_rate": 2.271391739405519e-06,
      "loss": 0.29353392124176025,
      "memory(GiB)": 72.72,
      "step": 37500,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.4982744147001212,
      "grad_norm": 2.4015791416168213,
      "learning_rate": 2.270099477905128e-06,
      "loss": 0.2671525478363037,
      "memory(GiB)": 72.72,
      "step": 37505,
      "token_acc": 0.6842105263157895,
      "train_speed(iter/s)": 0.251424
    },
    {
      "epoch": 3.498740789105494,
      "grad_norm": 3.5711569786071777,
      "learning_rate": 2.2688074761463645e-06,
      "loss": 0.31795296669006345,
      "memory(GiB)": 72.72,
      "step": 37510,
      "token_acc": 0.49074074074074076,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.4992071635108664,
      "grad_norm": 2.2617645263671875,
      "learning_rate": 2.2675157342521524e-06,
      "loss": 0.31207876205444335,
      "memory(GiB)": 72.72,
      "step": 37515,
      "token_acc": 0.6981132075471698,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.499673537916239,
      "grad_norm": 3.952537775039673,
      "learning_rate": 2.266224252345402e-06,
      "loss": 0.32852778434753416,
      "memory(GiB)": 72.72,
      "step": 37520,
      "token_acc": 0.5634920634920635,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.500139912321612,
      "grad_norm": 2.546870231628418,
      "learning_rate": 2.2649330305489924e-06,
      "loss": 0.28926103115081786,
      "memory(GiB)": 72.72,
      "step": 37525,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.5006062867269843,
      "grad_norm": 2.9065048694610596,
      "learning_rate": 2.26364206898578e-06,
      "loss": 0.29712481498718263,
      "memory(GiB)": 72.72,
      "step": 37530,
      "token_acc": 0.8987341772151899,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.501072661132357,
      "grad_norm": 3.2592477798461914,
      "learning_rate": 2.262351367778595e-06,
      "loss": 0.2691754102706909,
      "memory(GiB)": 72.72,
      "step": 37535,
      "train_speed(iter/s)": 0.251424
    },
    {
      "epoch": 3.50153903553773,
      "grad_norm": 2.685883045196533,
      "learning_rate": 2.261060927050243e-06,
      "loss": 0.315700101852417,
      "memory(GiB)": 72.72,
      "step": 37540,
      "token_acc": 0.5222222222222223,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.502005409943102,
      "grad_norm": 3.084592342376709,
      "learning_rate": 2.259770746923507e-06,
      "loss": 0.3200444221496582,
      "memory(GiB)": 72.72,
      "step": 37545,
      "token_acc": 0.9642857142857143,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.502471784348475,
      "grad_norm": 3.0689730644226074,
      "learning_rate": 2.258480827521143e-06,
      "loss": 0.2898519039154053,
      "memory(GiB)": 72.72,
      "step": 37550,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5029381587538477,
      "grad_norm": 3.4844696521759033,
      "learning_rate": 2.257191168965882e-06,
      "loss": 0.30796279907226565,
      "memory(GiB)": 72.72,
      "step": 37555,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.50340453315922,
      "grad_norm": 2.881577730178833,
      "learning_rate": 2.2559017713804326e-06,
      "loss": 0.3138270378112793,
      "memory(GiB)": 72.72,
      "step": 37560,
      "token_acc": 0.9380530973451328,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.503870907564593,
      "grad_norm": 2.724513292312622,
      "learning_rate": 2.2546126348874757e-06,
      "loss": 0.28663060665130613,
      "memory(GiB)": 72.72,
      "step": 37565,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5043372819699656,
      "grad_norm": 3.2080626487731934,
      "learning_rate": 2.2533237596096697e-06,
      "loss": 0.2915147066116333,
      "memory(GiB)": 72.72,
      "step": 37570,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.504803656375338,
      "grad_norm": 5.10161828994751,
      "learning_rate": 2.2520351456696466e-06,
      "loss": 0.30264697074890134,
      "memory(GiB)": 72.72,
      "step": 37575,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.5052700307807108,
      "grad_norm": 2.3157360553741455,
      "learning_rate": 2.250746793190014e-06,
      "loss": 0.2879506587982178,
      "memory(GiB)": 72.72,
      "step": 37580,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.5057364051860835,
      "grad_norm": 2.6357367038726807,
      "learning_rate": 2.2494587022933526e-06,
      "loss": 0.3110652923583984,
      "memory(GiB)": 72.72,
      "step": 37585,
      "token_acc": 0.6285714285714286,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.506202779591456,
      "grad_norm": 2.9055049419403076,
      "learning_rate": 2.2481708731022246e-06,
      "loss": 0.3028427600860596,
      "memory(GiB)": 72.72,
      "step": 37590,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5066691539968287,
      "grad_norm": 4.03648567199707,
      "learning_rate": 2.246883305739161e-06,
      "loss": 0.2802894115447998,
      "memory(GiB)": 72.72,
      "step": 37595,
      "token_acc": 0.5671641791044776,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.5071355284022014,
      "grad_norm": 2.7927911281585693,
      "learning_rate": 2.2455960003266693e-06,
      "loss": 0.26021151542663573,
      "memory(GiB)": 72.72,
      "step": 37600,
      "token_acc": 0.7727272727272727,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.507601902807574,
      "grad_norm": 3.1974661350250244,
      "learning_rate": 2.2443089569872327e-06,
      "loss": 0.27643110752105715,
      "memory(GiB)": 72.72,
      "step": 37605,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.5080682772129466,
      "grad_norm": 2.953683853149414,
      "learning_rate": 2.2430221758433124e-06,
      "loss": 0.2952582836151123,
      "memory(GiB)": 72.72,
      "step": 37610,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5085346516183193,
      "grad_norm": 2.8205785751342773,
      "learning_rate": 2.2417356570173347e-06,
      "loss": 0.2882669925689697,
      "memory(GiB)": 72.72,
      "step": 37615,
      "token_acc": 0.6515151515151515,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5090010260236917,
      "grad_norm": 5.420036315917969,
      "learning_rate": 2.2404494006317144e-06,
      "loss": 0.28229358196258547,
      "memory(GiB)": 72.72,
      "step": 37620,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5094674004290645,
      "grad_norm": 2.355071544647217,
      "learning_rate": 2.2391634068088323e-06,
      "loss": 0.2601816177368164,
      "memory(GiB)": 72.72,
      "step": 37625,
      "token_acc": 0.9024390243902439,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 3.5099337748344372,
      "grad_norm": 3.6123714447021484,
      "learning_rate": 2.2378776756710472e-06,
      "loss": 0.2881042242050171,
      "memory(GiB)": 72.72,
      "step": 37630,
      "token_acc": 0.8623188405797102,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.5104001492398096,
      "grad_norm": 2.6787426471710205,
      "learning_rate": 2.2365922073406924e-06,
      "loss": 0.3112175941467285,
      "memory(GiB)": 72.72,
      "step": 37635,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5108665236451824,
      "grad_norm": 2.943897008895874,
      "learning_rate": 2.2353070019400764e-06,
      "loss": 0.25793919563293455,
      "memory(GiB)": 72.72,
      "step": 37640,
      "token_acc": 0.52,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.511332898050555,
      "grad_norm": 2.35129976272583,
      "learning_rate": 2.234022059591482e-06,
      "loss": 0.2538586616516113,
      "memory(GiB)": 72.72,
      "step": 37645,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5117992724559275,
      "grad_norm": 4.034823894500732,
      "learning_rate": 2.2327373804171674e-06,
      "loss": 0.29080843925476074,
      "memory(GiB)": 72.72,
      "step": 37650,
      "token_acc": 0.7543859649122807,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.5122656468613003,
      "grad_norm": 2.3588101863861084,
      "learning_rate": 2.2314529645393675e-06,
      "loss": 0.3073408126831055,
      "memory(GiB)": 72.72,
      "step": 37655,
      "token_acc": 0.660377358490566,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.5127320212666726,
      "grad_norm": 3.6215109825134277,
      "learning_rate": 2.2301688120802883e-06,
      "loss": 0.2949725866317749,
      "memory(GiB)": 72.72,
      "step": 37660,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5131983956720454,
      "grad_norm": 33.11538314819336,
      "learning_rate": 2.228884923162114e-06,
      "loss": 0.30294013023376465,
      "memory(GiB)": 72.72,
      "step": 37665,
      "token_acc": 0.96875,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.513664770077418,
      "grad_norm": 8.390127182006836,
      "learning_rate": 2.2276012979070033e-06,
      "loss": 0.32032830715179444,
      "memory(GiB)": 72.72,
      "step": 37670,
      "token_acc": 0.5633802816901409,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.514131144482791,
      "grad_norm": 3.7187352180480957,
      "learning_rate": 2.226317936437088e-06,
      "loss": 0.2905410289764404,
      "memory(GiB)": 72.72,
      "step": 37675,
      "token_acc": 0.62,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.5145975188881633,
      "grad_norm": 6.224433898925781,
      "learning_rate": 2.2250348388744762e-06,
      "loss": 0.3097069501876831,
      "memory(GiB)": 72.72,
      "step": 37680,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.515063893293536,
      "grad_norm": 2.0080530643463135,
      "learning_rate": 2.2237520053412497e-06,
      "loss": 0.26690030097961426,
      "memory(GiB)": 72.72,
      "step": 37685,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.5155302676989084,
      "grad_norm": 3.8877410888671875,
      "learning_rate": 2.222469435959469e-06,
      "loss": 0.28796043395996096,
      "memory(GiB)": 72.72,
      "step": 37690,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.515996642104281,
      "grad_norm": 2.3856897354125977,
      "learning_rate": 2.2211871308511657e-06,
      "loss": 0.2517114162445068,
      "memory(GiB)": 72.72,
      "step": 37695,
      "token_acc": 0.4166666666666667,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.516463016509654,
      "grad_norm": 3.169316291809082,
      "learning_rate": 2.2199050901383456e-06,
      "loss": 0.2902965545654297,
      "memory(GiB)": 72.72,
      "step": 37700,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.5169293909150268,
      "grad_norm": 4.293824195861816,
      "learning_rate": 2.2186233139429925e-06,
      "loss": 0.34199116230010984,
      "memory(GiB)": 72.72,
      "step": 37705,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.517395765320399,
      "grad_norm": 2.262288808822632,
      "learning_rate": 2.2173418023870646e-06,
      "loss": 0.268435001373291,
      "memory(GiB)": 72.72,
      "step": 37710,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.517862139725772,
      "grad_norm": 11.642126083374023,
      "learning_rate": 2.2160605555924902e-06,
      "loss": 0.29334776401519774,
      "memory(GiB)": 72.72,
      "step": 37715,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5183285141311442,
      "grad_norm": 1.8828256130218506,
      "learning_rate": 2.2147795736811757e-06,
      "loss": 0.2636159896850586,
      "memory(GiB)": 72.72,
      "step": 37720,
      "token_acc": 0.9560439560439561,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.518794888536517,
      "grad_norm": 2.9102485179901123,
      "learning_rate": 2.2134988567750065e-06,
      "loss": 0.27158417701721194,
      "memory(GiB)": 72.72,
      "step": 37725,
      "token_acc": 0.78,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.51926126294189,
      "grad_norm": 3.0981786251068115,
      "learning_rate": 2.212218404995837e-06,
      "loss": 0.30648245811462405,
      "memory(GiB)": 72.72,
      "step": 37730,
      "token_acc": 0.48148148148148145,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5197276373472626,
      "grad_norm": 2.93330717086792,
      "learning_rate": 2.2109382184654986e-06,
      "loss": 0.3040749549865723,
      "memory(GiB)": 72.72,
      "step": 37735,
      "token_acc": 0.639344262295082,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.520194011752635,
      "grad_norm": 3.575383186340332,
      "learning_rate": 2.2096582973057967e-06,
      "loss": 0.2775080680847168,
      "memory(GiB)": 72.72,
      "step": 37740,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5206603861580077,
      "grad_norm": 2.8332152366638184,
      "learning_rate": 2.2083786416385123e-06,
      "loss": 0.2838072538375854,
      "memory(GiB)": 72.72,
      "step": 37745,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.52112676056338,
      "grad_norm": 2.4510345458984375,
      "learning_rate": 2.2070992515854e-06,
      "loss": 0.32667696475982666,
      "memory(GiB)": 72.72,
      "step": 37750,
      "token_acc": 0.6206896551724138,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.521593134968753,
      "grad_norm": 2.4385054111480713,
      "learning_rate": 2.20582012726819e-06,
      "loss": 0.2875649929046631,
      "memory(GiB)": 72.72,
      "step": 37755,
      "token_acc": 0.8095238095238095,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 3.5220595093741256,
      "grad_norm": 2.786031723022461,
      "learning_rate": 2.204541268808588e-06,
      "loss": 0.3084279537200928,
      "memory(GiB)": 72.72,
      "step": 37760,
      "token_acc": 0.7254901960784313,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 3.5225258837794984,
      "grad_norm": 2.7291152477264404,
      "learning_rate": 2.2032626763282717e-06,
      "loss": 0.2919711351394653,
      "memory(GiB)": 72.72,
      "step": 37765,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.5229922581848707,
      "grad_norm": 3.4082605838775635,
      "learning_rate": 2.2019843499488964e-06,
      "loss": 0.26949143409729004,
      "memory(GiB)": 72.72,
      "step": 37770,
      "token_acc": 0.5573770491803278,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.5234586325902435,
      "grad_norm": 2.981271982192993,
      "learning_rate": 2.2007062897920904e-06,
      "loss": 0.28320310115814207,
      "memory(GiB)": 72.72,
      "step": 37775,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.523925006995616,
      "grad_norm": 2.6771559715270996,
      "learning_rate": 2.1994284959794583e-06,
      "loss": 0.29579863548278806,
      "memory(GiB)": 72.72,
      "step": 37780,
      "token_acc": 0.6545454545454545,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5243913814009886,
      "grad_norm": 3.650783061981201,
      "learning_rate": 2.198150968632575e-06,
      "loss": 0.3124518871307373,
      "memory(GiB)": 72.72,
      "step": 37785,
      "token_acc": 0.5961538461538461,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5248577558063614,
      "grad_norm": 2.3234496116638184,
      "learning_rate": 2.196873707872998e-06,
      "loss": 0.26613287925720214,
      "memory(GiB)": 72.72,
      "step": 37790,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.525324130211734,
      "grad_norm": 2.3482017517089844,
      "learning_rate": 2.195596713822252e-06,
      "loss": 0.2655160427093506,
      "memory(GiB)": 72.72,
      "step": 37795,
      "token_acc": 0.7222222222222222,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5257905046171065,
      "grad_norm": 5.615509986877441,
      "learning_rate": 2.19431998660184e-06,
      "loss": 0.2892764091491699,
      "memory(GiB)": 72.72,
      "step": 37800,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5262568790224793,
      "grad_norm": 2.8064069747924805,
      "learning_rate": 2.1930435263332394e-06,
      "loss": 0.2956697463989258,
      "memory(GiB)": 72.72,
      "step": 37805,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.5267232534278516,
      "grad_norm": 2.5364561080932617,
      "learning_rate": 2.191767333137899e-06,
      "loss": 0.2741673469543457,
      "memory(GiB)": 72.72,
      "step": 37810,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.5271896278332244,
      "grad_norm": 3.116607189178467,
      "learning_rate": 2.190491407137246e-06,
      "loss": 0.3016797065734863,
      "memory(GiB)": 72.72,
      "step": 37815,
      "token_acc": 0.9382716049382716,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.527656002238597,
      "grad_norm": 3.133896589279175,
      "learning_rate": 2.189215748452678e-06,
      "loss": 0.2696655035018921,
      "memory(GiB)": 72.72,
      "step": 37820,
      "token_acc": 0.74,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.52812237664397,
      "grad_norm": 3.8674159049987793,
      "learning_rate": 2.1879403572055753e-06,
      "loss": 0.2893038272857666,
      "memory(GiB)": 72.72,
      "step": 37825,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5285887510493423,
      "grad_norm": 2.669654130935669,
      "learning_rate": 2.1866652335172844e-06,
      "loss": 0.30274019241333006,
      "memory(GiB)": 72.72,
      "step": 37830,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.529055125454715,
      "grad_norm": 2.5510122776031494,
      "learning_rate": 2.1853903775091295e-06,
      "loss": 0.26974318027496336,
      "memory(GiB)": 72.72,
      "step": 37835,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5295214998600875,
      "grad_norm": 2.295031785964966,
      "learning_rate": 2.1841157893024102e-06,
      "loss": 0.2670677661895752,
      "memory(GiB)": 72.72,
      "step": 37840,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 3.5299878742654602,
      "grad_norm": 3.356084108352661,
      "learning_rate": 2.1828414690183993e-06,
      "loss": 0.29405503273010253,
      "memory(GiB)": 72.72,
      "step": 37845,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 3.530454248670833,
      "grad_norm": 4.110642433166504,
      "learning_rate": 2.1815674167783436e-06,
      "loss": 0.30316035747528075,
      "memory(GiB)": 72.72,
      "step": 37850,
      "token_acc": 0.5892857142857143,
      "train_speed(iter/s)": 0.251439
    },
    {
      "epoch": 3.530920623076206,
      "grad_norm": 2.917449951171875,
      "learning_rate": 2.180293632703466e-06,
      "loss": 0.27094221115112305,
      "memory(GiB)": 72.72,
      "step": 37855,
      "token_acc": 0.5454545454545454,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 3.531386997481578,
      "grad_norm": 2.7378787994384766,
      "learning_rate": 2.1790201169149624e-06,
      "loss": 0.27554681301116946,
      "memory(GiB)": 72.72,
      "step": 37860,
      "token_acc": 0.5365853658536586,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.531853371886951,
      "grad_norm": 2.6787681579589844,
      "learning_rate": 2.1777468695340047e-06,
      "loss": 0.3017099380493164,
      "memory(GiB)": 72.72,
      "step": 37865,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.5323197462923233,
      "grad_norm": 3.4655323028564453,
      "learning_rate": 2.1764738906817385e-06,
      "loss": 0.2914461135864258,
      "memory(GiB)": 72.72,
      "step": 37870,
      "token_acc": 0.5833333333333334,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.532786120697696,
      "grad_norm": 2.8387651443481445,
      "learning_rate": 2.1752011804792834e-06,
      "loss": 0.2996448278427124,
      "memory(GiB)": 72.72,
      "step": 37875,
      "token_acc": 0.6705882352941176,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.533252495103069,
      "grad_norm": 2.3529889583587646,
      "learning_rate": 2.173928739047734e-06,
      "loss": 0.30158319473266604,
      "memory(GiB)": 72.72,
      "step": 37880,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.5337188695084416,
      "grad_norm": 5.879361629486084,
      "learning_rate": 2.172656566508159e-06,
      "loss": 0.2781817436218262,
      "memory(GiB)": 72.72,
      "step": 37885,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.534185243913814,
      "grad_norm": 3.260239601135254,
      "learning_rate": 2.1713846629816e-06,
      "loss": 0.3329185485839844,
      "memory(GiB)": 72.72,
      "step": 37890,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.5346516183191867,
      "grad_norm": 3.516893148422241,
      "learning_rate": 2.170113028589079e-06,
      "loss": 0.267830491065979,
      "memory(GiB)": 72.72,
      "step": 37895,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 3.535117992724559,
      "grad_norm": 5.758932113647461,
      "learning_rate": 2.1688416634515845e-06,
      "loss": 0.2968616247177124,
      "memory(GiB)": 72.72,
      "step": 37900,
      "token_acc": 0.7446808510638298,
      "train_speed(iter/s)": 0.25144
    },
    {
      "epoch": 3.535584367129932,
      "grad_norm": 7.545707702636719,
      "learning_rate": 2.167570567690087e-06,
      "loss": 0.2823646068572998,
      "memory(GiB)": 72.72,
      "step": 37905,
      "train_speed(iter/s)": 0.251438
    },
    {
      "epoch": 3.5360507415353046,
      "grad_norm": 2.703113555908203,
      "learning_rate": 2.166299741425522e-06,
      "loss": 0.28686387538909913,
      "memory(GiB)": 72.72,
      "step": 37910,
      "token_acc": 0.9523809523809523,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 3.5365171159406774,
      "grad_norm": 2.926541328430176,
      "learning_rate": 2.1650291847788074e-06,
      "loss": 0.2662333965301514,
      "memory(GiB)": 72.72,
      "step": 37915,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 3.5369834903460498,
      "grad_norm": 3.2769834995269775,
      "learning_rate": 2.1637588978708323e-06,
      "loss": 0.26621084213256835,
      "memory(GiB)": 72.72,
      "step": 37920,
      "token_acc": 0.9493670886075949,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5374498647514225,
      "grad_norm": 2.7490336894989014,
      "learning_rate": 2.1624888808224596e-06,
      "loss": 0.3174001216888428,
      "memory(GiB)": 72.72,
      "step": 37925,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.537916239156795,
      "grad_norm": 2.678615093231201,
      "learning_rate": 2.16121913375453e-06,
      "loss": 0.27919893264770507,
      "memory(GiB)": 72.72,
      "step": 37930,
      "token_acc": 0.7096774193548387,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5383826135621677,
      "grad_norm": 2.942035436630249,
      "learning_rate": 2.1599496567878546e-06,
      "loss": 0.28909275531768797,
      "memory(GiB)": 72.72,
      "step": 37935,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.5388489879675404,
      "grad_norm": 2.55825138092041,
      "learning_rate": 2.1586804500432213e-06,
      "loss": 0.297711181640625,
      "memory(GiB)": 72.72,
      "step": 37940,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.539315362372913,
      "grad_norm": 4.857644557952881,
      "learning_rate": 2.157411513641389e-06,
      "loss": 0.2862647533416748,
      "memory(GiB)": 72.72,
      "step": 37945,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.5397817367782856,
      "grad_norm": 3.97522234916687,
      "learning_rate": 2.1561428477030955e-06,
      "loss": 0.2936528205871582,
      "memory(GiB)": 72.72,
      "step": 37950,
      "token_acc": 0.6756756756756757,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.5402481111836583,
      "grad_norm": 14.369681358337402,
      "learning_rate": 2.1548744523490487e-06,
      "loss": 0.3045816898345947,
      "memory(GiB)": 72.72,
      "step": 37955,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.5407144855890307,
      "grad_norm": 3.489567518234253,
      "learning_rate": 2.1536063276999336e-06,
      "loss": 0.32286574840545657,
      "memory(GiB)": 72.72,
      "step": 37960,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5411808599944035,
      "grad_norm": 7.4620137214660645,
      "learning_rate": 2.1523384738764074e-06,
      "loss": 0.31482298374176027,
      "memory(GiB)": 72.72,
      "step": 37965,
      "token_acc": 0.7619047619047619,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.5416472343997762,
      "grad_norm": 3.011714220046997,
      "learning_rate": 2.151070890999103e-06,
      "loss": 0.28217382431030275,
      "memory(GiB)": 72.72,
      "step": 37970,
      "token_acc": 0.9578947368421052,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.542113608805149,
      "grad_norm": 2.5663013458251953,
      "learning_rate": 2.1498035791886276e-06,
      "loss": 0.32240934371948243,
      "memory(GiB)": 72.72,
      "step": 37975,
      "token_acc": 0.5344827586206896,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.5425799832105214,
      "grad_norm": 3.8252158164978027,
      "learning_rate": 2.1485365385655605e-06,
      "loss": 0.30594596862792967,
      "memory(GiB)": 72.72,
      "step": 37980,
      "token_acc": 0.9325842696629213,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.543046357615894,
      "grad_norm": 2.71509051322937,
      "learning_rate": 2.147269769250458e-06,
      "loss": 0.3132927417755127,
      "memory(GiB)": 72.72,
      "step": 37985,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.5435127320212665,
      "grad_norm": 2.79215931892395,
      "learning_rate": 2.146003271363847e-06,
      "loss": 0.28165924549102783,
      "memory(GiB)": 72.72,
      "step": 37990,
      "token_acc": 0.5348837209302325,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.5439791064266393,
      "grad_norm": 2.1467089653015137,
      "learning_rate": 2.1447370450262343e-06,
      "loss": 0.2805872201919556,
      "memory(GiB)": 72.72,
      "step": 37995,
      "token_acc": 0.7647058823529411,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.544445480832012,
      "grad_norm": 2.8263919353485107,
      "learning_rate": 2.143471090358097e-06,
      "loss": 0.30461440086364744,
      "memory(GiB)": 72.72,
      "step": 38000,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.544911855237385,
      "grad_norm": 3.0832016468048096,
      "learning_rate": 2.1422054074798863e-06,
      "loss": 0.29949991703033446,
      "memory(GiB)": 72.72,
      "step": 38005,
      "token_acc": 0.7674418604651163,
      "train_speed(iter/s)": 0.251398
    },
    {
      "epoch": 3.545378229642757,
      "grad_norm": 3.7552926540374756,
      "learning_rate": 2.1409399965120263e-06,
      "loss": 0.27399744987487795,
      "memory(GiB)": 72.72,
      "step": 38010,
      "train_speed(iter/s)": 0.251396
    },
    {
      "epoch": 3.54584460404813,
      "grad_norm": 4.8888139724731445,
      "learning_rate": 2.1396748575749183e-06,
      "loss": 0.291563892364502,
      "memory(GiB)": 72.72,
      "step": 38015,
      "train_speed(iter/s)": 0.251395
    },
    {
      "epoch": 3.5463109784535023,
      "grad_norm": 6.011248588562012,
      "learning_rate": 2.1384099907889356e-06,
      "loss": 0.2802287578582764,
      "memory(GiB)": 72.72,
      "step": 38020,
      "train_speed(iter/s)": 0.251394
    },
    {
      "epoch": 3.546777352858875,
      "grad_norm": 3.5576906204223633,
      "learning_rate": 2.137145396274425e-06,
      "loss": 0.3235476016998291,
      "memory(GiB)": 72.72,
      "step": 38025,
      "train_speed(iter/s)": 0.251394
    },
    {
      "epoch": 3.547243727264248,
      "grad_norm": 2.5096564292907715,
      "learning_rate": 2.135881074151713e-06,
      "loss": 0.3179991006851196,
      "memory(GiB)": 72.72,
      "step": 38030,
      "token_acc": 0.6216216216216216,
      "train_speed(iter/s)": 0.251395
    },
    {
      "epoch": 3.5477101016696206,
      "grad_norm": 2.756753921508789,
      "learning_rate": 2.1346170245410937e-06,
      "loss": 0.2879662990570068,
      "memory(GiB)": 72.72,
      "step": 38035,
      "train_speed(iter/s)": 0.251397
    },
    {
      "epoch": 3.548176476074993,
      "grad_norm": 2.925457000732422,
      "learning_rate": 2.1333532475628366e-06,
      "loss": 0.30349686145782473,
      "memory(GiB)": 72.72,
      "step": 38040,
      "train_speed(iter/s)": 0.2514
    },
    {
      "epoch": 3.5486428504803658,
      "grad_norm": 3.6313507556915283,
      "learning_rate": 2.1320897433371878e-06,
      "loss": 0.30035102367401123,
      "memory(GiB)": 72.72,
      "step": 38045,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 3.549109224885738,
      "grad_norm": 2.8582634925842285,
      "learning_rate": 2.130826511984365e-06,
      "loss": 0.28487415313720704,
      "memory(GiB)": 72.72,
      "step": 38050,
      "train_speed(iter/s)": 0.2514
    },
    {
      "epoch": 3.549575599291111,
      "grad_norm": 2.6674981117248535,
      "learning_rate": 2.129563553624561e-06,
      "loss": 0.30513825416564944,
      "memory(GiB)": 72.72,
      "step": 38055,
      "token_acc": 0.5757575757575758,
      "train_speed(iter/s)": 0.251401
    },
    {
      "epoch": 3.5500419736964837,
      "grad_norm": 3.009101629257202,
      "learning_rate": 2.128300868377942e-06,
      "loss": 0.2703361749649048,
      "memory(GiB)": 72.72,
      "step": 38060,
      "token_acc": 0.7551020408163265,
      "train_speed(iter/s)": 0.251402
    },
    {
      "epoch": 3.550508348101856,
      "grad_norm": 1.8732566833496094,
      "learning_rate": 2.127038456364649e-06,
      "loss": 0.27808194160461425,
      "memory(GiB)": 72.72,
      "step": 38065,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.251403
    },
    {
      "epoch": 3.550974722507229,
      "grad_norm": 2.4645471572875977,
      "learning_rate": 2.125776317704797e-06,
      "loss": 0.2605142593383789,
      "memory(GiB)": 72.72,
      "step": 38070,
      "token_acc": 0.5625,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.5514410969126016,
      "grad_norm": 3.9326388835906982,
      "learning_rate": 2.1245144525184736e-06,
      "loss": 0.3035807371139526,
      "memory(GiB)": 72.72,
      "step": 38075,
      "token_acc": 0.8931297709923665,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.551907471317974,
      "grad_norm": 2.942192316055298,
      "learning_rate": 2.123252860925742e-06,
      "loss": 0.301781964302063,
      "memory(GiB)": 72.72,
      "step": 38080,
      "token_acc": 0.6470588235294118,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.5523738457233467,
      "grad_norm": 2.4223766326904297,
      "learning_rate": 2.121991543046638e-06,
      "loss": 0.29613518714904785,
      "memory(GiB)": 72.72,
      "step": 38085,
      "token_acc": 0.7288135593220338,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.5528402201287195,
      "grad_norm": 2.7228684425354004,
      "learning_rate": 2.120730499001172e-06,
      "loss": 0.28008458614349363,
      "memory(GiB)": 72.72,
      "step": 38090,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.553306594534092,
      "grad_norm": 2.3428843021392822,
      "learning_rate": 2.11946972890933e-06,
      "loss": 0.2519089221954346,
      "memory(GiB)": 72.72,
      "step": 38095,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.5537729689394646,
      "grad_norm": 2.818483829498291,
      "learning_rate": 2.1182092328910727e-06,
      "loss": 0.3137312173843384,
      "memory(GiB)": 72.72,
      "step": 38100,
      "token_acc": 0.576271186440678,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.5542393433448374,
      "grad_norm": 2.692073106765747,
      "learning_rate": 2.1169490110663265e-06,
      "loss": 0.2434938907623291,
      "memory(GiB)": 72.72,
      "step": 38105,
      "train_speed(iter/s)": 0.251405
    },
    {
      "epoch": 3.5547057177502097,
      "grad_norm": 2.7611961364746094,
      "learning_rate": 2.1156890635550007e-06,
      "loss": 0.2709318161010742,
      "memory(GiB)": 72.72,
      "step": 38110,
      "token_acc": 0.9595959595959596,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.5551720921555825,
      "grad_norm": 3.5330827236175537,
      "learning_rate": 2.1144293904769754e-06,
      "loss": 0.2573745012283325,
      "memory(GiB)": 72.72,
      "step": 38115,
      "token_acc": 0.958904109589041,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.5556384665609553,
      "grad_norm": 4.688493728637695,
      "learning_rate": 2.1131699919521036e-06,
      "loss": 0.2983083724975586,
      "memory(GiB)": 72.72,
      "step": 38120,
      "token_acc": 0.5531914893617021,
      "train_speed(iter/s)": 0.251409
    },
    {
      "epoch": 3.5561048409663276,
      "grad_norm": 2.812793016433716,
      "learning_rate": 2.111910868100213e-06,
      "loss": 0.29994850158691405,
      "memory(GiB)": 72.72,
      "step": 38125,
      "token_acc": 0.8924050632911392,
      "train_speed(iter/s)": 0.25141
    },
    {
      "epoch": 3.5565712153717004,
      "grad_norm": 3.2406187057495117,
      "learning_rate": 2.110652019041108e-06,
      "loss": 0.275038743019104,
      "memory(GiB)": 72.72,
      "step": 38130,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 3.557037589777073,
      "grad_norm": 4.795763969421387,
      "learning_rate": 2.1093934448945625e-06,
      "loss": 0.2410513401031494,
      "memory(GiB)": 72.72,
      "step": 38135,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.5575039641824455,
      "grad_norm": 1.8515210151672363,
      "learning_rate": 2.108135145780326e-06,
      "loss": 0.27876079082489014,
      "memory(GiB)": 72.72,
      "step": 38140,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.5579703385878183,
      "grad_norm": 3.3995935916900635,
      "learning_rate": 2.106877121818121e-06,
      "loss": 0.31897294521331787,
      "memory(GiB)": 72.72,
      "step": 38145,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.558436712993191,
      "grad_norm": 3.2073540687561035,
      "learning_rate": 2.1056193731276463e-06,
      "loss": 0.26834583282470703,
      "memory(GiB)": 72.72,
      "step": 38150,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.5589030873985634,
      "grad_norm": 7.162073135375977,
      "learning_rate": 2.1043618998285715e-06,
      "loss": 0.30413386821746824,
      "memory(GiB)": 72.72,
      "step": 38155,
      "token_acc": 0.7377049180327869,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.559369461803936,
      "grad_norm": 2.4263103008270264,
      "learning_rate": 2.1031047020405417e-06,
      "loss": 0.27073466777801514,
      "memory(GiB)": 72.72,
      "step": 38160,
      "token_acc": 0.8707482993197279,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.559835836209309,
      "grad_norm": 4.768346309661865,
      "learning_rate": 2.1018477798831756e-06,
      "loss": 0.30003650188446046,
      "memory(GiB)": 72.72,
      "step": 38165,
      "train_speed(iter/s)": 0.251406
    },
    {
      "epoch": 3.5603022106146813,
      "grad_norm": 2.4227993488311768,
      "learning_rate": 2.100591133476065e-06,
      "loss": 0.3032320737838745,
      "memory(GiB)": 72.72,
      "step": 38170,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 3.560768585020054,
      "grad_norm": 2.8909060955047607,
      "learning_rate": 2.099334762938776e-06,
      "loss": 0.29133334159851076,
      "memory(GiB)": 72.72,
      "step": 38175,
      "train_speed(iter/s)": 0.251407
    },
    {
      "epoch": 3.561234959425427,
      "grad_norm": 2.223273277282715,
      "learning_rate": 2.0980786683908494e-06,
      "loss": 0.29092798233032224,
      "memory(GiB)": 72.72,
      "step": 38180,
      "token_acc": 0.9655172413793104,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 3.5617013338307992,
      "grad_norm": 3.6870362758636475,
      "learning_rate": 2.096822849951797e-06,
      "loss": 0.2931087493896484,
      "memory(GiB)": 72.72,
      "step": 38185,
      "token_acc": 0.7098765432098766,
      "train_speed(iter/s)": 0.251408
    },
    {
      "epoch": 3.562167708236172,
      "grad_norm": 2.9989566802978516,
      "learning_rate": 2.0955673077411077e-06,
      "loss": 0.3241525173187256,
      "memory(GiB)": 72.72,
      "step": 38190,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 3.562634082641545,
      "grad_norm": 5.382513999938965,
      "learning_rate": 2.0943120418782397e-06,
      "loss": 0.29517307281494143,
      "memory(GiB)": 72.72,
      "step": 38195,
      "token_acc": 0.6875,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 3.563100457046917,
      "grad_norm": 3.0200822353363037,
      "learning_rate": 2.0930570524826334e-06,
      "loss": 0.31266770362854,
      "memory(GiB)": 72.72,
      "step": 38200,
      "train_speed(iter/s)": 0.251412
    },
    {
      "epoch": 3.56356683145229,
      "grad_norm": 3.5125443935394287,
      "learning_rate": 2.091802339673691e-06,
      "loss": 0.282051682472229,
      "memory(GiB)": 72.72,
      "step": 38205,
      "train_speed(iter/s)": 0.251414
    },
    {
      "epoch": 3.5640332058576627,
      "grad_norm": 3.909270763397217,
      "learning_rate": 2.090547903570798e-06,
      "loss": 0.27693724632263184,
      "memory(GiB)": 72.72,
      "step": 38210,
      "token_acc": 0.795774647887324,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.564499580263035,
      "grad_norm": 8.841967582702637,
      "learning_rate": 2.0892937442933087e-06,
      "loss": 0.2689206123352051,
      "memory(GiB)": 72.72,
      "step": 38215,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.564965954668408,
      "grad_norm": 2.5687415599823,
      "learning_rate": 2.0880398619605534e-06,
      "loss": 0.2658601522445679,
      "memory(GiB)": 72.72,
      "step": 38220,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.56543232907378,
      "grad_norm": 3.0431582927703857,
      "learning_rate": 2.0867862566918347e-06,
      "loss": 0.28499927520751955,
      "memory(GiB)": 72.72,
      "step": 38225,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.565898703479153,
      "grad_norm": 10.853224754333496,
      "learning_rate": 2.0855329286064267e-06,
      "loss": 0.28149237632751467,
      "memory(GiB)": 72.72,
      "step": 38230,
      "token_acc": 0.7111111111111111,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.5663650778845257,
      "grad_norm": 3.7889926433563232,
      "learning_rate": 2.0842798778235844e-06,
      "loss": 0.28478183746337893,
      "memory(GiB)": 72.72,
      "step": 38235,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.5668314522898985,
      "grad_norm": 5.35929012298584,
      "learning_rate": 2.08302710446253e-06,
      "loss": 0.306703519821167,
      "memory(GiB)": 72.72,
      "step": 38240,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.567297826695271,
      "grad_norm": 2.3338701725006104,
      "learning_rate": 2.0817746086424604e-06,
      "loss": 0.30160090923309324,
      "memory(GiB)": 72.72,
      "step": 38245,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5677642011006436,
      "grad_norm": 2.724769353866577,
      "learning_rate": 2.0805223904825474e-06,
      "loss": 0.2567939043045044,
      "memory(GiB)": 72.72,
      "step": 38250,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.568230575506016,
      "grad_norm": 2.465162515640259,
      "learning_rate": 2.0792704501019352e-06,
      "loss": 0.28673014640808103,
      "memory(GiB)": 72.72,
      "step": 38255,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5686969499113887,
      "grad_norm": 2.9817495346069336,
      "learning_rate": 2.0780187876197417e-06,
      "loss": 0.2674291133880615,
      "memory(GiB)": 72.72,
      "step": 38260,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5691633243167615,
      "grad_norm": 5.097166061401367,
      "learning_rate": 2.0767674031550593e-06,
      "loss": 0.29824075698852537,
      "memory(GiB)": 72.72,
      "step": 38265,
      "token_acc": 0.7230769230769231,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.5696296987221343,
      "grad_norm": 2.4036691188812256,
      "learning_rate": 2.0755162968269533e-06,
      "loss": 0.2566878318786621,
      "memory(GiB)": 72.72,
      "step": 38270,
      "token_acc": 0.5794392523364486,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.5700960731275067,
      "grad_norm": 3.104583978652954,
      "learning_rate": 2.0742654687544623e-06,
      "loss": 0.2653511524200439,
      "memory(GiB)": 72.72,
      "step": 38275,
      "token_acc": 0.7115384615384616,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.5705624475328794,
      "grad_norm": 2.755270004272461,
      "learning_rate": 2.0730149190565995e-06,
      "loss": 0.27174551486968995,
      "memory(GiB)": 72.72,
      "step": 38280,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.5710288219382518,
      "grad_norm": 4.755852699279785,
      "learning_rate": 2.07176464785235e-06,
      "loss": 0.2858225107192993,
      "memory(GiB)": 72.72,
      "step": 38285,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5714951963436246,
      "grad_norm": 2.67549204826355,
      "learning_rate": 2.0705146552606738e-06,
      "loss": 0.3142873287200928,
      "memory(GiB)": 72.72,
      "step": 38290,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5719615707489973,
      "grad_norm": 6.9561872482299805,
      "learning_rate": 2.0692649414005018e-06,
      "loss": 0.29266526699066164,
      "memory(GiB)": 72.72,
      "step": 38295,
      "token_acc": 0.9333333333333333,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.57242794515437,
      "grad_norm": 3.3300135135650635,
      "learning_rate": 2.0680155063907457e-06,
      "loss": 0.2824493646621704,
      "memory(GiB)": 72.72,
      "step": 38300,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.5728943195597425,
      "grad_norm": 4.213883399963379,
      "learning_rate": 2.0667663503502807e-06,
      "loss": 0.27284629344940187,
      "memory(GiB)": 72.72,
      "step": 38305,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.5733606939651152,
      "grad_norm": 2.4388427734375,
      "learning_rate": 2.065517473397961e-06,
      "loss": 0.2876695156097412,
      "memory(GiB)": 72.72,
      "step": 38310,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.5738270683704876,
      "grad_norm": 4.065563678741455,
      "learning_rate": 2.0642688756526136e-06,
      "loss": 0.2707245111465454,
      "memory(GiB)": 72.72,
      "step": 38315,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.5742934427758604,
      "grad_norm": 2.7465145587921143,
      "learning_rate": 2.063020557233039e-06,
      "loss": 0.26521730422973633,
      "memory(GiB)": 72.72,
      "step": 38320,
      "token_acc": 0.5957446808510638,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 3.574759817181233,
      "grad_norm": 2.8394651412963867,
      "learning_rate": 2.0617725182580113e-06,
      "loss": 0.30010647773742677,
      "memory(GiB)": 72.72,
      "step": 38325,
      "train_speed(iter/s)": 0.251415
    },
    {
      "epoch": 3.575226191586606,
      "grad_norm": 2.713789939880371,
      "learning_rate": 2.0605247588462747e-06,
      "loss": 0.25513691902160646,
      "memory(GiB)": 72.72,
      "step": 38330,
      "token_acc": 0.6973684210526315,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.5756925659919783,
      "grad_norm": 2.983074188232422,
      "learning_rate": 2.0592772791165545e-06,
      "loss": 0.2628457546234131,
      "memory(GiB)": 72.72,
      "step": 38335,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.576158940397351,
      "grad_norm": 3.394965410232544,
      "learning_rate": 2.058030079187541e-06,
      "loss": 0.29677591323852537,
      "memory(GiB)": 72.72,
      "step": 38340,
      "token_acc": 0.7735849056603774,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5766253148027234,
      "grad_norm": 3.476233720779419,
      "learning_rate": 2.0567831591779035e-06,
      "loss": 0.2923712730407715,
      "memory(GiB)": 72.72,
      "step": 38345,
      "token_acc": 0.5303030303030303,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.577091689208096,
      "grad_norm": 4.07593297958374,
      "learning_rate": 2.055536519206281e-06,
      "loss": 0.3128413915634155,
      "memory(GiB)": 72.72,
      "step": 38350,
      "token_acc": 0.8172043010752689,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.577558063613469,
      "grad_norm": 4.064759254455566,
      "learning_rate": 2.05429015939129e-06,
      "loss": 0.2964359998703003,
      "memory(GiB)": 72.72,
      "step": 38355,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5780244380188417,
      "grad_norm": 3.16357421875,
      "learning_rate": 2.0530440798515146e-06,
      "loss": 0.2761862277984619,
      "memory(GiB)": 72.72,
      "step": 38360,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.578490812424214,
      "grad_norm": 2.4053375720977783,
      "learning_rate": 2.051798280705514e-06,
      "loss": 0.30073771476745603,
      "memory(GiB)": 72.72,
      "step": 38365,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.578957186829587,
      "grad_norm": 5.727643013000488,
      "learning_rate": 2.050552762071827e-06,
      "loss": 0.3094335079193115,
      "memory(GiB)": 72.72,
      "step": 38370,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.579423561234959,
      "grad_norm": 3.0119476318359375,
      "learning_rate": 2.0493075240689584e-06,
      "loss": 0.29667208194732664,
      "memory(GiB)": 72.72,
      "step": 38375,
      "token_acc": 0.7884615384615384,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.579889935640332,
      "grad_norm": 2.5070173740386963,
      "learning_rate": 2.0480625668153898e-06,
      "loss": 0.3121944427490234,
      "memory(GiB)": 72.72,
      "step": 38380,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.5803563100457048,
      "grad_norm": 2.4113972187042236,
      "learning_rate": 2.046817890429574e-06,
      "loss": 0.2652764797210693,
      "memory(GiB)": 72.72,
      "step": 38385,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.5808226844510775,
      "grad_norm": 6.634678363800049,
      "learning_rate": 2.0455734950299384e-06,
      "loss": 0.27062187194824217,
      "memory(GiB)": 72.72,
      "step": 38390,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.58128905885645,
      "grad_norm": 8.413389205932617,
      "learning_rate": 2.0443293807348815e-06,
      "loss": 0.27528440952301025,
      "memory(GiB)": 72.72,
      "step": 38395,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5817554332618227,
      "grad_norm": 3.5043869018554688,
      "learning_rate": 2.0430855476627827e-06,
      "loss": 0.30287387371063235,
      "memory(GiB)": 72.72,
      "step": 38400,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.582221807667195,
      "grad_norm": 3.4346518516540527,
      "learning_rate": 2.0418419959319824e-06,
      "loss": 0.28194074630737304,
      "memory(GiB)": 72.72,
      "step": 38405,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.582688182072568,
      "grad_norm": 2.8569910526275635,
      "learning_rate": 2.0405987256608038e-06,
      "loss": 0.3072300910949707,
      "memory(GiB)": 72.72,
      "step": 38410,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.5831545564779406,
      "grad_norm": 2.8418803215026855,
      "learning_rate": 2.0393557369675406e-06,
      "loss": 0.29119076728820803,
      "memory(GiB)": 72.72,
      "step": 38415,
      "token_acc": 0.5408163265306123,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.5836209308833133,
      "grad_norm": 3.960749626159668,
      "learning_rate": 2.0381130299704577e-06,
      "loss": 0.27609379291534425,
      "memory(GiB)": 72.72,
      "step": 38420,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.5840873052886857,
      "grad_norm": 2.572845697402954,
      "learning_rate": 2.0368706047877957e-06,
      "loss": 0.30402412414550783,
      "memory(GiB)": 72.72,
      "step": 38425,
      "token_acc": 0.946236559139785,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.5845536796940585,
      "grad_norm": 2.9553678035736084,
      "learning_rate": 2.035628461537766e-06,
      "loss": 0.28564860820770266,
      "memory(GiB)": 72.72,
      "step": 38430,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.585020054099431,
      "grad_norm": 2.7559049129486084,
      "learning_rate": 2.0343866003385574e-06,
      "loss": 0.27512121200561523,
      "memory(GiB)": 72.72,
      "step": 38435,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.5854864285048036,
      "grad_norm": 2.2741525173187256,
      "learning_rate": 2.0331450213083287e-06,
      "loss": 0.26825675964355467,
      "memory(GiB)": 72.72,
      "step": 38440,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.5859528029101764,
      "grad_norm": 3.1972217559814453,
      "learning_rate": 2.031903724565212e-06,
      "loss": 0.277292537689209,
      "memory(GiB)": 72.72,
      "step": 38445,
      "token_acc": 0.6086956521739131,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.586419177315549,
      "grad_norm": 3.4811575412750244,
      "learning_rate": 2.0306627102273114e-06,
      "loss": 0.30199666023254396,
      "memory(GiB)": 72.72,
      "step": 38450,
      "token_acc": 0.9666666666666667,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.5868855517209215,
      "grad_norm": 3.0225369930267334,
      "learning_rate": 2.029421978412709e-06,
      "loss": 0.3226142406463623,
      "memory(GiB)": 72.72,
      "step": 38455,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.5873519261262943,
      "grad_norm": 4.383397102355957,
      "learning_rate": 2.0281815292394525e-06,
      "loss": 0.27986903190612794,
      "memory(GiB)": 72.72,
      "step": 38460,
      "train_speed(iter/s)": 0.251416
    },
    {
      "epoch": 3.5878183005316666,
      "grad_norm": 3.6289005279541016,
      "learning_rate": 2.026941362825566e-06,
      "loss": 0.30034894943237306,
      "memory(GiB)": 72.72,
      "step": 38465,
      "token_acc": 0.6296296296296297,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.5882846749370394,
      "grad_norm": 3.2273499965667725,
      "learning_rate": 2.025701479289053e-06,
      "loss": 0.245328950881958,
      "memory(GiB)": 72.72,
      "step": 38470,
      "train_speed(iter/s)": 0.251417
    },
    {
      "epoch": 3.588751049342412,
      "grad_norm": 2.3243093490600586,
      "learning_rate": 2.024461878747881e-06,
      "loss": 0.27680482864379885,
      "memory(GiB)": 72.72,
      "step": 38475,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.589217423747785,
      "grad_norm": 2.8256585597991943,
      "learning_rate": 2.023222561319995e-06,
      "loss": 0.28145651817321776,
      "memory(GiB)": 72.72,
      "step": 38480,
      "token_acc": 0.8609271523178808,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.5896837981531573,
      "grad_norm": 3.1418533325195312,
      "learning_rate": 2.0219835271233123e-06,
      "loss": 0.28405184745788575,
      "memory(GiB)": 72.72,
      "step": 38485,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.59015017255853,
      "grad_norm": 3.108076333999634,
      "learning_rate": 2.020744776275723e-06,
      "loss": 0.2704991579055786,
      "memory(GiB)": 72.72,
      "step": 38490,
      "token_acc": 0.7552447552447552,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.5906165469639024,
      "grad_norm": 2.751924514770508,
      "learning_rate": 2.0195063088950905e-06,
      "loss": 0.2857952117919922,
      "memory(GiB)": 72.72,
      "step": 38495,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.591082921369275,
      "grad_norm": 6.099747180938721,
      "learning_rate": 2.0182681250992508e-06,
      "loss": 0.2995255470275879,
      "memory(GiB)": 72.72,
      "step": 38500,
      "token_acc": 0.8961038961038961,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.591549295774648,
      "grad_norm": 2.6108603477478027,
      "learning_rate": 2.0170302250060137e-06,
      "loss": 0.3030384540557861,
      "memory(GiB)": 72.72,
      "step": 38505,
      "token_acc": 0.9743589743589743,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.5920156701800208,
      "grad_norm": 4.29600191116333,
      "learning_rate": 2.015792608733161e-06,
      "loss": 0.2910141944885254,
      "memory(GiB)": 72.72,
      "step": 38510,
      "token_acc": 0.9775280898876404,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.592482044585393,
      "grad_norm": 2.915471315383911,
      "learning_rate": 2.0145552763984487e-06,
      "loss": 0.2670541048049927,
      "memory(GiB)": 72.72,
      "step": 38515,
      "train_speed(iter/s)": 0.251424
    },
    {
      "epoch": 3.592948418990766,
      "grad_norm": 3.286616325378418,
      "learning_rate": 2.013318228119605e-06,
      "loss": 0.28939342498779297,
      "memory(GiB)": 72.72,
      "step": 38520,
      "token_acc": 0.8,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.5934147933961382,
      "grad_norm": 2.928537130355835,
      "learning_rate": 2.0120814640143317e-06,
      "loss": 0.2944488525390625,
      "memory(GiB)": 72.72,
      "step": 38525,
      "token_acc": 0.8726114649681529,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.593881167801511,
      "grad_norm": 2.9091410636901855,
      "learning_rate": 2.010844984200302e-06,
      "loss": 0.2723811864852905,
      "memory(GiB)": 72.72,
      "step": 38530,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.594347542206884,
      "grad_norm": 2.6324045658111572,
      "learning_rate": 2.0096087887951622e-06,
      "loss": 0.29471325874328613,
      "memory(GiB)": 72.72,
      "step": 38535,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.5948139166122566,
      "grad_norm": 8.581859588623047,
      "learning_rate": 2.0083728779165357e-06,
      "loss": 0.294050931930542,
      "memory(GiB)": 72.72,
      "step": 38540,
      "token_acc": 0.5846153846153846,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.595280291017629,
      "grad_norm": 8.210634231567383,
      "learning_rate": 2.0071372516820144e-06,
      "loss": 0.3081829309463501,
      "memory(GiB)": 72.72,
      "step": 38545,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.5957466654230017,
      "grad_norm": 3.690471649169922,
      "learning_rate": 2.005901910209163e-06,
      "loss": 0.28099119663238525,
      "memory(GiB)": 72.72,
      "step": 38550,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.596213039828374,
      "grad_norm": 6.727989673614502,
      "learning_rate": 2.0046668536155236e-06,
      "loss": 0.29591896533966067,
      "memory(GiB)": 72.72,
      "step": 38555,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.596679414233747,
      "grad_norm": 3.4904823303222656,
      "learning_rate": 2.0034320820186037e-06,
      "loss": 0.3021218776702881,
      "memory(GiB)": 72.72,
      "step": 38560,
      "token_acc": 0.9555555555555556,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.5971457886391196,
      "grad_norm": 2.7886056900024414,
      "learning_rate": 2.0021975955358884e-06,
      "loss": 0.27343130111694336,
      "memory(GiB)": 72.72,
      "step": 38565,
      "token_acc": 0.7555555555555555,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.5976121630444924,
      "grad_norm": 3.0536141395568848,
      "learning_rate": 2.000963394284839e-06,
      "loss": 0.28913083076477053,
      "memory(GiB)": 72.72,
      "step": 38570,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.5980785374498647,
      "grad_norm": 2.43127703666687,
      "learning_rate": 1.9997294783828835e-06,
      "loss": 0.2600369453430176,
      "memory(GiB)": 72.72,
      "step": 38575,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.5985449118552375,
      "grad_norm": 2.4906165599823,
      "learning_rate": 1.9984958479474253e-06,
      "loss": 0.27936735153198244,
      "memory(GiB)": 72.72,
      "step": 38580,
      "token_acc": 0.7540983606557377,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.59901128626061,
      "grad_norm": 4.079272270202637,
      "learning_rate": 1.9972625030958413e-06,
      "loss": 0.2708458423614502,
      "memory(GiB)": 72.72,
      "step": 38585,
      "token_acc": 0.6862745098039216,
      "train_speed(iter/s)": 0.251424
    },
    {
      "epoch": 3.5994776606659826,
      "grad_norm": 2.163461208343506,
      "learning_rate": 1.9960294439454796e-06,
      "loss": 0.3144320726394653,
      "memory(GiB)": 72.72,
      "step": 38590,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.5999440350713554,
      "grad_norm": 4.575530052185059,
      "learning_rate": 1.994796670613663e-06,
      "loss": 0.29545447826385496,
      "memory(GiB)": 72.72,
      "step": 38595,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.600410409476728,
      "grad_norm": 2.883998394012451,
      "learning_rate": 1.993564183217685e-06,
      "loss": 0.28026866912841797,
      "memory(GiB)": 72.72,
      "step": 38600,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.6008767838821005,
      "grad_norm": 4.081279277801514,
      "learning_rate": 1.9923319818748133e-06,
      "loss": 0.3097844123840332,
      "memory(GiB)": 72.72,
      "step": 38605,
      "token_acc": 0.8486842105263158,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.6013431582874733,
      "grad_norm": 2.653944730758667,
      "learning_rate": 1.9911000667022885e-06,
      "loss": 0.29166059494018554,
      "memory(GiB)": 72.72,
      "step": 38610,
      "token_acc": 0.7741935483870968,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.6018095326928457,
      "grad_norm": 3.470675468444824,
      "learning_rate": 1.989868437817323e-06,
      "loss": 0.3044985294342041,
      "memory(GiB)": 72.72,
      "step": 38615,
      "token_acc": 0.5689655172413793,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.6022759070982184,
      "grad_norm": 2.801220417022705,
      "learning_rate": 1.9886370953371025e-06,
      "loss": 0.27435832023620604,
      "memory(GiB)": 72.72,
      "step": 38620,
      "token_acc": 0.9666666666666667,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.602742281503591,
      "grad_norm": 2.8662216663360596,
      "learning_rate": 1.9874060393787857e-06,
      "loss": 0.2523670673370361,
      "memory(GiB)": 72.72,
      "step": 38625,
      "token_acc": 0.9230769230769231,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.6032086559089636,
      "grad_norm": 4.113424777984619,
      "learning_rate": 1.9861752700595037e-06,
      "loss": 0.30609908103942873,
      "memory(GiB)": 72.72,
      "step": 38630,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.6036750303143363,
      "grad_norm": 4.321769714355469,
      "learning_rate": 1.984944787496359e-06,
      "loss": 0.2806345701217651,
      "memory(GiB)": 72.72,
      "step": 38635,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.604141404719709,
      "grad_norm": 3.679176092147827,
      "learning_rate": 1.9837145918064315e-06,
      "loss": 0.2946995496749878,
      "memory(GiB)": 72.72,
      "step": 38640,
      "token_acc": 0.796875,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.6046077791250815,
      "grad_norm": 4.210995674133301,
      "learning_rate": 1.9824846831067686e-06,
      "loss": 0.2963420867919922,
      "memory(GiB)": 72.72,
      "step": 38645,
      "token_acc": 0.7567567567567568,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.6050741535304542,
      "grad_norm": 2.8885657787323,
      "learning_rate": 1.9812550615143937e-06,
      "loss": 0.3065373182296753,
      "memory(GiB)": 72.72,
      "step": 38650,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.605540527935827,
      "grad_norm": 4.951997756958008,
      "learning_rate": 1.980025727146299e-06,
      "loss": 0.28396005630493165,
      "memory(GiB)": 72.72,
      "step": 38655,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.6060069023411994,
      "grad_norm": 3.2001876831054688,
      "learning_rate": 1.978796680119453e-06,
      "loss": 0.28471975326538085,
      "memory(GiB)": 72.72,
      "step": 38660,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.606473276746572,
      "grad_norm": 3.3578524589538574,
      "learning_rate": 1.977567920550796e-06,
      "loss": 0.28098068237304685,
      "memory(GiB)": 72.72,
      "step": 38665,
      "token_acc": 0.6574074074074074,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.606939651151945,
      "grad_norm": 4.841279029846191,
      "learning_rate": 1.9763394485572384e-06,
      "loss": 0.2740117073059082,
      "memory(GiB)": 72.72,
      "step": 38670,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.6074060255573173,
      "grad_norm": 2.3729074001312256,
      "learning_rate": 1.975111264255669e-06,
      "loss": 0.27454042434692383,
      "memory(GiB)": 72.72,
      "step": 38675,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251424
    },
    {
      "epoch": 3.60787239996269,
      "grad_norm": 2.3693480491638184,
      "learning_rate": 1.9738833677629456e-06,
      "loss": 0.29710965156555175,
      "memory(GiB)": 72.72,
      "step": 38680,
      "token_acc": 0.7333333333333333,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.608338774368063,
      "grad_norm": 13.55014419555664,
      "learning_rate": 1.9726557591958966e-06,
      "loss": 0.30792803764343263,
      "memory(GiB)": 72.72,
      "step": 38685,
      "token_acc": 0.6949152542372882,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.608805148773435,
      "grad_norm": 2.142071008682251,
      "learning_rate": 1.971428438671327e-06,
      "loss": 0.24855365753173828,
      "memory(GiB)": 72.72,
      "step": 38690,
      "token_acc": 0.8095238095238095,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.609271523178808,
      "grad_norm": 3.1127419471740723,
      "learning_rate": 1.9702014063060106e-06,
      "loss": 0.23763010501861573,
      "memory(GiB)": 72.72,
      "step": 38695,
      "token_acc": 0.9444444444444444,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6097378975841807,
      "grad_norm": 3.0540146827697754,
      "learning_rate": 1.9689746622166976e-06,
      "loss": 0.3130988121032715,
      "memory(GiB)": 72.72,
      "step": 38700,
      "token_acc": 0.5514018691588785,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.610204271989553,
      "grad_norm": 4.301854133605957,
      "learning_rate": 1.9677482065201083e-06,
      "loss": 0.27614047527313235,
      "memory(GiB)": 72.72,
      "step": 38705,
      "token_acc": 0.5531914893617021,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.610670646394926,
      "grad_norm": 2.8321988582611084,
      "learning_rate": 1.9665220393329353e-06,
      "loss": 0.3286874771118164,
      "memory(GiB)": 72.72,
      "step": 38710,
      "token_acc": 0.7644230769230769,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6111370208002986,
      "grad_norm": 3.1229357719421387,
      "learning_rate": 1.965296160771846e-06,
      "loss": 0.2576837778091431,
      "memory(GiB)": 72.72,
      "step": 38715,
      "token_acc": 0.9195402298850575,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.611603395205671,
      "grad_norm": 2.6897644996643066,
      "learning_rate": 1.9640705709534785e-06,
      "loss": 0.32496750354766846,
      "memory(GiB)": 72.72,
      "step": 38720,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.6120697696110438,
      "grad_norm": 3.083946466445923,
      "learning_rate": 1.9628452699944432e-06,
      "loss": 0.31735882759094236,
      "memory(GiB)": 72.72,
      "step": 38725,
      "token_acc": 0.6966292134831461,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6125361440164165,
      "grad_norm": 3.92423939704895,
      "learning_rate": 1.961620258011325e-06,
      "loss": 0.2732339382171631,
      "memory(GiB)": 72.72,
      "step": 38730,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.613002518421789,
      "grad_norm": 3.4518773555755615,
      "learning_rate": 1.960395535120677e-06,
      "loss": 0.2919814109802246,
      "memory(GiB)": 72.72,
      "step": 38735,
      "token_acc": 0.6904761904761905,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6134688928271617,
      "grad_norm": 3.2834694385528564,
      "learning_rate": 1.959171101439032e-06,
      "loss": 0.3081014156341553,
      "memory(GiB)": 72.72,
      "step": 38740,
      "token_acc": 0.6203703703703703,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.6139352672325344,
      "grad_norm": 3.42574405670166,
      "learning_rate": 1.9579469570828893e-06,
      "loss": 0.29139862060546873,
      "memory(GiB)": 72.72,
      "step": 38745,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.614401641637907,
      "grad_norm": 3.0451807975769043,
      "learning_rate": 1.956723102168724e-06,
      "loss": 0.29857492446899414,
      "memory(GiB)": 72.72,
      "step": 38750,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6148680160432796,
      "grad_norm": 2.993253231048584,
      "learning_rate": 1.9554995368129786e-06,
      "loss": 0.28963747024536135,
      "memory(GiB)": 72.72,
      "step": 38755,
      "token_acc": 0.7857142857142857,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.615334390448652,
      "grad_norm": 2.114731550216675,
      "learning_rate": 1.954276261132074e-06,
      "loss": 0.2869265556335449,
      "memory(GiB)": 72.72,
      "step": 38760,
      "token_acc": 0.875,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6158007648540247,
      "grad_norm": 2.639185905456543,
      "learning_rate": 1.9530532752423997e-06,
      "loss": 0.29138472080230715,
      "memory(GiB)": 72.72,
      "step": 38765,
      "token_acc": 0.9393939393939394,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.6162671392593975,
      "grad_norm": 3.4339213371276855,
      "learning_rate": 1.951830579260319e-06,
      "loss": 0.29832167625427247,
      "memory(GiB)": 72.72,
      "step": 38770,
      "token_acc": 0.8444444444444444,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.6167335136647702,
      "grad_norm": 2.656816244125366,
      "learning_rate": 1.950608173302169e-06,
      "loss": 0.25888087749481203,
      "memory(GiB)": 72.72,
      "step": 38775,
      "token_acc": 0.96875,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.6171998880701426,
      "grad_norm": 5.297947406768799,
      "learning_rate": 1.949386057484259e-06,
      "loss": 0.28545174598693845,
      "memory(GiB)": 72.72,
      "step": 38780,
      "token_acc": 0.6888888888888889,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.6176662624755154,
      "grad_norm": 2.434199333190918,
      "learning_rate": 1.948164231922867e-06,
      "loss": 0.275741720199585,
      "memory(GiB)": 72.72,
      "step": 38785,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.6181326368808877,
      "grad_norm": 2.8723747730255127,
      "learning_rate": 1.9469426967342474e-06,
      "loss": 0.29934988021850584,
      "memory(GiB)": 72.72,
      "step": 38790,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.6185990112862605,
      "grad_norm": 4.241430759429932,
      "learning_rate": 1.945721452034625e-06,
      "loss": 0.2875967502593994,
      "memory(GiB)": 72.72,
      "step": 38795,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.6190653856916333,
      "grad_norm": 5.371154308319092,
      "learning_rate": 1.944500497940197e-06,
      "loss": 0.31065690517425537,
      "memory(GiB)": 72.72,
      "step": 38800,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.619531760097006,
      "grad_norm": 2.755488872528076,
      "learning_rate": 1.9432798345671343e-06,
      "loss": 0.3117061138153076,
      "memory(GiB)": 72.72,
      "step": 38805,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.6199981345023784,
      "grad_norm": 2.2031850814819336,
      "learning_rate": 1.942059462031579e-06,
      "loss": 0.2881165981292725,
      "memory(GiB)": 72.72,
      "step": 38810,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.620464508907751,
      "grad_norm": 2.071329355239868,
      "learning_rate": 1.9408393804496456e-06,
      "loss": 0.2770832538604736,
      "memory(GiB)": 72.72,
      "step": 38815,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.6209308833131235,
      "grad_norm": 2.3998281955718994,
      "learning_rate": 1.9396195899374214e-06,
      "loss": 0.26039905548095704,
      "memory(GiB)": 72.72,
      "step": 38820,
      "token_acc": 0.9367088607594937,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.6213972577184963,
      "grad_norm": 3.4686098098754883,
      "learning_rate": 1.938400090610965e-06,
      "loss": 0.2819249629974365,
      "memory(GiB)": 72.72,
      "step": 38825,
      "token_acc": 0.5714285714285714,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.621863632123869,
      "grad_norm": 2.7256672382354736,
      "learning_rate": 1.9371808825863088e-06,
      "loss": 0.2918132781982422,
      "memory(GiB)": 72.72,
      "step": 38830,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.622330006529242,
      "grad_norm": 5.051585674285889,
      "learning_rate": 1.9359619659794566e-06,
      "loss": 0.29632675647735596,
      "memory(GiB)": 72.72,
      "step": 38835,
      "token_acc": 0.7446808510638298,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.622796380934614,
      "grad_norm": 2.9121575355529785,
      "learning_rate": 1.934743340906382e-06,
      "loss": 0.3035491943359375,
      "memory(GiB)": 72.72,
      "step": 38840,
      "token_acc": 0.9404761904761905,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.623262755339987,
      "grad_norm": 2.3711349964141846,
      "learning_rate": 1.9335250074830374e-06,
      "loss": 0.2940032482147217,
      "memory(GiB)": 72.72,
      "step": 38845,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.6237291297453593,
      "grad_norm": 3.3110673427581787,
      "learning_rate": 1.932306965825344e-06,
      "loss": 0.27552664279937744,
      "memory(GiB)": 72.72,
      "step": 38850,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.624195504150732,
      "grad_norm": 2.586181879043579,
      "learning_rate": 1.9310892160491913e-06,
      "loss": 0.28130784034729006,
      "memory(GiB)": 72.72,
      "step": 38855,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.624661878556105,
      "grad_norm": 3.82702898979187,
      "learning_rate": 1.9298717582704447e-06,
      "loss": 0.3267343521118164,
      "memory(GiB)": 72.72,
      "step": 38860,
      "token_acc": 0.5166666666666667,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.6251282529614777,
      "grad_norm": 4.557868957519531,
      "learning_rate": 1.928654592604943e-06,
      "loss": 0.29056429862976074,
      "memory(GiB)": 72.72,
      "step": 38865,
      "token_acc": 0.989247311827957,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.62559462736685,
      "grad_norm": 3.647775173187256,
      "learning_rate": 1.9274377191684936e-06,
      "loss": 0.28442983627319335,
      "memory(GiB)": 72.72,
      "step": 38870,
      "token_acc": 0.5686274509803921,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.626061001772223,
      "grad_norm": 2.9893958568573,
      "learning_rate": 1.9262211380768815e-06,
      "loss": 0.2622897386550903,
      "memory(GiB)": 72.72,
      "step": 38875,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.626527376177595,
      "grad_norm": 3.3144757747650146,
      "learning_rate": 1.9250048494458594e-06,
      "loss": 0.28060805797576904,
      "memory(GiB)": 72.72,
      "step": 38880,
      "token_acc": 0.65625,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.626993750582968,
      "grad_norm": 3.5312838554382324,
      "learning_rate": 1.9237888533911533e-06,
      "loss": 0.26305935382843015,
      "memory(GiB)": 72.72,
      "step": 38885,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.6274601249883407,
      "grad_norm": 2.903597593307495,
      "learning_rate": 1.9225731500284606e-06,
      "loss": 0.2605527400970459,
      "memory(GiB)": 72.72,
      "step": 38890,
      "token_acc": 0.6886792452830188,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6279264993937135,
      "grad_norm": 3.0307722091674805,
      "learning_rate": 1.921357739473453e-06,
      "loss": 0.2792350769042969,
      "memory(GiB)": 72.72,
      "step": 38895,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.628392873799086,
      "grad_norm": 2.7940609455108643,
      "learning_rate": 1.920142621841772e-06,
      "loss": 0.2746657609939575,
      "memory(GiB)": 72.72,
      "step": 38900,
      "token_acc": 0.625,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.6288592482044586,
      "grad_norm": 2.990349054336548,
      "learning_rate": 1.9189277972490327e-06,
      "loss": 0.32412285804748536,
      "memory(GiB)": 72.72,
      "step": 38905,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.629325622609831,
      "grad_norm": 2.3651022911071777,
      "learning_rate": 1.9177132658108227e-06,
      "loss": 0.2730530023574829,
      "memory(GiB)": 72.72,
      "step": 38910,
      "token_acc": 0.6379310344827587,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6297919970152037,
      "grad_norm": 5.955507278442383,
      "learning_rate": 1.9164990276427e-06,
      "loss": 0.2854651689529419,
      "memory(GiB)": 72.72,
      "step": 38915,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.6302583714205765,
      "grad_norm": 15.554773330688477,
      "learning_rate": 1.9152850828601954e-06,
      "loss": 0.29656062126159666,
      "memory(GiB)": 72.72,
      "step": 38920,
      "token_acc": 0.696969696969697,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.6307247458259493,
      "grad_norm": 3.2089908123016357,
      "learning_rate": 1.914071431578813e-06,
      "loss": 0.30898475646972656,
      "memory(GiB)": 72.72,
      "step": 38925,
      "train_speed(iter/s)": 0.251424
    },
    {
      "epoch": 3.6311911202313216,
      "grad_norm": 2.046147584915161,
      "learning_rate": 1.9128580739140275e-06,
      "loss": 0.25960042476654055,
      "memory(GiB)": 72.72,
      "step": 38930,
      "token_acc": 0.8995983935742972,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.6316574946366944,
      "grad_norm": 3.447934150695801,
      "learning_rate": 1.9116450099812857e-06,
      "loss": 0.3137419939041138,
      "memory(GiB)": 72.72,
      "step": 38935,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.6321238690420667,
      "grad_norm": 3.4640402793884277,
      "learning_rate": 1.9104322398960055e-06,
      "loss": 0.2871399402618408,
      "memory(GiB)": 72.72,
      "step": 38940,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.6325902434474395,
      "grad_norm": 2.537367343902588,
      "learning_rate": 1.909219763773584e-06,
      "loss": 0.34020195007324217,
      "memory(GiB)": 72.72,
      "step": 38945,
      "token_acc": 0.65,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.6330566178528123,
      "grad_norm": 2.7992444038391113,
      "learning_rate": 1.9080075817293784e-06,
      "loss": 0.28844096660614016,
      "memory(GiB)": 72.72,
      "step": 38950,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.633522992258185,
      "grad_norm": 3.4037203788757324,
      "learning_rate": 1.9067956938787262e-06,
      "loss": 0.25641090869903566,
      "memory(GiB)": 72.72,
      "step": 38955,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.6339893666635574,
      "grad_norm": 3.475390911102295,
      "learning_rate": 1.9055841003369357e-06,
      "loss": 0.28316197395324705,
      "memory(GiB)": 72.72,
      "step": 38960,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.63445574106893,
      "grad_norm": 8.084399223327637,
      "learning_rate": 1.9043728012192846e-06,
      "loss": 0.3080826997756958,
      "memory(GiB)": 72.72,
      "step": 38965,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.6349221154743026,
      "grad_norm": 2.6117103099823,
      "learning_rate": 1.9031617966410254e-06,
      "loss": 0.2926074743270874,
      "memory(GiB)": 72.72,
      "step": 38970,
      "token_acc": 0.9583333333333334,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.6353884898796753,
      "grad_norm": 2.1764965057373047,
      "learning_rate": 1.9019510867173795e-06,
      "loss": 0.2559802532196045,
      "memory(GiB)": 72.72,
      "step": 38975,
      "token_acc": 0.4827586206896552,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.635854864285048,
      "grad_norm": 5.536269664764404,
      "learning_rate": 1.9007406715635457e-06,
      "loss": 0.2655863046646118,
      "memory(GiB)": 72.72,
      "step": 38980,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.636321238690421,
      "grad_norm": 2.6942930221557617,
      "learning_rate": 1.89953055129469e-06,
      "loss": 0.29804539680480957,
      "memory(GiB)": 72.72,
      "step": 38985,
      "token_acc": 0.5507246376811594,
      "train_speed(iter/s)": 0.251424
    },
    {
      "epoch": 3.6367876130957932,
      "grad_norm": 6.780904769897461,
      "learning_rate": 1.89832072602595e-06,
      "loss": 0.2745169401168823,
      "memory(GiB)": 72.72,
      "step": 38990,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.637253987501166,
      "grad_norm": 2.8078043460845947,
      "learning_rate": 1.8971111958724387e-06,
      "loss": 0.2649106025695801,
      "memory(GiB)": 72.72,
      "step": 38995,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.6377203619065384,
      "grad_norm": 5.085819244384766,
      "learning_rate": 1.8959019609492385e-06,
      "loss": 0.2941758632659912,
      "memory(GiB)": 72.72,
      "step": 39000,
      "token_acc": 0.6736842105263158,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.638186736311911,
      "grad_norm": 4.762241840362549,
      "learning_rate": 1.894693021371406e-06,
      "loss": 0.30070631504058837,
      "memory(GiB)": 72.72,
      "step": 39005,
      "train_speed(iter/s)": 0.251418
    },
    {
      "epoch": 3.638653110717284,
      "grad_norm": 3.041564702987671,
      "learning_rate": 1.8934843772539624e-06,
      "loss": 0.29305319786071776,
      "memory(GiB)": 72.72,
      "step": 39010,
      "token_acc": 0.7631578947368421,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.6391194851226567,
      "grad_norm": 3.6148335933685303,
      "learning_rate": 1.8922760287119125e-06,
      "loss": 0.2821808338165283,
      "memory(GiB)": 72.72,
      "step": 39015,
      "token_acc": 0.6097560975609756,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.639585859528029,
      "grad_norm": 5.412897109985352,
      "learning_rate": 1.8910679758602252e-06,
      "loss": 0.31026492118835447,
      "memory(GiB)": 72.72,
      "step": 39020,
      "token_acc": 0.7878787878787878,
      "train_speed(iter/s)": 0.251422
    },
    {
      "epoch": 3.640052233933402,
      "grad_norm": 2.2375926971435547,
      "learning_rate": 1.889860218813842e-06,
      "loss": 0.24769191741943358,
      "memory(GiB)": 72.72,
      "step": 39025,
      "token_acc": 0.5652173913043478,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.640518608338774,
      "grad_norm": 2.4445297718048096,
      "learning_rate": 1.8886527576876784e-06,
      "loss": 0.2553557872772217,
      "memory(GiB)": 72.72,
      "step": 39030,
      "token_acc": 0.5967741935483871,
      "train_speed(iter/s)": 0.251419
    },
    {
      "epoch": 3.640984982744147,
      "grad_norm": 11.766387939453125,
      "learning_rate": 1.88744559259662e-06,
      "loss": 0.2871662139892578,
      "memory(GiB)": 72.72,
      "step": 39035,
      "train_speed(iter/s)": 0.25142
    },
    {
      "epoch": 3.6414513571495197,
      "grad_norm": 3.7533938884735107,
      "learning_rate": 1.8862387236555235e-06,
      "loss": 0.28058662414550783,
      "memory(GiB)": 72.72,
      "step": 39040,
      "train_speed(iter/s)": 0.251421
    },
    {
      "epoch": 3.6419177315548925,
      "grad_norm": 3.663788318634033,
      "learning_rate": 1.8850321509792236e-06,
      "loss": 0.29285876750946044,
      "memory(GiB)": 72.72,
      "step": 39045,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.642384105960265,
      "grad_norm": 5.41252326965332,
      "learning_rate": 1.8838258746825172e-06,
      "loss": 0.27540125846862795,
      "memory(GiB)": 72.72,
      "step": 39050,
      "train_speed(iter/s)": 0.251423
    },
    {
      "epoch": 3.6428504803656376,
      "grad_norm": 4.211289405822754,
      "learning_rate": 1.8826198948801788e-06,
      "loss": 0.27805585861206056,
      "memory(GiB)": 72.72,
      "step": 39055,
      "token_acc": 0.8529411764705882,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.64331685477101,
      "grad_norm": 3.2557754516601562,
      "learning_rate": 1.8814142116869544e-06,
      "loss": 0.2825784683227539,
      "memory(GiB)": 72.72,
      "step": 39060,
      "token_acc": 0.9270833333333334,
      "train_speed(iter/s)": 0.251427
    },
    {
      "epoch": 3.6437832291763828,
      "grad_norm": 4.750548362731934,
      "learning_rate": 1.8802088252175604e-06,
      "loss": 0.3059704303741455,
      "memory(GiB)": 72.72,
      "step": 39065,
      "train_speed(iter/s)": 0.251425
    },
    {
      "epoch": 3.6442496035817555,
      "grad_norm": 2.7368431091308594,
      "learning_rate": 1.8790037355866858e-06,
      "loss": 0.266170072555542,
      "memory(GiB)": 72.72,
      "step": 39070,
      "token_acc": 0.978494623655914,
      "train_speed(iter/s)": 0.251426
    },
    {
      "epoch": 3.6447159779871283,
      "grad_norm": 3.5465891361236572,
      "learning_rate": 1.8777989429089898e-06,
      "loss": 0.28192710876464844,
      "memory(GiB)": 72.72,
      "step": 39075,
      "token_acc": 0.6785714285714286,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.6451823523925007,
      "grad_norm": 2.510050058364868,
      "learning_rate": 1.8765944472991081e-06,
      "loss": 0.29045581817626953,
      "memory(GiB)": 72.72,
      "step": 39080,
      "token_acc": 0.5909090909090909,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.6456487267978734,
      "grad_norm": 4.570398330688477,
      "learning_rate": 1.875390248871643e-06,
      "loss": 0.2825270175933838,
      "memory(GiB)": 72.72,
      "step": 39085,
      "token_acc": 0.9811320754716981,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.646115101203246,
      "grad_norm": 2.297434091567993,
      "learning_rate": 1.8741863477411698e-06,
      "loss": 0.3066550254821777,
      "memory(GiB)": 72.72,
      "step": 39090,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.6465814756086186,
      "grad_norm": 2.2720959186553955,
      "learning_rate": 1.8729827440222359e-06,
      "loss": 0.25609042644500735,
      "memory(GiB)": 72.72,
      "step": 39095,
      "token_acc": 0.9066666666666666,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.6470478500139913,
      "grad_norm": 3.0806162357330322,
      "learning_rate": 1.8717794378293614e-06,
      "loss": 0.30324904918670653,
      "memory(GiB)": 72.72,
      "step": 39100,
      "token_acc": 0.42,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.647514224419364,
      "grad_norm": 2.5317330360412598,
      "learning_rate": 1.8705764292770385e-06,
      "loss": 0.28400187492370604,
      "memory(GiB)": 72.72,
      "step": 39105,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.6479805988247365,
      "grad_norm": 3.0469970703125,
      "learning_rate": 1.8693737184797245e-06,
      "loss": 0.2567984819412231,
      "memory(GiB)": 72.72,
      "step": 39110,
      "token_acc": 0.5735294117647058,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.6484469732301092,
      "grad_norm": 2.1320271492004395,
      "learning_rate": 1.8681713055518586e-06,
      "loss": 0.27875866889953616,
      "memory(GiB)": 72.72,
      "step": 39115,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.6489133476354816,
      "grad_norm": 2.691572427749634,
      "learning_rate": 1.8669691906078447e-06,
      "loss": 0.3101269960403442,
      "memory(GiB)": 72.72,
      "step": 39120,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.6493797220408544,
      "grad_norm": 3.3080108165740967,
      "learning_rate": 1.8657673737620613e-06,
      "loss": 0.2924726724624634,
      "memory(GiB)": 72.72,
      "step": 39125,
      "token_acc": 1.0,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.649846096446227,
      "grad_norm": 4.205292701721191,
      "learning_rate": 1.864565855128857e-06,
      "loss": 0.27650136947631837,
      "memory(GiB)": 72.72,
      "step": 39130,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.6503124708516,
      "grad_norm": 2.7839298248291016,
      "learning_rate": 1.8633646348225525e-06,
      "loss": 0.3028359889984131,
      "memory(GiB)": 72.72,
      "step": 39135,
      "token_acc": 0.5277777777777778,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.6507788452569723,
      "grad_norm": 3.552720308303833,
      "learning_rate": 1.8621637129574405e-06,
      "loss": 0.3050945281982422,
      "memory(GiB)": 72.72,
      "step": 39140,
      "token_acc": 0.9404761904761905,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.651245219662345,
      "grad_norm": 14.50721549987793,
      "learning_rate": 1.8609630896477848e-06,
      "loss": 0.2731108427047729,
      "memory(GiB)": 72.72,
      "step": 39145,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.6517115940677174,
      "grad_norm": 2.661280870437622,
      "learning_rate": 1.859762765007821e-06,
      "loss": 0.2966907024383545,
      "memory(GiB)": 72.72,
      "step": 39150,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.65217796847309,
      "grad_norm": 2.7415122985839844,
      "learning_rate": 1.8585627391517562e-06,
      "loss": 0.2873229503631592,
      "memory(GiB)": 72.72,
      "step": 39155,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.652644342878463,
      "grad_norm": 3.1522257328033447,
      "learning_rate": 1.8573630121937697e-06,
      "loss": 0.29118924140930175,
      "memory(GiB)": 72.72,
      "step": 39160,
      "token_acc": 0.6052631578947368,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.6531107172838357,
      "grad_norm": 2.332689046859741,
      "learning_rate": 1.8561635842480114e-06,
      "loss": 0.2758674144744873,
      "memory(GiB)": 72.72,
      "step": 39165,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.653577091689208,
      "grad_norm": 2.942368507385254,
      "learning_rate": 1.8549644554286033e-06,
      "loss": 0.29973421096801756,
      "memory(GiB)": 72.72,
      "step": 39170,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.654043466094581,
      "grad_norm": 2.984442949295044,
      "learning_rate": 1.8537656258496368e-06,
      "loss": 0.2683746337890625,
      "memory(GiB)": 72.72,
      "step": 39175,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 3.654509840499953,
      "grad_norm": 2.655632734298706,
      "learning_rate": 1.8525670956251806e-06,
      "loss": 0.3007798671722412,
      "memory(GiB)": 72.72,
      "step": 39180,
      "token_acc": 0.5555555555555556,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 3.654976214905326,
      "grad_norm": 2.621088981628418,
      "learning_rate": 1.8513688648692696e-06,
      "loss": 0.2575977325439453,
      "memory(GiB)": 72.72,
      "step": 39185,
      "token_acc": 0.45098039215686275,
      "train_speed(iter/s)": 0.251436
    },
    {
      "epoch": 3.6554425893106988,
      "grad_norm": 3.2836995124816895,
      "learning_rate": 1.8501709336959113e-06,
      "loss": 0.2924444913864136,
      "memory(GiB)": 72.72,
      "step": 39190,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.655908963716071,
      "grad_norm": 1.886548399925232,
      "learning_rate": 1.8489733022190854e-06,
      "loss": 0.24431521892547609,
      "memory(GiB)": 72.72,
      "step": 39195,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.656375338121444,
      "grad_norm": 3.1714088916778564,
      "learning_rate": 1.8477759705527443e-06,
      "loss": 0.31402130126953126,
      "memory(GiB)": 72.72,
      "step": 39200,
      "token_acc": 0.5581395348837209,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.6568417125268167,
      "grad_norm": 14.525527000427246,
      "learning_rate": 1.8465789388108073e-06,
      "loss": 0.29063246250152586,
      "memory(GiB)": 72.72,
      "step": 39205,
      "token_acc": 0.9900990099009901,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.657308086932189,
      "grad_norm": 3.0055301189422607,
      "learning_rate": 1.8453822071071682e-06,
      "loss": 0.29892454147338865,
      "memory(GiB)": 72.72,
      "step": 39210,
      "token_acc": 0.5585585585585585,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.657774461337562,
      "grad_norm": 4.1504621505737305,
      "learning_rate": 1.8441857755556958e-06,
      "loss": 0.3217212677001953,
      "memory(GiB)": 72.72,
      "step": 39215,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.6582408357429346,
      "grad_norm": 3.755760431289673,
      "learning_rate": 1.842989644270225e-06,
      "loss": 0.32304513454437256,
      "memory(GiB)": 72.72,
      "step": 39220,
      "token_acc": 0.7543859649122807,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.658707210148307,
      "grad_norm": 3.1578493118286133,
      "learning_rate": 1.8417938133645647e-06,
      "loss": 0.2836459636688232,
      "memory(GiB)": 72.72,
      "step": 39225,
      "token_acc": 0.6166666666666667,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.6591735845536797,
      "grad_norm": 2.8238396644592285,
      "learning_rate": 1.8405982829524931e-06,
      "loss": 0.28292102813720704,
      "memory(GiB)": 72.72,
      "step": 39230,
      "token_acc": 0.9764705882352941,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.6596399589590525,
      "grad_norm": 2.777970790863037,
      "learning_rate": 1.839403053147763e-06,
      "loss": 0.29371860027313235,
      "memory(GiB)": 72.72,
      "step": 39235,
      "token_acc": 0.6346153846153846,
      "train_speed(iter/s)": 0.251428
    },
    {
      "epoch": 3.660106333364425,
      "grad_norm": 3.214966297149658,
      "learning_rate": 1.8382081240640953e-06,
      "loss": 0.291829252243042,
      "memory(GiB)": 72.72,
      "step": 39240,
      "token_acc": 0.9904761904761905,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.6605727077697976,
      "grad_norm": 2.811983823776245,
      "learning_rate": 1.8370134958151848e-06,
      "loss": 0.2770259857177734,
      "memory(GiB)": 72.72,
      "step": 39245,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.6610390821751704,
      "grad_norm": 3.2919435501098633,
      "learning_rate": 1.8358191685146965e-06,
      "loss": 0.28571572303771975,
      "memory(GiB)": 72.72,
      "step": 39250,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.6615054565805427,
      "grad_norm": 3.795858383178711,
      "learning_rate": 1.8346251422762663e-06,
      "loss": 0.25171401500701907,
      "memory(GiB)": 72.72,
      "step": 39255,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.6619718309859155,
      "grad_norm": 3.792820453643799,
      "learning_rate": 1.8334314172135025e-06,
      "loss": 0.2966817855834961,
      "memory(GiB)": 72.72,
      "step": 39260,
      "token_acc": 0.5959595959595959,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.6624382053912883,
      "grad_norm": 3.091449499130249,
      "learning_rate": 1.8322379934399854e-06,
      "loss": 0.2356882333755493,
      "memory(GiB)": 72.72,
      "step": 39265,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.6629045797966606,
      "grad_norm": 4.322083473205566,
      "learning_rate": 1.8310448710692642e-06,
      "loss": 0.2937171936035156,
      "memory(GiB)": 72.72,
      "step": 39270,
      "token_acc": 0.6274509803921569,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.6633709542020334,
      "grad_norm": 4.647116661071777,
      "learning_rate": 1.8298520502148609e-06,
      "loss": 0.26214871406555174,
      "memory(GiB)": 72.72,
      "step": 39275,
      "token_acc": 0.5087719298245614,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.663837328607406,
      "grad_norm": 2.8147506713867188,
      "learning_rate": 1.8286595309902678e-06,
      "loss": 0.2690783262252808,
      "memory(GiB)": 72.72,
      "step": 39280,
      "token_acc": 0.9390243902439024,
      "train_speed(iter/s)": 0.251429
    },
    {
      "epoch": 3.6643037030127785,
      "grad_norm": 3.9510433673858643,
      "learning_rate": 1.8274673135089526e-06,
      "loss": 0.29475865364074705,
      "memory(GiB)": 72.72,
      "step": 39285,
      "token_acc": 0.5045871559633027,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.6647700774181513,
      "grad_norm": 2.7494771480560303,
      "learning_rate": 1.826275397884349e-06,
      "loss": 0.27914450168609617,
      "memory(GiB)": 72.72,
      "step": 39290,
      "token_acc": 0.7073170731707317,
      "train_speed(iter/s)": 0.25143
    },
    {
      "epoch": 3.665236451823524,
      "grad_norm": 2.8007757663726807,
      "learning_rate": 1.8250837842298646e-06,
      "loss": 0.30200719833374023,
      "memory(GiB)": 72.72,
      "step": 39295,
      "token_acc": 0.8541666666666666,
      "train_speed(iter/s)": 0.251431
    },
    {
      "epoch": 3.6657028262288964,
      "grad_norm": 2.118666648864746,
      "learning_rate": 1.8238924726588792e-06,
      "loss": 0.2778339385986328,
      "memory(GiB)": 72.72,
      "step": 39300,
      "token_acc": 0.4897959183673469,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.666169200634269,
      "grad_norm": 3.2342865467071533,
      "learning_rate": 1.8227014632847395e-06,
      "loss": 0.27139759063720703,
      "memory(GiB)": 72.72,
      "step": 39305,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.666635575039642,
      "grad_norm": 2.521613597869873,
      "learning_rate": 1.8215107562207667e-06,
      "loss": 0.3341584920883179,
      "memory(GiB)": 72.72,
      "step": 39310,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.6671019494450143,
      "grad_norm": 2.8300065994262695,
      "learning_rate": 1.8203203515802531e-06,
      "loss": 0.27226853370666504,
      "memory(GiB)": 72.72,
      "step": 39315,
      "token_acc": 0.7547169811320755,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.667568323850387,
      "grad_norm": 2.2472665309906006,
      "learning_rate": 1.819130249476464e-06,
      "loss": 0.2626335144042969,
      "memory(GiB)": 72.72,
      "step": 39320,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.6680346982557595,
      "grad_norm": 2.4816296100616455,
      "learning_rate": 1.8179404500226327e-06,
      "loss": 0.2627780199050903,
      "memory(GiB)": 72.72,
      "step": 39325,
      "token_acc": 0.5384615384615384,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.6685010726611322,
      "grad_norm": 2.805701971054077,
      "learning_rate": 1.8167509533319655e-06,
      "loss": 0.2816204071044922,
      "memory(GiB)": 72.72,
      "step": 39330,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.668967447066505,
      "grad_norm": 3.721757173538208,
      "learning_rate": 1.8155617595176383e-06,
      "loss": 0.2888432264328003,
      "memory(GiB)": 72.72,
      "step": 39335,
      "token_acc": 0.5853658536585366,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.669433821471878,
      "grad_norm": 3.825040578842163,
      "learning_rate": 1.8143728686928003e-06,
      "loss": 0.2732884407043457,
      "memory(GiB)": 72.72,
      "step": 39340,
      "train_speed(iter/s)": 0.251433
    },
    {
      "epoch": 3.66990019587725,
      "grad_norm": 2.783759117126465,
      "learning_rate": 1.8131842809705697e-06,
      "loss": 0.309352970123291,
      "memory(GiB)": 72.72,
      "step": 39345,
      "train_speed(iter/s)": 0.251432
    },
    {
      "epoch": 3.670366570282623,
      "grad_norm": 3.5203211307525635,
      "learning_rate": 1.8119959964640382e-06,
      "loss": 0.2819075584411621,
      "memory(GiB)": 72.72,
      "step": 39350,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.6708329446879953,
      "grad_norm": 3.173417091369629,
      "learning_rate": 1.810808015286266e-06,
      "loss": 0.30057315826416015,
      "memory(GiB)": 72.72,
      "step": 39355,
      "token_acc": 0.7741935483870968,
      "train_speed(iter/s)": 0.251434
    },
    {
      "epoch": 3.671299319093368,
      "grad_norm": 3.29064679145813,
      "learning_rate": 1.8096203375502874e-06,
      "loss": 0.2789070844650269,
      "memory(GiB)": 72.72,
      "step": 39360,
      "token_acc": 0.9746835443037974,
      "train_speed(iter/s)": 0.251435
    },
    {
      "epoch": 3.671765693498741,
      "grad_norm": 2.556168556213379,
      "learning_rate": 1.808432963369105e-06,
      "loss": 0.28948814868927003,
      "memory(GiB)": 72.72,
      "step": 39365,
      "train_speed(iter/s)": 0.251437
    },
    {
      "epoch": 3.6722320679041136,
      "grad_norm": 1.9029347896575928,
      "learning_rate": 1.8072458928556941e-06,
      "loss": 0.28582937717437745,
      "memory(GiB)": 72.72,
      "step": 39370,
      "train_speed(iter/s)": 0.25144
    },
    {
      "epoch": 3.672698442309486,
      "grad_norm": 2.4471182823181152,
      "learning_rate": 1.8060591261230016e-06,
      "loss": 0.2698982715606689,
      "memory(GiB)": 72.72,
      "step": 39375,
      "token_acc": 0.7843137254901961,
      "train_speed(iter/s)": 0.25144
    },
    {
      "epoch": 3.6731648167148587,
      "grad_norm": 2.794618606567383,
      "learning_rate": 1.8048726632839414e-06,
      "loss": 0.2584056377410889,
      "memory(GiB)": 72.72,
      "step": 39380,
      "token_acc": 0.8202247191011236,
      "train_speed(iter/s)": 0.25144
    },
    {
      "epoch": 3.673631191120231,
      "grad_norm": 3.5476267337799072,
      "learning_rate": 1.8036865044514069e-06,
      "loss": 0.315666651725769,
      "memory(GiB)": 72.72,
      "step": 39385,
      "token_acc": 0.6733333333333333,
      "train_speed(iter/s)": 0.251441
    },
    {
      "epoch": 3.674097565525604,
      "grad_norm": 2.8709230422973633,
      "learning_rate": 1.8025006497382547e-06,
      "loss": 0.2913473129272461,
      "memory(GiB)": 72.72,
      "step": 39390,
      "train_speed(iter/s)": 0.251444
    },
    {
      "epoch": 3.6745639399309766,
      "grad_norm": 4.766124248504639,
      "learning_rate": 1.801315099257316e-06,
      "loss": 0.2617039680480957,
      "memory(GiB)": 72.72,
      "step": 39395,
      "train_speed(iter/s)": 0.251445
    },
    {
      "epoch": 3.6750303143363494,
      "grad_norm": 3.076443672180176,
      "learning_rate": 1.8001298531213929e-06,
      "loss": 0.2725051403045654,
      "memory(GiB)": 72.72,
      "step": 39400,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251448
    },
    {
      "epoch": 3.6754966887417218,
      "grad_norm": 3.2492499351501465,
      "learning_rate": 1.7989449114432555e-06,
      "loss": 0.28325462341308594,
      "memory(GiB)": 72.72,
      "step": 39405,
      "token_acc": 0.5423728813559322,
      "train_speed(iter/s)": 0.251448
    },
    {
      "epoch": 3.6759630631470945,
      "grad_norm": 3.6036248207092285,
      "learning_rate": 1.7977602743356487e-06,
      "loss": 0.28402395248413087,
      "memory(GiB)": 72.72,
      "step": 39410,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251449
    },
    {
      "epoch": 3.676429437552467,
      "grad_norm": 3.7438111305236816,
      "learning_rate": 1.796575941911285e-06,
      "loss": 0.3044910430908203,
      "memory(GiB)": 72.72,
      "step": 39415,
      "train_speed(iter/s)": 0.251449
    },
    {
      "epoch": 3.6768958119578397,
      "grad_norm": 2.624561071395874,
      "learning_rate": 1.795391914282854e-06,
      "loss": 0.2869987964630127,
      "memory(GiB)": 72.72,
      "step": 39420,
      "token_acc": 0.7058823529411765,
      "train_speed(iter/s)": 0.25145
    },
    {
      "epoch": 3.6773621863632124,
      "grad_norm": 1.9554193019866943,
      "learning_rate": 1.7942081915630106e-06,
      "loss": 0.26348540782928465,
      "memory(GiB)": 72.72,
      "step": 39425,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.677828560768585,
      "grad_norm": 4.009584903717041,
      "learning_rate": 1.7930247738643819e-06,
      "loss": 0.3065387725830078,
      "memory(GiB)": 72.72,
      "step": 39430,
      "token_acc": 0.6410256410256411,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.6782949351739576,
      "grad_norm": 2.4861507415771484,
      "learning_rate": 1.7918416612995665e-06,
      "loss": 0.2491706371307373,
      "memory(GiB)": 72.72,
      "step": 39435,
      "train_speed(iter/s)": 0.251451
    },
    {
      "epoch": 3.6787613095793303,
      "grad_norm": 3.597611665725708,
      "learning_rate": 1.7906588539811337e-06,
      "loss": 0.28464412689208984,
      "memory(GiB)": 72.72,
      "step": 39440,
      "token_acc": 0.6721311475409836,
      "train_speed(iter/s)": 0.25145
    },
    {
      "epoch": 3.6792276839847027,
      "grad_norm": 2.9996635913848877,
      "learning_rate": 1.7894763520216251e-06,
      "loss": 0.2806614637374878,
      "memory(GiB)": 72.72,
      "step": 39445,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.6796940583900755,
      "grad_norm": 5.073216915130615,
      "learning_rate": 1.7882941555335509e-06,
      "loss": 0.2883920669555664,
      "memory(GiB)": 72.72,
      "step": 39450,
      "token_acc": 0.8181818181818182,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.6801604327954482,
      "grad_norm": 2.3646459579467773,
      "learning_rate": 1.7871122646293938e-06,
      "loss": 0.2722638607025146,
      "memory(GiB)": 72.72,
      "step": 39455,
      "token_acc": 0.6415094339622641,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.680626807200821,
      "grad_norm": 2.744288682937622,
      "learning_rate": 1.7859306794216074e-06,
      "loss": 0.306766939163208,
      "memory(GiB)": 72.72,
      "step": 39460,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6810931816061934,
      "grad_norm": 3.89711594581604,
      "learning_rate": 1.7847494000226157e-06,
      "loss": 0.2828765869140625,
      "memory(GiB)": 72.72,
      "step": 39465,
      "token_acc": 0.7551020408163265,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 3.681559556011566,
      "grad_norm": 4.7370686531066895,
      "learning_rate": 1.7835684265448133e-06,
      "loss": 0.25238192081451416,
      "memory(GiB)": 72.72,
      "step": 39470,
      "token_acc": 0.971830985915493,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 3.6820259304169385,
      "grad_norm": 4.188823223114014,
      "learning_rate": 1.7823877591005672e-06,
      "loss": 0.29974386692047117,
      "memory(GiB)": 72.72,
      "step": 39475,
      "token_acc": 0.9833333333333333,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.6824923048223113,
      "grad_norm": 2.8984909057617188,
      "learning_rate": 1.7812073978022137e-06,
      "loss": 0.3193605899810791,
      "memory(GiB)": 72.72,
      "step": 39480,
      "token_acc": 0.6,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.682958679227684,
      "grad_norm": 2.850961685180664,
      "learning_rate": 1.7800273427620584e-06,
      "loss": 0.2841283559799194,
      "memory(GiB)": 72.72,
      "step": 39485,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.683425053633057,
      "grad_norm": 12.495994567871094,
      "learning_rate": 1.7788475940923845e-06,
      "loss": 0.284909987449646,
      "memory(GiB)": 72.72,
      "step": 39490,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.683891428038429,
      "grad_norm": 2.7295644283294678,
      "learning_rate": 1.77766815190544e-06,
      "loss": 0.2638314485549927,
      "memory(GiB)": 72.72,
      "step": 39495,
      "token_acc": 0.6410256410256411,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.684357802443802,
      "grad_norm": 2.613795518875122,
      "learning_rate": 1.7764890163134429e-06,
      "loss": 0.2935234308242798,
      "memory(GiB)": 72.72,
      "step": 39500,
      "token_acc": 0.6949152542372882,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.6848241768491743,
      "grad_norm": 2.8462913036346436,
      "learning_rate": 1.7753101874285855e-06,
      "loss": 0.30646543502807616,
      "memory(GiB)": 72.72,
      "step": 39505,
      "token_acc": 0.6595744680851063,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.685290551254547,
      "grad_norm": 2.6256513595581055,
      "learning_rate": 1.7741316653630297e-06,
      "loss": 0.26142492294311526,
      "memory(GiB)": 72.72,
      "step": 39510,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.68575692565992,
      "grad_norm": 2.548354148864746,
      "learning_rate": 1.772953450228907e-06,
      "loss": 0.2528191566467285,
      "memory(GiB)": 72.72,
      "step": 39515,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6862233000652926,
      "grad_norm": 2.4913458824157715,
      "learning_rate": 1.7717755421383238e-06,
      "loss": 0.2596879959106445,
      "memory(GiB)": 72.72,
      "step": 39520,
      "token_acc": 0.7796610169491526,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.686689674470665,
      "grad_norm": 3.105353832244873,
      "learning_rate": 1.770597941203353e-06,
      "loss": 0.2815152883529663,
      "memory(GiB)": 72.72,
      "step": 39525,
      "token_acc": 0.6964285714285714,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6871560488760378,
      "grad_norm": 3.1115903854370117,
      "learning_rate": 1.76942064753604e-06,
      "loss": 0.2766151189804077,
      "memory(GiB)": 72.72,
      "step": 39530,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.68762242328141,
      "grad_norm": 6.2682695388793945,
      "learning_rate": 1.7682436612484e-06,
      "loss": 0.26395132541656496,
      "memory(GiB)": 72.72,
      "step": 39535,
      "token_acc": 0.5806451612903226,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.688088797686783,
      "grad_norm": 2.4688987731933594,
      "learning_rate": 1.76706698245242e-06,
      "loss": 0.2708784580230713,
      "memory(GiB)": 72.72,
      "step": 39540,
      "token_acc": 0.8843537414965986,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.6885551720921557,
      "grad_norm": 2.58510160446167,
      "learning_rate": 1.7658906112600576e-06,
      "loss": 0.2633353710174561,
      "memory(GiB)": 72.72,
      "step": 39545,
      "token_acc": 0.9560439560439561,
      "train_speed(iter/s)": 0.25145
    },
    {
      "epoch": 3.6890215464975284,
      "grad_norm": 3.8214333057403564,
      "learning_rate": 1.7647145477832405e-06,
      "loss": 0.27627272605895997,
      "memory(GiB)": 72.72,
      "step": 39550,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.689487920902901,
      "grad_norm": 2.80442476272583,
      "learning_rate": 1.7635387921338677e-06,
      "loss": 0.2618389129638672,
      "memory(GiB)": 72.72,
      "step": 39555,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.6899542953082736,
      "grad_norm": 3.1835718154907227,
      "learning_rate": 1.7623633444238081e-06,
      "loss": 0.2747601747512817,
      "memory(GiB)": 72.72,
      "step": 39560,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.690420669713646,
      "grad_norm": 2.8780462741851807,
      "learning_rate": 1.761188204764903e-06,
      "loss": 0.32527110576629636,
      "memory(GiB)": 72.72,
      "step": 39565,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6908870441190187,
      "grad_norm": 3.9372470378875732,
      "learning_rate": 1.7600133732689628e-06,
      "loss": 0.3218828201293945,
      "memory(GiB)": 72.72,
      "step": 39570,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.6913534185243915,
      "grad_norm": 2.5814013481140137,
      "learning_rate": 1.7588388500477687e-06,
      "loss": 0.24055726528167726,
      "memory(GiB)": 72.72,
      "step": 39575,
      "token_acc": 1.0,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6918197929297643,
      "grad_norm": 3.9875900745391846,
      "learning_rate": 1.7576646352130737e-06,
      "loss": 0.2902451276779175,
      "memory(GiB)": 72.72,
      "step": 39580,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6922861673351366,
      "grad_norm": 2.5576653480529785,
      "learning_rate": 1.7564907288765991e-06,
      "loss": 0.27408196926116946,
      "memory(GiB)": 72.72,
      "step": 39585,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6927525417405094,
      "grad_norm": 2.3969199657440186,
      "learning_rate": 1.755317131150041e-06,
      "loss": 0.28536224365234375,
      "memory(GiB)": 72.72,
      "step": 39590,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6932189161458817,
      "grad_norm": 2.0611140727996826,
      "learning_rate": 1.754143842145064e-06,
      "loss": 0.2972327709197998,
      "memory(GiB)": 72.72,
      "step": 39595,
      "token_acc": 0.6851851851851852,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 3.6936852905512545,
      "grad_norm": 2.898242950439453,
      "learning_rate": 1.7529708619733e-06,
      "loss": 0.2813981533050537,
      "memory(GiB)": 72.72,
      "step": 39600,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.6941516649566273,
      "grad_norm": 2.570826768875122,
      "learning_rate": 1.7517981907463556e-06,
      "loss": 0.3069629192352295,
      "memory(GiB)": 72.72,
      "step": 39605,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.694618039362,
      "grad_norm": 2.4939043521881104,
      "learning_rate": 1.7506258285758065e-06,
      "loss": 0.2755460739135742,
      "memory(GiB)": 72.72,
      "step": 39610,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.6950844137673724,
      "grad_norm": 2.411936044692993,
      "learning_rate": 1.7494537755732006e-06,
      "loss": 0.269704794883728,
      "memory(GiB)": 72.72,
      "step": 39615,
      "train_speed(iter/s)": 0.251451
    },
    {
      "epoch": 3.695550788172745,
      "grad_norm": 2.924069881439209,
      "learning_rate": 1.7482820318500526e-06,
      "loss": 0.2741071701049805,
      "memory(GiB)": 72.72,
      "step": 39620,
      "token_acc": 0.6060606060606061,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.6960171625781175,
      "grad_norm": 2.716630458831787,
      "learning_rate": 1.7471105975178533e-06,
      "loss": 0.28996977806091306,
      "memory(GiB)": 72.72,
      "step": 39625,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.6964835369834903,
      "grad_norm": 2.2875514030456543,
      "learning_rate": 1.7459394726880602e-06,
      "loss": 0.26725029945373535,
      "memory(GiB)": 72.72,
      "step": 39630,
      "token_acc": 0.970873786407767,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.696949911388863,
      "grad_norm": 2.6877224445343018,
      "learning_rate": 1.7447686574721018e-06,
      "loss": 0.26735215187072753,
      "memory(GiB)": 72.72,
      "step": 39635,
      "token_acc": 0.58,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.697416285794236,
      "grad_norm": 3.867664337158203,
      "learning_rate": 1.7435981519813778e-06,
      "loss": 0.30476839542388917,
      "memory(GiB)": 72.72,
      "step": 39640,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.697882660199608,
      "grad_norm": 3.4154269695281982,
      "learning_rate": 1.7424279563272584e-06,
      "loss": 0.2889231204986572,
      "memory(GiB)": 72.72,
      "step": 39645,
      "token_acc": 0.5963302752293578,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.698349034604981,
      "grad_norm": 3.99261474609375,
      "learning_rate": 1.741258070621083e-06,
      "loss": 0.28453788757324217,
      "memory(GiB)": 72.72,
      "step": 39650,
      "token_acc": 0.972972972972973,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.6988154090103533,
      "grad_norm": 2.4036717414855957,
      "learning_rate": 1.7400884949741638e-06,
      "loss": 0.3241133689880371,
      "memory(GiB)": 72.72,
      "step": 39655,
      "token_acc": 0.5641025641025641,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.699281783415726,
      "grad_norm": 5.73895788192749,
      "learning_rate": 1.738919229497782e-06,
      "loss": 0.2646071434020996,
      "memory(GiB)": 72.72,
      "step": 39660,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.699748157821099,
      "grad_norm": 2.2818524837493896,
      "learning_rate": 1.7377502743031892e-06,
      "loss": 0.27134227752685547,
      "memory(GiB)": 72.72,
      "step": 39665,
      "train_speed(iter/s)": 0.25145
    },
    {
      "epoch": 3.7002145322264717,
      "grad_norm": 2.797093152999878,
      "learning_rate": 1.736581629501608e-06,
      "loss": 0.28072094917297363,
      "memory(GiB)": 72.72,
      "step": 39670,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.700680906631844,
      "grad_norm": 3.019587993621826,
      "learning_rate": 1.735413295204232e-06,
      "loss": 0.2917171478271484,
      "memory(GiB)": 72.72,
      "step": 39675,
      "token_acc": 0.6326530612244898,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.701147281037217,
      "grad_norm": 2.4237074851989746,
      "learning_rate": 1.734245271522224e-06,
      "loss": 0.2750868558883667,
      "memory(GiB)": 72.72,
      "step": 39680,
      "token_acc": 0.8110236220472441,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.701613655442589,
      "grad_norm": 3.1270978450775146,
      "learning_rate": 1.7330775585667164e-06,
      "loss": 0.3035660982131958,
      "memory(GiB)": 72.72,
      "step": 39685,
      "token_acc": 0.8288288288288288,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.702080029847962,
      "grad_norm": 4.104952812194824,
      "learning_rate": 1.7319101564488166e-06,
      "loss": 0.2840742588043213,
      "memory(GiB)": 72.72,
      "step": 39690,
      "train_speed(iter/s)": 0.251449
    },
    {
      "epoch": 3.7025464042533347,
      "grad_norm": 2.6590473651885986,
      "learning_rate": 1.7307430652795997e-06,
      "loss": 0.29942224025726316,
      "memory(GiB)": 72.72,
      "step": 39695,
      "token_acc": 0.6808510638297872,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 3.7030127786587075,
      "grad_norm": 2.8512613773345947,
      "learning_rate": 1.729576285170107e-06,
      "loss": 0.30567045211791993,
      "memory(GiB)": 72.72,
      "step": 39700,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 3.70347915306408,
      "grad_norm": 2.985555410385132,
      "learning_rate": 1.7284098162313561e-06,
      "loss": 0.3029171943664551,
      "memory(GiB)": 72.72,
      "step": 39705,
      "train_speed(iter/s)": 0.251448
    },
    {
      "epoch": 3.7039455274694526,
      "grad_norm": 2.7233328819274902,
      "learning_rate": 1.727243658574333e-06,
      "loss": 0.29843769073486326,
      "memory(GiB)": 72.72,
      "step": 39710,
      "token_acc": 0.7560975609756098,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 3.704411901874825,
      "grad_norm": 3.331852912902832,
      "learning_rate": 1.7260778123099936e-06,
      "loss": 0.2911835193634033,
      "memory(GiB)": 72.72,
      "step": 39715,
      "token_acc": 0.5094339622641509,
      "train_speed(iter/s)": 0.251449
    },
    {
      "epoch": 3.7048782762801977,
      "grad_norm": 2.685969591140747,
      "learning_rate": 1.7249122775492633e-06,
      "loss": 0.2719886779785156,
      "memory(GiB)": 72.72,
      "step": 39720,
      "token_acc": 0.6956521739130435,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 3.7053446506855705,
      "grad_norm": 3.0677270889282227,
      "learning_rate": 1.7237470544030421e-06,
      "loss": 0.2597250461578369,
      "memory(GiB)": 72.72,
      "step": 39725,
      "train_speed(iter/s)": 0.251445
    },
    {
      "epoch": 3.705811025090943,
      "grad_norm": 2.5586514472961426,
      "learning_rate": 1.722582142982196e-06,
      "loss": 0.29668264389038085,
      "memory(GiB)": 72.72,
      "step": 39730,
      "train_speed(iter/s)": 0.251445
    },
    {
      "epoch": 3.7062773994963156,
      "grad_norm": 3.072953462600708,
      "learning_rate": 1.7214175433975627e-06,
      "loss": 0.26423680782318115,
      "memory(GiB)": 72.72,
      "step": 39735,
      "token_acc": 0.8705035971223022,
      "train_speed(iter/s)": 0.251445
    },
    {
      "epoch": 3.7067437739016884,
      "grad_norm": 7.033896446228027,
      "learning_rate": 1.7202532557599506e-06,
      "loss": 0.29219970703125,
      "memory(GiB)": 72.72,
      "step": 39740,
      "train_speed(iter/s)": 0.251443
    },
    {
      "epoch": 3.7072101483070607,
      "grad_norm": 20.371889114379883,
      "learning_rate": 1.7190892801801373e-06,
      "loss": 0.2870445728302002,
      "memory(GiB)": 72.72,
      "step": 39745,
      "train_speed(iter/s)": 0.251442
    },
    {
      "epoch": 3.7076765227124335,
      "grad_norm": 2.5245864391326904,
      "learning_rate": 1.7179256167688735e-06,
      "loss": 0.29453840255737307,
      "memory(GiB)": 72.72,
      "step": 39750,
      "train_speed(iter/s)": 0.251442
    },
    {
      "epoch": 3.7081428971178063,
      "grad_norm": 4.316240310668945,
      "learning_rate": 1.716762265636873e-06,
      "loss": 0.28277020454406737,
      "memory(GiB)": 72.72,
      "step": 39755,
      "token_acc": 0.7681159420289855,
      "train_speed(iter/s)": 0.251445
    },
    {
      "epoch": 3.7086092715231787,
      "grad_norm": 2.960571765899658,
      "learning_rate": 1.7155992268948307e-06,
      "loss": 0.2965794563293457,
      "memory(GiB)": 72.72,
      "step": 39760,
      "token_acc": 0.515625,
      "train_speed(iter/s)": 0.251446
    },
    {
      "epoch": 3.7090756459285514,
      "grad_norm": 2.172703742980957,
      "learning_rate": 1.714436500653404e-06,
      "loss": 0.29457089900970457,
      "memory(GiB)": 72.72,
      "step": 39765,
      "token_acc": 0.5370370370370371,
      "train_speed(iter/s)": 0.251448
    },
    {
      "epoch": 3.709542020333924,
      "grad_norm": 2.46077036857605,
      "learning_rate": 1.7132740870232234e-06,
      "loss": 0.30959010124206543,
      "memory(GiB)": 72.72,
      "step": 39770,
      "token_acc": 0.4883720930232558,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 3.7100083947392966,
      "grad_norm": 4.756933689117432,
      "learning_rate": 1.7121119861148877e-06,
      "loss": 0.27257063388824465,
      "memory(GiB)": 72.72,
      "step": 39775,
      "train_speed(iter/s)": 0.251447
    },
    {
      "epoch": 3.7104747691446693,
      "grad_norm": 2.581101417541504,
      "learning_rate": 1.7109501980389682e-06,
      "loss": 0.2917336463928223,
      "memory(GiB)": 72.72,
      "step": 39780,
      "train_speed(iter/s)": 0.251449
    },
    {
      "epoch": 3.710941143550042,
      "grad_norm": 3.476064443588257,
      "learning_rate": 1.7097887229060052e-06,
      "loss": 0.26425349712371826,
      "memory(GiB)": 72.72,
      "step": 39785,
      "token_acc": 0.5238095238095238,
      "train_speed(iter/s)": 0.25145
    },
    {
      "epoch": 3.7114075179554145,
      "grad_norm": 3.8825206756591797,
      "learning_rate": 1.7086275608265073e-06,
      "loss": 0.304137659072876,
      "memory(GiB)": 72.72,
      "step": 39790,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.7118738923607872,
      "grad_norm": 2.1871042251586914,
      "learning_rate": 1.7074667119109617e-06,
      "loss": 0.2855236053466797,
      "memory(GiB)": 72.72,
      "step": 39795,
      "token_acc": 0.74,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.71234026676616,
      "grad_norm": 2.5102570056915283,
      "learning_rate": 1.7063061762698135e-06,
      "loss": 0.26683816909790037,
      "memory(GiB)": 72.72,
      "step": 39800,
      "token_acc": 0.9801980198019802,
      "train_speed(iter/s)": 0.251452
    },
    {
      "epoch": 3.7128066411715324,
      "grad_norm": 2.458853244781494,
      "learning_rate": 1.7051459540134863e-06,
      "loss": 0.2634695768356323,
      "memory(GiB)": 72.72,
      "step": 39805,
      "token_acc": 0.6886792452830188,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.713273015576905,
      "grad_norm": 2.723076820373535,
      "learning_rate": 1.7039860452523716e-06,
      "loss": 0.25752055644989014,
      "memory(GiB)": 72.72,
      "step": 39810,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 3.713739389982278,
      "grad_norm": 3.1070048809051514,
      "learning_rate": 1.7028264500968312e-06,
      "loss": 0.2909337043762207,
      "memory(GiB)": 72.72,
      "step": 39815,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.7142057643876503,
      "grad_norm": 2.3350844383239746,
      "learning_rate": 1.7016671686571951e-06,
      "loss": 0.27644691467285154,
      "memory(GiB)": 72.72,
      "step": 39820,
      "train_speed(iter/s)": 0.251454
    },
    {
      "epoch": 3.714672138793023,
      "grad_norm": 2.578861951828003,
      "learning_rate": 1.7005082010437684e-06,
      "loss": 0.29642348289489745,
      "memory(GiB)": 72.72,
      "step": 39825,
      "token_acc": 0.6363636363636364,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 3.715138513198396,
      "grad_norm": 4.448915004730225,
      "learning_rate": 1.6993495473668225e-06,
      "loss": 0.29679150581359864,
      "memory(GiB)": 72.72,
      "step": 39830,
      "token_acc": 0.8835616438356164,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 3.715604887603768,
      "grad_norm": 2.109865427017212,
      "learning_rate": 1.6981912077365992e-06,
      "loss": 0.27664861679077146,
      "memory(GiB)": 72.72,
      "step": 39835,
      "token_acc": 0.7254901960784313,
      "train_speed(iter/s)": 0.251457
    },
    {
      "epoch": 3.716071262009141,
      "grad_norm": 11.703951835632324,
      "learning_rate": 1.6970331822633107e-06,
      "loss": 0.27764525413513186,
      "memory(GiB)": 72.72,
      "step": 39840,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 3.7165376364145137,
      "grad_norm": 2.627842426300049,
      "learning_rate": 1.6958754710571402e-06,
      "loss": 0.2576929569244385,
      "memory(GiB)": 72.72,
      "step": 39845,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.717004010819886,
      "grad_norm": 3.6762747764587402,
      "learning_rate": 1.6947180742282415e-06,
      "loss": 0.2850974082946777,
      "memory(GiB)": 72.72,
      "step": 39850,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.717470385225259,
      "grad_norm": 2.8302760124206543,
      "learning_rate": 1.6935609918867323e-06,
      "loss": 0.24363763332366944,
      "memory(GiB)": 72.72,
      "step": 39855,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.717936759630631,
      "grad_norm": 2.530320167541504,
      "learning_rate": 1.6924042241427112e-06,
      "loss": 0.2900623559951782,
      "memory(GiB)": 72.72,
      "step": 39860,
      "token_acc": 0.5952380952380952,
      "train_speed(iter/s)": 0.251455
    },
    {
      "epoch": 3.718403134036004,
      "grad_norm": 2.789613723754883,
      "learning_rate": 1.6912477711062387e-06,
      "loss": 0.284552001953125,
      "memory(GiB)": 72.72,
      "step": 39865,
      "token_acc": 0.9555555555555556,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 3.7188695084413768,
      "grad_norm": 2.9014272689819336,
      "learning_rate": 1.690091632887348e-06,
      "loss": 0.3219283580780029,
      "memory(GiB)": 72.72,
      "step": 39870,
      "token_acc": 0.5,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 3.7193358828467495,
      "grad_norm": 2.770456552505493,
      "learning_rate": 1.6889358095960417e-06,
      "loss": 0.29862022399902344,
      "memory(GiB)": 72.72,
      "step": 39875,
      "token_acc": 0.654320987654321,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 3.719802257252122,
      "grad_norm": 2.945307731628418,
      "learning_rate": 1.6877803013422934e-06,
      "loss": 0.3135993957519531,
      "memory(GiB)": 72.72,
      "step": 39880,
      "token_acc": 0.5185185185185185,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 3.7202686316574947,
      "grad_norm": 2.771493673324585,
      "learning_rate": 1.686625108236045e-06,
      "loss": 0.26748578548431395,
      "memory(GiB)": 72.72,
      "step": 39885,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 3.720735006062867,
      "grad_norm": 3.825883388519287,
      "learning_rate": 1.6854702303872116e-06,
      "loss": 0.3184027671813965,
      "memory(GiB)": 72.72,
      "step": 39890,
      "token_acc": 0.5882352941176471,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 3.72120138046824,
      "grad_norm": 3.4687530994415283,
      "learning_rate": 1.6843156679056748e-06,
      "loss": 0.2646897315979004,
      "memory(GiB)": 72.72,
      "step": 39895,
      "token_acc": 0.6666666666666666,
      "train_speed(iter/s)": 0.251463
    },
    {
      "epoch": 3.7216677548736126,
      "grad_norm": 2.863490343093872,
      "learning_rate": 1.683161420901288e-06,
      "loss": 0.278426194190979,
      "memory(GiB)": 72.72,
      "step": 39900,
      "token_acc": 0.717391304347826,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 3.7221341292789853,
      "grad_norm": 2.2550981044769287,
      "learning_rate": 1.682007489483874e-06,
      "loss": 0.2754249334335327,
      "memory(GiB)": 72.72,
      "step": 39905,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 3.7226005036843577,
      "grad_norm": 9.13412094116211,
      "learning_rate": 1.6808538737632264e-06,
      "loss": 0.25949411392211913,
      "memory(GiB)": 72.72,
      "step": 39910,
      "token_acc": 0.7285714285714285,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 3.7230668780897305,
      "grad_norm": 3.1856329441070557,
      "learning_rate": 1.6797005738491074e-06,
      "loss": 0.2952519655227661,
      "memory(GiB)": 72.72,
      "step": 39915,
      "token_acc": 0.5192307692307693,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 3.723533252495103,
      "grad_norm": 2.888653039932251,
      "learning_rate": 1.6785475898512504e-06,
      "loss": 0.3031607151031494,
      "memory(GiB)": 72.72,
      "step": 39920,
      "token_acc": 0.74,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 3.7239996269004756,
      "grad_norm": 4.677375316619873,
      "learning_rate": 1.6773949218793567e-06,
      "loss": 0.29994959831237794,
      "memory(GiB)": 72.72,
      "step": 39925,
      "train_speed(iter/s)": 0.25146
    },
    {
      "epoch": 3.7244660013058484,
      "grad_norm": 4.27323055267334,
      "learning_rate": 1.6762425700431023e-06,
      "loss": 0.28826379776000977,
      "memory(GiB)": 72.72,
      "step": 39930,
      "token_acc": 0.6095238095238096,
      "train_speed(iter/s)": 0.251462
    },
    {
      "epoch": 3.724932375711221,
      "grad_norm": 3.012268304824829,
      "learning_rate": 1.6750905344521284e-06,
      "loss": 0.29861338138580323,
      "memory(GiB)": 72.72,
      "step": 39935,
      "train_speed(iter/s)": 0.251461
    },
    {
      "epoch": 3.7253987501165935,
      "grad_norm": 3.086352586746216,
      "learning_rate": 1.6739388152160475e-06,
      "loss": 0.28448939323425293,
      "memory(GiB)": 72.72,
      "step": 39940,
      "train_speed(iter/s)": 0.251458
    },
    {
      "epoch": 3.7258651245219663,
      "grad_norm": 2.8082754611968994,
      "learning_rate": 1.6727874124444422e-06,
      "loss": 0.26906189918518064,
      "memory(GiB)": 72.72,
      "step": 39945,
      "token_acc": 0.9396551724137931,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 3.7263314989273386,
      "grad_norm": 2.2895047664642334,
      "learning_rate": 1.6716363262468666e-06,
      "loss": 0.2768997669219971,
      "memory(GiB)": 72.72,
      "step": 39950,
      "train_speed(iter/s)": 0.251459
    },
    {
      "epoch": 3.7267978733327114,
      "grad_norm": 3.066324234008789,
      "learning_rate": 1.6704855567328377e-06,
      "loss": 0.3005053997039795,
      "memory(GiB)": 72.72,
      "step": 39955,
      "train_speed(iter/s)": 0.251457
    },
    {
      "epoch": 3.727264247738084,
      "grad_norm": 3.9658074378967285,
      "learning_rate": 1.6693351040118527e-06,
      "loss": 0.24718174934387208,
      "memory(GiB)": 72.72,
      "step": 39960,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 3.727730622143457,
      "grad_norm": 2.4352660179138184,
      "learning_rate": 1.6681849681933726e-06,
      "loss": 0.2707459211349487,
      "memory(GiB)": 72.72,
      "step": 39965,
      "token_acc": 0.6111111111111112,
      "train_speed(iter/s)": 0.251457
    },
    {
      "epoch": 3.7281969965488293,
      "grad_norm": 2.763672351837158,
      "learning_rate": 1.6670351493868287e-06,
      "loss": 0.27780675888061523,
      "memory(GiB)": 72.72,
      "step": 39970,
      "token_acc": 0.7697841726618705,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 3.728663370954202,
      "grad_norm": 2.8175361156463623,
      "learning_rate": 1.6658856477016227e-06,
      "loss": 0.25894525051116946,
      "memory(GiB)": 72.72,
      "step": 39975,
      "train_speed(iter/s)": 0.251458
    },
    {
      "epoch": 3.7291297453595744,
      "grad_norm": 2.0997962951660156,
      "learning_rate": 1.6647364632471269e-06,
      "loss": 0.25661048889160154,
      "memory(GiB)": 72.72,
      "step": 39980,
      "token_acc": 0.6923076923076923,
      "train_speed(iter/s)": 0.251457
    },
    {
      "epoch": 3.729596119764947,
      "grad_norm": 3.08597731590271,
      "learning_rate": 1.663587596132682e-06,
      "loss": 0.2957457065582275,
      "memory(GiB)": 72.72,
      "step": 39985,
      "token_acc": 0.5904761904761905,
      "train_speed(iter/s)": 0.251458
    },
    {
      "epoch": 3.73006249417032,
      "grad_norm": 9.40012264251709,
      "learning_rate": 1.6624390464675988e-06,
      "loss": 0.29990127086639407,
      "memory(GiB)": 72.72,
      "step": 39990,
      "token_acc": 0.6037735849056604,
      "train_speed(iter/s)": 0.251456
    },
    {
      "epoch": 3.7305288685756928,
      "grad_norm": 5.5979766845703125,
      "learning_rate": 1.661290814361159e-06,
      "loss": 0.30753862857818604,
      "memory(GiB)": 72.72,
      "step": 39995,
      "token_acc": 0.6896551724137931,
      "train_speed(iter/s)": 0.251453
    },
    {
      "epoch": 3.730995242981065,
      "grad_norm": 2.7716798782348633,
      "learning_rate": 1.6601428999226127e-06,
      "loss": 0.2926988124847412,
      "memory(GiB)": 72.72,
      "step": 40000,
      "train_speed(iter/s)": 0.251454
    }
  ],
  "logging_steps": 5,
  "max_steps": 53605,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.210784880489105e+20,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
